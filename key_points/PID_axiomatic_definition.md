# PID的公理化定义

香农信息论的数学工具本身存在局限性，它无法分离冗余与协同信息。

在标准信息论中，唯一一个能同时衡量三个变量交互关系的工具是**交互信息 (Interaction Information)**。它的定义是：

$$ I(X_1; X_2; Y) = I(X_1; X_2) - I(X_1; X_2 | Y) $$

这个公式衡量的是：知道 $Y$ 之后，$X_1$ 和 $X_2$ 之间的互信息减少了多少。

- 如果 $X_1$ 和 $X_2$ 共享的信息恰好是关于 $Y$ 的信息，那么一旦我们知道了 $Y$，$X_1$ 和 $X_2$ 之间的这种共享关系就“被解释了”，它们之间的互信息就会下降。

$ I(X_1; X_2; Y) $ 的输出可以是正数也可以是负数。它衡量的是一个净效应。

- **PID 理论想要的是**：像集合的交集和并集一样，每个信息成分（$R$, $S$, $U_1$, $U_2$）都必须是**非负的**。信息量要么存在（大于0），要么不存在（等于0）。

## PID 的解决方案：公理化定义

因为找不到一个构造性的公式，PID 的创始人 Williams 和 Beer 采取了一种完全不同的方法：**公理化定义**。

他们没有说“冗余 $R$ 等于某个公式”，而是说：“我们不知道 $R$ 的确切公式，但任何一个合理的‘冗余’度量都**必须满足**以下几个基本性质（公理）”：

- **对称性**: $R(X_1; X_2; Y)$ 应该和 $R(X_2; X_1; Y)$ 相等。
- **非负性**: $R$ 必须大于等于零。
- **单调性**: 如果你对一个输入 $X_1$ 进行了处理（比如增加了噪声）得到 $X_1'$，那么新的冗余信息不能超过原来的。$R(X_1; X_2; Y) ≥ R(X_1'; X_2; Y)$。

然后，整个领域的研究就变成了：**去寻找一个满足这些公理的数学函数 $R$**。至今，已经有多种不同的 $R$ 的定义被提出（如 $I_{min}$, $I_{red}$, $I_{BROJA}$ 等），但**学术界尚未就哪一个是最终的、唯一的正确答案达成共识**。
