[
  {
    "s2PaperId": "d170cb89c8ca9f56640a81a0bfb21d71eaf46757",
    "title": "Information dynamics and the emergence of high-order individuality in ecosystems",
    "abstract": "At what level does natural selection occur? When considering the reproductive dynamics of interacting and mutating agents, it has long been debated whether selection is better understood by focusing on the individual or if hierarchical selection emerges as a consequence of joint adaptation. Despite longstanding efforts in theoretical ecology, there is still no consensus on this fundamental issue, most likely due to the difficulty in obtaining adequate data spanning a sufficient number of generations and the lack of adequate tools to quantify the effect of hierarchical selection. Here, we capitalise on recent advances in information-theoretic data analysis to advance this state of affairs by investigating the emergence of high-order structures- such as groups of species- in the collective dynamics of the Tangled Nature model of evolutionary ecology. Our results show that evolutionary dynamics can lead to clusters of species that act as a self-perpetuating group that exhibits greater information-theoretic agency than a single species for a broad range of stable mutation rates. However, this higher-order organization breaks down for mutation rates close to the error threshold, where increased information processing is observed at the level of a single species. For mutation rates higher than the error threshold, no stable population of species are observed in time, and all individuality is lost in the ecosystem. Overall, our findings provide quantitative evidence supporting the emergence of higher-order structures in evolutionary ecology from relatively simple processes of adaptation and reproduction.",
    "year": 2025,
    "venue": "Communications Biology",
    "url": "https://www.semanticscholar.org/paper/d170cb89c8ca9f56640a81a0bfb21d71eaf46757",
    "doi": "10.1038/s42003-025-08619-2",
    "arxivId": "",
    "authors": "Hardik Rajpal, Clem von Stengel, P. Mediano, F. Rosas, Eduardo Viegas, P. Marquet, H. J. Jensen",
    "citationCount": 0
  },
  {
    "s2PaperId": "d4a491a6edb8f57c82f52840ce46cdf16cc75af0",
    "title": "Multivariate Partial Information Decomposition: Constructions, Inconsistencies, and Alternative Measures",
    "abstract": "While mutual information effectively quantifies dependence between two variables, it cannot capture complex, fine-grained interactions that emerge in multivariate systems.The Partial Information Decomposition (PID) framework was introduced to address this by decomposing the mutual information between a set of source variables and a target variable into fine-grained information atoms such as redundant, unique, and synergistic components. In this work, we review the axiomatic system and desired properties of the PID framework and make three main contributions. First, we resolve the two-source PID case by providing explicit closed-form formulas for all information atoms that satisfy the full set of axioms and desirable properties. Second, we prove that for three or more sources, PID suffers from fundamental inconsistencies: we present a three-variable counterexample where the sum of atoms exceeds the total information, and prove an impossibility theorem showing that no lattice-based decomposition can be consistent for all subsets when the number of sources exceeds three. Finally, we deviate from the PID lattice approach to avoid its inconsistencies, and present explicit measures of multivariate unique and synergistic information. Our proposed measures, which rely on new systems of random variables that eliminate higher-order dependencies, satisfy key axioms such as additivity and continuity, provide a robust theoretical explanation of high-order relations, and show strong numerical performance in comprehensive experiments on the Ising model. Our findings highlight the need for a new framework for studying multivariate information decomposition.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/d4a491a6edb8f57c82f52840ce46cdf16cc75af0",
    "doi": "",
    "arxivId": "2508.05530",
    "authors": "Aobo Lyu, Andrew Clark, Netanel Raviv",
    "citationCount": 0
  },
  {
    "s2PaperId": "02ab19e8a33317439a9caf1a1a6d987473206a4a",
    "title": "Cooperative effects in feature importance of individual patterns: application to air pollutants and Alzheimer disease",
    "abstract": "Leveraging recent advances in the analysis of synergy and redundancy in systems of random variables, an adaptive version of the widely used metric Leave One Covariate Out (LOCO) has been recently proposed to quantify cooperative effects in feature importance (Hi-Fi), a key technique in explainable artificial intelligence (XAI), so as to disentangle high-order effects involving a particular input feature in regression problems. Differently from standard feature importance tools, where a single score measures the relevance of each feature, each feature is here characterized by three scores, a two-body (unique) score and higher-order scores (redundant and synergistic). This paper presents a framework to assign those three scores (unique, redundant, and synergistic) to each individual pattern of the data set, while comparing it with the well-known measure of feature importance named {\\it Shapley effect}. To illustrate the potential of the proposed framework, we focus on a One-Health application: the relation between air pollutants and Alzheimer's disease mortality rate. Our main result is the synergistic association between features related to $O_3$ and $NO_2$ with mortality, especially in the provinces of Bergamo e Brescia; notably also the density of urban green areas displays synergistic influence with pollutants for the prediction of AD mortality. Our results place local Hi-Fi as a promising tool of wide applicability, which opens new perspectives for XAI as well as to analyze high-order relationships in complex systems.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/02ab19e8a33317439a9caf1a1a6d987473206a4a",
    "doi": "",
    "arxivId": "2508.00930",
    "authors": "M. Ontivero-Ortega, A. Fania, A. Lacalamita, R. Bellotti, A. Monaco, S. Stramaglia",
    "citationCount": 0
  },
  {
    "s2PaperId": "8c313ee74070639d395ce9f710a982f3da2b4c45",
    "title": "Extreme Solar Storm Reveals Causal Interactions in Space Weather",
    "abstract": "Solar storms perturb Earth's magnetosphere, triggering geomagnetic storms that threaten space-based systems and infrastructure. Despite advances in spaceborne and ground-based observations, the causal chain driving solar-magnetosphere-ionosphere dynamics remains elusive due to multiphysics coupling, nonlinearity, and cross-scale complexity. This study presents an information-theoretic framework to decipher interaction mechanisms in extreme solar geomagnetic storms across intensity levels within space weather causal chains, using 1980-2024 datasets. Unexpectedly, we uncover auroral spatial causality patterns associated with space weather threats in the Arctic during May 2024 extreme storms. By integrating causal consistency constraints into spatiotemporal modeling, SolarAurora outperforms existing frameworks, achieving superior accuracy in forecasting May/October 2024 events. These results advance understanding of space weather dynamics and establish a promising framework for scientific discovery and forecasting extreme space weather events.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/8c313ee74070639d395ce9f710a982f3da2b4c45",
    "doi": "",
    "arxivId": "2508.06507",
    "authors": "Xinan Dai, Haiyang Fu, Zichong Yan, Zitong Wang, Feng Xu, Chi Wang, Yuhong Liu, Ya-Qiu Jin",
    "citationCount": 0
  },
  {
    "s2PaperId": "82be6d57c9ed667d67dea22593b96ee219dc04b3",
    "title": "Cross Mutual Information",
    "abstract": "Mutual information (MI) is a useful information-theoretic measure to quantify the statistical dependence between two random variables: $X$ and $Y$. Often, we are interested in understanding how the dependence between $X$ and $Y$ in one set of samples compares to another. Although the dependence between $X$ and $Y$ in each set of samples can be measured separately using MI, these estimates cannot be compared directly if they are based on samples from a non-stationary distribution. Here, we propose an alternative measure for characterising how the dependence between $X$ and $Y$ as defined by one set of samples is expressed in another, \\textit{cross mutual information}. We present a comprehensive set of simulation studies sampling data with $X$-$Y$ dependencies to explore this measure. Finally, we discuss how this relates to measures of model fit in linear regression, and some future applications in neuroimaging data analysis.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/82be6d57c9ed667d67dea22593b96ee219dc04b3",
    "doi": "10.48550/arXiv.2507.15372",
    "arxivId": "2507.15372",
    "authors": "Chetan Gohil, Oliver M. Cliff, James M. Shine, Ben D. Fulcher, J. Lizier",
    "citationCount": 0
  },
  {
    "s2PaperId": "41a8ab764b21e902cf2191ed8fe52a5442dd97db",
    "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data",
    "abstract": "Firstly, assuming Gaussianity, equations for the following information theory measures are presented: total correlation/coherence (TC), dual total correlation/coherence (DTC), O-information, TSE complexity, and redundancy-synergy index (RSI). Since these measures are functions of the covariance matrix\"S\"and its inverse\"S^-1\", the associated Wishart and inverse-Wishart distributions are of note. DTC is shown to be the Kullback-Leibler (KL) divergence for the inverse-Wishart pair\"(S^-1)\"and its diagonal matrix\"D=diag(S^-1)\", shedding light on its interpretation as a measure of\"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where\"P\"is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2). The second aim of this paper introduces a generalization of all these measures for structured groups of variables. For instance, consider three or more groups, each consisting of three or more variables, with predominant redundancy within each group, but with synergistic interactions between groups. O-information will miss the between group synergy (since redundancy occurs more often in the system). In contrast, the structured O-information measure presented here will correctly report predominant synergy between groups. This is a relevant generalization towards structured multivariate information measures. A third aim is the presentation of a framework for quantifying the contribution of\"connections\"between variables, to the system's TC, DTC, O-information, and TSE complexity. A fourth aim is to present a generalization of the redundancy-synergy index for quantifying the contribution of a group of variables to the system's redundancy-synergy balance. Finally, it is shown that the expressions derived here directly apply to data from several other elliptical distributions. All program codes, data files, and executables are available (https://osf.io/jd37g/).",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/41a8ab764b21e902cf2191ed8fe52a5442dd97db",
    "doi": "10.48550/arXiv.2507.08773",
    "arxivId": "2507.08773",
    "authors": "R. Pascual-Marqui, K. Kochi, Toshihiko Kinoshita",
    "citationCount": 0
  },
  {
    "s2PaperId": "ef6f52687fae346ca914c5aa2ca222af82bec5a4",
    "title": "Influence and information in a collective of self-propelled particles",
    "abstract": "While information-theoretic quantities, such as transfer entropy, have been widely adopted to infer causal relationships in collective systems, a critical gap exists: the absence of quantitative evidence directly linking information-theoretic quantities to a physically defined influence. This letter addresses this gap by proposing a modified Vicsek model that enables the calculation of a physically interpretable influence grounded in the angular interactions between particles. Averaged pairwise influences can serve as new order parameters to indicate collective phase transitions. We reveal quantitative relations between information, represented by transfer entropy, and average influence in pairwise and collective interactions. We test three typical methods of partial information decomposition and find that the method based on intrinsic mutual information gives the most appropriate interpretation. Overall, this work provides a model system for quantitative studies of influence and information in complex systems.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/ef6f52687fae346ca914c5aa2ca222af82bec5a4",
    "doi": "",
    "arxivId": "2506.20888",
    "authors": "Jiahuan Pang, Wendong Wang",
    "citationCount": 0
  },
  {
    "s2PaperId": "cd34e5d26a4ea834076e62d41f66c927aca54a39",
    "title": "A scalable estimator of high-order information in complex dynamical systems",
    "abstract": "Our understanding of neural systems rests on our ability to characterise how they perform distributed computation and integrate information. Advances in information theory have introduced several quantities to describe complex information structures, where collective patterns of coordination emerge from high-order (i.e. beyond-pairwise) interdependencies. Unfortunately, the use of these approaches to study large neural systems is severely hindered by the poor scalability of existing techniques. Moreover, there are relatively few measures specifically designed for multivariate time series data. Here we introduce a novel measure of information about macroscopic structures, termed M-information, which quantifies the high-order integration of information in complex dynamical systems. We show that M-information can be calculated via a convex optimisation problem, and we derive a robust and efficient algorithm that scales gracefully with system size. Our analyses show that M-information is resilient to noise, indexes critical behaviour in artificial neuronal populations, and reflects task performance in real-world mouse brain activity data. Furthermore, M-information can be incorporated into existing information decomposition frameworks to reveal a comprehensive taxonomy of information dynamics. Taken together, these results help us unravel collective computation in complex neural systems.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/cd34e5d26a4ea834076e62d41f66c927aca54a39",
    "doi": "10.48550/arXiv.2506.18498",
    "arxivId": "2506.18498",
    "authors": "Alberto Liardi, George Blackburne, Hardik Rajpal, Fernando E. Rosas, P. Mediano",
    "citationCount": 0
  },
  {
    "s2PaperId": "e94a61762fb8c75483b180dbbed5ec114075be96",
    "title": "Benchmarking methods for mapping functional connectivity in the brain",
    "abstract": "The networked architecture of the brain promotes synchrony among neuronal populations. These communication patterns can be mapped using functional imaging, yielding functional connectivity (FC) networks. While most studies use Pearson’s correlations by default, numerous pairwise interaction statistics exist in the scientific literature. How does the organization of the FC matrix vary with the choice of pairwise statistic? Here we use a library of 239 pairwise statistics to benchmark canonical features of FC networks, including hub mapping, weight–distance trade-offs, structure–function coupling, correspondence with other neurophysiological networks, individual fingerprinting and brain–behavior prediction. We find substantial quantitative and qualitative variation across FC methods. Measures such as covariance, precision and distance display multiple desirable properties, including correspondence with structural connectivity and the capacity to differentiate individuals and predict individual differences in behavior. Our report highlights how FC mapping can be optimized by tailoring pairwise statistics to specific neurophysiological mechanisms and research questions.",
    "year": 2025,
    "venue": "Nature Methods",
    "url": "https://www.semanticscholar.org/paper/e94a61762fb8c75483b180dbbed5ec114075be96",
    "doi": "10.1038/s41592-025-02704-4",
    "arxivId": "",
    "authors": "Zhen-Qi Liu, Andrea I. Luppi, J. Hansen, Y. Tian, Andrew Zalesky, B. Yeo, Ben D. Fulcher, B. Mišić",
    "citationCount": 1
  },
  {
    "s2PaperId": "741c1a7acd147c90ab352b8f0eaa1f546b6657f1",
    "title": "MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping",
    "abstract": "Recent advances in multimodal foundation models have achieved state-of-the-art performance across a range of tasks. These breakthroughs are largely driven by new pre-training paradigms that leverage large-scale, unlabeled multimodal data, followed by instruction fine-tuning on curated labeled datasets and high-quality prompts. While there is growing interest in scaling instruction fine-tuning to ever-larger datasets in both quantity and scale, our findings reveal that simply increasing the number of instruction-tuning tasks does not consistently yield better performance. Instead, we observe that grouping tasks by the common interactions across modalities, such as discovering redundant shared information, prioritizing modality selection with unique information, or requiring synergistic fusion to discover new information from both modalities, encourages the models to learn transferrable skills within a group while suppressing interference from mismatched tasks. To this end, we introduce MINT, a simple yet surprisingly effective task-grouping strategy based on the type of multimodal interaction. We demonstrate that the proposed method greatly outperforms existing task grouping baselines for multimodal instruction tuning, striking an effective balance between generalization and specialization.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/741c1a7acd147c90ab352b8f0eaa1f546b6657f1",
    "doi": "10.48550/arXiv.2506.02308",
    "arxivId": "2506.02308",
    "authors": "Xiaojun Shan, Qi Cao, Xing Han, Haofei Yu, P. Liang",
    "citationCount": 0
  },
  {
    "s2PaperId": "78916a07189ba30ab87d92575a839e1b14093ec2",
    "title": "Dynamic Synergy Network Analysis Reveals Stage-Specific Regional Dysfunction in Alzheimer’s Disease",
    "abstract": "Background: Alzheimer’s disease (AD) is a prevalent neurodegenerative disorder characterized by progressive neurodegeneration and connectivity deterioration. While resting-state functional magnetic resonance imaging (fMRI) provides critical insights into brain network abnormalities, traditional mutual information-based methods exhibit inherent limitations in characterizing the dynamic synergistic mechanisms between cerebral regions. Method: This study pioneered the application of an Integrated Information Decomposition (ΦID) framework in AD brain network analysis, constructing single-sample network models based on ΦID-derived synergy metrics to systematically compare their differences with mutual information-based methods in pathological sensitivity, computational robustness, and network representation capability, while detecting brain regions with declining dynamic synergy during AD progression through intergroup t-tests. Result: The key finding are as follows: (1) synergy metrics exhibited lower intra-group coefficient of variation than mutual information metrics, indicating higher computational stability; (2) single-sample reconstruction significantly enhanced the statistical power in intergroup difference detection; (3) synergy metrics captured brain network features that are undetectable by traditional mutual information methods, with more pronounced differences between networks; (4) key node analysis demonstrated spatiotemporal degradation patterns progressing from initial dysfunction in orbitofrontal–striatal–temporoparietal pathways accompanied by multi-regional impairments during prodromal stages, through moderate-phase decline located in the right middle frontal and postcentral gyri, to advanced-stage degeneration of the right supramarginal gyrus and left inferior parietal lobule. ΦID-driven dynamic synergy network analysis provides novel information integration theory-based biomarkers for AD progression diagnosis and potentially lays the foundation for pathological understanding and subsequent targeted therapy development.",
    "year": 2025,
    "venue": "Brain Science",
    "url": "https://www.semanticscholar.org/paper/78916a07189ba30ab87d92575a839e1b14093ec2",
    "doi": "10.3390/brainsci15060636",
    "arxivId": "",
    "authors": "Xiaoyan Zhang, Chao Han, Jingbo Xia, Lingli Deng, Jiyang Dong",
    "citationCount": 0
  },
  {
    "s2PaperId": "42676975207e15df02ab2136d6cac29514fcd22d",
    "title": "Synergistic motifs in linear Gaussian systems",
    "abstract": "Higher-order interdependencies are central features of complex systems, yet a mechanistic explanation for their emergence remains elusive. For linear Gaussian systems of arbitrary dimension, we derive an expression for synergy-dominance in terms of signed network motifs in the system's correlation matrix. We prove that antibalanced correlational structures ensure synergy-dominance and further show that antibalanced triads in the dyadic interaction matrix of Ornstein-Uhlenbeck processes are necessary for synergy-dominance. Our results demonstrate that pairwise interactions alone can give rise to synergistic information in the absence of explicit higher-order mechanisms, and highlight structural balance theory as an instrumental conceptual framework to study higher-order interdependencies.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/42676975207e15df02ab2136d6cac29514fcd22d",
    "doi": "",
    "arxivId": "2505.24686",
    "authors": "Enrico Caprioglio, Luc Berthouze",
    "citationCount": 0
  },
  {
    "s2PaperId": "76dabf5b2e9a64082ac5f728e4986f1776e9688f",
    "title": "Localizing synergies of hidden factors across complex systems: resting brain networks and HeLa gene expression profile as case studies",
    "abstract": "Factor analysis is a well-known statistical method to describe the variability of observed variables in terms of a smaller number of unobserved latent variables called factors. Even though latent factors are conceptually independent of each other, their influence on the observed variables is often joint and synergistic. We propose to quantify the synergy of the joint influence of factors on the observed variables using the O-information, a recently introduced metrics to assess high order dependencies in complex systems, in a new framework where latent factors and observed variables are jointly analyzed in terms of their joint informational character. Two case studies are reported: analyzing resting fMRI data, we find that DMN and FP networks show the highest synergy, consistently with their crucial role in higher cognitive functions; concerning HeLa cells, we find that the most synergistic gene is STK-12 (AURKB), suggesting that this gene is involved in controlling the HeLa cell cycle. We believe that this approach, representing a bridge between factor analysis and the field of high-order interactions, will find wide application across several domains.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/76dabf5b2e9a64082ac5f728e4986f1776e9688f",
    "doi": "",
    "arxivId": "2506.09053",
    "authors": "M. Ontivero-Ortega, G. Mijatović, Luca Faes, D. Marinazzo, S. Stramaglia",
    "citationCount": 0
  },
  {
    "s2PaperId": "2a5f8d6d47e5dfe4c73b5178a22b037a9c9cb497",
    "title": "Memory-Driven Dynamics: A Fractional Fisher Information Approach to Economic Interdependencies",
    "abstract": "This study introduces a novel approach for analyzing the dynamic interplay among key economic indicators by employing a Caputo Fractional Fisher Information framework combined with partial information decomposition. By integrating fractional derivatives into traditional Fisher Information metrics, our methodology captures long-range memory effects that govern the evolution of monetary policy, credit risk, market volatility, and inflation, represented by INTEREST, CDS, VIX, CPI, and PPI, respectively. We perform a comprehensive comparative analysis using rolling-window estimates to generate Caputo Fractional Fisher Information values at different fractional orders alongside the memoryless Ordinary Fisher Information. Subsequent correlation, cross-correlation, and transfer entropy analyses reveal how historical dependencies influence both unique and synergistic information flows between indices. Notably, our partial information decomposition results demonstrate that deep historical interactions significantly amplify the informational contribution of each indicator, particularly under long-memory conditions, while the Ordinary Fisher Information framework tends to underestimate these synergistic effects. The findings underscore the importance of incorporating memory effects into information-theoretic models to better understand the intricate, time-dependent relationships among financial indicators, with significant implications for forecasting and policy analysis.",
    "year": 2025,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2a5f8d6d47e5dfe4c73b5178a22b037a9c9cb497",
    "doi": "10.3390/e27060560",
    "arxivId": "",
    "authors": "L. Batrancea, Ömer Akgüller, M. A. Balcı, Dilara Altan Koç, L. Găban",
    "citationCount": 0
  },
  {
    "s2PaperId": "7fa5c398a739ddfb30d306f6ee47aae93eed88aa",
    "title": "I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts",
    "abstract": "Modality fusion is a cornerstone of multimodal learning, enabling information integration from diverse data sources. However, vanilla fusion methods are limited by (1) inability to account for heterogeneous interactions between modalities and (2) lack of interpretability in uncovering the multimodal interactions inherent in the data. To this end, we propose I2MoE (Interpretable Multimodal Interaction-aware Mixture of Experts), an end-to-end MoE framework designed to enhance modality fusion by explicitly modeling diverse multimodal interactions, as well as providing interpretation on a local and global level. First, I2MoE utilizes different interaction experts with weakly supervised interaction losses to learn multimodal interactions in a data-driven way. Second, I2MoE deploys a reweighting model that assigns importance scores for the output of each interaction expert, which offers sample-level and dataset-level interpretation. Extensive evaluation of medical and general multimodal datasets shows that I2MoE is flexible enough to be combined with different fusion techniques, consistently improves task performance, and provides interpretation across various real-world scenarios. Code is available at https://github.com/Raina-Xin/I2MoE.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/7fa5c398a739ddfb30d306f6ee47aae93eed88aa",
    "doi": "10.48550/arXiv.2505.19190",
    "arxivId": "2505.19190",
    "authors": "Jiayi Xin, Sukwon Yun, Jie Peng, Inyoung Choi, Jenna l. Ballard, Tianlong Chen, Qi Long",
    "citationCount": 1
  },
  {
    "s2PaperId": "dcf3b8892f59a0a35558e1db4e7f5bc8151d9b4e",
    "title": "Decomposing Predictive Information in Social Dynamics",
    "abstract": "",
    "year": 2025,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/dcf3b8892f59a0a35558e1db4e7f5bc8151d9b4e",
    "doi": "10.1101/2025.05.16.654393",
    "arxivId": "",
    "authors": "Akira Kawano, Liam O’Shaughnessy, Radmila Neiman, Kosmas Deligkaris, Luis Carretero Rodriguez, I. Masai, Greg J. Stephens",
    "citationCount": 0
  },
  {
    "s2PaperId": "fed8859855ed4ba1d06ac79dfb897fb3697ff254",
    "title": "ICYM2I: The illusion of multimodal informativeness under missingness",
    "abstract": "Multimodal learning is of continued interest in artificial intelligence-based applications, motivated by the potential information gain from combining different types of data. However, modalities collected and curated during development may differ from the modalities available at deployment due to multiple factors including cost, hardware failure, or -- as we argue in this work -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation of the information gain associated with including an additional modality without accounting for missingness may result in improper estimates of that modality's value in downstream tasks. Our work formalizes the problem of missingness in multimodal learning and demonstrates the biases resulting from ignoring this process. To address this issue, we introduce ICYM2I (In Case You Multimodal Missed It), a framework for the evaluation of predictive performance and information gain under missingness through inverse probability weighting-based correction. We demonstrate the importance of the proposed adjustment to estimate information gain under missingness on synthetic, semi-synthetic, and real-world medical datasets.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/fed8859855ed4ba1d06ac79dfb897fb3697ff254",
    "doi": "10.48550/arXiv.2505.16953",
    "arxivId": "2505.16953",
    "authors": "Young Sang Choi, Vincent Jeanselme, Pierre Elias, Shalmali Joshi",
    "citationCount": 0
  },
  {
    "s2PaperId": "7fd01dff9c6a89d6deca364b75ae2917b6fcdffa",
    "title": "MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory",
    "abstract": "This paper introduces MutualNeRF, a framework enhancing Neural Radiance Field (NeRF) performance under limited samples using Mutual Information Theory. While NeRF excels in 3D scene synthesis, challenges arise with limited data and existing methods that aim to introduce prior knowledge lack theoretical support in a unified framework. We introduce a simple but theoretically robust concept, Mutual Information, as a metric to uniformly measure the correlation between images, considering both macro (semantic) and micro (pixel) levels. For sparse view sampling, we strategically select additional viewpoints containing more non-overlapping scene information by minimizing mutual information without knowing ground truth images beforehand. Our framework employs a greedy algorithm, offering a near-optimal solution. For few-shot view synthesis, we maximize the mutual information between inferred images and ground truth, expecting inferred images to gain more relevant information from known images. This is achieved by incorporating efficient, plug-and-play regularization terms. Experiments under limited samples show consistent improvement over state-of-the-art baselines in different settings, affirming the efficacy of our framework.",
    "year": 2025,
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/7fd01dff9c6a89d6deca364b75ae2917b6fcdffa",
    "doi": "10.48550/arXiv.2505.11386",
    "arxivId": "2505.11386",
    "authors": "Zifan Wang, Jingwei Li, Yitang Li, Yunze Liu",
    "citationCount": 0
  },
  {
    "s2PaperId": "88efb031431c6f70fb6c11c01735d1fad412676c",
    "title": "Exploration of synergistic and redundant information sharing from hydrometeorological variables to net ecosystem exchange",
    "abstract": "Terrestrial ecosystems play a vital role in mitigating climate change by absorbing a substantial fraction of anthropogenic CO2 emissions, with net ecosystem exchange (NEE) serving as a critical metric of land-atmosphere carbon flux. While individual climate variables like temperature, precipitation, and radiation are well-studied drivers of NEE, their interactions in multivariate contexts remain poorly understood. This study leverages the O-Information framework to disentangle the synergistic and redundant contributions of temperature, precipitation, vapour pressure deficit (VPD), terrestrial water storage, and photosynthetically active radiation (PAR) to NEE variability. Analysing global and regional dynamics, we reveal the nature of multivariate interactions governing NEE. Globally, pairs like VPD-PAR consistently exhibit synergy, underscoring their complementary roles in driving carbon exchange, while T-VPD and T-terrestrial water storage interactions are predominantly redundant. Regional analyses highlight distinct patterns of information sharing: temperate forests and semiarid regions are synergy-dominated, whereas tropical ecosystems and Arctic regions exhibit unique spatial variability in synergy and redundancy. These findings advance our understanding of how complex climate-ecosystem interactions shape carbon fluxes and offer insights for improving predictive models of NEE under changing climatic conditions.",
    "year": 2025,
    "venue": "Environmental Research Letters",
    "url": "https://www.semanticscholar.org/paper/88efb031431c6f70fb6c11c01735d1fad412676c",
    "doi": "10.1088/1748-9326/add8a7",
    "arxivId": "",
    "authors": "Elizabeth Eldhose, Subimal Ghosh",
    "citationCount": 0
  },
  {
    "s2PaperId": "dfba9a75e03d176dcc5d3d7dd958f15e09b18837",
    "title": "Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era",
    "abstract": "Complexity science offers a wide range of measures for quantifying unpredictability, structure, and information. Yet, a systematic conceptual organization of these measures is still missing. We present a unified framework that locates statistical, algorithmic, and dynamical measures along three axes (regularity, randomness, and complexity) and situates them in a common conceptual space. We map statistical, algorithmic, and dynamical measures into this conceptual space, discussing their computational accessibility and approximability. This taxonomy reveals the deep challenges posed by uncomputability and highlights the emergence of modern data-driven methods (including autoencoders, latent dynamical models, symbolic regression, and physics-informed neural networks) as pragmatic approximations to classical complexity ideals. Latent spaces emerge as operational arenas where regularity extraction, noise management, and structured compression converge, bridging theoretical foundations with practical modeling in high-dimensional systems. We close by outlining implications for physics-informed AI and AI-guided discovery in complex physical systems, arguing that classical questions of complexity remain central to next-generation scientific modeling.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/dfba9a75e03d176dcc5d3d7dd958f15e09b18837",
    "doi": "10.48550/arXiv.2505.07222",
    "arxivId": "2505.07222",
    "authors": "Nima Dehghani",
    "citationCount": 0
  },
  {
    "s2PaperId": "ce8886f6165850f3d8e0539bfdcce59afabee3ab",
    "title": "Parameter-Efficient Transformer Embeddings",
    "abstract": "Embedding layers in transformer-based NLP models typically account for the largest share of model parameters, scaling with vocabulary size but not yielding performance gains proportional to scale. We propose an alternative approach in which token embedding vectors are first generated deterministically, directly from the token IDs using a Fourier expansion of their normalized values, followed by a lightweight multilayer perceptron (MLP) that captures higher-order interactions. We train standard transformers and our architecture on natural language inference tasks (SNLI and MNLI), and evaluate zero-shot performance on sentence textual similarity (STS-B). Our results demonstrate that the proposed method achieves competitive performance using significantly fewer parameters, trains faster, and operates effectively without the need for dropout. This proof-of-concept study highlights the potential for scalable, memory-efficient language models and motivates further large-scale experimentation based on our findings.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/ce8886f6165850f3d8e0539bfdcce59afabee3ab",
    "doi": "10.48550/arXiv.2505.02266",
    "arxivId": "2505.02266",
    "authors": "Henry Ndubuaku, M. Talhi",
    "citationCount": 0
  },
  {
    "s2PaperId": "07310c5e7086961654a5a89d964c7631231da01b",
    "title": "Uncovering complementary information sharing in spider monkey collective foraging using higher-order spatial networks",
    "abstract": "Collectives are often able to process information in a distributed fashion, surpassing each individual member's processing capacity. In fission-fusion dynamics, where group members come together and split from others often, sharing complementary information about uniquely known foraging areas could allow a group to track a heterogenous foraging environment better than any group member on its own. We analyse the partial overlaps between individual core ranges, which we assume represent the knowledge of an individual during a given season. We identify sets of individuals whose overlap shows a balance between redundantly and uniquely known portions and we use simplicial complexes to represent these higher-order interactions. The structure of the simplicial complexes shows holes in various dimensions, revealing complementarity in the foraging information that is being shared. We propose that the complex spatial networks arising from fission-fusion dynamics allow for adaptive, collective processing of foraging information in dynamic environments.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/07310c5e7086961654a5a89d964c7631231da01b",
    "doi": "10.48550/arXiv.2505.01167",
    "arxivId": "2505.01167",
    "authors": "G. Ramos-Fernández, Ross S. Walker, M. Silk, Denis Boyer, Sandra E. Smith Aguilar",
    "citationCount": 0
  },
  {
    "s2PaperId": "4334ca7a2aab75bdf008ae60416f93b19bfd20e8",
    "title": "Perturbational fitness analysis of CRISPR screens uncovers information-theoretic relation between gene function and selection",
    "abstract": "Despite major advances in genetic screening technology, a formal approach for quantifying gene function remains underdeveloped, thereby limiting the utility of these techniques in deciphering the complex behavior of human cells. In this study, we leverage information theory with a perturbational analysis of replicator dynamics to characterize functional drivers of selection in pooled CRISPR screens. Our approach challenges established methods for CRISPR screen analysis, while offering additional insight into selection dynamics through the Kullback-Leibler divergence (DKL) and cumulants of the fitness distribution. By modeling fluctuations in gene-fitness effects as a linear response to environmental perturbations, we derive a geometric measure for genomic information content based on a second-order approximation of the DKL. Our analysis reveals that functional information—encoded (or shared) between genes—can be quantified by analyzing the directions corresponding to maximal conditional selection within the space of decomposed gene-environment interactions. This geometric representation offers several advantages for the functional analysis of the human genome and its network architecture. Moreover, by constraining the space to cell-type-specific fluctuations, we uncover developmental and tissue-specific functional signatures. These findings represent significant progress in the dynamic analysis of gene function and in the functional wiring of the human genome.",
    "year": 2025,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/4334ca7a2aab75bdf008ae60416f93b19bfd20e8",
    "doi": "10.1101/2025.04.29.651199",
    "arxivId": "",
    "authors": "A.N. Andersen, N. Chica, L. Piechaczyk, S. Nakken, M. Zucknick, J. Enserink",
    "citationCount": 0
  },
  {
    "s2PaperId": "369d8de023055eaf0def31bb8545c868e5d27c2d",
    "title": "Genomic-Thermodynamic Phase Synchronization: Maxwell’s Demon-like Regulation of Cell Fate Transition",
    "abstract": "Dynamic criticality - the balance between order and chaos - is fundamental to genome regulation and cellular transitions. In this study, we investigate the distinct behaviors of gene expression dynamics in MCF-7 breast cancer cells under two stimuli: Heregulin (HRG), which promotes cell-fate transitions, and Epidermal Growth Factor (EGF), which binds to the same receptor but fails to induce cell-fate changes. We model the system as an open, non-equilibrium thermodynamic system and introduce a convergence-based framework for robust estimation of information-thermodynamic metrics. Our analysis reveals that the Shannon entropy of the critical point (CP) dynamically synchronizes with the entropy of the rest of the whole expression system (WES), reflecting coordinated transitions between ordered and disordered phases. This phase synchronization is driven by net mutual information scaling with CP entropy dynamics, demonstrating how the CP governs genome-wide coherence. Furthermore, higher-order mutual information emerges as a defining feature of the nonlinear gene expression network, capturing collective effects beyond simple pairwise interactions. By achieving thermodynamic phase synchronization, the CP orchestrates the entire expression system. Under HRG stimulation, the CP becomes active, functioning as a Maxwell’s demon with dynamic, rewritable chromatin memory to guide a critical transition in cell fate. In contrast, under EGF stimulation, the CP remains passive during non-critical expression dynamics. These findings establish a biophysical framework for cell-fate determination, paving the way for innovative approaches in cancer research and stem cell therapy.",
    "year": 2025,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/369d8de023055eaf0def31bb8545c868e5d27c2d",
    "doi": "10.3390/ijms26104911",
    "arxivId": "",
    "authors": "Masa Tsuchiya, Kenichi Yoshikawa, Alessandro Giuliani",
    "citationCount": 0
  },
  {
    "s2PaperId": "0d5974c28fce82b12d4e91bf8cd0525ee6268562",
    "title": "Biting Off More Than You Can Detect: Retrieval-Augmented Multimodal Experts for Short Video Hate Detection",
    "abstract": "Short Video Hate Detection (SVHD) is increasingly vital as hateful content - such as racial and gender-based discrimination - spreads rapidly across platforms like TikTok, YouTube Shorts, and Instagram Reels. Existing approaches face significant challenges: hate expressions continuously evolve, hateful signals are dispersed across multiple modalities (audio, text, and vision), and the contribution of each modality varies across different hate content. To address these issues, we introduce MoRE(Mixture of Retrieval-augmented multimodal Experts), a novel framework designed to enhance SVHD. MoRE employs specialized multimodal experts for each modality, leveraging their unique strengths to identify hateful content effectively. To ensure model's adaptability to rapidly evolving hate content, MoRE leverages contextual knowledge extracted from relevant instances retrieved by a powerful joint multimodal video retriever for each target short video. Moreover, a dynamic sample-sensitive integration network adaptively adjusts the importance of each modality on a per-sample basis, optimizing the detection process by prioritizing the most informative modalities for each instance. Our MoRE adopts an end-to-end training strategy that jointly optimizes both expert networks and the overall framework, resulting in nearly a twofold improvement in training efficiency, which in turn enhances its applicability to real-world scenarios. Extensive experiments on three benchmarks demonstrate that MoRE surpasses state-of-the-art baselines, achieving an average improvement of 6.91% in macro-F1 score across all datasets.",
    "year": 2025,
    "venue": "The Web Conference",
    "url": "https://www.semanticscholar.org/paper/0d5974c28fce82b12d4e91bf8cd0525ee6268562",
    "doi": "10.1145/3696410.3714560",
    "arxivId": "",
    "authors": "Jian Lang, Rongpei Hong, Jin Xu, Yili Li, Xovee Xu, Fan Zhou",
    "citationCount": 2
  },
  {
    "s2PaperId": "e8154ba3d354d8b16f27692c6deade8628926308",
    "title": "Control of two-pathway signal integration in a model neocortical pyramidal cell",
    "abstract": "",
    "year": 2025,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/e8154ba3d354d8b16f27692c6deade8628926308",
    "doi": "10.1101/2025.04.21.649759",
    "arxivId": "",
    "authors": "Bruce P. Graham, Jim Kay, William A. Phillips",
    "citationCount": 0
  },
  {
    "s2PaperId": "0593bd003187e6cc9fcc8302beecbcbb0059f51c",
    "title": "Nonequilibrium physics of brain dynamics",
    "abstract": "Information processing in the brain is coordinated by the dynamic activity of neurons and neural populations at a range of spatiotemporal scales. These dynamics, captured in the form of electrophysiological recordings and neuroimaging, show evidence of time-irreversibility and broken detailed balance suggesting that the brain operates in a nonequilibrium stationary state. Furthermore, the level of nonequilibrium, measured by entropy production or irreversibility appears to be a crucial signature of cognitive complexity and consciousness. The subsequent study of neural dynamics from the perspective of nonequilibrium statistical physics is an emergent field that challenges the assumptions of symmetry and maximum-entropy that are common in traditional models. In this review, we discuss the plethora of exciting results emerging at the interface of nonequilibrium dynamics and neuroscience. We begin with an introduction to the mathematical paradigms necessary to understand nonequilibrium dynamics in both continuous and discrete state-spaces. Next, we review both model-free and model-based approaches to analysing nonequilibrium dynamics in both continuous-state recordings and neural spike-trains, as well as the results of such analyses. We briefly consider the topic of nonequilibrium computation in neural systems, before concluding with a discussion and outlook on the field.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/0593bd003187e6cc9fcc8302beecbcbb0059f51c",
    "doi": "",
    "arxivId": "2504.12188",
    "authors": "Ramón Nartallo-Kaluarachchi, Morten L. Kringelbach, G. Deco, R. Lambiotte, Alain Goriely",
    "citationCount": 3
  },
  {
    "s2PaperId": "505d987ef7921ac25c131ad6009324a0ba9caf15",
    "title": "The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems",
    "abstract": "The study of irreducible higher-order interactions has become a core topic of study in complex systems. Two of the most well-developed frameworks, topological data analysis and multivariate information theory, aim to provide formal tools for identifying higher-order interactions in empirical data. Despite similar aims, however, these two approaches are built on markedly different mathematical foundations and have been developed largely in parallel. In this study, we present a head-to-head comparison of topological data analysis and information-theoretic approaches to describing higher-order interactions in multivariate data; with the aim of assessing the similarities and differences between how the frameworks define ``higher-order structures.\"We begin with toy examples with known topologies, before turning to naturalistic data: fMRI signals collected from the human brain. We find that intrinsic, higher-order synergistic information is associated with three-dimensional cavities in a point cloud: shapes such as spheres are synergy-dominated. In fMRI data, we find strong correlations between synergistic information and both the number and size of three-dimensional cavities. Furthermore, we find that dimensionality reduction techniques such as PCA preferentially represent higher-order redundancies, and largely fail to preserve both higher-order information and topological structure, suggesting that common manifold-based approaches to studying high-dimensional data are systematically failing to identify important features of the data. These results point towards the possibility of developing a rich theory of higher-order interactions that spans topological and information-theoretic approaches while simultaneously highlighting the profound limitations of more conventional methods.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/505d987ef7921ac25c131ad6009324a0ba9caf15",
    "doi": "10.48550/arXiv.2504.10140",
    "arxivId": "2504.10140",
    "authors": "Thomas F. Varley, P. Mediano, Alice Patania, Joshua Bongard",
    "citationCount": 3
  },
  {
    "s2PaperId": "250d1f795ab50bbfb221aba2cf2e0aeb2a561c88",
    "title": "A Hierarchical Decomposition of Kullback-Leibler Divergence: Disentangling Marginal Mismatches from Statistical Dependencies",
    "abstract": "The Kullback-Leibler (KL) divergence is a foundational measure for comparing probability distributions. Yet in multivariate settings, its single value often obscures the underlying reasons for divergence, conflating mismatches in individual variable distributions (marginals) with effects arising from statistical dependencies. We derive an algebraically exact, additive, and hierarchical decomposition of the KL divergence between a joint distribution P(X1,...,Xn) and a standard product reference distribution Q(X1,...,Xn) = product_i q(Xi), where variables are assumed independent and identically distributed according to a common reference q. The total divergence precisely splits into two primary components: (1) the summed divergence of each marginal distribution Pi(Xi) from the common reference q(Xi), quantifying marginal deviations; and (2) the total correlation (or multi-information), capturing the total statistical dependency among variables. Leveraging Mobius inversion on the subset lattice, we further decompose this total correlation term into a hierarchy of signed contributions from distinct pairwise, triplet, and higher-order statistical interactions, expressed using standard Shannon information quantities. This decomposition provides an algebraically complete and interpretable breakdown of KL divergence using established information measures, requiring no approximations or model assumptions. Numerical validation using hypergeometric sampling confirms the decomposition's exactness to machine precision across diverse system configurations.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/250d1f795ab50bbfb221aba2cf2e0aeb2a561c88",
    "doi": "10.48550/arXiv.2504.09029",
    "arxivId": "2504.09029",
    "authors": "William Cook",
    "citationCount": 0
  },
  {
    "s2PaperId": "a7bec80af2f9f2e5f67c334e1ad8d0132cd5536a",
    "title": "COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation",
    "abstract": "Recent works in multimodal recommendations, which leverage diverse modal information to address data sparsity and enhance recommendation accuracy, have garnered considerable interest. Two key processes in multimodal recommendations are modality fusion and representation learning. Previous approaches in modality fusion often employ simplistic attentive or pre-defined strategies at early or late stages, failing to effectively handle irrelevant information among modalities. In representation learning, prior research has constructed heterogeneous and homogeneous graph structures encapsulating user-item, user-user, and item-item relationships to better capture user interests and item profiles. Modality fusion and representation learning were considered as two independent processes in previous work. In this paper, we reveal that these two processes are complementary and can support each other. Specifically, powerful representation learning enhances modality fusion, while effective fusion improves representation quality. Stemming from these two processes, we introduce a COmposite grapH convolutional nEtwork with dual-stage fuSION for the multimodal recommendation, named COHESION. Specifically, it introduces a dual-stage fusion strategy to reduce the impact of irrelevant information, refining all modalities using ID embedding in the early stage and fusing their representations at the late stage. It also proposes a composite graph convolutional network that utilizes user-item, user-user, and item-item graphs to extract heterogeneous and homogeneous latent relationships within users and items. Besides, it introduces a novel adaptive optimization to ensure balanced and reasonable representations across modalities. Extensive experiments on three widely used datasets demonstrate the significant superiority of COHESION over various competitive baselines.",
    "year": 2025,
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "url": "https://www.semanticscholar.org/paper/a7bec80af2f9f2e5f67c334e1ad8d0132cd5536a",
    "doi": "10.48550/arXiv.2504.04452",
    "arxivId": "2504.04452",
    "authors": "Jinfeng Xu, Zheyu Chen, Wei Wang, Xiping Hu, Sang-Wook Kim, Edith C. H. Ngai",
    "citationCount": 6
  },
  {
    "s2PaperId": "989670a2c7af2438bb1bcaffa3b76e068a1eccc6",
    "title": "How Physical Information Underlies Causation and the Emergence of Systems at all Biological Levels",
    "abstract": "To bring clarity, the term ‘information’ is resolved into three distinct meanings: physical pattern, statistical relations and knowledge about things. In parallel, three kinds of ’causation’ are resolved: the action of physical force constrained by physical pattern (efficient cause), cybernetic (formal cause) and statistical inference. Cybernetic causation is an expression of fundamental (necessary) logical relations, statistical inference is phenomenological, but physical information and causation are proposed as what actually happens in the physical world. Examples of the latter are given to illustrate the underlying material dynamics in a range of biological systems from the appearance of ‘synergistic information’ among multiple variables (mainly in neuroscience); positional information in multicellular development; and the organisational structure of ecological communities, especially incorporating niche construction theory. A rigorous treatment of multi-level causation is provided as well as an explanation of the causal power of non-physical information structure, especially of interaction networks. The focus on physical information as particular pattern, echoing the insights of Howard Pattee, provides a more physically grounded view of emergence, downward causation and the concept of ‘closure to efficient causation’, all now prevalent in the organisational approach to biology.",
    "year": 2025,
    "venue": "Acta Biotheoretica",
    "url": "https://www.semanticscholar.org/paper/989670a2c7af2438bb1bcaffa3b76e068a1eccc6",
    "doi": "10.1007/s10441-025-09495-3",
    "arxivId": "",
    "authors": "Keith D Farnsworth",
    "citationCount": 1
  },
  {
    "s2PaperId": "de406d94c3fb84617a498558c999d0f382508480",
    "title": "Functional correspondences in the human and marmoset visual cortex during movie watching: Insights from correlation, redundancy, and synergy",
    "abstract": "",
    "year": 2025,
    "venue": "Brain Research",
    "url": "https://www.semanticscholar.org/paper/de406d94c3fb84617a498558c999d0f382508480",
    "doi": "10.1016/j.brainres.2025.149864",
    "arxivId": "2503.15218",
    "authors": "Qiang Li, Ting Xu, V. Calhoun",
    "citationCount": 0
  },
  {
    "s2PaperId": "18f25b125b6b527486e77dd0f2dc143b6fe4fa87",
    "title": "Information-Theoretical Analysis of Team Dynamics in Football Matches",
    "abstract": "Team dynamics significantly influence the outcomes of modern football matches. This study employs an information-theoretical approach, specifically causal emergence, combined with graph theory to explore how team-level dynamics arise from complex interactions among players, utilizing tracking data from 34 J-League matches. We focused on how collective behaviors arise from the interdependence of individual actions, examining team coordination and dynamics through player positions and movements to identify emergent properties. Specifically, we selected relative distance to the field’s center, center of mass (CoM) and clustering coefficients based on velocity similarity and inverse distance as macroscopic features to capture the key aspects of team structure, coordination, and spatial relationships. Relative distance and CoM represent the collective positioning of the team, while clustering coefficients provide insights into localized cooperation and movement similarity among the players. The results indicate that average causal emergence with relative distance and CoM as a macroscopic feature across entire games shows a strong correlation with differences in ball possession rate between home and away teams. In contrast, clustering coefficients based on inverse distance and velocity similarity showed moderate to weak correlations with ball possession rate, indicating that these metrics may capture localized interactions that are less directly tied to team-level emergent behavior compared to CoM. Additionally, relative distance and CoM as macroscopic features yield higher causal emergence in attacking phases than in defending phases before shooting, suggesting that the collective positioning of players may play a more significant role in facilitating successful attacks than in defensive stability. This study offers a novel perspective on team coordination in football, suggesting that effective team coordination may be characterized by emergent patterns arising from collective positioning. These findings have practical implications for understanding coordinated team behaviors and inform coaching and performance analysis focused on enhancing team dynamics.",
    "year": 2025,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/18f25b125b6b527486e77dd0f2dc143b6fe4fa87",
    "doi": "10.3390/e27030224",
    "arxivId": "",
    "authors": "Yi-Shan Cheng, Acer Yu-Chan Chang, Kenji Doya",
    "citationCount": 0
  },
  {
    "s2PaperId": "fdb975c141ceb8d7e64a745d76d1fcd187d14a95",
    "title": "Agentic LLM Framework for Adaptive Decision Discourse",
    "abstract": "Effective decision-making in complex systems requires synthesizing diverse perspectives to address multifaceted challenges under uncertainty. This study introduces a real-world inspired agentic Large Language Models (LLMs) framework, to simulate and enhance decision discourse-the deliberative process through which actionable strategies are collaboratively developed. Unlike traditional decision-support tools, the framework emphasizes dialogue, trade-off exploration, and the emergent synergies generated by interactions among agents embodying distinct personas. These personas simulate diverse stakeholder roles, each bringing unique priorities, expertise, and value-driven reasoning to the table. The framework incorporates adaptive and self-governing mechanisms, enabling agents to dynamically summon additional expertise and refine their assembly to address evolving challenges. An illustrative hypothetical example focused on extreme flooding in a Midwestern township demonstrates the framework's ability to navigate uncertainty, balance competing priorities, and propose mitigation and adaptation strategies by considering social, economic, and environmental dimensions. Results reveal how the breadth-first exploration of alternatives fosters robust and equitable recommendation pathways. This framework transforms how decisions are approached in high-stakes scenarios and can be incorporated in digital environments. It not only augments decision-makers' capacity to tackle complexity but also sets a foundation for scalable and context-aware AI-driven recommendations. This research explores novel and alternate routes leveraging agentic LLMs for adaptive, collaborative, and equitable recommendation processes, with implications across domains where uncertainty and complexity converge.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/fdb975c141ceb8d7e64a745d76d1fcd187d14a95",
    "doi": "10.48550/arXiv.2502.10978",
    "arxivId": "2502.10978",
    "authors": "Antoine Dolant, Praveen Kumar",
    "citationCount": 1
  },
  {
    "s2PaperId": "46dade7a5372aeac662228001eb6168ad0a61f0b",
    "title": "Broadcast Channel Cooperative Gain: An Operational Interpretation of Partial Information Decomposition",
    "abstract": "Partial information decomposition has recently found applications in biological signal processing and machine learning. Despite its impacts, the decomposition was introduced through an informal and heuristic route, and its exact operational meaning is unclear. In this work, we fill this gap by connecting partial information decomposition to the capacity of the broadcast channel, which has been well studied in the information theory literature. We show that the synergistic information in the decomposition can be rigorously interpreted as the cooperative gain, or a lower bound of this gain, on the corresponding broadcast channel. This interpretation can help practitioners to better explain and expand the applications of the partial information decomposition technique.",
    "year": 2025,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/46dade7a5372aeac662228001eb6168ad0a61f0b",
    "doi": "10.3390/e27030310",
    "arxivId": "2502.10878",
    "authors": "Chao Tian, Shlomo Shamai Shitz",
    "citationCount": 1
  },
  {
    "s2PaperId": "cf2b9d082ef430cb84af164f4e8545e9e042146d",
    "title": "SVD-based Causal Emergence for Gaussian Iterative Systems",
    "abstract": "Causal emergence (CE) based on effective information (EI) shows that macro-states can exhibit stronger causal effects than micro-states in dynamics. However, the identification of CE and the maximization of EI both rely on coarse-graining strategies, which is a key challenge. A recently proposed CE framework based on approximate dynamical reversibility utilizing singular value decomposition (SVD) is independent of coarse-graining but is limited to transition probability matrices (TPM) in discrete states. To address this problem, this article proposes a pioneering CE quantification framework for Gaussian iterative systems (GIS), based on approximate dynamical reversibility derived from the SVD of covariance matrices in forward and backward dynamics. The positive correlation between SVD-based and EI-based CE, along with the equivalence condition, are given analytically. After that, we can provide precise coarse-graining strategies directly from singular value spectrums and orthogonal matrices. This new framework can be applied to any dynamical system with continuous states and Gaussian noise, such as auto-regressive growth models, Markov Gaussian systems, and even SIR modeling by neural networks (NN). Numerical simulations on typical cases validate our theory and offer a new approach to studying the CE phenomenon, emphasizing noise and covariance over dynamical functions in both known models and machine learning.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/cf2b9d082ef430cb84af164f4e8545e9e042146d",
    "doi": "",
    "arxivId": "2502.08261",
    "authors": "Kaiwei Liu, Linli Pan, Zhipeng Wang, Mingzhe Yang, Bing Yuan, Jiang Zhang",
    "citationCount": 0
  },
  {
    "s2PaperId": "fbc97c9b2145d03c0ec72a07bb6d3cd65d0adb95",
    "title": "Algebraic Representations of Entropy and Fixed-Sign Information Quantities",
    "abstract": "Many information-theoretic quantities have corresponding representations in terms of sets. Many of these information quantities do not have a fixed sign—for example, the co-information can be both positive and negative. In previous work, we presented a signed measure space for entropy where the smallest sets (called atoms) all have fixed signs. In the present work, we demonstrate that these atoms have natural algebraic behaviour which can be expressed in terms of ideals (characterised here as upper sets), and we show that this behaviour allows us to make bounding arguments and describe many fixed-sign information quantity expressions. As an application, we give an algebraic proof that the only completely synergistic system of three finite variables X, Y and Z=f(X,Y) is the XOR gate.",
    "year": 2025,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/fbc97c9b2145d03c0ec72a07bb6d3cd65d0adb95",
    "doi": "10.3390/e27020151",
    "arxivId": "",
    "authors": "Keenan J. A. Down, P. Mediano",
    "citationCount": 2
  },
  {
    "s2PaperId": "b6dc6d42c9660ed6da98f54a6c98cbcc4b6e3f8c",
    "title": "A Taxonomy of Neuroscientific Strategies Based on Interaction Orders",
    "abstract": "In recent decades, neuroscience has advanced with increasingly sophisticated strategies for recording and analysing brain activity, enabling detailed investigations into the roles of functional units, such as individual neurons, brain regions and their interactions. Recently, new strategies for the investigation of cognitive functions regard the study of higher order interactions—that is, the interactions involving more than two brain regions or neurons. Although methods focusing on individual units and their interactions at various levels offer valuable and often complementary insights, each approach comes with its own set of limitations. In this context, a conceptual map to categorize and locate diverse strategies could be crucial to orient researchers and guide future research directions. To this end, we define the spectrum of orders of interaction, namely, a framework that categorizes the interactions among neurons or brain regions based on the number of elements involved in these interactions. We use a simulation of a toy model and a few case studies to demonstrate the utility and the challenges of the exploration of the spectrum. We conclude by proposing future research directions aimed at enhancing our understanding of brain function and cognition through a more nuanced methodological framework.",
    "year": 2025,
    "venue": "European Journal of Neuroscience",
    "url": "https://www.semanticscholar.org/paper/b6dc6d42c9660ed6da98f54a6c98cbcc4b6e3f8c",
    "doi": "10.1111/ejn.16676",
    "arxivId": "",
    "authors": "Matteo Neri, A. Brovelli, Samy Castro, Fausto Fraisopi, Marilyn Gatica, Rubén Herzog, P. Mediano, Ivan Mindlin, Giovanni Petri, Daniel Bor, Fernando E. Rosas, Antonella Tramacere, Mar Estarellas",
    "citationCount": 4
  },
  {
    "s2PaperId": "e4a5bb7f0e7f466c2d1f5b09a3eb4e76cc39514b",
    "title": "Rate-Distortion Under Neural Tracking of Speech: A Directed Redundancy Approach",
    "abstract": "The data acquired at different scalp EEG electrodes when human subjects are exposed to speech stimuli are highly redundant. The redundancy is partly due to volume conduction effects and partly due to localized regions of the brain synchronizing their activity in response to the stimuli. In a competing talker scenario, we use a recent measure of directed redundancy to assess the amount of redundant information that is causally conveyed from the attended stimuli to the left temporal region of the brain. We observe that for the attended stimuli, the transfer entropy as well as the directed redundancy is proportional to the correlation between the speech stimuli and the reconstructed signal from the EEG signals. This demonstrates that both the rate as well as the rate-redundancy are inversely proportional to the distortion in neural speech tracking. Thus, a greater rate indicates a greater redundancy between the electrode signals, and a greater correlation between the reconstructed signal and the attended stimuli. A similar relationship is not observed for the distracting stimuli.",
    "year": 2025,
    "venue": "Data Compression Conference",
    "url": "https://www.semanticscholar.org/paper/e4a5bb7f0e7f466c2d1f5b09a3eb4e76cc39514b",
    "doi": "10.1109/DCC62719.2025.00036",
    "arxivId": "2501.16762",
    "authors": "Jan Østergaard, Sangeeth Geetha Jayaprakash, Rodrigo Ordonez",
    "citationCount": 0
  },
  {
    "s2PaperId": "b0b5bf2e76bf362d5914b1bd213ac4f36f1648a7",
    "title": "Quantifying system-environment synergistic information by effective information decomposition",
    "abstract": "What is the most crucial characteristic of a system with life activity? Currently, many theories have attempted to explain the most essential difference between living systems and general systems, such as the self-organization theory and the free energy principle, but there is a lack of a reasonable indicator that can measure to what extent a system can be regarded as a system with life characteristics, especially the lack of attention to the dynamic characteristics of life systems. In this article, we propose a new indicator at the level of dynamic mechanisms to measure the ability of a system to flexibly respond to the environment. We proved that this indicator satisfies the axiom system of multivariate information decomposition in the partial information decomposition (PID) framework. Through further disassembly and analysis of this indicator, we found that it is determined by the degree of entanglement between system and environmental variables in the dynamics and the magnitude of noise. We conducted measurements on cellular automata (CA), random Boolean networks, and real gene regulatory networks (GRN), verified its relationship with the type of CA and the Langton parameter, and identified that the feedback loops have high abilities to flexibly respond to the environment on the GRN. We also combined machine learning technology to prove that this framework can be applied in the case of unknown dynamics.",
    "year": 2025,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/b0b5bf2e76bf362d5914b1bd213ac4f36f1648a7",
    "doi": "",
    "arxivId": "2501.16676",
    "authors": "Ming Yang, Linli Pan, Jiang Zhang",
    "citationCount": 0
  },
  {
    "s2PaperId": "73e6b64d1d858cf2c663c3bea6ee1821faf6dc79",
    "title": "Qualitative Mechanism Independence",
    "abstract": "We define what it means for a joint probability distribution to be compatible with a set of independent causal mechanisms, at a qualitative level -- or, more precisely, with a directed hypergraph ${\\mathcal{A}}$, which is the qualitative structure of a probabilistic dependency graph (PDG). When ${\\mathcal{A}}$ represents a qualitative Bayesian network, QIM-compatibility with ${\\mathcal{A}}$ reduces to satisfying the appropriate conditional independencies. But giving semantics to hypergraphs using QIM-compatibility lets us do much more. For one thing, we can capture functional dependencies. For another, we can capture important aspects of causality using compatibility: we can use compatibility to understand cyclic causal graphs, and to demonstrate structural compatibility, we must essentially produce a causal model. Finally, QIM-compatibility has deep connections to information theory. Applying our notion to cyclic structures helps to clarify a longstanding conceptual issue in information theory.",
    "year": 2025,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/73e6b64d1d858cf2c663c3bea6ee1821faf6dc79",
    "doi": "10.48550/arXiv.2501.15488",
    "arxivId": "2501.15488",
    "authors": "Oliver Richardson, Spencer J. Peters, Joseph Y. Halpern",
    "citationCount": 1
  },
  {
    "s2PaperId": "1e8f2d0f9bc01206a73a3523b8c2a2c123abec6b",
    "title": "Modality Interactive Mixture-of-Experts for Fake News Detection",
    "abstract": "The proliferation of fake news on social media platforms disproportionately impacts vulnerable populations, eroding trust, exacerbating inequality, and amplifying harmful narratives. Detecting fake news in multimodal contexts-where deceptive content combines text and images-is particularly challenging due to the nuanced interplay between modalities. Existing multimodal fake news detection methods often emphasize cross-modal consistency but ignore the complex interactions between text and visual elements, which may complement, contradict, or independently influence the predicted veracity of a post. To address these challenges, we present Modality Interactive Mixture-of-Experts for Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Expert framework designed to enhance multimodal fake news detection by explicitly modeling modality interactions through an interaction gating mechanism. Our approach models modality interactions by evaluating two key aspects of modality interactions: unimodal prediction agreement and semantic alignment. The hierarchical structure of MIMoE-FND allows for distinct learning pathways tailored to different fusion scenarios, adapting to the unique characteristics of each modality interaction. By tailoring fusion strategies to diverse modality interaction scenarios, MIMoE-FND provides a more robust and nuanced approach to multimodal fake news detection. We evaluate our approach on three real-world benchmarks spanning two languages, demonstrating its superior performance compared to state-of-the-art methods. By enhancing the accuracy and interpretability of fake news detection, MIMoE-FND offers a promising tool to mitigate the spread of misinformation, with potential to better safeguard vulnerable communities against its harmful effects.",
    "year": 2025,
    "venue": "The Web Conference",
    "url": "https://www.semanticscholar.org/paper/1e8f2d0f9bc01206a73a3523b8c2a2c123abec6b",
    "doi": "10.1145/3696410.3714522",
    "arxivId": "2501.12431",
    "authors": "Yifan Liu, Yaokun Liu, Zelin Li, Ruichen Yao, Yang Zhang, Dong Wang",
    "citationCount": 1
  },
  {
    "s2PaperId": "5a5b24841c42c6582bed4389832ad74e60df8388",
    "title": "Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components",
    "abstract": "We introduce a novel framework for decomposing interventional causal effects into synergistic, redundant, and unique components, building on the intuition of Partial Information Decomposition (PID) and the principle of M\\\"obius inversion. While recent work has explored a similar decomposition of an observational measure, we argue that a proper causal decomposition must be interventional in nature. We develop a mathematical approach that systematically quantifies how causal power is distributed among variables in a system, using a recently derived closed-form expression for the M\\\"obius function of the redundancy lattice. The formalism is then illustrated by decomposing the causal power in logic gates, cellular automata, and chemical reaction networks. Our results reveal how the distribution of causal power can be context- and parameter-dependent. This decomposition provides new insights into complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in legal or AI systems, to the analysis of biological networks or climate models.",
    "year": 2025,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/5a5b24841c42c6582bed4389832ad74e60df8388",
    "doi": "10.48550/arXiv.2501.11447",
    "arxivId": "2501.11447",
    "authors": "Abel Jansma",
    "citationCount": 0
  },
  {
    "s2PaperId": "e7f6483fbb5911eccb8dcf780427ba0dd81a9184",
    "title": "Role of Micrometeorological Memory in Modulating Sub‐Daily Scale Variability of Net Ecosystem Exchange",
    "abstract": "Net Ecosystem Exchange (NEE) is crucial for understanding the carbon balance in ecosystems, indicating whether they act as carbon sinks or sources. While the impact of hydrometeorological factors on NEE at daily and monthly scales has been well‐researched, the significance of sub‐daily variability and the influence of memory in micrometeorological variables remain understudied. This study addresses this gap by analyzing the temporal dynamics of NEE using half‐hourly data from 29 FLUXNET sites over at least 6 years. We found that sub‐daily variability of NEE contributes 10%–55% of 13‐day NEE variability, depending on seasonal cycles and biome characteristics. Using an information theory based transfer entropy (TE) approach, we identified the causal drivers of NEE variability at sub‐daily scales within a 6‐hr memory. Our results show that the memory of micrometeorological variables significantly impacts NEE, surpassing their instantaneous effects. Temperature (TA), vapor pressure deficit (VPD), and soil water content (SWCMean) consistently affect NEE within this 6‐hr memory, whereas the influence of sensible heat (H) and incoming shortwave radiation (SWIN) diminishes at higher lags. While the magnitude of average TE from micrometeorological variables to NEE exhibits notable seasonal variations, the temporal structure of how information is transferred does not significantly differ across seasons, as reflected by the shape of TE values over various time lags. SWCMean, VPD, and TA impact NEE jointly, while H and SWIN have overlapping effects. Additionally, precipitation influences NEE indirectly through SWCMean. Our findings highlight the importance of accounting for high‐frequency NEE variability and its underlying drivers when investigating the ecohydrological interactions, shedding light on the role of memory in carbon‐water interactions.",
    "year": 2025,
    "venue": "Journal of Geophysical Research: Biogeosciences",
    "url": "https://www.semanticscholar.org/paper/e7f6483fbb5911eccb8dcf780427ba0dd81a9184",
    "doi": "10.1029/2024JG008356",
    "arxivId": "",
    "authors": "Akash Verma, Leena Khadke, Elizabeth Eldhose, Subimal Ghosh",
    "citationCount": 0
  },
  {
    "s2PaperId": "e79edb02462f3438cf1a8b4cfde9bab339545e23",
    "title": "Dissipation Alters Modes of Information Encoding in Small Quantum Reservoirs near Criticality",
    "abstract": "Quantum reservoir computing (QRC) has emerged as a promising paradigm for harnessing near-term quantum devices to tackle temporal machine learning tasks. Yet, identifying the mechanisms that underlie enhanced performance remains challenging, particularly in many-body open systems where nonlinear interactions and dissipation intertwine in complex ways. Here, we investigate a minimal model of a driven-dissipative quantum reservoir described by two coupled Kerr-nonlinear oscillators, an experimentally realizable platform that features controllable coupling, intrinsic nonlinearity, and tunable photon loss. Using Partial Information Decomposition (PID), we examine how different dynamical regimes encode input drive signals in terms of redundancy (information shared by each oscillator) and synergy (information accessible only through their joint observation). Our key results show that, near a critical point marking a dynamical bifurcation, the system transitions from predominantly redundant to synergistic encoding. We further demonstrate that synergy amplifies short-term responsiveness, thereby enhancing immediate memory retention, whereas strong dissipation leads to more redundant encoding that supports long-term memory retention. These findings elucidate how the interplay of instability and dissipation shapes information processing in small quantum systems, providing a fine-grained, information-theoretic perspective for analyzing and designing QRC platforms.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/e79edb02462f3438cf1a8b4cfde9bab339545e23",
    "doi": "10.3390/e27010088",
    "arxivId": "2412.18290",
    "authors": "Krai Cheamsawat, Thiparat Chotibut",
    "citationCount": 3
  },
  {
    "s2PaperId": "4ac53cd871d9a38edfb6efe3cf69d8eb7d7869ff",
    "title": "Shannon information and integrated information: message and meaning",
    "abstract": "Information theory, introduced by Shannon, has been extremely successful and influential as a mathematical theory of communication. Shannon's notion of information does not consider the meaning of the messages being communicated but only their probability. Even so, computational approaches regularly appeal to\"information processing\"to study how meaning is encoded and decoded in natural and artificial systems. Here, we contrast Shannon information theory with integrated information theory (IIT), which was developed to account for the presence and properties of consciousness. IIT considers meaning as integrated information and characterizes it as a structure, rather than as a message or code. In principle, IIT's axioms and postulates allow one to\"unfold\"a cause-effect structure from a substrate in a state, a structure that fully defines the intrinsic meaning of an experience and its contents. It follows that, for the communication of meaning, the cause-effect structures of sender and receiver must be similar.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/4ac53cd871d9a38edfb6efe3cf69d8eb7d7869ff",
    "doi": "10.48550/arXiv.2412.10626",
    "arxivId": "2412.10626",
    "authors": "Alireza Zaeemzadeh, Giulio Tononi",
    "citationCount": 4
  },
  {
    "s2PaperId": "eeffb427fea8e9efe43091303cdc939b9938e5f2",
    "title": "What should a neuron aim for? Designing local objective functions based on information theory",
    "abstract": "In modern deep neural networks, the learning dynamics of the individual neurons is often obscure, as the networks are trained via global optimization. Conversely, biological systems build on self-organized, local learning, achieving robustness and efficiency with limited global information. We here show how self-organization between individual artificial neurons can be achieved by designing abstract bio-inspired local learning goals. These goals are parameterized using a recent extension of information theory, Partial Information Decomposition (PID), which decomposes the information that a set of information sources holds about an outcome into unique, redundant and synergistic contributions. Our framework enables neurons to locally shape the integration of information from various input classes, i.e. feedforward, feedback, and lateral, by selecting which of the three inputs should contribute uniquely, redundantly or synergistically to the output. This selection is expressed as a weighted sum of PID terms, which, for a given problem, can be directly derived from intuitive reasoning or via numerical optimization, offering a window into understanding task-relevant local information processing. Achieving neuron-level interpretability while enabling strong performance using local learning, our work advances a principled information-theoretic foundation for local learning strategies.",
    "year": 2024,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/eeffb427fea8e9efe43091303cdc939b9938e5f2",
    "doi": "10.48550/arXiv.2412.02482",
    "arxivId": "2412.02482",
    "authors": "A. C. Schneider, Valentin Neuhaus, David A. Ehrlich, Abdullah Makkeh, Alexander S. Ecker, V. Priesemann, M. Wibral",
    "citationCount": 3
  },
  {
    "s2PaperId": "104fdfca3e97feb24824e4cd3ca9cfb029a788fb",
    "title": "Rethinking Self-Supervised Learning Within the Framework of Partial Information Decomposition",
    "abstract": "Self Supervised learning (SSL) has demonstrated its effectiveness in feature learning from unlabeled data. Regarding this success, there have been some arguments on the role that mutual information plays within the SSL framework. Some works argued for increasing mutual information between representation of augmented views. Others suggest decreasing mutual information between them, while increasing task-relevant information. We ponder upon this debate and propose to revisit the core idea of SSL within the framework of partial information decomposition (PID). Thus, with SSL under PID we propose to replace traditional mutual information with the more general concept of joint mutual information to resolve the argument. Our investigation on instantiation of SSL within the PID framework leads to upgrading the existing pipelines by considering the components of the PID in the SSL models for improved representation learning. Accordingly we propose a general pipeline that can be applied to improve existing baselines. Our pipeline focuses on extracting the unique information component under the PID to build upon lower level supervision for generic feature learning and on developing higher-level supervisory signals for task-related feature learning. In essence, this could be interpreted as a joint utilization of local and global clustering. Experiments on four baselines and four datasets show the effectiveness and generality of our approach in improving existing SSL frameworks.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/104fdfca3e97feb24824e4cd3ca9cfb029a788fb",
    "doi": "10.48550/arXiv.2412.02121",
    "arxivId": "2412.02121",
    "authors": "S. Mohamadi, Gianfranco Doretto, Don Adjeroh",
    "citationCount": 0
  },
  {
    "s2PaperId": "35c199fd7b98a0c6f6bac1b9e78bd9fe6c40f7e6",
    "title": "An Approach to Decompose the Information Shared between Cardiovascular and Respiratory Physiological Systems",
    "abstract": "The framework of Partial Information Decomposition (PID) quantifies the redundant and synergistic information that two source variables share with a third variable within a network of interacting systems. While the PID has been formulated so far either for discrete or continuous Gaussian variables, this work introduces a computation strategy, based on nearest-neighbor entropy estimation, to de-compose the information that a discrete variable shares with two continuous sources. The approach is first validated in a Boolean logic gate producing exclusive synergy, and then applied in the context of cardiovascular physiology to decompose the information shared by the binary variable mapping the respiratory phase and the continuous time series of heart period and systolic arterial pressure variability. We show how cardiac and vascular regulatory mechanisms are individually related to respiration at rest and during postural stress, and jointly interact in maintaining cardiovascular and cardiorespiratory homeostasis during the inspiratory and expiratory breathing phases.",
    "year": 2024,
    "venue": "International Conference on Computing in Cardiology",
    "url": "https://www.semanticscholar.org/paper/35c199fd7b98a0c6f6bac1b9e78bd9fe6c40f7e6",
    "doi": "10.22489/cinc.2024.351",
    "arxivId": "",
    "authors": "Chiara Barà, Y. Antonacci, M. Javorka, Luca Faes",
    "citationCount": 0
  },
  {
    "s2PaperId": "f6b4592632589f87ae98536e68d6f28cbdbeb56b",
    "title": "Quantifying the diverse contributions of hierarchical muscle interactions to motor function",
    "abstract": "The muscle synergy concept suggests that the human motor system is organised into functional modules comprised of muscles ‘working together’ towards common task-goals. This study offers a nuanced computational perspective to muscle synergies, where muscles interacting across multiple scales have functionally-similar, - complementary and -independent roles. Making this viewpoint implicit to a methodological approach applying Partial Information Decomposition to large-scale muscle activations, we unveiled nested networks of functionally diverse inter- and intra-muscular interactions with distinct functional consequences on task performance. This approach’s effectiveness is demonstrated using simulations and by extracting generalisable muscle networks from benchmark datasets of muscle activity. Specific network components are shown to correlate with a) balance performance and b) differences in motor variability between young and older adults. By aligning muscle synergy analysis with leading theoretical insights on movement modularity, the mechanistic insights presented here suggest the proposed methodology offers enhanced research opportunities towards health and engineering applications.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/f6b4592632589f87ae98536e68d6f28cbdbeb56b",
    "doi": "10.1101/2023.11.30.569159",
    "arxivId": "",
    "authors": "David O’Reilly, William L. Shaw, P. Hilt, Rafael de Castro Aguiar, Sarah Astill, Ioannis Delis",
    "citationCount": 2
  },
  {
    "s2PaperId": "e574c473e4d7d783488bbc934104f0f1c7f7af02",
    "title": "Empirical methods that provide physical descriptions of dynamic cellular processes",
    "abstract": "",
    "year": 2024,
    "venue": "Biophysical Journal",
    "url": "https://www.semanticscholar.org/paper/e574c473e4d7d783488bbc934104f0f1c7f7af02",
    "doi": "10.1016/j.bpj.2024.12.003",
    "arxivId": "",
    "authors": "Ian Seim, Stephan W Grill",
    "citationCount": 1
  },
  {
    "s2PaperId": "95ebc8dcbf561ff355e38acb14caf91b3c21f1e2",
    "title": "Surveying the space of descriptions of a composite system with machine learning",
    "abstract": "Multivariate information theory provides a general and principled framework for understanding how the components of a system are connected. Existing analyses are coarse in nature-built up from characterizations of discrete subsystems-and can be computationally prohibitive. In this work, we propose to study the continuous space of possible descriptions of a composite system as a window into its organizational structure. A description consists of specific information conveyed about each of the components, and the space of possible descriptions is equivalent to the space of lossy compression schemes of the components. We introduce a machine-learning framework to optimize descriptions that extremize key information theoretic quantities used to characterize organization, such as total correlation and O-information. Through case studies on spin systems, sudoku boards, and letter sequences from natural language, we identify extremal descriptions that reveal how system-wide variation emerges from individual components. By integrating machine learning into a fine-grained information theoretic analysis of composite random variables, our framework opens a new avenues for probing the structure of real-world complex systems.",
    "year": 2024,
    "venue": "Physical Review Letters",
    "url": "https://www.semanticscholar.org/paper/95ebc8dcbf561ff355e38acb14caf91b3c21f1e2",
    "doi": "10.1103/gxrh-2xsv",
    "arxivId": "2411.18579",
    "authors": "Kieran A. Murphy, Yujing Zhang, Danielle Bassett",
    "citationCount": 0
  },
  {
    "s2PaperId": "df1506c0a13c1fb887c4a53c940fc330a9244d5b",
    "title": "Quantifying Knowledge Distillation Using Partial Information Decomposition",
    "abstract": "Knowledge distillation deploys complex machine learning models in resource-constrained environments by training a smaller student model to emulate internal representations of a complex teacher model. However, the teacher's representations can also encode nuisance or additional information not relevant to the downstream task. Distilling such irrelevant information can actually impede the performance of a capacity-limited student model. This observation motivates our primary question: What are the information-theoretic limits of knowledge distillation? To this end, we leverage Partial Information Decomposition to quantify and explain the transferred knowledge and knowledge left to distill for a downstream task. We theoretically demonstrate that the task-relevant transferred knowledge is succinctly captured by the measure of redundant information about the task between the teacher and student. We propose a novel multi-level optimization to incorporate redundant information as a regularizer, leading to our framework of Redundant Information Distillation (RID). RID leads to more resilient and effective distillation under nuisance teachers as it succinctly quantifies task-relevant knowledge rather than simply aligning student and teacher representations.",
    "year": 2024,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "url": "https://www.semanticscholar.org/paper/df1506c0a13c1fb887c4a53c940fc330a9244d5b",
    "doi": "10.48550/arXiv.2411.07483",
    "arxivId": "2411.07483",
    "authors": "Pasan Dissanayake, Faisal Hamman, Barproda Halder, Ilia Sucholutsky, Qiuyi Zhang, Sanghamitra Dutta",
    "citationCount": 1
  },
  {
    "s2PaperId": "ba6dede99cd9454c326720a92c7513100c3cb1aa",
    "title": "HOI: A Python toolbox for high-performance estimation of Higher-Order Interactions from multivariate data",
    "abstract": "",
    "year": 2024,
    "venue": "Journal of Open Source Software",
    "url": "https://www.semanticscholar.org/paper/ba6dede99cd9454c326720a92c7513100c3cb1aa",
    "doi": "10.21105/joss.07360",
    "arxivId": "",
    "authors": "Matteo Neri, Dishie Vinchhi, Christian Ferreyra, Thomas Robiglio, Onur Ates, M. Ontivero-Ortega, A. Brovelli, D. Marinazzo, Etienne Combrisson",
    "citationCount": 4
  },
  {
    "s2PaperId": "8c690b4d1fa3ee9e6749b0c12355efd95792e138",
    "title": "MINT: A toolbox for the analysis of multivariate neural information coding and transmission",
    "abstract": "Information theory has deeply influenced the conceptualization of brain information processing and is a mainstream framework for analyzing how neural networks in the brain process information to generate behavior. Information theory tools have been initially conceived and used to study how information about sensory variables is encoded by the activity of small neural populations. However, recent multivariate information theoretic advances have enabled addressing how information is exchanged across areas and used to inform behavior. Moreover, its integration with dimensionality-reduction techniques has enabled addressing information encoding and communication by the activity of large neural populations or many brain areas, as recorded by multichannel activity measurements in functional imaging and electrophysiology. Here, we provide a Multivariate Information in Neuroscience Toolbox (MINT) that combines these new methods with statistical tools for robust estimation from limited-size empirical datasets. We demonstrate the capabilities of MINT by applying it to both simulated and real neural data recorded with electrophysiology or calcium imaging, but all MINT functions are equally applicable to other brain-activity measurement modalities. We highlight the synergistic opportunities that combining its methods afford for reverse engineering of specific information processing and flow between neural populations or areas, and for discovering how information processing functions emerge from interactions between neurons or areas. MINT works on Linux, Windows and macOS operating systems, is written in MATLAB (requires MATLAB version 2018b or newer) and depends on 5 native MATLAB toolboxes. The calculation of one possible way to compute information redundancy requires the installation and compilation of C files (made available by us also as pre-compiled files). MINT is freely available at https://github.com/panzerilab/MINT with DOI 10.5281/zenodo.13998526 and operates under a GNU GPLv3 license.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/8c690b4d1fa3ee9e6749b0c12355efd95792e138",
    "doi": "10.1371/journal.pcbi.1012934",
    "arxivId": "",
    "authors": "Gabriel Matías Lorenz, Nicola M. Engel, Marco Celotto, L. Koçillari, Sebastiano Curreli, Tommaso Fellin, Stefano Panzeri",
    "citationCount": 1
  },
  {
    "s2PaperId": "6cdd6e28e835ac9d723f5a7a52bba932fe932d59",
    "title": "Disentangling Interactions and Dependencies in Feature Attribution",
    "abstract": "In explainable machine learning, global feature importance methods try to determine how much each individual feature contributes to predicting the target variable, resulting in one importance score for each feature. But often, predicting the target variable requires interactions between several features (such as in the XOR function), and features might have complex statistical dependencies that allow to partially replace one feature with another one. In commonly used feature importance scores these cooperative effects are conflated with the features' individual contributions, making them prone to misinterpretations. In this work, we derive DIP, a new mathematical decomposition of individual feature importance scores that disentangles three components: the standalone contribution and the contributions stemming from interactions and dependencies. We prove that the DIP decomposition is unique and show how it can be estimated in practice. Based on these results, we propose a new visualization of feature importance scores that clearly illustrates the different contributions.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/6cdd6e28e835ac9d723f5a7a52bba932fe932d59",
    "doi": "10.48550/arXiv.2410.23772",
    "arxivId": "2410.23772",
    "authors": "Gunnar König, Eric Günther, U. V. Luxburg",
    "citationCount": 3
  },
  {
    "s2PaperId": "5a3ecf18ef5129a6feb63b236340b902ab799918",
    "title": "Role of Arterial Pressure Changes on the Time-Lagged Baroreflex Response",
    "abstract": "Physiological dynamics result from the control exerted by interconnected mechanisms including causal interactions occurring at various latencies. In this work, the Partial Information Decomposition framework is exploited to investigate the causal influence of systolic arterial pressure (SAP) lagged dynamics on heart rate (HR) variations in 61 young healthy subjects undergoing the orthostatic challenge. Our results highlight how the baroreflex dynamics are mainly characterized by a fast response of the cardiac activity to arterial pressure changes and how internal SAP dynamics affect this causal interaction.",
    "year": 2024,
    "venue": "2024 13th Conference of the European Study Group on Cardiovascular Oscillations (ESGCO)",
    "url": "https://www.semanticscholar.org/paper/5a3ecf18ef5129a6feb63b236340b902ab799918",
    "doi": "10.1109/ESGCO63003.2024.10767015",
    "arxivId": "",
    "authors": "Chiara Barà, Y. Antonacci, Michal Javorka, Luca Faes",
    "citationCount": 0
  },
  {
    "s2PaperId": "2d37f8dcf53f9015c0febc895d74ccd11c281e31",
    "title": "Decomposing the transfer entropy to assess higher order effects in Cardiovascular Interactions*",
    "abstract": "Transfer Entropy (TE) can exhibit bias-either in deficiency or excess-during both pairwise and conditioned calculations, owing to high-order dependencies among the dynamic processes under consideration and the remaining processes in the system used for conditioning. To handle high order effects, instead of conditioning TE on all the measured processes except the driver and target, as in its fully conditioned version, or not conditioning at all, as in the pairwise approach, one can search for both the multiplets of variables that maximize information flow and those that minimize it, thus obtaining a decomposition of TE into unique, redundant, and synergistic atoms. This approach quantifies the relative importance of high-order effects compared to pure two-body effects while highlighting the processes that contribute to building these high-order effects alongside the driver. We employ this approach to analyze cardiovascular and cardiorespiratory interactions related to baroreflex and respiratory sinus arrhythma mechanisms.",
    "year": 2024,
    "venue": "2024 13th Conference of the European Study Group on Cardiovascular Oscillations (ESGCO)",
    "url": "https://www.semanticscholar.org/paper/2d37f8dcf53f9015c0febc895d74ccd11c281e31",
    "doi": "10.1109/ESGCO63003.2024.10767000",
    "arxivId": "",
    "authors": "S. Stramaglia, Hélder Pinto, Y. Antonacci, Michal Javorka, Luca Faes",
    "citationCount": 0
  },
  {
    "s2PaperId": "cdc423ac0e4cae2a07bde40958e927d8775e2a58",
    "title": "Partial Information Rate Decomposition in Physiological Networks",
    "abstract": "In the field of information theory, the framework of partial information decomposition (PID) has been extensively applied to networks of two source variables sharing information with a target. A dynamic version of the PID, extended to the case of three sources and providing spectral estimates of the information shared among the involved processes, is still missing. We fill this gap by introducing a coarse-grained partial information rate decomposition (PIRD) for random processes in the time and frequency domains, applied to the network of cardiovascular, respiratory and cerebrovascular oscillations studied in patients prone to postural syncope during a protocol of postural stress.",
    "year": 2024,
    "venue": "2024 13th Conference of the European Study Group on Cardiovascular Oscillations (ESGCO)",
    "url": "https://www.semanticscholar.org/paper/cdc423ac0e4cae2a07bde40958e927d8775e2a58",
    "doi": "10.1109/ESGCO63003.2024.10767037",
    "arxivId": "",
    "authors": "Laura Sparacino, Y. Antonacci, Luca Faes",
    "citationCount": 0
  },
  {
    "s2PaperId": "c7fe95ecf1227d6491fca79a1ecf62489a05c7ef",
    "title": "Competitive interactions shape brain dynamics and computation across species",
    "abstract": "Adaptive cognition relies on cooperation across anatomically distributed brain circuits. However, specialised neural systems are also in constant competition for limited processing resources. How does the brain’s network architecture enable it to balance these cooperative and competitive tendencies? Here we use computational whole-brain modelling to examine the dynamical and computational relevance of cooperative and competitive interactions in the mammalian connectome. Across human, macaque, and mouse we show that the architecture of the models that most faithfully reproduce brain activity, consistently combines modular cooperative interactions with diffuse, long-range competitive interactions. The model with competitive interactions consistently outperforms the cooperative-only model, with excellent fit to both spatial and dynamical properties of the living brain, which were not explicitly optimised but rather emerge spontaneously. Competitive interactions in the effective connectivity produce greater levels of synergistic information and local-global hierarchy, and lead to superior computational capacity when used for neuromorphic computing. Altogether, this work provides a mechanistic link between network architecture, dynamical properties, and computation in the mammalian brain.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/c7fe95ecf1227d6491fca79a1ecf62489a05c7ef",
    "doi": "10.1101/2024.10.19.619194",
    "arxivId": "",
    "authors": "Andrea I. Luppi, Y. Sanz Perl, J. Vohryzek, P. Mediano, F. Rosas, Filip Milisav, Laura E. Suárez, S. Gini, Daniel Gutierrez-Barragan, A. Gozzi, B. Mišić, G. Deco, M. Kringelbach",
    "citationCount": 3
  },
  {
    "s2PaperId": "a34255f24c0b9ab07b51be5cd54c49ba1accdbeb",
    "title": "Null models for comparing information decomposition across complex systems",
    "abstract": "A key feature of information theory is its universality, as it can be applied to study a broad variety of complex systems. However, many information-theoretic measures can vary significantly even across systems with similar properties, making normalisation techniques essential for allowing meaningful comparisons across datasets. Inspired by the framework of Partial Information Decomposition (PID), here we introduce Null Models for Information Theory (NuMIT), a null model-based non-linear normalisation procedure which improves upon standard entropy-based normalisation approaches and overcomes their limitations. We provide practical implementations of the technique for systems with different statistics, and showcase the method on synthetic models and on human neuroimaging data. Our results demonstrate that NuMIT provides a robust and reliable tool to characterise complex systems of interest, allowing cross-dataset comparisons and providing a meaningful significance test for PID analyses.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/a34255f24c0b9ab07b51be5cd54c49ba1accdbeb",
    "doi": "10.48550/arXiv.2410.11583",
    "arxivId": "2410.11583",
    "authors": "Alberto Liardi, F. Rosas, Robin L. Carhart-Harris, George Blackburne, Daniel Bor, P. Mediano",
    "citationCount": 4
  },
  {
    "s2PaperId": "27ad626aa401f2ffcbac7fca924db9bea4dc952e",
    "title": "Cellular psychology: relating cognition to context-sensitive pyramidal cells",
    "abstract": "",
    "year": 2024,
    "venue": "Trends in Cognitive Sciences",
    "url": "https://www.semanticscholar.org/paper/27ad626aa401f2ffcbac7fca924db9bea4dc952e",
    "doi": "10.1016/j.tics.2024.09.002",
    "arxivId": "",
    "authors": "William A. Phillips, Talis Bachmann, Michael W. Spratling, Lars Muckli, Lucy S. Petro, Timothy Zolnik",
    "citationCount": 8
  },
  {
    "s2PaperId": "9714aa86f44225cbc4d2f11c1a9d4c82349ffb43",
    "title": "A Synergistic Perspective on Multivariate Computation and Causality in Complex Systems",
    "abstract": "What does it mean for a complex system to “compute” or perform “computations”? Intuitively, we can understand complex “computation” as occurring when a system’s state is a function of multiple inputs (potentially including its own past state). Here, we discuss how computational processes in complex systems can be generally studied using the concept of statistical synergy, which is information about an output that can only be learned when the joint state of all inputs is known. Building on prior work, we show that this approach naturally leads to a link between multivariate information theory and topics in causal inference, specifically, the phenomenon of causal colliders. We begin by showing how Berkson’s paradox implies a higher-order, synergistic interaction between multidimensional inputs and outputs. We then discuss how causal structure learning can refine and orient analyses of synergies in empirical data, and when empirical synergies meaningfully reflect computation versus when they may be spurious. We end by proposing that this conceptual link between synergy, causal colliders, and computation can serve as a foundation on which to build a mathematically rich general theory of computation in complex systems.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/9714aa86f44225cbc4d2f11c1a9d4c82349ffb43",
    "doi": "10.3390/e26100883",
    "arxivId": "",
    "authors": "Thomas F. Varley",
    "citationCount": 1
  },
  {
    "s2PaperId": "5080e877ed647ee7296d3bd314f81a79df26e2ec",
    "title": "Functional Hypergraphs of Stock Markets",
    "abstract": "In stock markets, nonlinear interdependencies between various companies result in nontrivial time-varying patterns in stock prices. A network representation of these interdependencies has been successful in identifying and understanding hidden signals before major events like stock market crashes. However, these studies have revolved around the assumption that correlations are mediated in a pairwise manner, whereas, in a system as intricate as this, the interactions need not be limited to pairwise only. Here, we introduce a general methodology using information-theoretic tools to construct a higher-order representation of the stock market data, which we call functional hypergraphs. This framework enables us to examine stock market events by analyzing the following functional hypergraph quantities: Forman–Ricci curvature, von Neumann entropy, and eigenvector centrality. We compare the corresponding quantities of networks and hypergraphs to analyze the evolution of both structures and observe features like robustness towards events like crashes during the course of a time period.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5080e877ed647ee7296d3bd314f81a79df26e2ec",
    "doi": "10.3390/e26100848",
    "arxivId": "",
    "authors": "Jerry Jones David, Narayan G. Sabhahit, S. Stramaglia, T. D. Matteo, Stefano Boccaletti, S. Jalan",
    "citationCount": 0
  },
  {
    "s2PaperId": "494baa4d39e279a90e171d68cc1d30533e834820",
    "title": "Bias in O-Information Estimation",
    "abstract": "Higher-order relationships are a central concept in the science of complex systems. A popular method of attempting to estimate the higher-order relationships of synergy and redundancy from data is through the O-information. It is an information–theoretic measure composed of Shannon entropy terms that quantifies the balance between redundancy and synergy in a system. However, bias is not yet taken into account in the estimation of the O-information of discrete variables. In this paper, we explain where this bias comes from and explore it for fully synergistic, fully redundant, and fully independent simulated systems of n=3 variables. Specifically, we explore how the sample size and number of bins affect the bias in the O-information estimation. The main finding is that the O-information of independent systems is severely biased towards synergy if the sample size is smaller than the number of jointly possible observations. This could mean that triplets identified as highly synergistic may in fact be close to independent. A bias approximation based on the Miller–Maddow method is derived for the O-information. We find that for systems of n=3 variables the bias approximation can partially correct for the bias. However, simulations of fully independent systems are still required as null models to provide a benchmark of the bias of the O-information.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/494baa4d39e279a90e171d68cc1d30533e834820",
    "doi": "10.3390/e26100837",
    "arxivId": "",
    "authors": "Johanna Gehlen, Jie Li, Cillian Hourican, Stavroula Tassi, Pashupati P. Mishra, T. Lehtimäki, M. Kähönen, O. Raitakari, Jos A. Bosch, Rick Quax",
    "citationCount": 1
  },
  {
    "s2PaperId": "f5a83e4bd36d0a3c5655e5642fce4de2290805e8",
    "title": "Integrating Optimal Transport and Structural Inference Models for GRN Inference from Single-cell Data",
    "abstract": "We introduce a novel gene regulatory network (GRN) inference method that integrates optimal transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of cell evolutionary trajectories. Due to technological and cost constraints, single-cell experiments often feature cells sampled at irregular and sparse time points with a small sample size. Although trajectory-based structural inference models can accurately reveal the underlying interaction graph from observed data, their efficacy depends on the inputs of thousands of regularly sampled trajectories. The irregularly-sampled nature of single-cell data precludes the direct use of these powerful models for reconstructing GRNs. Optimal transport, a classical mathematical framework that minimize transportation costs between distributions, has shown promise in multi-omics data integration and cell fate prediction. Utilizing OT, our method constructs mappings between consecutively sampled cells to form cell-level trajectories, which are given as input to a structural inference model that recovers the GRN from single-cell data. Through case studies in two synthetic datasets, we demonstrate the feasibility of our proposed method and its promising performance over eight state-of-the-art GRN inference methods.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/f5a83e4bd36d0a3c5655e5642fce4de2290805e8",
    "doi": "10.48550/arXiv.2409.15080",
    "arxivId": "2409.15080",
    "authors": "Tsz Pan Tong, Aoran Wang, G. Panagopoulos, Jun Pang",
    "citationCount": 1
  },
  {
    "s2PaperId": "ab03aa5cb250c43b84f3c1d44aac9ee5e324f177",
    "title": "An Information-Theoretic Analysis of Leadership in Self-Organised Collective Action",
    "abstract": "In the absence of pre-established hierarchical authority or coercive control, resolving collective action situations through self-organisation requires a range of alternative mechanisms, including voluntary association, mutually-agreed social contracts, and socially-constructed roles with institutionalised power. In the context of Megabike, a generic testbed for examining multiple inter-dependent social coordination dilemmas, we examine the emergence of effective leadership as a critical element of self-organisation. Using an information-theoretic framework to analyse multi-agent simulations of iterated collective action situations, we show that there is causal emergence and downwards causation, but no causal decoupling. This is significant in the context of social systems in which local interactions between individuals produce beneficial leadership structures, which have, in turn, causal power over the individuals’ agency, and as such expose the society to the risk of degenerative asymmetric power structures.",
    "year": 2024,
    "venue": "International Conference on Autonomic Computing and Self-Organizing Systems",
    "url": "https://www.semanticscholar.org/paper/ab03aa5cb250c43b84f3c1d44aac9ee5e324f177",
    "doi": "10.1109/ACSOS61780.2024.00028",
    "arxivId": "",
    "authors": "Matthew Scott, Madalina Sas, Jeremy V. Pitt",
    "citationCount": 0
  },
  {
    "s2PaperId": "2df317980923bcae7cf29656855b797b74a27353",
    "title": "What to align in multimodal contrastive learning?",
    "abstract": "Humans perceive the world through multisensory integration, blending the information of different modalities to adapt their behavior. Contrastive learning offers an appealing solution for multimodal self-supervised learning. Indeed, by considering each modality as a different view of the same entity, it learns to align features of different modalities in a shared representation space. However, this approach is intrinsically limited as it only learns shared or redundant information between modalities, while multimodal interactions can arise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal learning strategy that enables the communication between modalities in a single multimodal space. Instead of imposing cross- or intra- modality constraints, we propose to align multimodal representations by maximizing the mutual information between augmented versions of these multimodal features. Our theoretical analysis shows that shared, synergistic and unique terms of information naturally emerge from this formulation, allowing us to estimate multimodal interactions beyond redundancy. We test CoMM both in a controlled and in a series of real-world settings: in the former, we demonstrate that CoMM effectively captures redundant, unique and synergistic information between modalities. In the latter, CoMM learns complex multimodal interactions and achieves state-of-the-art results on the seven multimodal benchmarks. Code is available at https://github.com/Duplums/CoMM",
    "year": 2024,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/2df317980923bcae7cf29656855b797b74a27353",
    "doi": "10.48550/arXiv.2409.07402",
    "arxivId": "2409.07402",
    "authors": "Benoit Dufumier, J. Castillo-Navarro, D. Tuia, Jean-Philippe Thiran",
    "citationCount": 8
  },
  {
    "s2PaperId": "656108c02acc60f288727c291802c569ca094442",
    "title": "Milking a spherical cow: Toy models in neuroscience",
    "abstract": "There are many different kinds of models, and they play many different roles in the scientific endeavour. Neuroscience, and biology more generally, has understandably tended to emphasise empirical models that are grounded in data and make specific, experimentally testable predictions. Meanwhile, strongly idealised or ‘toy’ models have played a central role in the theoretical development of other sciences such as physics. In this paper, we examine the nature of toy models and their prospects in neuroscience.",
    "year": 2024,
    "venue": "European Journal of Neuroscience",
    "url": "https://www.semanticscholar.org/paper/656108c02acc60f288727c291802c569ca094442",
    "doi": "10.1111/ejn.16529",
    "arxivId": "",
    "authors": "Randall D Beer, Ann‐Sophie Barwich, Gabriel J. Severino",
    "citationCount": 0
  },
  {
    "s2PaperId": "74eb7a69ae01afa70b4bb87c16ef205219c82f97",
    "title": "Algebraic Representations of Entropy and Fixed-Parity Information Quantities",
    "abstract": "Many information-theoretic quantities have corresponding representations in terms of sets. The prevailing signed measure space for characterising entropy, the $I$-measure of Yeung, is occasionally unable to discern between qualitatively distinct systems. In previous work, we presented a refinement of this signed measure space and demonstrated its capability to represent many quantities, which we called logarithmically decomposable quantities. In the present work we demonstrate that this framework has natural algebraic behaviour which can be expressed in terms of ideals (characterised here as upper-sets), and we show that this behaviour allows us to make various counting arguments and characterise many fixed-parity information quantity expressions. As an application, we give an algebraic proof that the only completely synergistic system of three finite variables $X$, $Y$ and $Z = f(X,Y)$ is the XOR gate.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/74eb7a69ae01afa70b4bb87c16ef205219c82f97",
    "doi": "10.48550/arXiv.2409.04845",
    "arxivId": "2409.04845",
    "authors": "Keenan J. A. Down, P. Mediano",
    "citationCount": 1
  },
  {
    "s2PaperId": "271d025069eec83cdaef46e8920efee4dd0e13df",
    "title": "A Logarithmic Decomposition and a Signed Measure Space for Entropy",
    "abstract": "The Shannon entropy of a random variable has much behaviour analogous to a signed measure. Previous work has explored this connection by defining a signed measure on abstract sets, which are taken to represent the information that different random variables contain. This construction is sufficient to derive many measure-theoretical counterparts to information quantities such as the mutual information (the intersection of sets), the joint entropy (the union of sets), and the conditional entropy (the difference of sets). Here we provide concrete characterisations of these abstract sets and a corresponding signed measure by extending the approach used by Yeung to all possible outcomes in an outcome space $\\Omega$, and in doing so we demonstrate that there exists a much finer decomposition with intuitive properties which we call the logarithmic decomposition (LD). We show that this signed measure space has the useful property that its logarithmic atoms are easily characterised with negative or positive entropy, depending only on their structure, while also being consistent with Yeung's I-measure. We present the usability of our approach by re-examining the G\\'acs-K\\\"orner common information and minimally sufficient statistics from this new geometric perspective and characterising it in terms of our logarithmic atoms -- a property we call logarithmic decomposability. We present possible extensions of this construction to continuous probability distributions before discussing implications for quality-led information theory. As a motivating example, we apply our new decomposition to the Dyadic and Triadic systems of James and Crutchfield and show that, in contrast to the I-measure alone, our decomposition is able to qualitatively distinguish between them.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/271d025069eec83cdaef46e8920efee4dd0e13df",
    "doi": "10.48550/arXiv.2409.03732",
    "arxivId": "2409.03732",
    "authors": "Keenan J. A. Down, P. Mediano",
    "citationCount": 2
  },
  {
    "s2PaperId": "4b37725f7f155bb5dd7e856c5d0fe631c4514e26",
    "title": "Marriage Market Sorting in the U.S.",
    "abstract": "We examine shifts in the U.S. marriage market, assessing how online dating, demographic changes, and evolving societal norms inﬂuence mate choice and broader sorting trends. Using a targeted search model, we analyse mate selection based on factors such as education, age, race, income, and skill. Intriguingly, despite the rise of online dating, preferences, mate choice, and overall sorting patterns showed negligible change from 2008 to 2021. However, a longer historical view from 1960 to 2020 reveals a trend towards preferences for similarity, particularly concerning income, education, and skills. Our ﬁndings refute two out of three potential explanations: reduced search costs and growing spatial segregation – as potential causes of these long-term shifts. In particular, we conclude that people’s capacity to process and evaluate information hasn’t improved despite technological advancements. Among the remaining demographic factors we identify enhanced workforce participation and college attainment among women as the primary drivers of the U.S. marriage market transformation. Furthermore, we ﬁnd that the corresponding changes in mate preferences and increased assortativeness by skill and education over this timeframe account for about half of the increased income inequality among households.",
    "year": 2024,
    "venue": "Federal Reserve Bank of Dallas, Working Papers",
    "url": "https://www.semanticscholar.org/paper/4b37725f7f155bb5dd7e856c5d0fe631c4514e26",
    "doi": "10.20955/wp.2023.023",
    "arxivId": "",
    "authors": "Paulina Restrepo-Echavarria, Antonella Tutino, Anton Cheremukhin",
    "citationCount": 0
  },
  {
    "s2PaperId": "f9a6944e0774f8de8d55cc26f0d01e724983f8eb",
    "title": "Network Representation of Higher-Order Interactions Based on Information Dynamics",
    "abstract": "Many complex systems in science and engineering are modeled as networks whose nodes and links depict the temporal evolution of each system unit and the dynamic interaction between pairs of units, which are assessed respectively using measures of auto- and cross-correlation or variants thereof. However, a growing body of work is documenting that this standard network representation can neglect potentially crucial information shared by three or more dynamic processes in the form of higher-order interactions (HOIs). While several measures, mostly derived from information theory, are available to assess HOIs in network systems mapped by multivariate time series, none of them is able to provide a compact yet detailed representation of higher-order interdependencies. In this work, we fill this gap by introducing a framework for the assessment of HOIs in dynamic network systems at different levels of resolution. The framework is grounded on the dynamic implementation of the O-information, a new measure assessing HOIs in dynamic networks, which is here used together with its local counterpart and its gradient to quantify HOIs respectively for the network as a whole, for each link, and for each node. The integration of these measures into the conventional network representation results in a tool for the representation of HOIs as networks, which is defined formally using measures of information dynamics, implemented in its linear version by using vector regression models and statistical validation techniques, illustrated in simulated network systems, and finally applied to an illustrative example in the field of network physiology.",
    "year": 2024,
    "venue": "IEEE Transactions on Network Science and Engineering",
    "url": "https://www.semanticscholar.org/paper/f9a6944e0774f8de8d55cc26f0d01e724983f8eb",
    "doi": "10.1109/TNSE.2025.3540982",
    "arxivId": "2408.15617",
    "authors": "G. Mijatović, Y. Antonacci, M. Javorka, D. Marinazzo, S. Stramaglia, Luca Faes",
    "citationCount": 3
  },
  {
    "s2PaperId": "15e488fc71357e4484494c34a0860a388c74c729",
    "title": "Information-Theoretic Measures on Lattices for High-Order Interactions",
    "abstract": "Traditional measures based solely on pairwise associations often fail to capture the complex statistical structure of multivariate data. Existing approaches for identifying information shared among $d>3$ variables are frequently computationally intractable, asymmetric with respect to a target variable, or unable to account for all the ways in which the joint probability distribution can be factorised. Here we present a systematic framework based on lattice theory to derive higher-order information-theoretic measures for multivariate data. Our construction uses lattice and operator function pairs, whereby an operator function is applied over a lattice that represents the algebraic relationships among variables. We show that many commonly used measures can be derived within this framework, yet they fail to capture all interactions for $d>3$, either because they are defined on restricted sublattices, or because the use of the KL divergence as an operator function, a typical choice, leads to undesired disregard of groups of interactions. To fully characterise all interactions among $d$ variables, we introduce the Streitberg Information, which is defined over the full partition lattice and uses generalised divergences (beyond KL) as operator functions. We validate the Streitberg Information on synthetic data, and illustrate its application in detecting complex interactions among stocks, decoding neural signals, and performing feature selection in machine learning.",
    "year": 2024,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "url": "https://www.semanticscholar.org/paper/15e488fc71357e4484494c34a0860a388c74c729",
    "doi": "10.48550/arXiv.2408.07533",
    "arxivId": "2408.07533",
    "authors": "Zhaolu Liu, Mauricio Barahona, R. Peach",
    "citationCount": 1
  },
  {
    "s2PaperId": "34e6a4c3d0a791e18d030b4a0fdd52ba7c744d7e",
    "title": "Synergy Makes Direct Perception Inefficient",
    "abstract": "A typical claim in anti-representationalist approaches to cognition such as ecological psychology or radical embodied cognitive science is that ecological information is sufficient for guiding behavior. According to this view, affordances are immediately perceptually available to the agent (in the so-called “ambient energy array”), so sensory data does not require much further inner processing. As a consequence, mental representations are explanatorily idle: perception is immediate and direct. Here we offer one way to formalize this direct-perception claim and identify some important limits to it. We argue that the claim should be read as saying that successful behavior just implies picking out affordance-related information from the ambient energy array. By relying on the Partial Information Decomposition framework, and more concretely on its development of the notion of synergy, we show that in multimodal perception, where various energy arrays carry affordance-related information, the “just pick out affordance-related information” approach is very inefficient, as it is bound to miss all synergistic components. Efficient multimodal information combination requires transmitting sensory-specific (and not affordance-specific) information to wherever it is that the various information streams are combined. The upshot is that some amount of computation is necessary for efficient affordance reconstruction.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/34e6a4c3d0a791e18d030b4a0fdd52ba7c744d7e",
    "doi": "10.3390/e26080708",
    "arxivId": "",
    "authors": "Miguel De Llanza Varona, Manolo Martínez",
    "citationCount": 0
  },
  {
    "s2PaperId": "30d7f51f74b2f71225130650f00963a54d8da5e6",
    "title": "Structural Constraints in Current Stomatal Conductance Models Preclude Accurate Prediction of Evapotranspiration",
    "abstract": "Evapotranspiration (ET) plays a critical role in water and energy budgets at regional to global scales. ET is composed of direct evaporation (E) and plant transpiration (T) where the latter is regulated via stomatal conductance (gsc), which depends on a multitude of plant physiological processes and hydrometeorological forcings. In recent years, significant advances have been made toward estimating gsc using a variety of models, ranging from relatively simple empirical models to more complex and data‐intensive plant hydraulic models. Using machine learning (ML) and eddy covariance flux tower data of 642 site years across 84 sites distributed across 10 land covers globally, here we show that structural constraints inherent in current empirical and plant hydraulic models of gsc limit their effectiveness for predicting ET. These constraints also prevent the models from fully utilizing the available hydrometeorological data at eddy covariance sites. Even if these gsc models are calibrated locally, structural simplifications inherent in them limit their capability to accurately capture gsc dynamics. In contrast, a ML approach, wherein the model structure is learned from the data, outperforms traditional models, thus highlighting that there still is significant room for improvement in the structure of traditional models for predicting ET. These results underscore the need to prioritize improvements in gsc models for more accurate ET estimation. This, in turn, will help reduce uncertainties in the assessments of plants' role in regulating the Earth's climate.",
    "year": 2024,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/30d7f51f74b2f71225130650f00963a54d8da5e6",
    "doi": "10.1029/2024WR037652",
    "arxivId": "",
    "authors": "Pushpendra Raghav, Mukesh Kumar, Yanlan Liu",
    "citationCount": 8
  },
  {
    "s2PaperId": "19e81207d1252eda51e2a888fcbfd47d1da715ef",
    "title": "Considering dynamical synergy and integrated information; the unusual case of minimum mutual information",
    "abstract": "This brief note considers the problem of estimating temporal synergy and integrated information in dyadic dynamical processes. One of the standard estimators of dynamic synergy is based on the minimal mutual information between sets of elements, however, despite it's increasingly widespread use, the mathematical features of this redundancy function have largely gone unexplored. Here, we show that it has two previously unrecognized limitations: it cannot disambiguate between truly integrated systems and disintegrated systems with first-order autocorrelation. Second, paradoxically, there are some systems that become more synergistic when dis-integrated (as long as first-order autocorrelations are preserved). In these systems, integrated information can decrease while synergy simultaneously increases. We derive conditions under which this occurs and discuss the implications of these findings for past and future work in applied fields such as neuroscience.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/19e81207d1252eda51e2a888fcbfd47d1da715ef",
    "doi": "10.48550/arXiv.2407.16601",
    "arxivId": "2407.16601",
    "authors": "Thomas F. Varley",
    "citationCount": 0
  },
  {
    "s2PaperId": "5f47209141065ebe088de6f0a3f7848c3b9da4ea",
    "title": "An Information-Geometric Formulation of Pattern Separation and Evaluation of Existing Indices",
    "abstract": "Pattern separation is a computational process by which dissimilar neural patterns are generated from similar input patterns. We present an information-geometric formulation of pattern separation, where a pattern separator is modeled as a family of statistical distributions on a manifold. Such a manifold maps an input (i.e., coordinates) to a probability distribution that generates firing patterns. Pattern separation occurs when small coordinate changes result in large distances between samples from the corresponding distributions. Under this formulation, we implement a two-neuron system whose probability law forms a three-dimensional manifold with mutually orthogonal coordinates representing the neurons’ marginal and correlational firing rates. We use this highly controlled system to examine the behavior of spike train similarity indices commonly used in pattern separation research. We find that all indices (except scaling factor) are sensitive to relative differences in marginal firing rates, but no index adequately captures differences in spike trains that result from altering the correlation in activity between the two neurons. That is, existing pattern separation metrics appear (A) sensitive to patterns that are encoded by different neurons but (B) insensitive to patterns that differ only in relative spike timing (e.g., synchrony between neurons in the ensemble).",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5f47209141065ebe088de6f0a3f7848c3b9da4ea",
    "doi": "10.3390/e26090737",
    "arxivId": "2407.14798",
    "authors": "Harvey Wang, Selena Singh, Thomas Trappenberg, Abraham Nunes",
    "citationCount": 1
  },
  {
    "s2PaperId": "be440fb8ae86f32eb0ab546b407e8ee229f7939a",
    "title": "Many Perception Tasks are Highly Redundant Functions of their Input Data",
    "abstract": "We show that many perception tasks, from visual recognition, semantic segmentation, optical flow, depth estimation to vocalization discrimination, are highly redundant functions of their input data. Images or spectrograms, projected into different subspaces, formed by orthogonal bases in pixel, Fourier or wavelet domains, can be used to solve these tasks remarkably well regardless of whether it is the top subspace where data varies the most, some intermediate subspace with moderate variability--or the bottom subspace where data varies the least. This phenomenon occurs because different subspaces have a large degree of redundant information relevant to the task.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/be440fb8ae86f32eb0ab546b407e8ee229f7939a",
    "doi": "10.48550/arXiv.2407.13841",
    "arxivId": "2407.13841",
    "authors": "Rahul Ramesh, Anthony Bisulco, Ronald W. DiTullio, Linran Wei, Vijay Balasubramanian, Kostas Daniilidis, Pratik Chaudhari",
    "citationCount": 3
  },
  {
    "s2PaperId": "2918f602e75e18a7d657ca2017db509358af3a08",
    "title": "Evaluating theories of neural information integration during visual search",
    "abstract": "The brain routes and integrates information from many sources during behavior. A number of models explain this phenomenon within the framework of mixed selectivity theory, yet it is difficult to compare their predictions to understand how neurons and circuits integrate information. In this work, we apply time-series partial information decomposition [PID] to compare models of integration on a dataset of superior colliculus [SC] recordings collected during a multi-target visual search task. On this task, SC must integrate target guidance, bottom-up salience, and previous fixation signals to drive attention. We find evidence that SC neurons integrate these factors in diverse ways, including decision-variable selectivity to expected value, functional specialization to previous fixation, and code-switching (to incorporate new visual input).",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/2918f602e75e18a7d657ca2017db509358af3a08",
    "doi": "10.1101/2024.07.03.601936",
    "arxivId": "",
    "authors": "Abe Leite, Hossein Adeli, Robert M. McPeek, G. Zelinsky",
    "citationCount": 0
  },
  {
    "s2PaperId": "7df1111928e7d9af8378e5dd880546b18cb026c4",
    "title": "Quantifying Spuriousness of Biased Datasets Using Partial Information Decomposition",
    "abstract": "Spurious patterns refer to a mathematical association between two or more variables in a dataset that are not causally related. However, this notion of spuriousness, which is usually introduced due to sampling biases in the dataset, has classically lacked a formal definition. To address this gap, this work presents the first information-theoretic formalization of spuriousness in a dataset (given a split of spurious and core features) using a mathematical framework called Partial Information Decomposition (PID). Specifically, we disentangle the joint information content that the spurious and core features share about another target variable (e.g., the prediction label) into distinct components, namely unique, redundant, and synergistic information. We propose the use of unique information, with roots in Blackwell Sufficiency, as a novel metric to formally quantify dataset spuriousness and derive its desirable properties. We empirically demonstrate how higher unique information in the spurious features in a dataset could lead a model into choosing the spurious features over the core features for inference, often having low worst-group-accuracy. We also propose a novel autoencoder-based estimator for computing unique information that is able to handle high-dimensional image data. Finally, we also show how this unique information in the spurious feature is reduced across several dataset-based spurious-pattern-mitigation techniques such as data reweighting and varying levels of background mixing, demonstrating a novel tradeoff between unique information (spuriousness) and worst-group-accuracy.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/7df1111928e7d9af8378e5dd880546b18cb026c4",
    "doi": "10.48550/arXiv.2407.00482",
    "arxivId": "2407.00482",
    "authors": "Barproda Halder, Faisal Hamman, Pasan Dissanayake, Qiuyi Zhang, Ilia Sucholutsky, Sanghamitra Dutta",
    "citationCount": 2
  },
  {
    "s2PaperId": "0a522ad008c3834c827ff4c847aba49c51a21625",
    "title": "ES3: Evolving Self-Supervised Learning of Robust Audio-Visual Speech Representations",
    "abstract": "",
    "year": 2024,
    "venue": "Computer Vision and Pattern Recognition",
    "url": "https://www.semanticscholar.org/paper/0a522ad008c3834c827ff4c847aba49c51a21625",
    "doi": "10.1109/CVPR52733.2024.02556",
    "arxivId": "",
    "authors": "Yuanhang Zhang, Shuang Yang, Shiguang Shan, Xilin Chen",
    "citationCount": 7
  },
  {
    "s2PaperId": "c8dfc1d8cd90058e292d8a81f6f256b29991affb",
    "title": "Brain-state mediated modulation of inter-laminar dependencies in visual cortex",
    "abstract": "Spatial attention is critical for recognizing behaviorally relevant objects in a cluttered environment. How the deployment of spatial attention aids the hierarchical computations of object recognition remains unclear. We investigated this in the laminar cortical network of visual area V4, an area strongly modulated by attention. We found that deployment of attention strengthened unique dependencies in neural activity across cortical layers. On the other hand, shared dependencies were reduced within the excitatory population of a layer. Surprisingly, attention strengthened unique dependencies within a laminar population. Crucially, these modulation patterns were also observed during successful behavioral outcomes that are thought to be mediated by internal brain state fluctuations. Successful behavioral outcomes were also associated with phases of reduced neural excitability, suggesting a mechanism for enhanced information transfer during optimal states. Our results suggest common computation goals of optimal sensory states that are attained by either task demands or internal fluctuations.",
    "year": 2024,
    "venue": "Nature Communications",
    "url": "https://www.semanticscholar.org/paper/c8dfc1d8cd90058e292d8a81f6f256b29991affb",
    "doi": "10.1038/s41467-024-49144-w",
    "arxivId": "",
    "authors": "Anirban Das, Alec G. Sheffield, Anirvan S. Nandy, M. Jadi",
    "citationCount": 3
  },
  {
    "s2PaperId": "bd854035dc5025dcad4c826810167969a0ebf1b1",
    "title": "DiffusionPID: Interpreting Diffusion via Partial Information Decomposition",
    "abstract": "Text-to-image diffusion models have made significant progress in generating naturalistic images from textual inputs, and demonstrate the capacity to learn and represent complex visual-semantic relationships. While these diffusion models have achieved remarkable success, the underlying mechanisms driving their performance are not yet fully accounted for, with many unanswered questions surrounding what they learn, how they represent visual-semantic relationships, and why they sometimes fail to generalize. Our work presents Diffusion Partial Information Decomposition (DiffusionPID), a novel technique that applies information-theoretic principles to decompose the input text prompt into its elementary components, enabling a detailed examination of how individual tokens and their interactions shape the generated image. We introduce a formal approach to analyze the uniqueness, redundancy, and synergy terms by applying PID to the denoising model at both the image and pixel level. This approach enables us to characterize how individual tokens and their interactions affect the model output. We first present a fine-grained analysis of characteristics utilized by the model to uniquely localize specific concepts, we then apply our approach in bias analysis and show it can recover gender and ethnicity biases. Finally, we use our method to visually characterize word ambiguity and similarity from the model's perspective and illustrate the efficacy of our method for prompt intervention. Our results show that PID is a potent tool for evaluating and diagnosing text-to-image diffusion models.",
    "year": 2024,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/bd854035dc5025dcad4c826810167969a0ebf1b1",
    "doi": "10.48550/arXiv.2406.05191",
    "arxivId": "2406.05191",
    "authors": "Shaurya Dewan, Rushikesh Zawar, Prakanshul Saxena, Yingshan Chang, Andrew F. Luo, Yonatan Bisk",
    "citationCount": 5
  },
  {
    "s2PaperId": "a6ec5ac82cf7f972cb9e24b3968c515d2e142dce",
    "title": "Sampling bias corrections for accurate neural measures of redundant, unique, and synergistic information",
    "abstract": "Shannon Information theory has long been a tool of choice to measure empirically how populations of neurons in the brain encode information about cognitive variables. Recently, Partial Information Decomposition (PID) has emerged as principled way to break down this information into components identifying not only the unique information carried by each neuron, but also whether relationships between neurons generate synergistic or redundant information. While it has been long recognized that Shannon information measures on neural activity suffer from a (mostly upward) limited sampling estimation bias, this issue has largely been ignored in the burgeoning field of PID analysis of neural activity. We used simulations to investigate the limited sampling bias of PID computed from discrete probabilities (suited to describe neural spiking activity). We found that PID suffers from a large bias that is uneven across components, with synergy by far the most biased. Using approximate analytical expansions, we found that the bias of synergy increases quadratically with the number of discrete responses of each neuron, whereas the bias of unique and redundant information increase only linearly or sub-linearly. Based on the understanding of the PID bias properties, we developed simple yet effective procedures that correct for the bias effectively, and that improve greatly the PID estimation with respect to current state-of-the-art procedures. We apply these PID bias correction procedures to datasets of 53117 pairs neurons in auditory cortex, posterior parietal cortex and hippocampus of mice performing cognitive tasks, deriving precise estimates and bounds of how synergy and redundancy vary across these brain regions.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/a6ec5ac82cf7f972cb9e24b3968c515d2e142dce",
    "doi": "10.1101/2024.06.04.597303",
    "arxivId": "",
    "authors": "L. Koçillari, Gabriel Matías Lorenz, Nicola M. Engel, Marco Celotto, Sebastiano Curreli, Simone Blanco Malerba, Andreas K. Engel, Tommaso Fellin, Stefano Panzeri",
    "citationCount": 1
  },
  {
    "s2PaperId": "a26c452673fe6cf0b87640cf2ff7ab071a6febed",
    "title": "Higher-order Common Information",
    "abstract": "We present a new notion $R_\\ell$ of higher-order common information, which quantifies the information that $\\ell\\geq 2$ arbitrarily distributed random variables have in common. We provide analytical lower bounds on $R_3$ and $R_4$ for jointly Gaussian distributed sources and provide computable lower bounds for $R_\\ell$ for any $\\ell$ and any sources. We also provide a practical method to estimate the lower bounds on, e.g., real-world time-series data. As an example, we consider EEG data acquired in a setup with competing acoustic stimuli. We demonstrate that $R_3$ has descriptive properties that is not in $R_2$. Moreover, we observe a linear relationship between the amount of common information $R_3$ communicated from the acoustic stimuli and to the brain and the corresponding cortical activity in terms of neural tracking of the envelopes of the stimuli.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/a26c452673fe6cf0b87640cf2ff7ab071a6febed",
    "doi": "10.48550/arXiv.2406.02001",
    "arxivId": "2406.02001",
    "authors": "Jan Østergaard",
    "citationCount": 1
  },
  {
    "s2PaperId": "a51b253312408563714c8f1a94d240a610eae0c9",
    "title": "Causal Drivers of Land‐Atmosphere Carbon Fluxes From Machine Learning Models and Data",
    "abstract": "Interactions among atmospheric, root‐soil, and vegetation processes drive carbon dioxide fluxes (Fc) from land to atmosphere. Eddy covariance measurements are commonly used to measure Fc at sub‐daily timescales and validate process‐based and data‐driven models. However, these validations do not reveal process interactions, thresholds, and key differences in how models replicate them. We use information theory‐based measures to explore multivariate information flow pathways from forcing data to observed and modeled hourly Fc, using flux tower data sets in the Midwestern U.S. in intensively managed corn‐soybean landscapes. We compare multiple linear regressions, long‐short term memory, and random forests (RF), and evaluate how different model structures use information from combinations of sources to predict Fc. We extend a framework for model predictive and functional performance, which examines a suite of dependencies from all forcing variables to the observed or modeled target. Of the three model types, RF exhibited the highest functional and predictive performance, correctly capturing strong dependencies between radiation and temperature variables with Fc. Regionally trained models demonstrate lower predictive but higher functional performance compared to site‐specific models, suggesting superior reproduction of observed relationships at the expense of predictive accuracy. This study shows that some metrics of predictive performance encapsulate functional behaviors better than others, highlighting the need for multiple metrics of both types. This study improves our understanding of carbon fluxes in an intensively managed landscape, and more generally provides insight into how model structures and forcing variables translate to interactions that are well versus poorly captured in models.",
    "year": 2024,
    "venue": "Journal of Geophysical Research: Biogeosciences",
    "url": "https://www.semanticscholar.org/paper/a51b253312408563714c8f1a94d240a610eae0c9",
    "doi": "10.1029/2023JG007815",
    "arxivId": "",
    "authors": "M. A. Farahani, A. Goodwell",
    "citationCount": 3
  },
  {
    "s2PaperId": "6813f0d258ec2d7709f0284fc04e1daa5d7b3b0c",
    "title": "Partial Information Decomposition for Data Interpretability and Feature Selection",
    "abstract": "In this paper, we introduce Partial Information Decomposition of Features (PIDF), a new paradigm for simultaneous data interpretability and feature selection. Contrary to traditional methods that assign a single importance value, our approach is based on three metrics per feature: the mutual information shared with the target variable, the feature's contribution to synergistic information, and the amount of this information that is redundant. In particular, we develop a novel procedure based on these three metrics, which reveals not only how features are correlated with the target but also the additional and overlapping information provided by considering them in combination with other features. We extensively evaluate PIDF using both synthetic and real-world data, demonstrating its potential applications and effectiveness, by considering case studies from genetics and neuroscience.",
    "year": 2024,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "url": "https://www.semanticscholar.org/paper/6813f0d258ec2d7709f0284fc04e1daa5d7b3b0c",
    "doi": "10.48550/arXiv.2405.19212",
    "arxivId": "2405.19212",
    "authors": "Charles Westphal, Stephen Hailes, Mirco Musolesi",
    "citationCount": 0
  },
  {
    "s2PaperId": "770744d49903f3c374e1c4ab8e0d90f2ceda2020",
    "title": "Stimulus information guides the emergence of behavior-related signals in primary somatosensory cortex during learning",
    "abstract": "",
    "year": 2024,
    "venue": "Cell Reports",
    "url": "https://www.semanticscholar.org/paper/770744d49903f3c374e1c4ab8e0d90f2ceda2020",
    "doi": "10.1016/j.celrep.2024.114244",
    "arxivId": "",
    "authors": "M. Panniello, Colleen J. Gillon, R. Maffulli, Marco Celotto, Blake A. Richards, Stefano Panzeri, Michael M. Kohl",
    "citationCount": 1
  },
  {
    "s2PaperId": "3bd9798481efb089191ff786dae900509bbc8102",
    "title": "Causal Structure Learning with Conditional and Unique Information Groups-Decomposition Inequalities",
    "abstract": "The causal structure of a system imposes constraints on the joint probability distribution of variables that can be generated by the system. Archetypal constraints consist of conditional independencies between variables. However, particularly in the presence of hidden variables, many causal structures are compatible with the same set of independencies inferred from the marginal distributions of observed variables. Additional constraints allow further testing for the compatibility of data with specific causal structures. An existing family of causally informative inequalities compares the information about a set of target variables contained in a collection of variables, with a sum of the information contained in different groups defined as subsets of that collection. While procedures to identify the form of these groups-decomposition inequalities have been previously derived, we substantially enlarge the applicability of the framework. We derive groups-decomposition inequalities subject to weaker independence conditions, with weaker requirements in the configuration of the groups, and additionally allowing for conditioning sets. Furthermore, we show how constraints with higher inferential power may be derived with collections that include hidden variables, and then converted into testable constraints using data processing inequalities. For this purpose, we apply the standard data processing inequality of conditional mutual information and derive an analogous property for a measure of conditional unique information recently introduced to separate redundant, synergistic, and unique contributions to the information that a set of variables has about a target.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/3bd9798481efb089191ff786dae900509bbc8102",
    "doi": "10.3390/e26060440",
    "arxivId": "",
    "authors": "Daniel Chicharro, Julia K. Nguyen",
    "citationCount": 0
  },
  {
    "s2PaperId": "91b1ceabdcfe2274808cd1250ad57ecb402d9a5b",
    "title": "Quantifying Multivariate Graph Dependencies: Theory and Estimation for Multiplex Graphs",
    "abstract": "Multiplex graphs, characterised by their layered structure, exhibit informative interdependencies within layers that are crucial for understanding complex network dynamics. Quantifying the interaction and shared information among these layers is challenging due to the non-Euclidean structure of graphs. Our paper introduces a comprehensive theory of multivariate information measures for multiplex graphs. We introduce graphon mutual information for pairs of graphs and expand this to graphon interaction information for three or more graphs, including their conditional variants. We then define graphon total correlation and graphon dual total correlation, along with their conditional forms, and introduce graphon $O-$information. We discuss and quantify the concepts of synergy and redundancy in graphs for the first time, introduce consistent nonparametric estimators for these multivariate graphon information--theoretic measures, and provide their convergence rates. We also conduct a simulation study to illustrate our theoretical findings and demonstrate the relationship between the introduced measures, multiplex graph structure, and higher--order interdependecies. Real-world applications further show the utility of our estimators in revealing shared information and dependence structures in real-world multiplex graphs. This work not only answers fundamental questions about information sharing across multiple graphs but also sets the stage for advanced pattern analysis in complex networks.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/91b1ceabdcfe2274808cd1250ad57ecb402d9a5b",
    "doi": "10.48550/arXiv.2405.14482",
    "arxivId": "2405.14482",
    "authors": "Anda Skeja, S. Olhede",
    "citationCount": 2
  },
  {
    "s2PaperId": "5824d0c05bee8c98a14f85fe6447b46d67f45f15",
    "title": "Which Information Matters? Dissecting Human-written Multi-document Summaries with Partial Information Decomposition",
    "abstract": "Understanding the nature of high-quality summaries is crucial to further improve the performance of multi-document summarization. We propose an approach to characterize human-written summaries using partial information decomposition, which decomposes the mutual information provided by all source documents into union, redundancy, synergy, and unique information. Our empirical analysis on different MDS datasets shows that there is a direct dependency between the number of sources and their contribution to the summary.",
    "year": 2024,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "url": "https://www.semanticscholar.org/paper/5824d0c05bee8c98a14f85fe6447b46d67f45f15",
    "doi": "10.48550/arXiv.2405.14470",
    "arxivId": "2405.14470",
    "authors": "Laura Mascarell, Yan L'Homme, Majed El Helou",
    "citationCount": 0
  },
  {
    "s2PaperId": "057402f43c3022d847a84355a2c3d19e96177d79",
    "title": "Decomposing causality into its synergistic, unique, and redundant components",
    "abstract": "Causality lies at the heart of scientific inquiry, serving as the fundamental basis for understanding interactions among variables in physical systems. Despite its central role, current methods for causal inference face significant challenges due to nonlinear dependencies, stochastic interactions, self-causation, collider effects, and influences from exogenous factors, among others. While existing methods can effectively address some of these challenges, no single approach has successfully integrated all these aspects. Here, we address these challenges with SURD: Synergistic-Unique-Redundant Decomposition of causality. SURD quantifies causality as the increments of redundant, unique, and synergistic information gained about future events from past observations. The formulation is non-intrusive and applicable to both computational and experimental investigations, even when samples are scarce. We benchmark SURD in scenarios that pose significant challenges for causal inference and demonstrate that it offers a more reliable quantification of causality compared to previous methods.",
    "year": 2024,
    "venue": "Nature Communications",
    "url": "https://www.semanticscholar.org/paper/057402f43c3022d847a84355a2c3d19e96177d79",
    "doi": "10.1038/s41467-024-53373-4",
    "arxivId": "2405.12411",
    "authors": "Álvaro Martínez-Sánchez, G. Arranz, Adri'an Lozano-Dur'an",
    "citationCount": 17
  },
  {
    "s2PaperId": "e8d433af638e3480730f320f680f1a07bbe2a07c",
    "title": "An Exact Theory of Causal Emergence for Linear Stochastic Iteration Systems",
    "abstract": "After coarse-graining a complex system, the dynamics of its macro-state may exhibit more pronounced causal effects than those of its micro-state. This phenomenon, known as causal emergence, is quantified by the indicator of effective information. However, two challenges confront this theory: the absence of well-developed frameworks in continuous stochastic dynamical systems and the reliance on coarse-graining methodologies. In this study, we introduce an exact theoretic framework for causal emergence within linear stochastic iteration systems featuring continuous state spaces and Gaussian noise. Building upon this foundation, we derive an analytical expression for effective information across general dynamics and identify optimal linear coarse-graining strategies that maximize the degree of causal emergence when the dimension averaged uncertainty eliminated by coarse-graining has an upper bound. Our investigation reveals that the maximal causal emergence and the optimal coarse-graining methods are primarily determined by the principal eigenvalues and eigenvectors of the dynamic system’s parameter matrix, with the latter not being unique. To validate our propositions, we apply our analytical models to three simplified physical systems, comparing the outcomes with numerical simulations, and consistently achieve congruent results.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/e8d433af638e3480730f320f680f1a07bbe2a07c",
    "doi": "10.3390/e26080618",
    "arxivId": "2405.09207",
    "authors": "Kaiwei Liu, Bing Yuan, Jiang Zhang",
    "citationCount": 3
  },
  {
    "s2PaperId": "50b1d5f91beed1663aa5a20b03c3561ae4f4d2a7",
    "title": "Neural interactions in the human frontal cortex dissociate reward and punishment learning",
    "abstract": "How human prefrontal and insular regions interact while maximizing rewards and minimizing punishments is unknown. Capitalizing on human intracranial recordings, we demonstrate that the functional specificity toward reward or punishment learning is better disentangled by interactions compared to local representations. Prefrontal and insular cortices display non-selective neural populations to rewards and punishments. Non-selective responses, however, give rise to context-specific interareal interactions. We identify a reward subsystem with redundant interactions between the orbitofrontal and ventromedial prefrontal cortices, with a driving role of the latter. In addition, we find a punishment subsystem with redundant interactions between the insular and dorsolateral cortices, with a driving role of the insula. Finally, switching between reward and punishment learning is mediated by synergistic interactions between the two subsystems. These results provide a unifying explanation of distributed cortical representations and interactions supporting reward and punishment learning.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/50b1d5f91beed1663aa5a20b03c3561ae4f4d2a7",
    "doi": "10.1101/2023.05.02.539138",
    "arxivId": "",
    "authors": "Etienne Combrisson, Ruggero Basanisi, Maëlle C. M. Gueguen, S. Rheims, P. Kahane, J. Bastin, A. Brovelli",
    "citationCount": 10
  },
  {
    "s2PaperId": "51ad2f150ef4afa7c84fa6ca63b8c4705328079c",
    "title": "Partial Information Decomposition: Redundancy as Information Bottleneck",
    "abstract": "The partial information decomposition (PID) aims to quantify the amount of redundant information that a set of sources provides about a target. Here, we show that this goal can be formulated as a type of information bottleneck (IB) problem, termed the “redundancy bottleneck” (RB). The RB formalizes a tradeoff between prediction and compression: it extracts information from the sources that best predict the target, without revealing which source provided the information. It can be understood as a generalization of “Blackwell redundancy”, which we previously proposed as a principled measure of PID redundancy. The “RB curve” quantifies the prediction–compression tradeoff at multiple scales. This curve can also be quantified for individual sources, allowing subsets of redundant sources to be identified without combinatorial optimization. We provide an efficient iterative algorithm for computing the RB curve.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/51ad2f150ef4afa7c84fa6ca63b8c4705328079c",
    "doi": "10.3390/e26070546",
    "arxivId": "2405.07665",
    "authors": "Artemy Kolchinsky",
    "citationCount": 1
  },
  {
    "s2PaperId": "92f56a5acbe39a2def98999587191473df5a201a",
    "title": "Harmonizing Program Induction with Rate-Distortion Theory",
    "abstract": "Many aspects of human learning have been proposed as a process of constructing mental programs: from acquiring symbolic number representations to intuitive theories about the world. In parallel, there is a long-tradition of using information processing to model human cognition through Rate Distortion Theory (RDT). Yet, it is still poorly understood how to apply RDT when mental representations take the form of programs. In this work, we adapt RDT by proposing a three way trade-off among rate (description length), distortion (error), and computational costs (search budget). We use simulations on a melody task to study the implications of this trade-off, and show that constructing a shared program library across tasks provides global benefits. However, this comes at the cost of sensitivity to curricula, which is also characteristic of human learners. Finally, we use methods from partial information decomposition to generate training curricula that induce more effective libraries and better generalization.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/92f56a5acbe39a2def98999587191473df5a201a",
    "doi": "10.48550/arXiv.2405.05294",
    "arxivId": "2405.05294",
    "authors": "Hanqi Zhou, David G. Nagy, Charley M. Wu",
    "citationCount": 5
  },
  {
    "s2PaperId": "586e89f8dc6aa8bc9b502b6e8973b8838efbb467",
    "title": "Non-Negative Decomposition of Multivariate Information: From Minimum to Blackwell-Specific Information",
    "abstract": "Partial information decompositions (PIDs) aim to categorize how a set of source variables provides information about a target variable redundantly, uniquely, or synergetically. The original proposal for such an analysis used a lattice-based approach and gained significant attention. However, finding a suitable underlying decomposition measure is still an open research question at an arbitrary number of discrete random variables. This work proposes a solution with a non-negative PID that satisfies an inclusion–exclusion relation for any f-information measure. The decomposition is constructed from a pointwise perspective of the target variable to take advantage of the equivalence between the Blackwell and zonogon order in this setting. Zonogons are the Neyman–Pearson region for an indicator variable of each target state, and f-information is the expected value of quantifying its boundary. We prove that the proposed decomposition satisfies the desired axioms and guarantees non-negative partial information results. Moreover, we demonstrate how the obtained decomposition can be transformed between different decomposition lattices and that it directly provides a non-negative decomposition of Rényi-information at a transformed inclusion–exclusion relation. Finally, we highlight that the decomposition behaves differently depending on the information measure used and how it can be used for tracing partial information flows through Markov chains.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/586e89f8dc6aa8bc9b502b6e8973b8838efbb467",
    "doi": "10.3390/e26050424",
    "arxivId": "",
    "authors": "Tobias Mages, Elli Anastasiadi, Christian Rohner",
    "citationCount": 5
  },
  {
    "s2PaperId": "439011c879b0c2afd321f53fcbe5d4a97c5d0eeb",
    "title": "Unravelling consciousness and brain function through the lens of time, space, and information",
    "abstract": "",
    "year": 2024,
    "venue": "Trends in Neurosciences",
    "url": "https://www.semanticscholar.org/paper/439011c879b0c2afd321f53fcbe5d4a97c5d0eeb",
    "doi": "10.1016/j.tins.2024.05.007",
    "arxivId": "",
    "authors": "A. Luppi, F. Rosas, P. Mediano, A. Demertzi, David K. Menon, E. Stamatakis",
    "citationCount": 11
  },
  {
    "s2PaperId": "2cd3c017011936a3e28e23a8c5c364a29cc46918",
    "title": "A Mereological Approach to Higher-Order Structure in Complex Systems: from Macro to Micro with M\\\"obius",
    "abstract": "Relating macroscopic observables to microscopic interactions is a central challenge in the study of complex systems. While current approaches often focus on pairwise interactions, a complete understanding requires going beyond these to capture the full range of possible interactions. We present a unified mathematical formalism, based on the M\\\"obius inversion theorem, that reveals how different decompositions of a system into parts lead to different, but equally valid, microscopic theories. By providing an exact bridge between microscopic and macroscopic descriptions, this framework demonstrates that many existing notions of interaction, from epistasis in genetics and many-body couplings in physics, to synergy in game theory and artificial intelligence, naturally and uniquely arise from particular choices of system decomposition, or mereology. By revealing the common mathematical structure underlying seemingly disparate phenomena, our work highlights how the choice of decomposition fundamentally determines the nature of the resulting interactions. We discuss how this unifying perspective can facilitate the transfer of insights across domains, guide the selection of appropriate system decompositions, and enable the search for new notions of interaction. To illustrate the latter in practice, we decompose the Kullback-Leibler divergence, and show that our method correctly identifies which variables are responsible for the divergence. In addition, we use Rota's Galois connection theorem to describe coarse-grainings of mereologies, and efficiently derive the renormalised couplings of a 1D Ising model. Our results suggest that the M\\\"obius inversion theorem provides a powerful and practical lens for understanding the emergence of complex behaviour from the interplay of microscopic parts, with applications across a wide range of disciplines.",
    "year": 2024,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2cd3c017011936a3e28e23a8c5c364a29cc46918",
    "doi": "",
    "arxivId": "2404.14423",
    "authors": "Abel Jansma",
    "citationCount": 4
  },
  {
    "s2PaperId": "606e7a1886b540ded8354e3583f799eaf1c1cdc8",
    "title": "Synergy as the Failure of Distributivity",
    "abstract": "The concept of emergence, or synergy in its simplest form, is widely used but lacks a rigorous definition. Our work connects information and set theory to uncover the mathematical nature of synergy as the failure of distributivity. For the trivial case of discrete random variables, we explore whether and how it is possible to get more information out of lesser parts. The approach is inspired by the role of set theory as the fundamental description of part–whole relations. If taken unaltered, synergistic behavior is forbidden by the set-theoretic axioms. However, random variables are not a perfect analogy of sets: we formalize the distinction, highlighting a single broken axiom—union/intersection distributivity. Nevertheless, it remains possible to describe information using Venn-type diagrams. The proposed multivariate theory resolves the persistent self-contradiction of partial information decomposition and reinstates it as a primary route toward a rigorous definition of emergence. Our results suggest that non-distributive variants of set theory may be used to describe emergent physical systems.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/606e7a1886b540ded8354e3583f799eaf1c1cdc8",
    "doi": "10.3390/e26110916",
    "arxivId": "2404.03455",
    "authors": "Ivan A. Sevostianov, O. Feinerman",
    "citationCount": 0
  },
  {
    "s2PaperId": "830417dcdb1b331041532586e310cb80d9697dda",
    "title": "Information flow between motor cortex and striatum reverses during skill learning",
    "abstract": "",
    "year": 2024,
    "venue": "Current Biology",
    "url": "https://www.semanticscholar.org/paper/830417dcdb1b331041532586e310cb80d9697dda",
    "doi": "10.1016/j.cub.2024.03.023",
    "arxivId": "",
    "authors": "Stefan Lemke, Marco Celotto, R. Maffulli, Karunesh Ganguly, Stefano Panzeri",
    "citationCount": 9
  },
  {
    "s2PaperId": "757544eca9357990f44dbd64c380ef8a200135fe",
    "title": "Towards the Disappearing Truth: Fine-Grained Joint Causal Influences Learning with Hidden Variable-Driven Causal Hypergraphs in Time Series",
    "abstract": "Causal discovery under Granger causality framework has yielded widespread concerns in time series analysis task. Nevertheless, most previous methods are unaware of the underlying causality disappearing problem, that is, certain weak causalities are less focusable and may be lost during the modeling process, thus leading to biased causal conclusions. Therefore, we propose to introduce joint causal influences (i.e., causal influences from the union of multiple variables) as additional causal indication information to help identify weak causalities. Further, to break the limitation of existing methods that implicitly and coarsely model joint causal influences, we propose a novel hidden variable-driven causal hypergraph neural network to meticulously explore the locality and diversity of joint causal influences, and realize its explicit and fine-grained modeling. Specifically, we introduce hidden variables to construct a causal hypergraph for explicitly characterizing various fine-grained joint causal influences. Then, we customize a dual causal information transfer mechanism (encompassing a multi-level causal path and an information aggregation path) to realize the free diffusion and meticulous aggregation of joint causal influences and facilitate its adaptive learning. Finally, we design a multi-view collaborative optimization constraint to guarantee the characterization diversity of causal hypergraph and capture remarkable forecasting relationships (i.e., causalities). Experiments are conducted to demonstrate the superiority of the proposed model.",
    "year": 2024,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/757544eca9357990f44dbd64c380ef8a200135fe",
    "doi": "10.1609/aaai.v38i15.29662",
    "arxivId": "",
    "authors": "Kun Zhu, Chunhui Zhao",
    "citationCount": 4
  },
  {
    "s2PaperId": "b9a246cac64bbcc20f1ab5b29b96caa5f27e50ee",
    "title": "Predictive learning shapes the representational geometry of the human brain",
    "abstract": "Predictive coding theories propose that the brain constantly updates its internal models of the world to minimize prediction errors and optimize sensory processing. However, the neural mechanisms that link the encoding of prediction errors and optimization of sensory representations remain unclear. Here, we provide direct evidence how predictive learning shapes the representational geometry of the human brain. We recorded magnetoencephalography (MEG) in human participants listening to acoustic sequences with different levels of regularity. Representational similarity analysis revealed how, through learning, the brain aligned its representational geometry to match the statistical structure of the sensory inputs, by clustering the representations of temporally contiguous and predictable stimuli. Crucially, we found that in sensory areas the magnitude of the representational shift correlated with the encoding strength of prediction errors. Furthermore, using partial information decomposition we found that, prediction errors were processed by a synergistic network of high-level associative and sensory areas. Importantly, the strength of synergistic encoding of precition errors predicted the magnitude of representational alignment during learning. Our findings provide evidence that large-scale neural interactions engaged in predictive processing modulate the representational content of sensory areas, which may enhance the efficiency of perceptual processing in response to the statistical regularities of the environment.",
    "year": 2024,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/b9a246cac64bbcc20f1ab5b29b96caa5f27e50ee",
    "doi": "10.1101/2024.03.07.583842",
    "arxivId": "",
    "authors": "Antonino Greco, Julia Moser, Hubert Preissl, Markus Siegel",
    "citationCount": 8
  },
  {
    "s2PaperId": "ca3bc187aae5cbe6f5f8a6b56d40fddd680724b8",
    "title": "A Measure of Synergy Based on Union Information",
    "abstract": "The partial information decomposition (PID) framework is concerned with decomposing the information that a set of (two or more) random variables (the sources) has about another variable (the target) into three types of information: unique, redundant, and synergistic. Classical information theory alone does not provide a unique way to decompose information in this manner and additional assumptions have to be made. One often overlooked way to achieve this decomposition is using a so-called measure of union information—which quantifies the information that is present in at least one of the sources—from which a synergy measure stems. In this paper, we introduce a new measure of union information based on adopting a communication channel perspective, compare it with existing measures, and study some of its properties. We also include a comprehensive critical review of characterizations of union information and synergy measures that have been proposed in the literature.",
    "year": 2024,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ca3bc187aae5cbe6f5f8a6b56d40fddd680724b8",
    "doi": "10.3390/e26030271",
    "arxivId": "2403.16575",
    "authors": "André F. C. Gomes, Mário A. T. Figueiredo",
    "citationCount": 3
  },
  {
    "s2PaperId": "5904d0b59569e8361dfe3bebb2f6af2c192a1fc0",
    "title": "Quantifying synergy and redundancy between networks",
    "abstract": "",
    "year": 2024,
    "venue": "Cell Reports Physical Science",
    "url": "https://www.semanticscholar.org/paper/5904d0b59569e8361dfe3bebb2f6af2c192a1fc0",
    "doi": "10.1016/j.xcrp.2024.101892",
    "arxivId": "",
    "authors": "A. Luppi, E. Olbrich, Conor Finn, Laura E. Suárez, F. Rosas, P. Mediano, Jürgen Jost",
    "citationCount": 3
  },
  {
    "s2PaperId": "daca44c83caed407054fb2d15197cea7a70b3c5a",
    "title": "A scalable, synergy-first backbone decomposition of higher-order structures in complex systems",
    "abstract": "In the last decade, there has been an explosion of interest in the field of multivariate information theory and the study of emergent, higher-order interactions. These “synergistic” dependencies reflect information that is in the “whole” but not any of the “parts.” Arguably the most successful framework for exploring synergies is the partial information decomposition (PID). Despite its considerable power, the PID has a number of limitations that restrict its general applicability. Subsequently, other heuristic measures, such as the O-information, have been introduced, although these measures typically only provide a summary statistic of redundancy/synergy dominance, rather than direct insight into the synergy itself. To address this issue, we present an alternative decomposition that is synergy-first, scales much more gracefully than the PID, and has a straightforward interpretation. We define synergy as that information encoded in the joint state of a set of elements that would be lost following the minimally invasive perturbation on any single element. By generalizing this idea to sets of elements, we construct a totally ordered “backbone” of partial synergy atoms that sweeps the system’s scale. This approach applies to the entropy, the Kullback-Leibler divergence, and by extension, to the total correlation and the single-target mutual information (thus recovering a “backbone” PID). Finally, we show that this approach can be used to decompose higher-order interactions beyond information theory by showing how synergistic combinations of edges in a graph support global integration via communicability. We conclude by discussing how this perspective on synergistic structure can deepen our understanding of part-whole relationships in complex systems.",
    "year": 2024,
    "venue": "npj Complexity",
    "url": "https://www.semanticscholar.org/paper/daca44c83caed407054fb2d15197cea7a70b3c5a",
    "doi": "10.48550/arXiv.2402.08135",
    "arxivId": "2402.08135",
    "authors": "Thomas F. Varley",
    "citationCount": 7
  },
  {
    "s2PaperId": "e959b547aad7777891b67a2863e39e9baf299f88",
    "title": "SΩI: Score-based O-INFORMATION Estimation",
    "abstract": "The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is O-information, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce S$\\Omega$I, which allows for the first time to compute O-information without restrictive assumptions about the system. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of S$\\Omega$I in the context of a real-world use case.",
    "year": 2024,
    "venue": "International Conference on Machine Learning",
    "url": "https://www.semanticscholar.org/paper/e959b547aad7777891b67a2863e39e9baf299f88",
    "doi": "10.48550/arXiv.2402.05667",
    "arxivId": "2402.05667",
    "authors": "Mustapha Bounoua, Giulio Franzese, Pietro Michiardi",
    "citationCount": 1
  },
  {
    "s2PaperId": "088af11b566dd88bc571d56427bf217397af4bae",
    "title": "Explicit Formula for Partial Information Decomposition",
    "abstract": "Mutual information between two random variables is a well-studied notion, whose understanding is fairly complete. Mutual information between one random variable and a pair of other random variables, however, is a far more involved notion. Specifically, Shannon's mutual information does not capture fine-grained interactions between those three variables, resulting in limited insights in complex systems. To capture these fine-grained interactions, in 2010 Williams and Beer proposed to decompose this mutual information to information atoms, called unique, redundant, and synergistic, and proposed several operational axioms that these atoms must satisfy. In spite of numerous efforts, a general formula which satisfies these axioms has yet to be found. Inspired by Judea Pearl's do-calculus, we resolve this open problem by introducing the do-operation, an operation over the variable system which sets a certain marginal to a desired value, which is distinct from any existing approaches. Using this operation, we provide the first explicit formula for calculating the information atoms so that Williams and Beer's axioms are satisfied, as well as additional properties from subsequent studies in the field.",
    "year": 2024,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/088af11b566dd88bc571d56427bf217397af4bae",
    "doi": "10.1109/ISIT57864.2024.10619369",
    "arxivId": "2402.03554",
    "authors": "Aobo Lyu, Andrew Clark, Netanel Raviv",
    "citationCount": 2
  },
  {
    "s2PaperId": "8d6d9d64db850cd1c21e47f005aeecbde415caf3",
    "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
    "abstract": "There has recently been an explosion of interest in how \"higher-order\" structures emerge in complex systems comprised of many interacting elements (often called \"synergistic\" information). This \"emergent\" organization has been found in a variety of natural and artificial systems, although at present, the field lacks a unified understanding of what the consequences of higher-order synergies and redundancies are for systems under study. Typical research treats the presence (or absence) of synergistic information as a dependent variable and report changes in the level of synergy in response to some change in the system. Here, we attempt to flip the script: rather than treating higher-order information as a dependent variable, we use evolutionary optimization to evolve boolean networks with significant higher-order redundancies, synergies, or statistical complexity. We then analyze these evolved populations of networks using established tools for characterizing discrete dynamics: the number of attractors, the average transient length, and the Derrida coefficient. We also assess the capacity of the systems to integrate information. We find that high-synergy systems are unstable and chaotic, but with a high capacity to integrate information. In contrast, evolved redundant systems are extremely stable, but have negligible capacity to integrate information. Finally, the complex systems that balance integration and segregation (known as Tononi-Sporns-Edelman complexity) show features of both chaosticity and stability, with a greater capacity to integrate information than the redundant systems while being more stable than the random and synergistic systems. We conclude that there may be a fundamental trade-off between the robustness of a system's dynamics and its capacity to integrate information (which inherently requires flexibility and sensitivity) and that certain kinds of complexity naturally balance this trade-off.",
    "year": 2024,
    "venue": "Chaos",
    "url": "https://www.semanticscholar.org/paper/8d6d9d64db850cd1c21e47f005aeecbde415caf3",
    "doi": "10.48550/arXiv.2401.14347",
    "arxivId": "2401.14347",
    "authors": "Thomas F. Varley, Joshua Bongard",
    "citationCount": 5
  },
  {
    "s2PaperId": "3e678c6555e4be379c1c39627c502467b863b31e",
    "title": "Synergistic Signatures of Group Mechanisms in Higher-Order Systems.",
    "abstract": "The interplay between causal mechanisms and emerging collective behaviors is a central aspect of understanding, controlling, and predicting complex networked systems. In our work, we investigate the relationship between higher-order mechanisms and higher-order behavioral observables in two representative models with group interactions: a simplicial Ising model and a social contagion model. In both systems, we find that group (higher-order) interactions show emergent synergistic (higher-order) behavior. The emergent synergy appears only at the group level and depends in a complex, nonlinear way on the trade-off between the strengths of the low- and higher-order mechanisms and is invisible to low-order behavioral observables. Our work sets the basis for systematically investigating the relation between causal mechanisms and behavioral patterns in complex networked systems with group interactions, offering a robust methodological framework to tackle this challenging task.",
    "year": 2024,
    "venue": "Physical Review Letters",
    "url": "https://www.semanticscholar.org/paper/3e678c6555e4be379c1c39627c502467b863b31e",
    "doi": "10.1103/PhysRevLett.134.137401",
    "arxivId": "2401.11588",
    "authors": "Thomas Robiglio, Matteo Neri, Davide Coppes, Cosimo Agostinelli, F. Battiston, Maxime Lucas, Giovanni Petri",
    "citationCount": 8
  },
  {
    "s2PaperId": "07a3b82a734fc150b29bdd995b968a6b84d8cb0f",
    "title": "Information-Theoretic State Variable Selection for Reinforcement Learning",
    "abstract": "Identifying the most suitable variables to represent the state is a fundamental challenge in Reinforcement Learning (RL). These variables must efficiently capture the information necessary for making optimal decisions. In order to address this problem, in this paper, we introduce the Transfer Entropy Redundancy Criterion (TERC), an information-theoretic criterion, which determines if there is \\textit{entropy transferred} from state variables to actions during training. We define an algorithm based on TERC that provably excludes variables from the state that have no effect on the final performance of the agent, resulting in more sample efficient learning. Experimental results show that this speed-up is present across three different algorithm classes (represented by tabular Q-learning, Actor-Critic, and Proximal Policy Optimization (PPO)) in a variety of environments. Furthermore, to highlight the differences between the proposed methodology and the current state-of-the-art feature selection approaches, we present a series of controlled experiments on synthetic data, before generalizing to real-world decision-making tasks. We also introduce a representation of the problem that compactly captures the transfer of information from state variables to actions as Bayesian networks.",
    "year": 2024,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/07a3b82a734fc150b29bdd995b968a6b84d8cb0f",
    "doi": "10.48550/arXiv.2401.11512",
    "arxivId": "2401.11512",
    "authors": "Charles Westphal, Stephen Hailes, Mirco Musolesi",
    "citationCount": 3
  },
  {
    "s2PaperId": "df77bf554b79a52ac1d8b5a91f447b73e1413db1",
    "title": "Assessing High-Order Links in Cardiovascular and Respiratory Networks via Static and Dynamic Information Measures",
    "abstract": "Goal: The network representation is becoming increasingly popular for the description of cardiovascular interactions based on the analysis of multiple simultaneously collected variables. However, the traditional methods to assess network links based on pairwise interaction measures cannot reveal high-order effects involving more than two nodes, and are not appropriate to infer the underlying network topology. To address these limitations, here we introduce a framework which combines the assessment of high-order interactions with statistical inference for the characterization of the functional links sustaining physiological networks. Methods: The framework develops information-theoretic measures quantifying how two nodes interact in a redundant or synergistic way with the rest of the network, and employs these measures for reconstructing the functional structure of the network. The measures are implemented for both static and dynamic networks mapped respectively by random variables and random processes using plug-in and model-based entropy estimators. Results: The validation on theoretical and numerical simulated networks documents the ability of the framework to represent high-order interactions as networks and to detect statistical structures associated to cascade, common drive and common target effects. The application to cardiovascular networks mapped by the beat-to-beat variability of heart rate, respiration, arterial pressure, cardiac output and vascular resistance allowed noninvasive characterization of several mechanisms of cardiovascular control operating in resting state and during orthostatic stress. Conclusion: Our approach brings to new comprehensive assessment of physiological interactions and complements existing strategies for the classification of pathophysiological states.",
    "year": 2024,
    "venue": "IEEE Open Journal of Engineering in Medicine and Biology",
    "url": "https://www.semanticscholar.org/paper/df77bf554b79a52ac1d8b5a91f447b73e1413db1",
    "doi": "10.1109/OJEMB.2024.3374956",
    "arxivId": "2401.05556",
    "authors": "G. Mijatović, Laura Sparacino, Y. Antonacci, M. Javorka, D. Marinazzo, S. Stramaglia, L. Faes",
    "citationCount": 5
  },
  {
    "s2PaperId": "817ab96d5257ad48d72f3b432f6b03cbe6753927",
    "title": "Gradients of O-information highlight synergy and redundancy in physiological applications",
    "abstract": "The study of high order dependencies in complex systems has recently led to the introduction of statistical synergy, a novel quantity corresponding to a form of emergence in which patterns at large scales are not traceable from lower scales. As a consequence, several works in the last years dealt with the synergy and its counterpart, the redundancy. In particular, the O-information is a signed metric that measures the balance between redundant and synergistic statistical dependencies. In spite of its growing use, this metric does not provide insight about the role played by low-order scales in the formation of high order effects. To fill this gap, the framework for the computation of the O-information has been recently expanded introducing the so-called gradients of this metric, which measure the irreducible contribution of a variable (or a group of variables) to the high order informational circuits of a system. Here, we review the theory behind the O-information and its gradients and present the potential of these concepts in the field of network physiology, showing two new applications relevant to brain functional connectivity probed via functional resonance imaging and physiological interactions among the variability of heart rate, arterial pressure, respiration and cerebral blood flow.",
    "year": 2024,
    "venue": "Frontiers in Network Physiology",
    "url": "https://www.semanticscholar.org/paper/817ab96d5257ad48d72f3b432f6b03cbe6753927",
    "doi": "10.3389/fnetp.2023.1335808",
    "arxivId": "",
    "authors": "Tomas Scagliarini, Laura Sparacino, L. Faes, D. Marinazzo, S. Stramaglia",
    "citationCount": 9
  },
  {
    "s2PaperId": "908dc78aec0b5eed3608ce74f0c74562186b0123",
    "title": "Information decomposition and the informational architecture of the brain",
    "abstract": "",
    "year": 2024,
    "venue": "Trends in Cognitive Sciences",
    "url": "https://www.semanticscholar.org/paper/908dc78aec0b5eed3608ce74f0c74562186b0123",
    "doi": "10.1016/j.tics.2023.11.005",
    "arxivId": "",
    "authors": "A. Luppi, F. Rosas, P. Mediano, David K. Menon, E. Stamatakis",
    "citationCount": 66
  },
  {
    "s2PaperId": "517bd2e1d50643baf1fc69d720bd7c554c2d8b88",
    "title": "Neural Causal Information Extractor for Unobserved Causes",
    "abstract": "Causal inference aims to faithfully depict the causal relationships between given variables. However, in many practical systems, variables are often partially observed, and some unobserved variables could carry significant information and induce causal effects on a target. Identifying these unobserved causes remains a challenge, and existing works have not considered extracting the unobserved causes while retaining the causes that have already been observed and included. In this work, we aim to construct the implicit variables with a generator–discriminator framework named the Neural Causal Information Extractor (NCIE), which can complement the information of unobserved causes and thus provide a complete set of causes with both observed causes and the representations of unobserved causes. By maximizing the mutual information between the targets and the union of observed causes and implicit variables, the implicit variables we generate could complement the information that the unobserved causes should have provided. The synthetic experiments show that the implicit variables preserve the information and dynamics of the unobserved causes. In addition, extensive real-world time series prediction tasks show improved precision after introducing implicit variables, thus indicating their causality to the targets.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/517bd2e1d50643baf1fc69d720bd7c554c2d8b88",
    "doi": "10.3390/e26010046",
    "arxivId": "",
    "authors": "K. Leong, Yuxuan Xiu, Bokui Chen, W.K. Victor Chan",
    "citationCount": 1
  },
  {
    "s2PaperId": "0dd06282124f96529ec5781a6b666bd8e892dbf2",
    "title": "Afferents to Action: Cortical Proprioceptive Processing Assessed with Corticokinematic Coherence Specifically Relates to Gross Motor Skills",
    "abstract": "Voluntary motor control is thought to be predicated on the ability to efficiently integrate and process somatosensory afferent information. However, current approaches in the field of motor control have not factored in objective markers of how the brain tracks incoming somatosensory information. Here, we asked whether motor performance relates to such markers obtained with an analysis of the coupling between peripheral kinematics and cortical oscillations during continuous movements, best known as corticokinematic coherence (CKC). Motor performance was evaluated by measuring both gross and fine motor skills using the Box and Blocks Test (BBT) and the Purdue Pegboard Test (PPT), respectively, and with a biomechanics measure of coordination. A total of 61 participants completed the BBT, while equipped with electroencephalography and electromyography, and the PPT. We evaluated CKC, from the signals collected during the BBT, as the coherence between movement rhythmicity and brain activity, and coordination as the cross-correlation between muscle activity. CKC at movements’ first harmonic was positively associated with BBT scores (r = 0.41, p = 0.001), and alone showed no relationship with PPT scores (r = 0.07, p = 0.60), but in synergy with BBT scores, participants with lower PPT scores had higher CKC than expected based on their BBT score. Coordination was not associated with motor performance or CKC (p > 0.05). These findings demonstrate that cortical somatosensory processing in the form of strengthened brain–peripheral coupling is specifically associated with better gross motor skills and thus may be considered as a valuable addition to classical tests of proprioception acuity.",
    "year": 2023,
    "venue": "eNeuro",
    "url": "https://www.semanticscholar.org/paper/0dd06282124f96529ec5781a6b666bd8e892dbf2",
    "doi": "10.1523/ENEURO.0384-23.2023",
    "arxivId": "",
    "authors": "Scott J. Mongold, Christian Georgiev, Thomas Legrand, Mathieu Bourguignon",
    "citationCount": 5
  },
  {
    "s2PaperId": "57a706d2b294c9cc2648cc286feea84ebb157756",
    "title": "Channel assisted noise propagation in a two-step cascade.",
    "abstract": "Signal propagation in biochemical networks is characterized by the inherent randomness in gene expression and fluctuations of the environmental components, commonly known as intrinsic and extrinsic noise, respectively. We present a theoretical framework for noise propagation in a generic two-step cascade (S→X→Y) regarding intrinsic and extrinsic noise. We identify different channels of noise transmission that regulate the individual and the overall noise properties of each component. Our analysis shows that the intrinsic noise of S alleviates the general noise and information transmission capacity along the cascade. On the other hand, the intrinsic noise of X and Y acts as a bottleneck of information transmission. We also show a hierarchical relationship among the intrinsic noise levels of S, X, and Y, with S exhibiting the highest level of intrinsic noise, followed by X and then Y. This hierarchy is preserved within the two-step cascade, facilitating the highest information transmission from S to Y via X.",
    "year": 2023,
    "venue": "Chaos",
    "url": "https://www.semanticscholar.org/paper/57a706d2b294c9cc2648cc286feea84ebb157756",
    "doi": "10.1063/5.0208543",
    "arxivId": "2312.07172",
    "authors": "Mintu Nandi, Sudip Chattopadhyay, Somshubhro Bandyopadhyay, S. Banik",
    "citationCount": 2
  },
  {
    "s2PaperId": "c48b1b6f7a9fdf84fda214ee909088183755a8fa",
    "title": "Behavioural relevance of redundant and synergistic stimulus information between functionally connected neurons in mouse auditory cortex",
    "abstract": "Measures of functional connectivity have played a central role in advancing our understanding of how information is transmitted and processed within the brain. Traditionally, these studies have focused on identifying redundant functional connectivity, which involves determining when activity is similar across different sites or neurons. However, recent research has highlighted the importance of also identifying synergistic connectivity—that is, connectivity that gives rise to information not contained in either site or neuron alone. Here, we measured redundant and synergistic functional connectivity between neurons in the mouse primary auditory cortex during a sound discrimination task. Specifically, we measured directed functional connectivity between neurons simultaneously recorded with calcium imaging. We used Granger Causality as a functional connectivity measure. We then used Partial Information Decomposition to quantify the amount of redundant and synergistic information about the presented sound that is carried by functionally connected or functionally unconnected pairs of neurons. We found that functionally connected pairs present proportionally more redundant information and proportionally less synergistic information about sound than unconnected pairs, suggesting that their functional connectivity is primarily redundant. Further, synergy and redundancy coexisted both when mice made correct or incorrect perceptual discriminations. However, redundancy was much higher (both in absolute terms and in proportion to the total information available in neuron pairs) in correct behavioural choices compared to incorrect ones, whereas synergy was higher in absolute terms but lower in relative terms in correct than in incorrect behavioural choices. Moreover, the proportion of redundancy reliably predicted perceptual discriminations, with the proportion of synergy adding no extra predictive power. These results suggest a crucial contribution of redundancy to correct perceptual discriminations, possibly due to the advantage it offers for information propagation, and also suggest a role of synergy in enhancing information level during correct discriminations.",
    "year": 2023,
    "venue": "Brain Informatics",
    "url": "https://www.semanticscholar.org/paper/c48b1b6f7a9fdf84fda214ee909088183755a8fa",
    "doi": "10.1186/s40708-023-00212-9",
    "arxivId": "",
    "authors": "L. Koçillari, Marco Celotto, Nikolas A. Francis, Shoutik Mukherjee, B. Babadi, P. Kanold, Stefano Panzeri",
    "citationCount": 2
  },
  {
    "s2PaperId": "53617fa5f5f0718e8af915ee2b83f91096d6fa45",
    "title": "How do correlations shape the landscape of information?",
    "abstract": "We explore a few common models on how correlations affect information. The main model considered is the Shannon mutual information $I(S:R_1,\\cdots, R_i)$ over distributions with marginals $P_{S,R_i}$ fixed for each $i$, with the analogy in which $S$ is the stimulus and $R_i$'s are neurons. We work out basic models in details, using algebro-geometric tools to write down discriminants that separate distributions with distinct qualitative behaviours in the probability simplex into toric chambers and evaluate the volumes of them algebraically. As a byproduct, we provide direct translation between a decomposition of mutual information inspired by a series expansion and one from partial information decomposition (PID) problems, characterising the synergistic terms of the former. We hope this paper serves for communication between communities especially mathematics and theoretical neuroscience on the topic. KEYWORDS: information theory, algebraic statistics, mathematical neuroscience, partial information decomposition",
    "year": 2023,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/53617fa5f5f0718e8af915ee2b83f91096d6fa45",
    "doi": "10.48550/arXiv.2312.00737",
    "arxivId": "2312.00737",
    "authors": "Ching-Peng Huang",
    "citationCount": 0
  },
  {
    "s2PaperId": "db803f113444668d402e8eb3d1ad73d4d6687e21",
    "title": "The coexistence of localized and distributed behavioral information in neural activity",
    "abstract": "The degree to which control of an animal’s behavior is localized within particular neurons or distributed over large populations is central to understanding mechanisms of decision-making in brains. A first step in answering this question comes from understanding the scales at which neural activity is predictive of behavior. Here, we demonstrate how information measures at the individual, pairwise, and larger group levels characterize the localization of predictive information. We demonstrate these tools using high-dimensional neural data related to nematode and macaque behavioral decisions. Intriguingly, in both examples we find that similar behavioral information coexists across scales: the same information can be extracted from small groups of individually informative neurons or larger groups of randomly chosen neurons that individually have little predictive power. Our results suggest that methods for causal inference may miss potential causal pathways if they are biased toward finding localized control mechanisms.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/db803f113444668d402e8eb3d1ad73d4d6687e21",
    "doi": "10.1101/2023.11.17.567603",
    "arxivId": "",
    "authors": "Gaurang Yadav, Bryan C. Daniels",
    "citationCount": 0
  },
  {
    "s2PaperId": "9c133bce1fe4bd19b33c3052ccb5f345d6043f8c",
    "title": "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts",
    "abstract": "Advances in multimodal models have greatly improved how interactions relevant to various tasks are modeled. Today’s multimodal models mainly focus on the correspondence between images and text, using this for tasks like image-text matching. However, this covers only a subset of real-world interactions. Novel interactions, such as sarcasm expressed through opposing spoken words and gestures or humor expressed through utterances and tone of voice, remain challenging. In this paper, we introduce an approach to enhance multimodal models, which we call Multimodal Mixtures of Experts (MMoE). The key idea in MMoE is to train separate expert models for each type of multimodal interaction, such as redundancy present in both modalities, uniqueness in one modality, or synergy that emerges when both modalities are fused. On a sarcasm detection task (MUStARD) and a humor detection task (URFUNNY), we obtain new state-of-the-art results. MMoE is also able to be applied to various types of models to gain improvement.",
    "year": 2023,
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "url": "https://www.semanticscholar.org/paper/9c133bce1fe4bd19b33c3052ccb5f345d6043f8c",
    "doi": "10.18653/v1/2024.emnlp-main.558",
    "arxivId": "2311.09580",
    "authors": "Haofei Yu, Zhengyang Qi, Lawrence Jang, R. Salakhutdinov, Louis-philippe Morency, Paul Pu Liang",
    "citationCount": 8
  },
  {
    "s2PaperId": "2aea22e8b3166b8e67e4945a8ccb1d8530d1f912",
    "title": "Partial Information Decomposition for Continuous Variables based on Shared Exclusions: Analytical Formulation and Estimation",
    "abstract": "Describing statistical dependencies is foundational to empirical scientific research. For uncovering intricate and possibly nonlinear dependencies between a single target variable and several source variables within a system, a principled and versatile framework can be found in the theory of partial information decomposition (PID). Nevertheless, the majority of existing PID measures are restricted to categorical variables, while many systems of interest in science are continuous. In this paper, we present a novel analytic formulation for continuous redundancy-a generalization of mutual information-drawing inspiration from the concept of shared exclusions in probability space as in the discrete PID definition of I_{∩}^{sx}. Furthermore, we introduce a nearest-neighbor-based estimator for continuous PID and showcase its effectiveness by applying it to a simulated energy management system provided by the Honda Research Institute Europe GmbH. This work bridges the gap between the measure-theoretically postulated existence proofs for a continuous I_{∩}^{sx} and its practical application to real-world scientific problems.",
    "year": 2023,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/2aea22e8b3166b8e67e4945a8ccb1d8530d1f912",
    "doi": "10.48550/arXiv.2311.06373",
    "arxivId": "2311.06373",
    "authors": "David A. Ehrlich, Kyle Schick-Poland, Abdullah Makkeh, Felix Lanfermann, Patricia Wollstadt, M. Wibral",
    "citationCount": 9
  },
  {
    "s2PaperId": "81a84c807d3d9cf129a4346bd69e38c7651b18ef",
    "title": "Transcranial ultrasound stimulation effect in the redundant and synergistic networks consistent across macaques",
    "abstract": "Low-intensity transcranial ultrasound stimulation (TUS) is a non-invasive technique that safely alters neural activity, reaching deep brain areas with good spatial accuracy. We investigated the effects of TUS at the level of macaque using a recent metric, the synergy minus redundancy rank gradient, that quantifies different kinds of causal neural information processing. We analyzed this high-order quantity on the fMRI data after TUS in two targets: the supplementary motor area (SMA-TUS) and the frontal polar cortex (FPC-TUS). The TUS produced specific changes at the limbic network at FPC-TUS and the motor network at SMA-TUS and altered, in both targets, the sensorimotor, temporal, and frontal networks, consistent across macaques. Moreover, there was a reduction in the structural and functional coupling after both stimulations. Finally, the TUS changed the intrinsic high-order network topology, decreasing the modular organization of the redundancy at SMA-TUS and increasing the synergistic integration at FPC-TUS.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/81a84c807d3d9cf129a4346bd69e38c7651b18ef",
    "doi": "10.1162/netn_a_00388",
    "arxivId": "",
    "authors": "Marilyn Gatica, C. Atkinson-Clement, P. Mediano, Mohammad Alkhawashki, James Ross, J. Sallet, Marcus Kaiser",
    "citationCount": 5
  },
  {
    "s2PaperId": "485e3feb999659b9301760088257f7092c10557f",
    "title": "Quantifying Hierarchical Selection",
    "abstract": "At what level does selective pressure effectively act? When considering the reproductive dynamics of interacting and mutating agents, it has long been debated whether selection is better understood by focusing on the individual or if hierarchical selection emerges as a consequence of joint adaptation. Despite longstanding efforts in theoretical ecology there is still no consensus on this fundamental issue, most likely due to the difficulty in obtaining adequate data spanning sufficient number of generations and the lack of adequate tools to quantify the effect of hierarchical selection. Here we capitalise on recent advances in information-theoretic data analysis to advance this state of affairs by investigating the emergence of high-order structures -- such as groups of species -- in the collective dynamics of the Tangled Nature model of evolutionary ecology. Our results show that evolutionary dynamics can lead to clusters of species that act as a selective group, that acquire information-theoretic agency. Overall, our findings provide quantitative evidence supporting the relevance of high-order structures in evolutionary ecology, which can emerge even from relatively simple processes of adaptation and selection.",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/485e3feb999659b9301760088257f7092c10557f",
    "doi": "",
    "arxivId": "2310.20386",
    "authors": "Hardik Rajpal, Clem von Stengel, P. Mediano, F. Rosas, Eduardo Viegas, P. Marquet, Henrik J. Jensen",
    "citationCount": 3
  },
  {
    "s2PaperId": "f420801e8968e314f98c0c1e1003e4b101280927",
    "title": "The serotonergic psychedelic N, N-dipropyltryptamine alters information-processing dynamics in cortical neural circuits",
    "abstract": "Most of the recent work in psychedelic neuroscience has been done using non-invasive neuroimaging, with data recorded from the brains of adult volunteers under the influence of a variety of drugs. While this data provides holistic insights into the effects of psychedelics on whole-brain dynamics, the effects of psychedelics on the meso-scale dynamics of cortical circuits remains much less explored. Here, we report the effects of the serotonergic psychedelic N,N-diproptyltryptamine (DPT) on information-processing dynamics in a sample of in vitro organotypic cultures made from rat cortical tissue. Three hours of spontaneous activity were recorded: an hour of pre-drug control, and hour of exposure to 10$\\mu$M DPT solution, and a final hour of washout, once again under control conditions. We found that DPT reversibly alters information dynamics in multiple ways: first, the DPT condition was associated with higher entropy of spontaneous firing activity and reduced the amount of time information was stored in individual neurons. Second, DPT also reduced the reversibility of neural activity, increasing the entropy produced and suggesting a drive away from equilibrium. Third, DPT altered the structure of neuronal circuits, decreasing the overall information flow coming into each neuron, but increasing the number of weak connections, creating a dynamic that combines elements of integration and disintegration. Finally, DPT decreased the higher-order statistical synergy present in sets of three neurons. Collectively, these results paint a complex picture of how psychedelics regulate information processing in meso-scale cortical tissue. Implications for existing hypotheses of psychedelic action, such as the Entropic Brain Hypothesis, are discussed.",
    "year": 2023,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/f420801e8968e314f98c0c1e1003e4b101280927",
    "doi": "10.48550/arXiv.2310.20582",
    "arxivId": "2310.20582",
    "authors": "Thomas F. Varley, Daniel Havert, Leandro Fosque, Abolfazl Alipour, Naruepon Weerawongphrom, Hiroki Naganobori, Lily O’Shea, Maria Pope, John Beggs",
    "citationCount": 1
  },
  {
    "s2PaperId": "ac83aa7c45690084d5a4282af28dd5c78632ae8d",
    "title": "Convergent Evolution of Prehistoric Technologies: the Entropy and Diversity of Limited Solutions",
    "abstract": "Linking the likelihood of convergent evolution to the technologies’ complexity, this paper identifies the scales of technological diffusion and convergence, i.e., the evolving of structures that are similar, but not related to a common “ancestor.” Our study provides quantitative measures for understanding complexity and connectivity in technologies. The utility of our approach is exemplified through the case study of Cucuteni-Tripolye pottery kilns in Chalcolithic Southeastern Europe. The analysis shows that technological evolution has to be scaled to the “technologically important” (in quantitative terms) component parts, whose introduction shapes a ground for extinction and self-evolvement caused by the cascade effects along technological design structure. Similar technological solutions to the technological design structure engender the spread of similar devices in various locations. Surprisingly, such a broad distribution may be the result of relatively low internal diversity, rather than arising from higher efficiency. This gives some reasons for the underestimation of convergence as a mechanism for evolution of technology in current prehistoric archaeology.",
    "year": 2023,
    "venue": "Journal of Archaeological Method and Theory",
    "url": "https://www.semanticscholar.org/paper/ac83aa7c45690084d5a4282af28dd5c78632ae8d",
    "doi": "10.1007/s10816-023-09623-8",
    "arxivId": "",
    "authors": "A. Diachenko, R. Rivers, I. Sobkowiak-Tabaka",
    "citationCount": 3
  },
  {
    "s2PaperId": "0b349cac39f1c521af21fd6aac7f9b7372fa8a66",
    "title": "Interpretable Diffusion via Information Decomposition",
    "abstract": "Denoising diffusion models enable conditional generation and density modeling of complex relationships like images and text. However, the nature of the learned relationships is opaque making it difficult to understand precisely what relationships between words and parts of an image are captured, or to predict the effect of an intervention. We illuminate the fine-grained relationships learned by diffusion models by noticing a precise relationship between diffusion and information decomposition. Exact expressions for mutual information and conditional mutual information can be written in terms of the denoising model. Furthermore, pointwise estimates can be easily estimated as well, allowing us to ask questions about the relationships between specific images and captions. Decomposing information even further to understand which variables in a high-dimensional space carry information is a long-standing problem. For diffusion models, we show that a natural non-negative decomposition of mutual information emerges, allowing us to quantify informative relationships between words and pixels in an image. We exploit these new relations to measure the compositional understanding of diffusion models, to do unsupervised localization of objects in images, and to measure effects when selectively editing images through prompt interventions.",
    "year": 2023,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/0b349cac39f1c521af21fd6aac7f9b7372fa8a66",
    "doi": "10.48550/arXiv.2310.07972",
    "arxivId": "2310.07972",
    "authors": "Xianghao Kong, Ollie Liu, Han Li, Dani Yogatama, G. V. Steeg",
    "citationCount": 25
  },
  {
    "s2PaperId": "2da41da2eb312ada8cd7c054ffc143375a7701ed",
    "title": "Tutorial on Multimodal Machine Learning: Principles, Challenges, and Open Questions",
    "abstract": "Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents capable of understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in healthcare and robotics, multimodality has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this tutorial is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. Building upon a new edition of our survey paper on multimodal ML and academic courses at CMU, this tutorial will cover three topics: (1) what is multimodal: the principles in learning from heterogeneous, connected, and interacting data, (2) why is it hard: a taxonomy of six core technical challenges faced in multimodal ML but understudied in unimodal ML, and (3) what is next: major directions for future research as identified by our taxonomy.",
    "year": 2023,
    "venue": "ICMI Companion",
    "url": "https://www.semanticscholar.org/paper/2da41da2eb312ada8cd7c054ffc143375a7701ed",
    "doi": "10.1145/3610661.3617602",
    "arxivId": "",
    "authors": "Paul Pu Liang, Louis-philippe Morency",
    "citationCount": 26
  },
  {
    "s2PaperId": "c1c81e86196115be9ca77f0e26494cdb70ad5753",
    "title": "Quantifying High-Order Interdependencies in Entangled Quantum States",
    "abstract": "Here, we leverage recent advances in information theory to develop a novel method to characterise the dominant character of the high-order dependencies of quantum systems. To this end, we introduce the Q-information: an information-theoretic measure capable of distinguishing quantum states dominated by synergy or redundancy. We illustrate the measure by investigating the properties of paradigmatic entangled Qubit states and find that -- in contrast to classical systems -- quantum systems need at least four variables to exhibit high-order properties. Furthermore, our results reveal that unitary evolution can radically affect the internal information organisation in a way that strongly depends on the corresponding Hamiltonian. Overall, the Q-information sheds light on novel aspects of the internal organisation of quantum systems and their time evolution, opening new avenues for studying several quantum phenomena and related technologies.",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/c1c81e86196115be9ca77f0e26494cdb70ad5753",
    "doi": "10.1103/PhysRevA.109.042605",
    "arxivId": "2310.03681",
    "authors": "M. A. Javarone, Fernando E. Rosas, P. Facchi, S. Pascazio, S. Stramaglia",
    "citationCount": 2
  },
  {
    "s2PaperId": "777cad26bd5702b329ae770cec99095cb213bc88",
    "title": "Afferents to Action: Cortical proprioceptive processing assessed with corticokinematic coherence specifically predicts gross motor skills",
    "abstract": "Voluntary motor control is thought to be predicated on the ability to efficiently integrate and process somatosensory afferent information. However, current approaches in the field of motor control have not factored in objective markers of how the brain actually tracks incoming somatosensory information. Here, we asked whether motor performance relates with such markers obtained with an analysis of the coupling between peripheral kinematics and cortical oscillations during continuous movements, best known as corticokinematic coherence (CKC). Motor performance was evaluated by measuring both gross and fine motor skills using the Box and Blocks Test (BBT) and the Purdue Pegboard Test (PPT), respectively, and with a biomechanics measure of coordination. Sixty-one participants completed the BBT, while equipped with electroencephalography and electromyography, and the PPT. We evaluated CKC, from the signals collected during the BBT, as the coherence between movement rhythmicity and brain activity, and coordination as the cross-correlation between muscle activity. CKC at movements’ first harmonic was positively associated with BBT scores, and showed a relationship with PPT scores, but only in synergy with BBT scores, where participants with lower PPT score had higher CKC than expected based on their BBT score. Coordination was not associated with motor performance and at most, weakly related to CKC. These findings demonstrate that cortical somatosensory processing in the form of strengthened brain-peripheral coupling is specifically associated with better gross motor skills. CKC might be considered as a valuable addition to classical tests of proprioceptive acuity, with important perspectives for future clinical studies and practice. Significance Statement Whether standing upright, jogging, or in Olympic competition, our nervous system not only sends out motor commands prompting muscles to contract, but also receives incoming information to fine-tune motor actions. Though the machinery involved in sensing mechanical changes is well-described, the neural processing of this information is not, making its relevance to motor function unresolved. We found that the coupling strength between peripheral kinematics and cortical activity was related to motor function and at most, only weakly related to conventional muscle-only assessments. We present novel behavioral relevance of this coupling and its specific relationship to gross motor skill. Our study paves the way for including novel brain-centered approaches to complement classical assessment sensorimotor functions in health and disease.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/777cad26bd5702b329ae770cec99095cb213bc88",
    "doi": "10.1101/2023.09.26.559273",
    "arxivId": "",
    "authors": "Mongold Scott, Georgiev Christian, Legrand Thomas, Bourguignon Mathieu",
    "citationCount": 0
  },
  {
    "s2PaperId": "1f85f85a68e856469d5908d14cdaf0c3e5e26ae8",
    "title": "Generalized decomposition of multivariate information",
    "abstract": "Since its introduction, the partial information decomposition (PID) has emerged as a powerful, information-theoretic technique useful for studying the structure of (potentially higher-order) interactions in complex systems. Despite its utility, the applicability of the PID is restricted by the need to assign elements as either “sources” or “targets”, as well as the specific structure of the mutual information itself. Here, I introduce a generalized information decomposition that relaxes the source/target distinction while still satisfying the basic intuitions about information. This approach is based on the decomposition of the Kullback-Leibler divergence, and consequently allows for the analysis of any information gained when updating from an arbitrary prior to an arbitrary posterior. As a result, any information-theoretic measure that can be written as a linear combination of Kullback-Leibler divergences admits a decomposition in the style of Williams and Beer, including the total correlation, the negentropy, and the mutual information as special cases. This paper explores how the generalized information decomposition can reveal novel insights into existing measures, as well as the nature of higher-order synergies. We show that synergistic information is intimately related to the well-known Tononi-Sporns-Edelman (TSE) complexity, and that synergistic information requires a similar integration/segregation balance as a high TSE complexity. Finally, I end with a discussion of how this approach fits into other attempts to generalize the PID and the possibilities for empirical applications.",
    "year": 2023,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/1f85f85a68e856469d5908d14cdaf0c3e5e26ae8",
    "doi": "10.1371/journal.pone.0297128",
    "arxivId": "2309.08003",
    "authors": "Thomas F. Varley",
    "citationCount": 12
  },
  {
    "s2PaperId": "2d54884a5f52e1d3a33c21c4a3e9acbf857faf3b",
    "title": "Exact and Soft Successive Refinement of the Information Bottleneck",
    "abstract": "The information bottleneck (IB) framework formalises the essential requirement for efficient information processing systems to achieve an optimal balance between the complexity of their representation and the amount of information extracted about relevant features. However, since the representation complexity affordable by real-world systems may vary in time, the processing cost of updating the representations should also be taken into account. A crucial question is thus the extent to which adaptive systems can leverage the information content of already existing IB-optimal representations for producing new ones, which target the same relevant features but at a different granularity. We investigate the information-theoretic optimal limits of this process by studying and extending, within the IB framework, the notion of successive refinement, which describes the ideal situation where no information needs to be discarded for adapting an IB-optimal representation’s granularity. Thanks in particular to a new geometric characterisation, we analytically derive the successive refinability of some specific IB problems (for binary variables, for jointly Gaussian variables, and for the relevancy variable being a deterministic function of the source variable), and provide a linear-programming-based tool to numerically investigate, in the discrete case, the successive refinement of the IB. We then soften this notion into a quantification of the loss of information optimality induced by several-stage processing through an existing measure of unique information. Simple numerical experiments suggest that this quantity is typically low, though not entirely negligible. These results could have important implications for (i) the structure and efficiency of incremental learning in biological and artificial agents, (ii) the comparison of IB-optimal observation channels in statistical decision problems, and (iii) the IB theory of deep neural networks.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2d54884a5f52e1d3a33c21c4a3e9acbf857faf3b",
    "doi": "10.3390/e25091355",
    "arxivId": "",
    "authors": "Hippolyte Charvin, Nicola Catenacci Volpi, Daniel Polani",
    "citationCount": 2
  },
  {
    "s2PaperId": "a081fe565079b46a837553ea4cb5106031b6a87e",
    "title": "Stable isotopes contain substantial additive information about terrestrial carbon and water cycling",
    "abstract": "Stable isotope ratios of H (δ 2 H), O (δ 18O), and C (δ 13C) are linked to key biogeochemical processes of the water and carbon cycles; however, the degree to which isotope-associated processes are reflected in macroscale ecosystem flux observations remains unquantified. Here through formal information assessment, new measurements of δ 13C of net ecosystem exchange (NEE) as well as δ 2H and δ 18O of latent heat (LH) fluxes across the United States National Ecological Observation Network (NEON) are used to determine conditions under which isotope measurements are informative of environmental exchanges. We find all three isotopic datasets individually contain comparable amounts of information about NEE and LH fluxes as wind speed observations. Such information from isotope measurements, however, is largely unique. Generally, δ 13C provides more information about LH as aridity increases or mean annual precipitation decreases. δ 2H provides more information about LH as temperatures or mean annual precipitation decreases, and also provides more information about NEE as temperatures decrease. Overall, we show that the stable isotope datasets collected by NEON contribute non-trivial amounts of new information about bulk environmental fluxes useful for interpreting biogeochemical and ecohydrological processes at landscape scales. However, the utility of this new information varies with environmental conditions at continental scales. This study provides an approach for quantifying the value adding non-traditional sensing approaches to environmental monitoring sites and the patterns identified here are expected to aid in modeling and data interpretation efforts focused on constraining carbon and water cycles’ mechanisms.",
    "year": 2023,
    "venue": "Environmental Research Letters",
    "url": "https://www.semanticscholar.org/paper/a081fe565079b46a837553ea4cb5106031b6a87e",
    "doi": "10.1088/1748-9326/acf4ab",
    "arxivId": "",
    "authors": "Bonan Li, S. Good, R. Fiorella, C. Finkenbiner, G. Bowen, D. Noone, C. Still, W. Anderegg",
    "citationCount": 4
  },
  {
    "s2PaperId": "d272de23afe972ac63c2fe82b493a66cc041ca68",
    "title": "Collective pooling of foraging information in animal fission-fusion dynamics",
    "abstract": "In animal species with fission-fusion dynamics, individuals can split from or follow others during collective movements. In spider monkeys (Ateles geoffroyi) this decision depends in part on the information they have about the location of available feeding trees. Foraging widely and continuously splitting and joining from others, individuals could be pooling their partial information such that the group as a whole has a more complete picture of a heterogeneous foraging environment. Here we use individual utilization areas over a realistic foraging landscape to infer the sets of potentially known trees by each individual. Then we measure the spatial entropy of these areas, considering tree species diversity and spatial distribution. We measure how complementary pairs of areas are, by decomposing the spatial entropy into redundant and unique components. We find that the areas uniquely known by each pair member still contain considerable amounts of information, but there is also a high redundancy in the information that a pair has about the foraging landscape. The networks joining individuals based on the unique information components seem to be structured efficiently for information transmission. Distributed foraging in fission-fusion dynamics would be an example of adaptive pooling of information and thus, collective intelligence.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/d272de23afe972ac63c2fe82b493a66cc041ca68",
    "doi": "10.1101/2023.06.16.545019",
    "arxivId": "",
    "authors": "G. Ramos-Fernández, Sandra E. Smith Aguilar",
    "citationCount": 0
  },
  {
    "s2PaperId": "fb97971b96d467976b0c8d691998d5c630a44e38",
    "title": "Finding emergence in data by maximizing effective information",
    "abstract": "ABSTRACT Quantifying emergence and modeling emergent dynamics in a data-driven manner for complex dynamical systems is challenging due to the fact that emergent behaviors cannot be directly captured by micro-level observational data. Thus, it is crucial to develop a framework to identify emergent phenomena and capture emergent dynamics at the macro-level using available data. Inspired by the theory of causal emergence (CE), this paper introduces a machine learning framework to learn macro-dynamics in an emergent latent space and quantify the degree of CE. The framework maximizes effective information, resulting in a macro-dynamics model with enhanced causal effects. Experimental results on simulated and real data demonstrate the effectiveness of the proposed framework. It quantifies degrees of CE effectively under various conditions and reveals distinct influences of different noise types. It can learn a one-dimensional coarse-grained macro-state from functional magnetic resonance imaging data to represent complex neural activities during movie clip viewing. Furthermore, improved generalization to different test environments is observed across all simulation data.",
    "year": 2023,
    "venue": "National Science Review",
    "url": "https://www.semanticscholar.org/paper/fb97971b96d467976b0c8d691998d5c630a44e38",
    "doi": "10.1093/nsr/nwae279",
    "arxivId": "2308.09952",
    "authors": "Mingzhe Yang, Zhipeng Wang, Kaiwei Liu, Ying Rong, Bing Yuan, Jiang Zhang",
    "citationCount": 9
  },
  {
    "s2PaperId": "3a121d77923fffbbf4b578a6f17b0c8be37f558d",
    "title": "Quantum Partial Information Decomposition",
    "abstract": "The Partial Information Decomposition (PID) takes one step beyond Shannon's theory in decomposing the information two variables $A,B$ possess about a third variable $T$ into distinct parts: unique, shared (or redundant) and synergistic information. Here we show how these concepts can be defined in a quantum setting. We apply a quantum PID to scrambling in quantum many-body systems, for which a quantum-theoretic description has been proven productive. Unique information in particular provides a finer description of scrambling than does the so-called tri-information.",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/3a121d77923fffbbf4b578a6f17b0c8be37f558d",
    "doi": "",
    "arxivId": "2308.04499",
    "authors": "S. J. Enk",
    "citationCount": 5
  },
  {
    "s2PaperId": "95be75de81cc094a129592fbc53eddc6835b446f",
    "title": "Quantifying direct associations between variables",
    "abstract": "",
    "year": 2023,
    "venue": "Fundamental Research",
    "url": "https://www.semanticscholar.org/paper/95be75de81cc094a129592fbc53eddc6835b446f",
    "doi": "10.1016/j.fmre.2023.06.012",
    "arxivId": "",
    "authors": "Minyuan Zhao, Yun Chen, Qin Liu, Sheng-Tong Wu",
    "citationCount": 1
  },
  {
    "s2PaperId": "fece099da70416cea4532d9fd9586a9b1c338c62",
    "title": "Gaussian Partial Information Decomposition: Bias Correction and Application to High-dimensional Data",
    "abstract": "Recent advances in neuroscientific experimental techniques have enabled us to simultaneously record the activity of thousands of neurons across multiple brain regions. This has led to a growing need for computational tools capable of analyzing how task-relevant information is represented and communicated between several brain regions. Partial information decompositions (PIDs) have emerged as one such tool, quantifying how much unique, redundant and synergistic information two or more brain regions carry about a task-relevant message. However, computing PIDs is computationally challenging in practice, and statistical issues such as the bias and variance of estimates remain largely unexplored. In this paper, we propose a new method for efficiently computing and estimating a PID definition on multivariate Gaussian distributions. We show empirically that our method satisfies an intuitive additivity property, and recovers the ground truth in a battery of canonical examples, even at high dimensionality. We also propose and evaluate, for the first time, a method to correct the bias in PID estimates at finite sample sizes. Finally, we demonstrate that our Gaussian PID effectively characterizes inter-areal interactions in the mouse brain, revealing higher redundancy between visual areas when a stimulus is behaviorally relevant.",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/fece099da70416cea4532d9fd9586a9b1c338c62",
    "doi": "10.48550/arXiv.2307.10515",
    "arxivId": "2307.10515",
    "authors": "Praveen Venkatesh, C. Bennett, Samuel D. Gale, Tamina Ramirez, Greggory Heller, S. Durand, Shawn R. Olsen, Stefan Mihalas",
    "citationCount": 9
  },
  {
    "s2PaperId": "c38ea5add9bc24517cbf88173bab34ab76587414",
    "title": "A Poisson Decomposition for Information and the Information-Event Diagram",
    "abstract": "Information diagram and the I-measure are useful mnemonics where random variables are treated as sets, and entropy and mutual information are treated as a signed measure. The theoretical underpinning of the “random variables as sets” analogy has been unclear until the recent works on mappings from random variables to sets by Ellerman (recovering order-2 Tsallis entropy over general probability space), and Down and Mediano (recovering Shannon entropy over discrete probability space). We generalize these constructions by designing a mapping which recovers the Shannon entropy (and the information density) over general probability space. Moreover, it has an intuitive interpretation based on the arrival time in a Poisson process, allowing us to understand the union, intersection and difference between (sets corresponding to) random variables and events. Cross entropy, KL divergence, and conditional entropy given an event, can be obtained as set intersections. We propose a generalization of the information diagram that also includes events, and demonstrate its usage by a diagrammatic proof of Fano's inequality.",
    "year": 2023,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/c38ea5add9bc24517cbf88173bab34ab76587414",
    "doi": "10.1109/ISIT57864.2024.10619612",
    "arxivId": "2307.07506",
    "authors": "Cheuk Ting Li",
    "citationCount": 4
  },
  {
    "s2PaperId": "40ab612503de4c0fa0713ee47ae22930f245c9b6",
    "title": "Information decomposition in complex systems via machine learning",
    "abstract": "Significance A defining characteristic of complex systems is an abundance of variation at one scale of observation that contains, hidden within, information about organization at another scale. To see the forest through the trees is a challenge faced whether studying society or a sandpile, climate, or a brain. We present a fully general and practical methodology, rigorously grounded in information theory, that surfaces important information out of a sea of variation in a comprehensible manner. At its core is the concept of lossy compression: Some information in a measurement is preserved, and the rest is discarded. We use machine learning to lossily compress tens to hundreds of measurements simultaneously, providing a route to insight about complex systems through information decomposition.",
    "year": 2023,
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "url": "https://www.semanticscholar.org/paper/40ab612503de4c0fa0713ee47ae22930f245c9b6",
    "doi": "10.1073/pnas.2312988121",
    "arxivId": "2307.04755",
    "authors": "Kieran A. Murphy, Danielle Bassett",
    "citationCount": 9
  },
  {
    "s2PaperId": "2c051b4652bbab1bc7aec3899f66ff145db8ab8a",
    "title": "More Synergy, Less Redundancy: Exploiting Joint Mutual Information for Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) is now a serious competitor for supervised learning, even though it does not require data annotation. Several baselines have attempted to make SSL models exploit information about data distribution, and less dependent on the augmentation effect. However, there is no clear consensus on whether maximizing or minimizing the mutual information between representations of augmentation views practically contribute to improvement or degradation in performance of SSL models. This paper is a fundamental work where, we investigate the role of mutual information in SSL, and reformulate the problem of SSL in the context of a new perspective on mutual information. To this end, we consider joint mutual information from the perspective of partial information decomposition (PID) as a key step in reliable multivariate information measurement. PID enables us to decompose joint mutual information into three important components, namely, unique information, redundant information and synergistic information. Our framework aims for minimizing the redundant information between views and the desired target representation while maximizing the synergistic information at the same time. Our experiments lead to a re-calibration of two redundancy reduction baselines, and a proposal for a new SSL training protocol. Experimental results on multiple datasets and two downstream tasks show the effectiveness of this framework.",
    "year": 2023,
    "venue": "International Conference on Information Photonics",
    "url": "https://www.semanticscholar.org/paper/2c051b4652bbab1bc7aec3899f66ff145db8ab8a",
    "doi": "10.1109/ICIP49359.2023.10222547",
    "arxivId": "2307.00651",
    "authors": "S. Mohamadi, Gianfranco Doretto, Don Adjeroh",
    "citationCount": 10
  },
  {
    "s2PaperId": "49af0332d4170b3a1e1ec8c246d91b98e0e5fcaa",
    "title": "Investigating Dynamic High-Order Interactions in Physiological Networks through Predictive Information Decomposition",
    "abstract": "We present an approach to assess redundant and synergistic interactions in network systems via the information-theoretic analysis of multivariate physiological processes. The approach sets up a strategy to decompose the information shared between the present states of a group of random processes and their own past states into unique contributions arising from the past of subgroups of processes and redundant and synergistic contributions arising from the dynamic interaction among the subgroups. The method is illustrated in a theoretical example of linearly interacting Gaussian processes, showing that redundancy and synergy are related mostly to unidirectional coupling and to bidirectional coupling with internal dynamics. It is then applied to the network of short-term heart period, arterial pressure and respiratory variability probed in healthy subjects, showing that redundancy and synergy prevail respectively in cardiorespiratory interactions and in cardiovascular interactions in the resting state, and that postural stress increases the predictive information and the redundancy of physiological interactions.",
    "year": 2023,
    "venue": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
    "url": "https://www.semanticscholar.org/paper/49af0332d4170b3a1e1ec8c246d91b98e0e5fcaa",
    "doi": "10.1109/EMBC40787.2023.10340690",
    "arxivId": "",
    "authors": "L. Faes, G. Mijatović, Laura Sparacino, Y. Antonacci, D. Marinazzo, S. Stramaglia",
    "citationCount": 0
  },
  {
    "s2PaperId": "9893db8beef36a26ef692faa418a3c909d02a169",
    "title": "Decomposing and Tracing Mutual Information by Quantifying Reachable Decision Regions",
    "abstract": "The idea of a partial information decomposition (PID) gained significant attention for attributing the components of mutual information from multiple variables about a target to being unique, redundant/shared or synergetic. Since the original measure for this analysis was criticized, several alternatives have been proposed but have failed to satisfy the desired axioms, an inclusion–exclusion principle or have resulted in negative partial information components. For constructing a measure, we interpret the achievable type I/II error pairs for predicting each state of a target variable (reachable decision regions) as notions of pointwise uncertainty. For this representation of uncertainty, we construct a distributive lattice with mutual information as consistent valuation and obtain an algebra for the constructed measure. The resulting definition satisfies the original axioms, an inclusion–exclusion principle and provides a non-negative decomposition for an arbitrary number of variables. We demonstrate practical applications of this approach by tracing the flow of information through Markov chains. This can be used to model and analyze the flow of information in communication networks or data processing systems.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/9893db8beef36a26ef692faa418a3c909d02a169",
    "doi": "10.3390/e25071014",
    "arxivId": "",
    "authors": "Tobias Mages, C. Rohner",
    "citationCount": 1
  },
  {
    "s2PaperId": "629bc13667cd258d6d0738f4bbab1a71da34349e",
    "title": "Assessing Information Transfer and Modification in Plateau Waves of Intracranial Pressure",
    "abstract": "Plateau waves (PW) of Intracranial Pressure occur mostly in patients with Traumatic Brain Injury (TBI) and preserved cerebral autoregulation. This cerebral vascular phenomenon is associated with an intense systemic stress response that can be evidenced by Heart Rate Variability (HRV), as a mirror of the autonomic nervous system dysfunction. The Network Physiology framework allows the multivariate and simultaneous analysis of the information processed in multiple interacting dynamical systems. In this study, we used the multiscale representation of Transfer Entropy (TE) within the network of interactions among slow waves and respiratory waves of Mean Arterial Pressure (MAP) and Intracranial Pressure (ICP), with the RR intervals. The decomposition into redundant and synergistic contributions, is obtained using a Vector AutoRegressive Fractionally Integrated (VARFI) framework for Gaussian processes. This recent method allows to assess directed interactions and to quantify the information flow accounting for the coexistence of short-term dynamics and long-range correlations. The results indicate that PWs are an extremely critical phenomenon with high persistence where the information transfer from MAP to RR is reduced. Moreover, the prevalence of synergistic interactions between MAP and ICP is observed, specially in the range of slow waves. The used approach enhanced the description of HRV during PW and was able to highlight the dependence of the information transfer on the balance between short-term and long-range correlations in this complex stress situation.",
    "year": 2023,
    "venue": "IEEE Portuguese Meeting on Bioengineering",
    "url": "https://www.semanticscholar.org/paper/629bc13667cd258d6d0738f4bbab1a71da34349e",
    "doi": "10.1109/ENBENG58165.2023.10175369",
    "arxivId": "",
    "authors": "Hélder Pinto, C. Dias, A. P. Rocha",
    "citationCount": 1
  },
  {
    "s2PaperId": "378956791620af85c24b40adf005bc19dd59ac6c",
    "title": "Measuring stimulus-related redundant and synergistic functional connectivity with single cell resolution in auditory cortex",
    "abstract": "Measures of functional connectivity have played a central role in advancing our understanding of how information is communicated within the brain. Traditionally, these studies have focused on identifying redundant functional connectivity, which involves determining when activity is similar across different sites. However, recent research has highlighted the potential importance of also identifying synergistic connectivity—that is, connectivity that gives rise to information not contained in either site alone. Here, we measured redundant and synergistic functional connectivity with individual-neuron resolution in the primary auditory cortex of the mouse during a perceptual task. Specifically, we identified pairs of neurons that exhibited directed functional connectivity between them, as measured using Granger Causality. We then used Partial Information Decomposition to quantify the amount of redundant and synergystic information carried by these neurons about auditory stimuli. Our findings revealed that functionally connected pairs carry proportionally more redundancy and less synergy than unconnected pairs, suggesting that their functional connectivity is primarily redundant in nature. Furthermore, we observe that the proportion of redundancy is higher for correct than for incorrect behavioral choices, supporting the notion that redundant connectivity is beneficial for behavior.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/378956791620af85c24b40adf005bc19dd59ac6c",
    "doi": "10.1101/2023.06.19.545531",
    "arxivId": "",
    "authors": "L. Koçillari, Marco Celotto, Nikolas A. Francis, Shoutik Mukherjee, B. Babadi, P. Kanold, S. Panzeri",
    "citationCount": 4
  },
  {
    "s2PaperId": "3f3d4cf406f2fc387308fae25f76e52e549051f7",
    "title": "System Information Decomposition",
    "abstract": "To characterize the complex higher-order interactions among variables within a system, this study introduces a novel framework, termed System Information Decomposition (SID), aimed at decomposing the information entropy of variables into information atoms based on their interrelations. Diverging from the established Partial Information Decomposition (PID) framework, which predominantly concentrates on the directional interactions stemming from an array of source variables to a single target variable, SID adopts a holistic approach, scrutinizing the interactions across all variables within the system. Specifically, we proved all the information atoms are symmetric, which means the disentanglement of unique, redundant, and synergistic information from any specific target variable. Hence, our proposed SID framework can capture the symmetric pairwise and higher-order relationships among variables. This advance positions SID as a promising framework with the potential to foster a deeper understanding of higher-order relationships within complex systems across disciplines.",
    "year": 2023,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/3f3d4cf406f2fc387308fae25f76e52e549051f7",
    "doi": "10.48550/arXiv.2306.08288",
    "arxivId": "2306.08288",
    "authors": "Aobo Lyu, B. Yuan, Ou Deng, Mingzhe Yang, Andrew Clark, Jiang Zhang",
    "citationCount": 2
  },
  {
    "s2PaperId": "670c735821c4240e3f3ae71f129fe96372785bb3",
    "title": "An information-theoretic quantification of the content of communication between brain regions",
    "abstract": "Quantifying the amount, content and direction of communication between brain regions is key to understanding brain function. Traditional methods to analyze brain activity based on the Wiener-Granger causality principle quantify the overall information propagated by neural activity between simultaneously recorded brain regions, but do not reveal the information flow about specific features of interest (such as sensory stimuli). Here, we develop a new information theoretic measure termed Feature-specific Information Transfer (FIT), quantifying how much information about a specific feature flows between two regions. FIT merges the Wiener-Granger causality principle with information-content specificity. We first derive FIT and prove analytically its key properties. We then illustrate and test them with simulations of neural activity, demonstrating that FIT identifies, within the total information flowing between regions, the information that is transmitted about specific features. We then analyze three neural datasets obtained with different recording methods, magneto- and electro-encephalography, and spiking activity, to demonstrate the ability of FIT to uncover the content and direction of information flow between brain regions beyond what can be discerned with traditional anaytical methods. FIT can improve our understanding of how brain regions communicate by uncovering previously hidden feature-specific information flow.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/670c735821c4240e3f3ae71f129fe96372785bb3",
    "doi": "10.1101/2023.06.14.544903",
    "arxivId": "",
    "authors": "Marco Celotto, J. Bím, A. Tlaie, Vito De Feo, Stefan Lemke, D. Chicharro, H. Nili, Malte Bieler, I. Hanganu-Opatz, T. Donner, A. Brovelli, S. Panzeri",
    "citationCount": 11
  },
  {
    "s2PaperId": "e1b2a35a000ca296c32284b323c7e36a28fe0693",
    "title": "Factorized Contrastive Learning: Going Beyond Multi-view Redundancy",
    "abstract": "In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/e1b2a35a000ca296c32284b323c7e36a28fe0693",
    "doi": "10.48550/arXiv.2306.05268",
    "arxivId": "2306.05268",
    "authors": "Paul Pu Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-philippe Morency, R. Salakhutdinov",
    "citationCount": 62
  },
  {
    "s2PaperId": "a988c09b7e76e86a93edcbf3f284dd028b0fb406",
    "title": "Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications",
    "abstract": "In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: how modalities combine to provide new task-relevant information that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contribution is the derivation of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds: one based on the shared information between modalities and the other based on disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings. We validate these estimated bounds and show how they accurately track true interactions. Finally, we show how these theoretical results can be used to estimate multimodal model performance, guide data collection, and select appropriate multimodal models for various tasks.",
    "year": 2023,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/a988c09b7e76e86a93edcbf3f284dd028b0fb406",
    "doi": "10.48550/arXiv.2306.04539",
    "arxivId": "2306.04539",
    "authors": "Paul Pu Liang, Chun Kai Ling, Yun Cheng, A. Obolenskiy, Yudong Liu, Rohan Pandey, Alex Wilf, Louis-philippe Morency, R. Salakhutdinov",
    "citationCount": 13
  },
  {
    "s2PaperId": "90b09bdb1bd78875ee8d8d324a568a36955e4765",
    "title": "Multimodal Fusion Interactions: A Study of Human and Automatic Quantification",
    "abstract": "In order to perform multimodal fusion of heterogeneous signals, we need to understand their interactions: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how humans annotate two categorizations of multimodal interactions: (1) partial labels, where different annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator annotates the label given the first modality before asking them to explicitly reason about how their answer changes when given the second. We further propose an alternative taxonomy based on (3) information decomposition, where annotators annotate the degrees of redundancy: the extent to which modalities individually and together give the same predictions, uniqueness: the extent to which one modality enables a prediction that the other does not, and synergy: the extent to which both modalities enable one to make a prediction that one would not otherwise make using individual modalities. Through experiments and annotations, we highlight several opportunities and limitations of each approach and propose a method to automatically convert annotations of partial and counterfactual labels to information decomposition, yielding an accurate and efficient method for quantifying multimodal interactions.",
    "year": 2023,
    "venue": "International Conference on Multimodal Interaction",
    "url": "https://www.semanticscholar.org/paper/90b09bdb1bd78875ee8d8d324a568a36955e4765",
    "doi": "10.1145/3577190.3614151",
    "arxivId": "2306.04125",
    "authors": "Paul Pu Liang, Yun Cheng, R. Salakhutdinov, Louis-philippe Morency",
    "citationCount": 8
  },
  {
    "s2PaperId": "79906b73bf4864ec4052879987306a7df9b5e385",
    "title": "A general framework for interpretable neural learning based on local information-theoretic goal functions",
    "abstract": "Significance Which learning goals must individual computational elements pursue to contribute to a network-level task solution? This local understanding is missing in both biological, but also artificial neural networks, despite their impressive performance. We address this question by characterizing the information processing motifs of individual neurons as local goal functions, derived from first principles of information theory. A simple parameterization then enables the definition of an abstract goal function that spans a broad space of different learning rules and tasks. The resulting “infomorphic” networks offer a constructive approach to understanding local learning and information processing in neural networks, creating a bridge between theoretical neuroscience and artificial intelligence.",
    "year": 2023,
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "url": "https://www.semanticscholar.org/paper/79906b73bf4864ec4052879987306a7df9b5e385",
    "doi": "10.1073/pnas.2408125122",
    "arxivId": "2306.02149",
    "authors": "Abdullah Makkeh, Marcel Graetz, A. C. Schneider, David A. Ehrlich, V. Priesemann, M. Wibral",
    "citationCount": 5
  },
  {
    "s2PaperId": "b14b916a6a6adaa227991c782222feeb155f79cb",
    "title": "From Babel to Boole: The Logical Organization of Information Decompositions",
    "abstract": "The field of partial information decomposition (PID) has become increasingly fragmented, with various proposed solutions approaching the problem from distinct perspectives. At the heart of each proposal lies what we call a  PID-inducing concept  —a type of information that, once formally specified, determines the PID components. Traditionally, redundancy has been the PID-inducing concept of choice, but other concepts, such as synergy, unique information and union information, have also been used. However, no cohesive logical framework exists to unify these approaches and clarify their relationships, particularly in the general case of      n      information sources. In this work, we introduce a unifying framework that connects PID components to Boolean functions and identifies PID-inducing concepts with logical conditions on these functions. We demonstrate that all existing PID-inducing concepts are special cases of this general construction. We also introduce novel concepts, including  vulnerable information  and  partner concepts  , and provide a comprehensive analysis of their properties, lattice structures and interrelationships.",
    "year": 2023,
    "venue": "Proceedings of the Royal Society A",
    "url": "https://www.semanticscholar.org/paper/b14b916a6a6adaa227991c782222feeb155f79cb",
    "doi": "10.48550/arXiv.2306.00734",
    "arxivId": "2306.00734",
    "authors": "A. Gutknecht, Abdullah Makkeh, M. Wibral",
    "citationCount": 4
  },
  {
    "s2PaperId": "d7764088b516c59ab4efa5f959d6f11bdc7d8adc",
    "title": "Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions",
    "abstract": "Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \\geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhance computational efficiency. We illustrate our results numerically with validations on synthetic data, and through an application to neuroimaging data.",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/d7764088b516c59ab4efa5f959d6f11bdc7d8adc",
    "doi": "10.48550/arXiv.2306.00904",
    "arxivId": "2306.00904",
    "authors": "Zhaolu Liu, R. Peach, P. Mediano, Mauricio Barahona",
    "citationCount": 5
  },
  {
    "s2PaperId": "2771e95c6f2c31cfa40732422e97022ac6eb8408",
    "title": "Routing by spontaneous synchronization",
    "abstract": "Selective attention allows to process stimuli which are behaviorally relevant, while attenuating distracting information. However, it is an open question what mechanisms implement selective routing, and how they are engaged in dependence on behavioral need. Here we introduce a novel framework for selective processing by spontaneous synchronization. Input signals become organized into 'avalanches' of synchronized spikes which propagate to target populations. Selective attention enhances spontaneous synchronization and boosts signal transfer by a simple disinhibition of a control population, without requiring changes in synaptic weights. Our framework is fully analytically tractable and provides a complete understanding of all stages of the routing mechanism, yielding closed-form expressions for input-output correlations. Interestingly, although gamma oscillations can naturally occur through a recurrent dynamics, we can formally show that the routing mechanism itself does not require such oscillatory activity and works equally well if synchronous events would be randomly shuffled over time. Our framework explains a large range of physiological findings in a unified framework and makes specific predictions about putative control mechanisms and their effects on neural dynamics.",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2771e95c6f2c31cfa40732422e97022ac6eb8408",
    "doi": "",
    "arxivId": "2305.13914",
    "authors": "M. Schunemann, U. Ernst",
    "citationCount": 0
  },
  {
    "s2PaperId": "43b87af59b94824073b7a16113cd960610738030",
    "title": "A Logarithmic Decomposition for Information",
    "abstract": "The Shannon entropy of a random variable X has much behaviour analogous to a signed measure. Previous work has concretized this connection by defining a signed measure µ on an abstract information space $\\tilde X$, which is taken to represent the information that X contains. This construction is sufficient to derive many measure-theoretical counterparts to information quantities such as the mutual information $I(X;Y) = \\mu (\\tilde X \\cap \\tilde Y)$, the joint entropy $H(X,Y) = \\mu (\\tilde X \\cup \\tilde Y)$, and the conditional entropy $H(X|Y) = \\mu (\\tilde X\\backslash \\tilde Y)$. We demonstrate that there exists a much finer decomposition with intuitive properties which we call the logarithmic decomposition (LD). We show that this signed measure space has the useful property that its logarithmic atoms are easily characterised with negative or positive entropy, while also being coherent with Yeung’s I-measure [14]. We present the usability of our approach by re-examining the Gács-Körner common information from this new geometric perspective and characterising it in terms of our logarithmic atoms. We then highlight that our geometric refinement can account for an entire class of information quantities, which we call logarithmically decomposable quantities.",
    "year": 2023,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/43b87af59b94824073b7a16113cd960610738030",
    "doi": "10.1109/ISIT54713.2023.10206673",
    "arxivId": "2305.07554",
    "authors": "Keenan J. A. Down, P. Mediano",
    "citationCount": 6
  },
  {
    "s2PaperId": "d1fd7b9cc6432dc05c3d05669ea5234817ee1369",
    "title": "Computing Unique Information for Poisson and Multinomial Systems",
    "abstract": "Bivariate Partial Information Decomposition (PID) describes how the mutual information between a random variable M and two random variables Y and Z is decomposed into unique, redundant, and synergistic terms. Recently, PID has shown promise as an emerging tool to understand biological systems and biases in machine learning. However, computing PID is a challenging problem as it typically involves optimizing over distributions. In this work, we study the problem of computing PID in two systems: the Poisson system inspired by the 'ideal Poisson channel' and the multinomial system inspired by multinomial thinning, for a scalar M. We provide sufficient conditions for both systems under which closed-form expressions for many operationally-motivated PID can be obtained, thereby allowing us to easily compute PID for these systems. Our proof consists of showing that one of the unique information terms is zero, which allows the remaining unique, redundant, and synergistic terms to be easily computed using only the marginal and the joint mutual information.",
    "year": 2023,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/d1fd7b9cc6432dc05c3d05669ea5234817ee1369",
    "doi": "10.48550/arXiv.2305.07013",
    "arxivId": "2305.07013",
    "authors": "Chaitanya Goswami, Amanda Merkley, P. Grover",
    "citationCount": 1
  },
  {
    "s2PaperId": "686c210851b9170b8a9343be613ace82c9a65c81",
    "title": "Orders between Channels and Implications for Partial Information Decomposition",
    "abstract": "The partial information decomposition (PID) framework is concerned with decomposing the information that a set of random variables has with respect to a target variable into three types of components: redundant, synergistic, and unique. Classical information theory alone does not provide a unique way to decompose information in this manner, and additional assumptions have to be made. Recently, Kolchinsky proposed a new general axiomatic approach to obtain measures of redundant information based on choosing an order relation between information sources (equivalently, order between communication channels). In this paper, we exploit this approach to introduce three new measures of redundant information (and the resulting decompositions) based on well-known preorders between channels, contributing to the enrichment of the PID landscape. We relate the new decompositions to existing ones, study several of their properties, and provide examples illustrating their novelty. As a side result, we prove that any preorder that satisfies Kolchinsky’s axioms yields a decomposition that meets the axioms originally introduced by Williams and Beer when they first proposed PID.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/686c210851b9170b8a9343be613ace82c9a65c81",
    "doi": "10.3390/e25070975",
    "arxivId": "2305.06021",
    "authors": "André F. C. Gomes, Mário A. T. Figueiredo",
    "citationCount": 3
  },
  {
    "s2PaperId": "53640454e1f4f3b17367dce45029bfdfc4465217",
    "title": "Causal Information Splitting: Engineering Proxy Features for Robustness to Distribution Shifts",
    "abstract": "Statistical prediction models are often trained on data from different probability distributions than their eventual use cases. One approach to proactively prepare for these shifts harnesses the intuition that causal mechanisms should remain invariant between environments. Here we focus on a challenging setting in which the causal and anticausal variables of the target are unobserved. Leaning on information theory, we develop feature selection and engineering techniques for the observed downstream variables that act as proxies. We identify proxies that help to build stable models and moreover utilize auxiliary training tasks to answer counterfactual questions that extract stability-enhancing information from proxies. We demonstrate the effectiveness of our techniques on synthetic and real data.",
    "year": 2023,
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/53640454e1f4f3b17367dce45029bfdfc4465217",
    "doi": "10.48550/arXiv.2305.05832",
    "arxivId": "2305.05832",
    "authors": "Bijan Mazaheri, Atalanti A. Mastakouri, D. Janzing, Mila Hardt",
    "citationCount": 4
  },
  {
    "s2PaperId": "ac69f4d010aef5c0f50ea41225bfe2c1e6b67dbf",
    "title": "Robust and consistent measures of pattern separation based on information theory and demonstrated in the dentate gyrus",
    "abstract": "Pattern separation is a valuable computational function performed by neuronal circuits, such as the dentate gyrus, where dissimilarity between inputs is increased, reducing noise and increasing the storage capacity of downstream networks. Pattern separation is studied from both in vivo experimental and computational perspectives and, a number of different measures (such as orthogonalisation, decorrelation, or spike train distance) have been applied to quantify the process of pattern separation. However, these are known to give conclusions that can differ qualitatively depending on the choice of measure and the parameters used to calculate it. We here demonstrate that arbitrarily increasing sparsity, a noticeable feature of dentate granule cell firing and one that is believed to be key to pattern separation, typically leads to improved classical measures for pattern separation even, inappropriately, up to the point where almost all information about the inputs is lost. Standard measures therefore both cannot differentiate between pattern separation and pattern destruction, and give results that may depend on arbitrary parameter choices. We propose that techniques from information theory, in particular mutual information, transfer entropy, and redundancy, should be applied to penalise the potential for lost information (often due to increased sparsity) that is neglected by existing measures. We compare five commonly-used measures of pattern separation with three novel techniques based on information theory, showing that the latter can be applied in a principled way and provide a robust and reliable measure for comparing the pattern separation performance of different neurons and networks. We demonstrate our new measures on detailed compartmental models of individual dentate granule cells and a dentate microcircuit, and show how structural changes associated with epilepsy affect pattern separation performance. We also demonstrate how our measures of pattern separation can predict pattern completion accuracy. Overall, our measures solve a widely acknowledged problem in assessing the pattern separation of neural circuits such as the dentate gyrus, as well as the cerebellum and mushroom body. Finally we provide a publicly available toolbox allowing for easy analysis of pattern separation in spike train ensembles. Author summary The hippocampus is a region of the brain strongly associated with spatial navigation and encoding of episodic memories. To perform these functions effectively it makes use of circuits that perform pattern separation, where redundant structure is removed from neural representations leaving only the most salient information. Pattern separation allows downstream pattern completion networks to better distinguish between similar situations. Pathological changes, caused by Alzheimer’s, schizophrenia, or epilepsy, to the circuits that perform pattern separation are associated with reduced discriminative ability in both animal models and humans. Traditionally, pattern separation has been described alongside the complementary process of pattern completion, but more recent studies have focussed on the detailed neuronal and circuit features that contribute to pattern separation alone. We here show that traditional measures of pattern separation are inappropriate in this case, as they do not give consistent conclusions when parameters are changed and can confound pattern separation with the loss of important information. We show that directly accounting for the information throughput of a pattern separation circuit can provide new measures of pattern separation that are robust and consistent, and allow for nuanced analysis of the structure-function relationship of such circuits and how this may be perturbed by pathology.",
    "year": 2023,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/ac69f4d010aef5c0f50ea41225bfe2c1e6b67dbf",
    "doi": "10.1101/2022.11.04.515143",
    "arxivId": "",
    "authors": "Alexander D. Bird, Hermann Cuntz, P. Jedlicka",
    "citationCount": 2
  },
  {
    "s2PaperId": "ef96956b3ca54d7634a0765da9daeb9753da5227",
    "title": "A Review of Partial Information Decomposition in Algorithmic Fairness and Explainability",
    "abstract": "Partial Information Decomposition (PID) is a body of work within information theory that allows one to quantify the information that several random variables provide about another random variable, either individually (unique information), redundantly (shared information), or only jointly (synergistic information). This review article aims to provide a survey of some recent and emerging applications of partial information decomposition in algorithmic fairness and explainability, which are of immense importance given the growing use of machine learning in high-stakes applications. For instance, PID, in conjunction with causality, has enabled the disentanglement of the non-exempt disparity which is the part of the overall disparity that is not due to critical job necessities. Similarly, in federated learning, PID has enabled the quantification of tradeoffs between local and global disparities. We introduce a taxonomy that highlights the role of PID in algorithmic fairness and explainability in three main avenues: (i) Quantifying the legally non-exempt disparity for auditing or training; (ii) Explaining contributions of various features or data points; and (iii) Formalizing tradeoffs among different disparities in federated learning. Lastly, we also review techniques for the estimation of PID measures, as well as discuss some challenges and future directions.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ef96956b3ca54d7634a0765da9daeb9753da5227",
    "doi": "10.3390/e25050795",
    "arxivId": "",
    "authors": "Sanghamitra Dutta, Faisal Hamman",
    "citationCount": 11
  },
  {
    "s2PaperId": "97b1f4980fc173e59ff3a3bdaf1b9a13965fb32e",
    "title": "To Compress or Not to Compress—Self-Supervised Learning and Information Theory: A Review",
    "abstract": "Deep neural networks excel in supervised learning tasks but are constrained by the need for extensive labeled data. Self-supervised learning emerges as a promising alternative, allowing models to learn without explicit labels. Information theory has shaped deep neural networks, particularly the information bottleneck principle. This principle optimizes the trade-off between compression and preserving relevant information, providing a foundation for efficient network design in supervised contexts. However, its precise role and adaptation in self-supervised learning remain unclear. In this work, we scrutinize various self-supervised learning approaches from an information-theoretic perspective, introducing a unified framework that encapsulates the self-supervised information-theoretic learning problem. This framework includes multiple encoders and decoders, suggesting that all existing work on self-supervised learning can be seen as specific instances. We aim to unify these approaches to understand their underlying principles better and address the main challenge: many works present different frameworks with differing theories that may seem contradictory. By weaving existing research into a cohesive narrative, we delve into contemporary self-supervised methodologies, spotlight potential research areas, and highlight inherent challenges. Moreover, we discuss how to estimate information-theoretic quantities and their associated empirical problems. Overall, this paper provides a comprehensive review of the intersection of information theory, self-supervised learning, and deep neural networks, aiming for a better understanding through our proposed unified approach.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/97b1f4980fc173e59ff3a3bdaf1b9a13965fb32e",
    "doi": "10.3390/e26030252",
    "arxivId": "2304.09355",
    "authors": "Ravid Shwartz-Ziv, Yann LeCun",
    "citationCount": 80
  },
  {
    "s2PaperId": "2453fc7c40e9c740ca025905ad743a11c1ba203b",
    "title": "Biological Network Mining.",
    "abstract": "",
    "year": 2023,
    "venue": "Methods in molecular biology",
    "url": "https://www.semanticscholar.org/paper/2453fc7c40e9c740ca025905ad743a11c1ba203b",
    "doi": "10.1007/978-1-0716-1534-8_8",
    "arxivId": "",
    "authors": "Z. Yue, Da Yan, Guimu Guo, J. Chen",
    "citationCount": 3
  },
  {
    "s2PaperId": "6dab08e8bf55591f45f6fa4259abeb9fd38263ce",
    "title": "MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation",
    "abstract": "This paper tackles the problem of semi-supervised video object segmentation on resource-constrained devices, such as mobile phones. We formulate this problem as a distillation task, whereby we demonstrate that small space-time-memory networks with finite memory can achieve competitive results with state of the art, but at a fraction of the computational cost (32 milliseconds per frame on a Samsung Galaxy S22). Specifically, we provide a theoretically grounded framework that unifies knowledge distillation with supervised contrastive representation learning. These models are able to jointly benefit from both pixel-wise contrastive learning and distillation from a pre-trained teacher. We validate this loss by achieving competitive J &F to state of the art on both the standard DAVIS and YouTube benchmarks, despite running up to × 5 faster, and with × 32 fewer parameters.",
    "year": 2023,
    "venue": "Computer Vision and Pattern Recognition",
    "url": "https://www.semanticscholar.org/paper/6dab08e8bf55591f45f6fa4259abeb9fd38263ce",
    "doi": "10.1109/CVPR52729.2023.01010",
    "arxivId": "2303.07815",
    "authors": "Roy Miles, M. K. Yucel, Bruno Manganelli, Albert Saà-Garriga",
    "citationCount": 27
  },
  {
    "s2PaperId": "ecd823203e78b8d97ea57046ef767453aeb59dc2",
    "title": "Measuring Multi-Source Redundancy in Factor Graphs",
    "abstract": "Factor graphs are a ubiquitous tool for multisource inference in robotics and multi-sensor networks. They allow for heterogeneous measurements from many sources to be concurrently represented as factors in the state posterior distribution, so that inference can be conducted via sparse graphical methods. Adding measurements from many sources can supply robustness to state estimation, as seen in distributed pose graph optimization. However, adding excessive measurements to a factor graph can also quickly degrade their performance as more cycles are added to the graph. In both situations, the relevant quality is the redundancy of information. Drawing on recent work in information theory on partial information decomposition (PID), we articulate two potential definitions of redundancy in factor graphs, both within a common axiomatic framework for redundancy in factor graphs. This is the first application of PID to factor graphs, and only one of a few quantitative measures of redundancy.",
    "year": 2023,
    "venue": "Fusion",
    "url": "https://www.semanticscholar.org/paper/ecd823203e78b8d97ea57046ef767453aeb59dc2",
    "doi": "10.23919/FUSION52260.2023.10224193",
    "arxivId": "2303.07105",
    "authors": "Jesse Milzman, Andre Harrison, Carlos Nieto-Granda, J. Rogers",
    "citationCount": 0
  },
  {
    "s2PaperId": "811b462dce7cc027d4eccf112afbeaec7e27a1fb",
    "title": "Connectivity Analysis in EEG Data: A Tutorial Review of the State of the Art and Emerging Trends",
    "abstract": "Understanding how different areas of the human brain communicate with each other is a crucial issue in neuroscience. The concepts of structural, functional and effective connectivity have been widely exploited to describe the human connectome, consisting of brain networks, their structural connections and functional interactions. Despite high-spatial-resolution imaging techniques such as functional magnetic resonance imaging (fMRI) being widely used to map this complex network of multiple interactions, electroencephalographic (EEG) recordings claim high temporal resolution and are thus perfectly suitable to describe either spatially distributed and temporally dynamic patterns of neural activation and connectivity. In this work, we provide a technical account and a categorization of the most-used data-driven approaches to assess brain-functional connectivity, intended as the study of the statistical dependencies between the recorded EEG signals. Different pairwise and multivariate, as well as directed and non-directed connectivity metrics are discussed with a pros–cons approach, in the time, frequency, and information-theoretic domains. The establishment of conceptual and mathematical relationships between metrics from these three frameworks, and the discussion of novel methodological approaches, will allow the reader to go deep into the problem of inferring functional connectivity in complex networks. Furthermore, emerging trends for the description of extended forms of connectivity (e.g., high-order interactions) are also discussed, along with graph-theory tools exploring the topological properties of the network of connections provided by the proposed metrics. Applications to EEG data are reviewed. In addition, the importance of source localization, and the impacts of signal acquisition and pre-processing techniques (e.g., filtering, source localization, and artifact rejection) on the connectivity estimates are recognized and discussed. By going through this review, the reader could delve deeply into the entire process of EEG pre-processing and analysis for the study of brain functional connectivity and learning, thereby exploiting novel methodologies and approaches to the problem of inferring connectivity within complex networks.",
    "year": 2023,
    "venue": "Bioengineering",
    "url": "https://www.semanticscholar.org/paper/811b462dce7cc027d4eccf112afbeaec7e27a1fb",
    "doi": "10.3390/bioengineering10030372",
    "arxivId": "",
    "authors": "Giovanni Chiarion, Laura Sparacino, Y. Antonacci, L. Faes, L. Mesin",
    "citationCount": 90
  },
  {
    "s2PaperId": "0126f8d40bd682b1c4659f3f7d2a64fb6a515354",
    "title": "Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework",
    "abstract": "The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations are compared with human annotations. Finally, we demonstrate their usefulness in (1) quantifying interactions within multimodal datasets, (2) quantifying interactions captured by multimodal models, (3) principled approaches for model selection, and (4) three real-world case studies engaging with domain experts in pathology, mood prediction, and robotic perception where our framework helps to recommend strong multimodal models for each application.",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/0126f8d40bd682b1c4659f3f7d2a64fb6a515354",
    "doi": "",
    "arxivId": "2302.12247",
    "authors": "Paul Pu Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Nicholas Allen, R. Auerbach, Faisal Mahmood, R. Salakhutdinov, Louis-philippe Morency",
    "citationCount": 37
  },
  {
    "s2PaperId": "38c7609e5a8b0ee0dccd7318da5bf33a1199d27a",
    "title": "Capturing and Interpreting Unique Information",
    "abstract": "Partial information decompositions (PIDs), which quantify information interactions between three or more variables in terms of uniqueness, redundancy and synergy, are gaining traction in many application domains. However, our understanding of the operational interpretations of PIDs is still incomplete for many popular PID definitions. In this paper, we discuss the operational interpretations of unique information through the lens of two well-known PID definitions. We reexamine an interpretation from statistical decision theory showing how unique information upper bounds the risk in a decision problem. We then explore a new connection between the two PIDs, which allows us to develop an informal but appealing interpretation, and generalize the PID definitions using a common Lagrangian formulation. Finally, we provide a new PID definition that is able to capture the information that is unique. We also show that it has a straightforward interpretation and examine its properties.The full version of this paper is available online [1].",
    "year": 2023,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/38c7609e5a8b0ee0dccd7318da5bf33a1199d27a",
    "doi": "10.1109/ISIT54713.2023.10206597",
    "arxivId": "2302.11873",
    "authors": "Praveen Venkatesh, Keerthana Gurushankar, Gabriel Schamberg",
    "citationCount": 5
  },
  {
    "s2PaperId": "61dc8087ad013decbfa601720284a461336b5b28",
    "title": "A statistical approach to topological entanglement: Boltzmann machine representation of higher-order irreducible correlation",
    "abstract": "Higher-order correlation is an interesting phenomena in many fields of physics and statistics. A quantum analogue of the higher-order correlation is the topological entanglement in topologically ordered states of matter at zero temperature, usually quantified by topological entanglement entropy (TEE). In this work we propose a statistical interpretation which unifies the two under the same information-theoretic framework. We demonstrate that the existence of a non-zero TEE can be understood in the statistical view as the emergent $n$th order mutual information $I_n$ (for arbitrary integer $n\\ge 3$) reflected in projectively measured samples, which also makes explicit the equivalence between the two existing methods for its extraction -- the Kitaev-Preskill and the Levin-Wen construction. To exploit the statistical nature of $I_n$, we construct a restricted Boltzmann machine (RBM) which captures the higher-order correlation and/or topological entanglement that are encoded in the distribution of projected sample by representing the entanglement Hamiltonian of a local region under the proper basis. Furthermore, we derive a closed form which presents a method to interrogate the trained RBM, making explicit the analytical form of arbitrary order of correlation relevant for $I_n$ in terms of the entanglement Hamiltonian. We remark that the interrogation method for extracting higher-order correlation can also be applied in the construction of auxiliary fields which disentangle many-body interactions relevant for diverse interacting models.",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/61dc8087ad013decbfa601720284a461336b5b28",
    "doi": "",
    "arxivId": "2302.03212",
    "authors": "Shih-Wen Feng, Deqian Kong, N. Trivedi",
    "citationCount": 4
  },
  {
    "s2PaperId": "70eb9b4bea04889bbbbd65749cfc75c1b3f1efaf",
    "title": "Pooling probability distributions and partial information decomposition.",
    "abstract": "Notwithstanding various attempts to construct a partial information decomposition (PID) for multiple variables by defining synergistic, redundant, and unique information, there is no consensus on how one ought to precisely define either of these quantities. One aim here is to illustrate how that ambiguity-or, more positively, freedom of choice-may arise. Using the basic idea that information equals the average reduction in uncertainty when going from an initial to a final probability distribution, synergistic information will likewise be defined as a difference between two entropies. One term is uncontroversial and characterizes \"the whole\" information that source variables carry jointly about a target variable T. The other term then is meant to characterize the information carried by the \"sum of its parts.\" Here we interpret that concept as needing a suitable probability distribution aggregated (\"pooled\") from multiple marginal distributions (the parts). Ambiguity arises in the definition of the optimum way to pool two (or more) probability distributions. Independent of the exact definition of optimum pooling, the concept of pooling leads to a lattice that differs from the often-used redundancy-based lattice. One can associate not just a number (an average entropy) with each node of the lattice, but (pooled) probability distributions. As an example, one simple and reasonable approach to pooling is presented, which naturally gives rise to the overlap between different probability distributions as being a crucial quantity that characterizes both synergistic and unique information.",
    "year": 2023,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/70eb9b4bea04889bbbbd65749cfc75c1b3f1efaf",
    "doi": "10.1103/PhysRevE.107.054133",
    "arxivId": "2302.02251",
    "authors": "S. J. Enk",
    "citationCount": 4
  },
  {
    "s2PaperId": "17fd1203a06e7c00bce85f631686a35ac5dc64de",
    "title": "Quick Estimate of Information Decomposition for Text Style Transfer",
    "abstract": "A growing number of papers on style transfer for texts rely on information decomposition. The performance of the resulting systems is usually assessed empirically in terms of the output quality or requires laborious experiments. This paper suggests a straightforward information theoretical framework to assess the quality of information decomposition for latent representations in the context of style transfer. Experimenting with several state-of-the-art models, we demonstrate that such estimates could be used as a fast and straightforward health check for the models instead of more laborious empirical experiments.",
    "year": 2023,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/17fd1203a06e7c00bce85f631686a35ac5dc64de",
    "doi": "10.3390/e25020322",
    "arxivId": "",
    "authors": "Viacheslav Shibaev, E. Olbrich, J. Jost, Ivan P. Yamshchikov",
    "citationCount": 1
  },
  {
    "s2PaperId": "bddcd7f31a078a64967f1a99f07c1d01fbdd5e20",
    "title": "Causal Analysis of Influence of the Solar Cycle and Latitudinal Solar-Wind Structure on Co-Rotation Forecasts",
    "abstract": "Studying solar-wind conditions is central to forecasting the impact of space weather on Earth. Under the assumption that the structure of this wind is constant in time and co-rotates with the Sun, solar-wind and thereby space-weather forecasts have been made quite effectively. Such co-rotation forecasts are well studied with decades of observations from STEREO and near-Earth spacecraft. Forecast accuracy is primarily determined by three factors: i) the longitudinal separation of spacecraft from Earth determines the corotation time (and hence forecast lead time) [$\\delta$  δ  t] over which the solar wind must be assumed to be constant, ii) the latitudinal separation (or offset) between Earth and spacecraft [$\\delta\\theta$  δ  θ  ]] determines the degree to which the same solar wind is being encountered at both locations, and iii) the solar cycle, via the sunspot number (SSN), acts as a proxy for both how fast the solar-wind structure is evolving and how much it varies in latitude. However, the precise dependencies factoring in uncertainties are a mixture of influences from each of these factors. Furthermore, for high-precision forecasts, it is important to understand what drives the forecast accuracy and its uncertainty. Here we present a causal inference approach based on information-theoretic measures to do this. Our framework can compute not only the direct (linear and nonlinear) dependencies of the forecast mean absolute error (MAE) on SSN, $\\Delta \\theta $  Δ  θ  , and $\\Delta t$  Δ  t  , but also how these individual variables combine to enhance or diminish the MAE. We provide an initial assessment of this with the potential of aiding data assimilation in the future.",
    "year": 2023,
    "venue": "Solar Physics",
    "url": "https://www.semanticscholar.org/paper/bddcd7f31a078a64967f1a99f07c1d01fbdd5e20",
    "doi": "10.1007/s11207-023-02232-4",
    "arxivId": "2301.11904",
    "authors": "N. Chakraborty, H. Turner, M. Owens, M. Lang",
    "citationCount": 0
  },
  {
    "s2PaperId": "600088a99b0f7a7a49fd254cd6a23d3616cb050d",
    "title": "Partial entropy decomposition reveals higher-order information structures in human brain activity",
    "abstract": "Significance One of the most common ways scientists understand the brain is as a network. This approach is limited, though; since everything is built out of pairs, there is no way to directly assess the interaction of three or more elements at once. In this paper, we use information theory to explore the information that is synergistic (i.e., cannot be reduced to pairs of nodes). We find that synergistic information is very widespread and is invisible to standard network-based approaches. This structure is complex and changes over time, opening a vast space to explore for brain/behavior relationships.",
    "year": 2023,
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "url": "https://www.semanticscholar.org/paper/600088a99b0f7a7a49fd254cd6a23d3616cb050d",
    "doi": "10.1073/pnas.2300888120",
    "arxivId": "2301.05307",
    "authors": "Thomas F. Varley, Maria Pope, M. G. Puxeddu, Joshua Faskowitz, O. Sporns",
    "citationCount": 56
  },
  {
    "s2PaperId": "c8a0f8b532899e5448dfd7e30dba20fb682afd05",
    "title": "Synergistic small worlds that drive technological sophistication",
    "abstract": "Abstract It is a well-known fact that economic growth goes hand in hand with improvements in technological sophistication. While critical to such sophistication, the nature and underlying structure of the input interactions taking place inside production processes remain opaque, at least in the study of large systems such as industries and entire economies. We develop a method to quantify the degree of input complementarity in production processes form input–output data. We propose that the information-theoretic concept of synergistic information is analog to economic complementarity and exploit this link to create a data-driven approach that does not require the ex ante assumption of production functions. In contrast to alternative empirical approaches, our method is able identify input–input interactions and to quantify their contribution to output, revealing an input–input synergistic interaction network that characterizes an industry’s productive technology. We find that more sophisticated industries tend to exhibit highly modular small-world topologies; with the tertiary sector as its central connective core. Overall, countries and industries that have a well-established connective core and specialized modules exhibit higher economic complexity, higher output, and lower emissions. The proposed method provides a framework to identify key relationships in the economy that can enhance economic performance.",
    "year": 2023,
    "venue": "PNAS Nexus",
    "url": "https://www.semanticscholar.org/paper/c8a0f8b532899e5448dfd7e30dba20fb682afd05",
    "doi": "10.1093/pnasnexus/pgaf102",
    "arxivId": "2301.04579",
    "authors": "Hardik Rajpal, Omar A. Guerrero",
    "citationCount": 0
  },
  {
    "s2PaperId": "57ebeeaff88ba14082d63e51e75dd80e8fa84869",
    "title": "Computational methods to study information processing in neural circuits",
    "abstract": "",
    "year": 2023,
    "venue": "Computational and Structural Biotechnology Journal",
    "url": "https://www.semanticscholar.org/paper/57ebeeaff88ba14082d63e51e75dd80e8fa84869",
    "doi": "10.1016/j.csbj.2023.01.009",
    "arxivId": "",
    "authors": "V. Koren, Giulio Bondanelli, S. Panzeri",
    "citationCount": 8
  },
  {
    "s2PaperId": "da0dc5f03ebc29d3326f264396ba8586d118389b",
    "title": "Neuroevolution gives rise to more focused information transfer compared to backpropagation in recurrent neural networks",
    "abstract": "Artificial neural networks (ANNs) are one of the most promising tools in the quest to develop general artificial intelligence. Their design was inspired by how neurons in natural brains connect and process, the only other substrate to harbor intelligence. Compared to biological brains that are sparsely connected and that form sparsely distributed representations, ANNs instead process information by connecting all nodes of one layer to all nodes of the next. In addition, modern ANNs are trained with backpropagation, while their natural counterparts have been optimized by natural evolution over eons. We study whether the training method influences how information propagates through the brain by measuring the transfer entropy, that is, the information that is transferred from one group of neurons to another. We find that while the distribution of connection weights in optimized networks is largely unaffected by the training method, neuroevolution leads to networks in which information transfer is significantly more focused on small groups of neurons (compared to those trained by backpropagation) while also being more robust to perturbations of the weights. We conclude that the specific attributes of a training method (local vs. global) can significantly affect how information is processed and relayed through the brain, even when the overall performance is similar.",
    "year": 2022,
    "venue": "Neural computing & applications (Print)",
    "url": "https://www.semanticscholar.org/paper/da0dc5f03ebc29d3326f264396ba8586d118389b",
    "doi": "10.1007/s00521-022-08125-0",
    "arxivId": "",
    "authors": "A. Hintze, C. Adami",
    "citationCount": 4
  },
  {
    "s2PaperId": "c5dd2a79d48248e19c2b17f3f38745b4ceee6835",
    "title": "NIT: an open-source tool for information theoretic analysis of neural population data",
    "abstract": "Information theory provides a popular and principled framework for the analysis of neural data. It allows to uncover in an assumption-free way how neurons encode and transmit information, capturing both linear and non-linear coding mechanisms and including the information carried by interactions of any order. To facilitate its application, here we present Neuroscience Information Toolbox (NIT), a new toolbox for the accurate information theoretical analysis of neural data. NIT contains widely used tools such as limited sampling bias corrections and discretization of neural probabilities for the calculation of stimulus coding in low-dimensional representation of neural activity (e.g. Local Field Potentials or the activity of small neural population).Importantly, it adds a range of recent tools for quantifying information encoding by large populations of neurons or brain areas, for the directed transmission of information between neurons or areas, and for the calculation of Partial Information Decompositions to quantify the behavioral relevance of neural information and the synergy and redundancy among neurons and brain areas. Further, because information theoretic algorithms have been previously validated mainly with electrophysiological recordings, here we used realistic simulations and analysis of real data to study how to optimally apply information theory to the analysis of two-photon calcium imaging data, which are particularly challenging due to their lower signal-to-noise and temporal resolution. We also included algorithms (based on parametric and non-parametric copulas) to compute robustly information specifically with analog signals such as calcium traces. We provide indications on how to best process calcium imaging traces and to apply NIT depending on the type of calcium indicator, imaging frame rate and firing rate levels. In sum, NIT provides a toolbox for the comprehensive and effective information theoretic analysis of all kinds of neural data, including calcium imaging.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/c5dd2a79d48248e19c2b17f3f38745b4ceee6835",
    "doi": "10.1101/2022.12.11.519966",
    "arxivId": "",
    "authors": "R. Maffulli, Miguel A. Casal, Marco Celotto, S. Zucca, Houman Safaai, Tommaso Fellin, S. Panzeri",
    "citationCount": 1
  },
  {
    "s2PaperId": "e91443bf8290a9221707d82a0eb045b0fa731ed7",
    "title": "Improving Mutual Information based Feature Selection by Boosting Unique Relevance",
    "abstract": "Mutual Information (MI) based feature selection makes use of MI to evaluate each feature and eventually shortlists a relevant feature subset, in order to address issues associated with high-dimensional datasets. Despite the effectiveness of MI in feature selection, we notice that many state-of-the-art algorithms disregard the so-called unique relevance (UR) of features, which is a necessary condition for the optimal feature subset. In our study of five representative MI based feature selection (MIBFS) algorithms, we find that all of them underperform as they ignore the UR of features and arrive at a suboptimal selected feature subset. We point out that the heart of the problem is that all these MIBFS algorithms follow the criterion of Maximize Relevance with Minimum Redundancy (MRwMR), which does not explicitly target UR. This motivates us to augment the existing criterion with the objective of boosting unique relevance (BUR), leading to a new criterion called MRwMR-BUR. Depending on the task being addressed, MRwMR-BUR has two variants, termed MRwMR-BUR-KSG and MRwMR-BUR-CLF, which estimate UR differently. MRwMR-BUR-KSG estimates UR via a nearest-neighbor based approach called the KSG estimator and is designed for three major tasks: (i) Classification Performance (i.e., higher classification accuracy). (ii) Feature Interpretability (i.e., a more precise selected feature subset for practitioners to explore the hidden relationship between features and labels). (iii) Classifier Generalization (i.e., the selected feature subset generalizes well to various classifiers). MRwMR-BUR-CLF estimates UR via a classifier based approach. It adapts UR to different classifiers, further improving the competitiveness of MRwMR-BUR for classification performance oriented tasks. The performance of MRwMR-BUR-KSG and MRwMR-BUR-CLF is validated via experiments using six public datasets and four popular classifiers. Specifically, as compared to MRwMR, the proposed MRwMR-BUR-KSG improves the test accuracy by 2% – 3% with 25% – 30% fewer features being selected, without increasing the algorithm complexity. MRwMR-BUR-CLF further improves the classification performance by 3.8% – 5.5% (relative to MRwMR), and it also outperforms three popular classifier dependent feature selection methods.",
    "year": 2022,
    "venue": "Journal of Artificial Intelligence Research",
    "url": "https://www.semanticscholar.org/paper/e91443bf8290a9221707d82a0eb045b0fa731ed7",
    "doi": "10.48550/arXiv.2212.06143",
    "arxivId": "2212.06143",
    "authors": "Shiyu Liu, M. Motani",
    "citationCount": 5
  },
  {
    "s2PaperId": "0fb3b0b3ab2d5333e2475a00cbe09595475f6fa9",
    "title": "Quantifying cooperation between artificial agents using synergistic information",
    "abstract": "When designing interactive human-machine sys-tems, it is often assumed that it is desirable for such systems to behave cooperatively towards a human operator in order to improve trust, acceptance, and usability, but also to increase task efficiency. To design cooperative human-machine interaction (HMI) systems, we have to be able to define and quantitatively describe cooperative behavior, for example, to control, optimize, or evaluate the interaction. Despite the increased interest in cooperative HMI in recent years, an approach that provides a suitable definition of cooperation and also a method for its quantification is still missing. In the present work, we therefore develop a novel definition of cooperative behavior in HMI contexts, based on which we propose to quantify cooperation using recent methods from information theory. We define cooperation as joint, coordinated actions that are mutually adapted such as to facilitate the realization of a goal. Thus, cooperation is characterized by a synergistic effect of joint actions towards the goal. Here, we propose to quantify cooperation using the recently introduced partial information decomposition framework from information theory, which proposes measures to quantify the synergistic contributions of two inputs to a target variable. In particular, we propose to apply the synergy measure to two or more input variables describing agents' actions towards a target variable that describes the current goal state. As a first validation, we applied our approach in a grid-world environment, in which two agents solve a cooperative foraging task. We found that synergy was higher for agents implementing cooperative strategies compared to baseline and non-cooperative strategies, and we found higher synergy in trials with high numbers of cooperative actions. We conclude that the synergy is a promising candidate measure for identifying cooperative behavior in goal-oriented interactions.",
    "year": 2022,
    "venue": "IEEE Symposium Series on Computational Intelligence",
    "url": "https://www.semanticscholar.org/paper/0fb3b0b3ab2d5333e2475a00cbe09595475f6fa9",
    "doi": "10.1109/SSCI51031.2022.10022283",
    "arxivId": "",
    "authors": "Patricia Wollstadt, Matti Krüger",
    "citationCount": 3
  },
  {
    "s2PaperId": "339400b45f5e57c9b74695a378941931f382df74",
    "title": "Speech listening entails neural encoding of invisible articulatory features",
    "abstract": "",
    "year": 2022,
    "venue": "NeuroImage",
    "url": "https://www.semanticscholar.org/paper/339400b45f5e57c9b74695a378941931f382df74",
    "doi": "10.1016/j.neuroimage.2022.119724",
    "arxivId": "",
    "authors": "Aldo Pastore, A. Tomassini, Ioannis Delis, E. Dolfini, L. Fadiga, A. D’Ausilio",
    "citationCount": 3
  },
  {
    "s2PaperId": "6deceb01afabd7adbbe36d745a6e0684c1c85d49",
    "title": "Multimodal Transformer for Parallel Concatenated Variational Autoencoders",
    "abstract": "In this paper, we propose a multimodal transformer using parallel concatenated architecture. Instead of using patches, we use column stripes for images in R, G, B channels as the transformer input. The column stripes keep the spatial relations of original image. We incorporate the multimodal transformer with variational autoencoder for synthetic cross-modal data generation. The multimodal transformer is designed using multiple compression matrices, and it serves as encoders for Parallel Concatenated Variational AutoEncoders (PC-VAE). The PC-VAE consists of multiple encoders, one latent space, and two decoders. The encoders are based on random Gaussian matrices and don't need any training. We propose a new loss function based on the interaction information from partial information decomposition. The interaction information evaluates the input cross-modal information and decoder output. The PC-VAE are trained via minimizing the loss function. Experiments are performed to validate the proposed multimodal transformer for PC-VAE.",
    "year": 2022,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/6deceb01afabd7adbbe36d745a6e0684c1c85d49",
    "doi": "10.48550/arXiv.2210.16174",
    "arxivId": "2210.16174",
    "authors": "Stephen D. Liang, J. Mendel",
    "citationCount": 5
  },
  {
    "s2PaperId": "59938241e3a7b2a993dca753cd9f83399c19f18c",
    "title": "Post Traumatic Seizure Classification with Missing Data using Multimodal Machine Learning on dMRI, EEG, and fMRI",
    "abstract": "Late post-traumatic seizure (LPTS) is a complication of traumatic brain injury (TBI), which can lead to a potentially lifelong condition of post-traumatic epilepsy (PTE). Currently, the patho-mechanism that induces epileptogenesis in TBI subjects is unclear. As such, the epilepsy community strives to identify which TBI subjects will develop epilepsy and find potential biomarkers. To that end, this study collects longitudinal multimodal data from TBI subjects at multiple participating institutes. A supervised, binary classification task is formed with data from the LPTS versus no LPTS subjects. Missing modalities in certain subjects is handled in two ways. First, we extend a graphical model based Bayesian estimator to directly classify subjects with missing modality, and second, we investigate standard imputation techniques. The multimodal information is then combined, following several fusion and dimensionality reduction techniques found in literature, and eventually fitted to a kernel- or a tree-based classifier. For this fusion, we propose two new algorithms: recursive elimination of correlated components (RECC) which filters information based on correlation, and information decomposition and selective fusion (IDSF) which meaningfully recombines information from decomposed multimodal features. Based on the cross-validated area under the curve (AUC) score, we find the proposed IDSF algorithm provides the best performance. Finally, following statistical analyses of the frequently selected features, we recommend alterations in inferior temporal gyrus as a potential biomarker.",
    "year": 2022,
    "venue": "medRxiv",
    "url": "https://www.semanticscholar.org/paper/59938241e3a7b2a993dca753cd9f83399c19f18c",
    "doi": "10.1101/2022.10.22.22281402",
    "arxivId": "",
    "authors": "Md Navid Akbar, Sebastian F. Ruf, Ashutosh Kumar Singh, Razieh Faghihpirayesh, R. Garner, Alexis, Bennett, Celina Alba, M. Rocca, Tales Imbiriba, Deniz Erdoğmuş, D. Duncan",
    "citationCount": 3
  },
  {
    "s2PaperId": "a315e1f4bfcd1799e594f4f21dfb308c65e7dfc8",
    "title": "Hippocampal gamma oscillations form complex ensembles modulated by behavior and learning",
    "abstract": "The hippocampus and the entorhinal cortex display a rich oscillatory activity, believed to support neural information processing in key cognitive functions1. In the hippocampal region CA1, a “slow gamma” rhythm (30-80 Hz) generated in CA3 would support memory retrieval whereas a “medium gamma” rhythm (60-120 Hz) generated in the entorhinal cortex would support memory encoding2,3. However, descriptions involving discrete gamma sub-bands can only partially account for the haphazard diversity of oscillatory behaviors observed in individual recordings during spatial navigation behavior. Here, we stress that transient gamma oscillatory episodes at any frequency or phase relative to the ongoing theta (4-12 Hz) rhythm can be recorded at any layer within CA1. Eventually, the commonly reported averages are dominated by a minority of very strong power events overshadowing gamma heterogeneity. Nevertheless, we show that such gamma diversity can be naturally explained by a simple mechanistic model, and that behavior-related information (position within a maze) can be decoded from most individual gamma events, despite their low power and erratic-like nature. Our results indicate that behavior specifically shapes ensembles of irregular hippocampal gamma oscillations, in a way which evolves with learning, depends on the hippocampal layer and is hard to reconcile with the hypothesis of rigid, narrowly tuned gamma sub-bands. Beyond randomness, the pervasive gamma diversity may thus reflect complexity at the “fringe-of-synchrony”4 likely functional but invisible to classic average-based analyses.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/a315e1f4bfcd1799e594f4f21dfb308c65e7dfc8",
    "doi": "10.1101/2022.10.17.512498",
    "arxivId": "",
    "authors": "Vincent Douchamps, M. di Volo, A. Torcini, Demian Battaglia, R. Goutagny",
    "citationCount": 6
  },
  {
    "s2PaperId": "1fe56e69f16a4a176cd4f7abfd082e75eb795388",
    "title": "Synergistic information supports modality integration and flexible learning in neural networks solving multiple tasks",
    "abstract": "Striking progress has been made in understanding cognition by analyzing how the brain is engaged in different modes of information processing. For instance, so-called synergistic information (information encoded by a set of neurons but not by any subset) plays a key role in areas of the human brain linked with complex cognition. However, two questions remain unanswered: (a) how and why a cognitive system can become highly synergistic; and (b) how informational states map onto artificial neural networks in various learning modes. Here we employ an information-decomposition framework to investigate neural networks performing cognitive tasks. Our results show that synergy increases as networks learn multiple diverse tasks, and that in tasks requiring integration of multiple sources, performance critically relies on synergistic neurons. Overall, our results suggest that synergy is used to combine information from multiple modalities—and more generally for flexible and efficient learning. These findings reveal new ways of investigating how and why learning systems employ specific information-processing strategies, and support the principle that the capacity for general-purpose learning critically relies on the system’s information dynamics.",
    "year": 2022,
    "venue": "PLoS Comput. Biol.",
    "url": "https://www.semanticscholar.org/paper/1fe56e69f16a4a176cd4f7abfd082e75eb795388",
    "doi": "10.1371/journal.pcbi.1012178",
    "arxivId": "2210.02996",
    "authors": "A. Proca, F. Rosas, A. Luppi, D. Bor, Matthew Crosby, P. Mediano",
    "citationCount": 25
  },
  {
    "s2PaperId": "49abbd4a7a2cb47bc8bb6b92e30a80acc5369fa7",
    "title": "Functional Connectome of the Human Brain with Total Correlation",
    "abstract": "Recent studies proposed the use of Total Correlation to describe functional connectivity among brain regions as a multivariate alternative to conventional pairwise measures such as correlation or mutual information. In this work, we build on this idea to infer a large-scale (whole-brain) connectivity network based on Total Correlation and show the possibility of using this kind of network as biomarkers of brain alterations. In particular, this work uses Correlation Explanation (CorEx) to estimate Total Correlation. First, we prove that CorEx estimates of Total Correlation and clustering results are trustable compared to ground truth values. Second, the inferred large-scale connectivity network extracted from the more extensive open fMRI datasets is consistent with existing neuroscience studies, but, interestingly, can estimate additional relations beyond pairwise regions. And finally, we show how the connectivity graphs based on Total Correlation can also be an effective tool to aid in the discovery of brain diseases.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/49abbd4a7a2cb47bc8bb6b92e30a80acc5369fa7",
    "doi": "10.3390/e24121725",
    "arxivId": "2210.03231",
    "authors": "Qiang Li, G. V. Steeg, Shujian Yu, J. Malo",
    "citationCount": 22
  },
  {
    "s2PaperId": "318d4b02c322edef09e4d72e2539cdffc46d4220",
    "title": "Entropic Statistics: Concept, Estimation, and Application in Machine Learning and Knowledge Extraction",
    "abstract": "The demands for machine learning and knowledge extraction methods have been booming due to the unprecedented surge in data volume and data quality. Nevertheless, challenges arise amid the emerging data complexity as significant chunks of information and knowledge lie within the non-ordinal realm of data. To address the challenges, researchers developed considerable machine learning and knowledge extraction methods regarding various domain-specific challenges. To characterize and extract information from non-ordinal data, all the developed methods pointed to the subject of Information Theory, established following Shannon’s landmark paper in 1948. This article reviews recent developments in entropic statistics, including estimation of Shannon’s entropy and its functionals (such as mutual information and Kullback–Leibler divergence), concepts of entropic basis, generalized Shannon’s entropy (and its functionals), and their estimations and potential applications in machine learning and knowledge extraction. With the knowledge of recent development in entropic statistics, researchers can customize existing machine learning and knowledge extraction methods for better performance or develop new approaches to address emerging domain-specific challenges.",
    "year": 2022,
    "venue": "Machine Learning and Knowledge Extraction",
    "url": "https://www.semanticscholar.org/paper/318d4b02c322edef09e4d72e2539cdffc46d4220",
    "doi": "10.3390/make4040044",
    "arxivId": "",
    "authors": "Jialin Zhang",
    "citationCount": 2
  },
  {
    "s2PaperId": "9e4823f3735e3e5df456a530f5a178bac81d1ae4",
    "title": "Untangling Synergistic Effects of Intersecting Social Identities with Partial Information Decomposition",
    "abstract": "The theory of intersectionality proposes that an individual’s experience of society has aspects that are irreducible to the sum of one’s various identities considered individually, but are “greater than the sum of their parts”. In recent years, this framework has become a frequent topic of discussion both in social sciences and among popular movements for social justice. In this work, we show that the effects of intersectional identities can be statistically observed in empirical data using information theory, particularly the partial information decomposition framework. We show that, when considering the predictive relationship between various identity categories such as race and sex, on outcomes such as income, health and wellness, robust statistical synergies appear. These synergies show that there are joint-effects of identities on outcomes that are irreducible to any identity considered individually and only appear when specific categories are considered together (for example, there is a large, synergistic effect of race and sex considered jointly on income irreducible to either race or sex). Furthermore, these synergies are robust over time, remaining largely constant year-to-year. We then show using synthetic data that the most widely used method of assessing intersectionalities in data (linear regression with multiplicative interaction coefficients) fails to disambiguate between truly synergistic, greater-than-the-sum-of-their-parts interactions, and redundant interactions. We explore the significance of these two distinct types of interactions in the context of making inferences about intersectional relationships in data and the importance of being able to reliably differentiate the two. Finally, we conclude that information theory, as a model-free framework sensitive to nonlinearities and synergies in data, is a natural method by which to explore the space of higher-order social dynamics.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/9e4823f3735e3e5df456a530f5a178bac81d1ae4",
    "doi": "10.3390/e24101387",
    "arxivId": "",
    "authors": "Thomas F. Varley, Patrick Kaminski",
    "citationCount": 16
  },
  {
    "s2PaperId": "9e049f2cdf1b1272520d9e5aa4de8a7cd745ba7e",
    "title": "Irrigation and warming drive the decreases in surface albedo over High Mountain Asia",
    "abstract": "Human and climate induced land surface changes resulting from irrigation, snow cover decreases, and greening impact the surface albedo over High Mountain Asia (HMA). Here we use a partial information decomposition approach and remote sensing data to quantify the effects of the changes in leaf area index, soil moisture, and snow cover on the surface albedo in HMA, home to over a billion people, from 2003 to 2020. The study establishes strong evidence of anthropogenic agricultural water use over irrigated lands (e.g., Ganges–Brahmaputra) which causes the highest surface albedo decreases (≤ 1%/year). Greening and decreased snow cover from warming also drive changes in visible and near-infrared surface albedo in different areas of HMA. The significant role of irrigation and greening in influencing albedo suggests the potential of a positive feedback cycle where albedo decreases lead to increased evaporative demand and increased stress on water resources.",
    "year": 2022,
    "venue": "Scientific Reports",
    "url": "https://www.semanticscholar.org/paper/9e049f2cdf1b1272520d9e5aa4de8a7cd745ba7e",
    "doi": "10.1038/s41598-022-20564-2",
    "arxivId": "",
    "authors": "F. Maina, Sujay V. Kumar, C. Gangodagamage",
    "citationCount": 7
  },
  {
    "s2PaperId": "ad2ef71dc3c775bdfea1e5f1904c6f1de8050e3f",
    "title": "Extracting Unique Information Through Markov Relations",
    "abstract": "We propose two new measures for extracting the unique information in $X$ and not $Y$ about a message $M$, when $X, Y$ and $M$ are joint random variables with a given joint distribution. We take a Markov based approach, motivated by questions in fair machine learning, and inspired by similar Markov-based optimization problems that have been used in the Information Bottleneck and Common Information frameworks. We obtain a complete characterization of our definitions in the Gaussian case (namely, when $X, Y$ and $M$ are jointly Gaussian), under the assumption of Gaussian optimality. We also examine the consistency of our definitions with the partial information decomposition (PID) framework, and show that these Markov based definitions achieve non-negativity, but not symmetry, within the PID framework.",
    "year": 2022,
    "venue": "Allerton Conference on Communication, Control, and Computing",
    "url": "https://www.semanticscholar.org/paper/ad2ef71dc3c775bdfea1e5f1904c6f1de8050e3f",
    "doi": "10.1109/Allerton49937.2022.9929411",
    "arxivId": "2210.14789",
    "authors": "Keerthana Gurushankar, Praveen Venkatesh, P. Grover",
    "citationCount": 7
  },
  {
    "s2PaperId": "42b41c171e6c11443cbb5f4b1b1783d77b036917",
    "title": "A Measure of the Complexity of Neural Representations based on Partial Information Decomposition",
    "abstract": "In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of\"Representational Complexity\", which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representational complexity decreases both through successive hidden layers and over training, and compare the results to related measures. Overall, we propose representational complexity as a principled and interpretable summary statistic for analyzing the structure and evolution of neural representations and complex systems in general.",
    "year": 2022,
    "venue": "Trans. Mach. Learn. Res.",
    "url": "https://www.semanticscholar.org/paper/42b41c171e6c11443cbb5f4b1b1783d77b036917",
    "doi": "",
    "arxivId": "2209.10438",
    "authors": "David A. Ehrlich, Andreas Schneider, V. Priesemann, M. Wibral, Abdullah Makkeh",
    "citationCount": 20
  },
  {
    "s2PaperId": "f52be2741418df216561bd4436da302ece39d9e2",
    "title": "Foundations & Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions",
    "abstract": "Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this article is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining three key principles of modality heterogeneity, connections, and interactions that have driven subsequent innovations, and propose a taxonomy of six core technical challenges: representation, alignment, reasoning, generation, transference, and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.",
    "year": 2022,
    "venue": "ACM Computing Surveys",
    "url": "https://www.semanticscholar.org/paper/f52be2741418df216561bd4436da302ece39d9e2",
    "doi": "10.1145/3656580",
    "arxivId": "2209.03430",
    "authors": "Paul Pu Liang, Amir Zadeh, Louis-philippe Morency",
    "citationCount": 99
  },
  {
    "s2PaperId": "c9c9e816ea29030fd5967a8835378636e0744b77",
    "title": "Outsourcing Control Requires Control Complexity",
    "abstract": "Abstract An embodied agent influences its environment and is influenced by it. We use the sensorimotor loop to model these interactions and quantify the information flows in the system by information-theoretic measures. This includes a measure for the interaction among the agent’s body and its environment, often referred to as morphological computation. Additionally, we examine the controller complexity, which can be seen in the context of the integrated information theory of consciousness. Applying this framework to an experimental setting with simulated agents allows us to analyze the interaction between an agent and its environment, as well as the complexity of its controller. Previous research revealed that a morphology adapted well to a task can substantially reduce the required complexity of the controller. In this work, we observe that the agents first have to understand the relevant dynamics of the environment to interact well with their surroundings. Hence an increased controller complexity can facilitate a better interaction between an agent’s body and its environment.",
    "year": 2022,
    "venue": "Artificial Life",
    "url": "https://www.semanticscholar.org/paper/c9c9e816ea29030fd5967a8835378636e0744b77",
    "doi": "10.1162/artl_a_00443",
    "arxivId": "2209.01418",
    "authors": "Carlotta Langer, N. Ay",
    "citationCount": 2
  },
  {
    "s2PaperId": "37619a1d4b322cdc170642cfb2aee6606107292c",
    "title": "Flickering Emergences: The Question of Locality in Information-Theoretic Approaches to Emergence",
    "abstract": "“Emergence”, the phenomenon where a complex system displays properties, behaviours, or dynamics not trivially reducible to its constituent elements, is one of the defining properties of complex systems. Recently, there has been a concerted effort to formally define emergence using the mathematical framework of information theory, which proposes that emergence can be understood in terms of how the states of wholes and parts collectively disclose information about the system’s collective future. In this paper, we show how a common, foundational component of information-theoretic approaches to emergence implies an inherent instability to emergent properties, which we call flickering emergence. A system may, on average, display a meaningful emergent property (be it an informative coarse-graining, or higher-order synergy), but for particular configurations, that emergent property falls apart and becomes misinformative. We show existence proofs that flickering emergence occurs in two different frameworks (one based on coarse-graining and another based on multivariate information decomposition) and argue that any approach based on temporal mutual information will display it. Finally, we argue that flickering emergence should not be a disqualifying property of any model of emergence, but that it should be accounted for when attempting to theorize about how emergence relates to practical models of the natural world.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/37619a1d4b322cdc170642cfb2aee6606107292c",
    "doi": "10.3390/e25010054",
    "arxivId": "2208.14502",
    "authors": "Thomas F. Varley",
    "citationCount": 15
  },
  {
    "s2PaperId": "270fb1dcd57d1c5ef1155a0f1696dacdbc5acc02",
    "title": "Decomposing predictability to identify dominant causal drivers in complex ecosystems",
    "abstract": "Ecosystems are complex systems of various physical, biological, and chemical processes. Since ecosystem dynamics are composed of a mixture of different levels of stochasticity and nonlinearity, handling these data is a challenge for existing methods of time-series based causal inferences. Here we show that, by harnessing contemporary machine learning approaches, the concept of Granger causality can be effectively extended to the analysis of complex ecosystem time series and bridge the gap between dynamical and statistical approaches. The central idea is to use an ensemble of fast and highly predictive artificial neural networks to select a minimal set of variables that maximizes the prediction of a given variable. It enables decomposition of the relationship among variables through quantifying the contribution of an individual variable to the overall predictive performance. We show how our approach, EcohNet, can improve interaction network inference for a mesocosm experiment and simulated ecosystems. The application of the method to a long-term lake monitoring dataset yielded new but interpretable results on the drivers causing cyanobacteria blooms, which is a serious threat to ecological integrity and ecosystem services. Since performance of EcohNet is enhanced by its predictive capabilities, it also provides an optimized forecasting of overall components in ecosystems. EcohNet could be used to analyze complex and hybrid multivariate time series in many scientific areas not limited to ecosystems. Significance Statement Effective use of ecosystem monitoring data to resolve global environmental issues is a major challenge of the 21st century ecology. A promising solution to address this challenge is a time-series-based causal analysis which can provide insight on the mechanical links between ecosystem components. In this work, a model-free framework named EcohNet is proposed. EcohNet utilizes ensemble predictions of echo state networks, which are known to be fast, accurate, and highly relevant for a variety of dynamical systems, and can robustly predict causal networks of ecosystem components. It also can provide an optimized forecasting of overall ecosystem components, and could be used to analyze complex and hybrid multivariate time series in many scientific areas, not limited to ecosystems.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/270fb1dcd57d1c5ef1155a0f1696dacdbc5acc02",
    "doi": "10.1101/2022.03.14.484197",
    "arxivId": "",
    "authors": "Kenta Suzuki, S. Matsuzaki, H. Masuya",
    "citationCount": 15
  },
  {
    "s2PaperId": "dd4d350ef5a83a2a9f105b1a31472b17e1e5f5d6",
    "title": "Decomposing Neural Circuit Function into Information Processing Primitives",
    "abstract": "It is challenging to measure how specific aspects of coordinated neural dynamics translate into operations of information processing and, ultimately, cognitive functions. An obstacle is that simple circuit mechanisms—such as self-sustained or propagating activity and nonlinear summation of inputs—do not directly give rise to high-level functions. Nevertheless, they already implement simple the information carried by neural activity. Here, we propose that distinct functions, such as stimulus representation, working memory, or selective attention, stem from different combinations and types of low-level manipulations of information or information processing primitives. To test this hypothesis, we combine approaches from information theory with simulations of multi-scale neural circuits involving interacting brain regions that emulate well-defined cognitive functions. Specifically, we track the information dynamics emergent from patterns of neural dynamics, using quantitative metrics to detect where and when information is actively buffered, transferred or nonlinearly merged, as possible modes of low-level processing (storage, transfer and modification). We find that neuronal subsets maintaining representations in working memory or performing attentional gain modulation are signaled by their boosted involvement in operations of information storage or modification, respectively. Thus, information dynamic metrics, beyond detecting which network units participate in cognitive processing, also promise to specify how and when they do it, that is, through which type of primitive computation, a capability that may be exploited for the analysis of experimental recordings.",
    "year": 2022,
    "venue": "Journal of Neuroscience",
    "url": "https://www.semanticscholar.org/paper/dd4d350ef5a83a2a9f105b1a31472b17e1e5f5d6",
    "doi": "10.1101/2022.08.04.502783",
    "arxivId": "",
    "authors": "N. Voges, Vinicius Lima, Johannes Hausmann, A. Brovelli, Demian Battaglia",
    "citationCount": 2
  },
  {
    "s2PaperId": "bf1f9a3c4f4d53d6e9aa4659620a5680c0143126",
    "title": "Cascades Towards Noise-Induced Transitions on Networks Revealed Using Information Flows",
    "abstract": "Complex networks, from neuronal assemblies to social systems, can exhibit abrupt, system-wide transitions without external forcing. These endogenously generated “noise-induced transitions” emerge from the intricate interplay between network structure and local dynamics, yet their underlying mechanisms remain elusive. Our study unveils two critical roles that nodes play in catalyzing these transitions within dynamical networks governed by the Boltzmann–Gibbs distribution. We introduce the concept of “initiator nodes”, which absorb and propagate short-lived fluctuations, temporarily destabilizing their neighbors. This process initiates a domino effect, where the stability of a node inversely correlates with the number of destabilized neighbors required to tip it. As the system approaches a tipping point, we identify “stabilizer nodes” that encode the system’s long-term memory, ultimately reversing the domino effect and settling the network into a new stable attractor. Through targeted interventions, we demonstrate how these roles can be manipulated to either promote or inhibit systemic transitions. Our findings provide a novel framework for understanding and potentially controlling endogenously generated metastable behavior in complex networks. This approach opens new avenues for predicting and managing critical transitions in diverse fields, from neuroscience to social dynamics and beyond.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/bf1f9a3c4f4d53d6e9aa4659620a5680c0143126",
    "doi": "10.3390/e26121050",
    "arxivId": "2207.14016",
    "authors": "Casper van Elteren, Rick Quax, P. Sloot",
    "citationCount": 1
  },
  {
    "s2PaperId": "f9bd8c8ed1e8c03a29c8181d98d3e9afdbf45972",
    "title": "Pairwise and high-order dependencies in the cryptocurrency trading network",
    "abstract": "In this paper we analyse the effects of information flows in cryptocurrency markets. We first define a cryptocurrency trading network, i.e. the network made using cryptocurrencies as nodes and the Granger causality among their weekly log returns as links, later we analyse its evolution over time. In particular, with reference to years 2020 and 2021, we study the logarithmic US dollar price returns of the cryptocurrency trading network using both pairwise and high-order statistical dependencies, quantified by Granger causality and O-information, respectively. With reference to the former, we find that it shows peaks in correspondence of important events, like e.g., Covid-19 pandemic turbulence or occasional sudden prices rise. The corresponding network structure is rather stable, across weekly time windows in the period considered and the coins are the most influential nodes in the network. In the pairwise description of the network, stable coins seem to play a marginal role whereas, turning high-order dependencies, they appear in the highest number of synergistic information circuits, thus proving that they play a major role for high order effects. With reference to redundancy and synergy with the time evolution of the total transactions in US dollars, we find that their large volume in the first semester of 2021 seems to have triggered a transition in the cryptocurrency network toward a more complex dynamical landscape. Our results show that pairwise and high-order descriptions of complex financial systems provide complementary information for cryptocurrency analysis.",
    "year": 2022,
    "venue": "Scientific Reports",
    "url": "https://www.semanticscholar.org/paper/f9bd8c8ed1e8c03a29c8181d98d3e9afdbf45972",
    "doi": "10.1038/s41598-022-21192-6",
    "arxivId": "2207.04004",
    "authors": "Tomas Scagliarini, G. Pappalardo, A. E. Biondo, A. Pluchino, Andrea Rapisarda, S. Stramaglia",
    "citationCount": 12
  },
  {
    "s2PaperId": "3c88790a6068a23cdac0f00be7edd51aa5f35526",
    "title": "Gradients of O-information: low-order descriptors of high-order dependencies",
    "abstract": "O-information is an information-theoretic metric that captures the overall balance between redundant and synergistic information shared by groups of three or more variables. To complement the global assessment provided by this metric, here we propose the gradients of the O-information as low-order descriptors that can characterise how high-order effects are localised across a system of interest. We illustrate the capabilities of the proposed framework by revealing the role of specific spins in Ising models with frustration, and on practical data analysis on US macroeconomic data. Our theoretical and empirical analyses demonstrate the potential of these gradients to highlight the contribution of variables in forming high-order informational circuits",
    "year": 2022,
    "venue": "Physical Review Research",
    "url": "https://www.semanticscholar.org/paper/3c88790a6068a23cdac0f00be7edd51aa5f35526",
    "doi": "10.48550/arXiv.2207.03581",
    "arxivId": "2207.03581",
    "authors": "Tomas Scagliarini, D. Nuzzi, Y. Antonacci, L. Faes, F. Rosas, D. Marinazzo, S. Stramaglia",
    "citationCount": 22
  },
  {
    "s2PaperId": "fdd4373973ae15ffc98c3d006103b03b2379a67f",
    "title": "Revealing the Dynamics of Neural Information Processing with Multivariate Information Decomposition",
    "abstract": "The varied cognitive abilities and rich adaptive behaviors enabled by the animal nervous system are often described in terms of information processing. This framing raises the issue of how biological neural circuits actually process information, and some of the most fundamental outstanding questions in neuroscience center on understanding the mechanisms of neural information processing. Classical information theory has long been understood to be a natural framework within which information processing can be understood, and recent advances in the field of multivariate information theory offer new insights into the structure of computation in complex systems. In this review, we provide an introduction to the conceptual and practical issues associated with using multivariate information theory to analyze information processing in neural circuits, as well as discussing recent empirical work in this vein. Specifically, we provide an accessible introduction to the partial information decomposition (PID) framework. PID reveals redundant, unique, and synergistic modes by which neurons integrate information from multiple sources. We focus particularly on the synergistic mode, which quantifies the “higher-order” information carried in the patterns of multiple inputs and is not reducible to input from any single source. Recent work in a variety of model systems has revealed that synergistic dynamics are ubiquitous in neural circuitry and show reliable structure–function relationships, emerging disproportionately in neuronal rich clubs, downstream of recurrent connectivity, and in the convergence of correlated activity. We draw on the existing literature on higher-order information dynamics in neuronal networks to illustrate the insights that have been gained by taking an information decomposition perspective on neural activity. Finally, we briefly discuss future promising directions for information decomposition approaches to neuroscience, such as work on behaving animals, multi-target generalizations of PID, and time-resolved local analyses.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/fdd4373973ae15ffc98c3d006103b03b2379a67f",
    "doi": "10.3390/e24070930",
    "arxivId": "",
    "authors": "E. Newman, Thomas F. Varley, Vibin Parakkattu, Samantha P. Sherrill, J. Beggs",
    "citationCount": 23
  },
  {
    "s2PaperId": "f9764b8ca7d29be6cc1317ffce164f698b05d315",
    "title": "Multiscale Information Decomposition of Long Memory Processes: Application to Plateau Waves of Intracranial Pressure",
    "abstract": "Traumatic Brain Injury (TBI) patients present high levels of physical stress, which in some situations can manifest as Plateau Wave (PW) episodes. This intense stress phenomenon can be evidenced by Heart Rate Variability (HRV). Thus, the multivariate and simultaneous analysis of cardio-cerebrovascular oscillations, involving the RR intervals, mean arterial pressure (MAP) and the amplitude of intracranial pressure (AMP), will be useful to understand the interconnections between body signals, allowing the interpretation of the combined activity of pathophysiological mechanisms. In this work, the multiscale representation of the Transfer Entropy (TE) and of its decomposition in the network of these three interacting processes is obtained, based on a Vector AutoRegressive Fractionally Integrated (VARFI) framework for Gaussian processes. This method allows to assess directed interactions and to quantify the information flow accounting for the simultaneous presence of short-term dynamics and long-range correlations. The results show that the baseline RR, but not MAP can provide information about the possibility of a PW arising. During PW, the long-term correlations highlight synergistic interactions between MAP and AMP processes on RR. The multiscale decomposition of the information along with the incorporation of the long term correlations allowed a better description of HRV during PW, highlighting the fact that the HRV mirrors this cerebrovascular phenomena.",
    "year": 2022,
    "venue": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
    "url": "https://www.semanticscholar.org/paper/f9764b8ca7d29be6cc1317ffce164f698b05d315",
    "doi": "10.1109/EMBC48229.2022.9870925",
    "arxivId": "",
    "authors": "Hélder Pinto, C. Dias, A. P. Rocha",
    "citationCount": 6
  },
  {
    "s2PaperId": "7c135737d648efe944f4910f16a4f14ac1512e95",
    "title": "Source Relationships and Model Structures Determine Information Flow Paths in Ecohydrologic Models",
    "abstract": "In a complex ecohydrologic system, vegetation and soil variables combine to dictate heat fluxes, and these fluxes may vary depending on the extent to which drivers are linearly or nonlinearly interrelated. From a modeling and causality perspective, uncertainty, sensitivity, and performance measures all relate to how information from different sources “flows” through a model to produce a target, or output. We address how model structure, broadly defined as a mapping from inputs to an output, combines with source dependencies to produce a range of information flow pathways from sources to a target. We apply information decomposition, which partitions reductions in uncertainty into synergistic, redundant, and unique information types, to a range of model cases. Toy models show that model structure and source dependencies both restrict the types of interactions that can arise between sources and targets. Regressions based on weather data illustrate how different model structures vary in their sensitivity to source dependencies, thus affecting predictive and functional performance. Finally, we compare the Surface Flux Equilibrium theory, a land‐surface model, and neural networks in estimating the Bowen ratio and find that models trade off information types particularly when sources have the highest and lowest dependencies. Overall, this study extends an information theory‐based model evaluation framework to incorporate the influence of source dependency on information pathways. This could be applied to explore behavioral ranges for both machine learning and process‐based models, and guide model development by highlighting model deficiencies based on information flow pathways that would not be apparent based on existing measures.",
    "year": 2022,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/7c135737d648efe944f4910f16a4f14ac1512e95",
    "doi": "10.1029/2021WR031164",
    "arxivId": "",
    "authors": "A. Goodwell, M. Bassiouni",
    "citationCount": 7
  },
  {
    "s2PaperId": "3f9ab354e6cb0e1ba9b4982a3f7877f678255bf2",
    "title": "Differential roles of delta and theta oscillations in understanding semantic gist during natural audiovisual speech perception: Functional and anatomical evidence",
    "abstract": "Understanding the main topic of naturalistic speech in a multi-speaker environment is demanding though the availability of visual speech can be beneficial for speech comprehension. Recent studies provided evidence that low-frequency brain rhythms play an important role in the processing of acoustic speech features. However, at present, the neural dynamics of brain rhythms implementing a higher-order semantic system during naturalistic audiovisual speech perception is unknown. Here we investigated information processing carried by low-frequency oscillations in delta and theta bands for audiovisual speech integration for high-level semantic gist processing using a representational interaction approach. By manipulating the degree of high-level semantic content (speech chunks with high versus low topic probability) using Latent Dirichlet Allocation (LDA) topic modelling algorithm and complexity of speaker environment (single versus multi-speaker), we first found that delta and theta phase exert distinctive roles in high-level semantic processing where delta phase represents auditory and visual inputs synergistically whereas theta band does so redundantly. Next, we show both forms of representational interaction are observed to be greater for speech with low semantic gist, supported by speech comprehension and white matter tractography. Furthermore, we show that the delta phase-specific synergistic interaction in the right auditory, temporal, and inferior frontal areas is sensitive to the speaker environment, whereas theta band activity showing redundant representations is sensitive to semantic content. Our results shed new light on dynamic neural mechanisms of implementing higher-order semantic systems through representational interactions between audiovisual speech information and differential roles of delta and theta bands depending on the speaker environment.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/3f9ab354e6cb0e1ba9b4982a3f7877f678255bf2",
    "doi": "10.1101/2022.06.21.497061",
    "arxivId": "",
    "authors": "Hyojin Park, Robin A. A. Ince, J. Gross",
    "citationCount": 0
  },
  {
    "s2PaperId": "2b275d80e053bf804f3d03e00036bb412335982c",
    "title": "Reduced emergent character of neural dynamics in patients with a disrupted connectome",
    "abstract": "High-level brain functions are widely believed to emerge from the orchestrated activity of multiple neural systems. However, lacking a formal definition and practical quantification of emergence for experimental data, neuroscientists have been unable to empirically test this long-standing conjecture. Here we investigate this fundamental question by leveraging a recently proposed framework known as “Integrated Information Decomposition,” which establishes a principled information-theoretic approach to operationalise and quantify emergence in dynamical systems — including the human brain. By analysing functional MRI data, our results show that the emergent and hierarchical character of neural dynamics is significantly diminished in chronically unresponsive patients suffering from severe brain injury. At a functional level, we demonstrate that emergence capacity is positively correlated with the extent of hierarchical organisation in brain activity. Furthermore, by combining computational approaches from network control theory and whole-brain biophysical modelling, we show that the reduced capacity for emergent and hierarchical dynamics in severely brain-injured patients can be mechanistically explained by disruptions in the patients’ structural connectome. Overall, our results suggest that chronic unresponsiveness resulting from severe brain injury may be due to structural impairment of the fundamental neural infrastructures required for brain dynamics to support emergence.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/2b275d80e053bf804f3d03e00036bb412335982c",
    "doi": "10.1101/2022.06.16.496445",
    "arxivId": "",
    "authors": "A. Luppi, P. Mediano, F. Rosas, J. Allanson, John D. Pickard, G. Williams, Michael M. Craig, Paola Finoia, Alexander R. D. Peattie, Peter Coppola, David K. Menon, Daniel Bor, E. Stamatakis",
    "citationCount": 0
  },
  {
    "s2PaperId": "46b144d6f80d54ea717c660215789590c769b087",
    "title": "Conservative significance testing of tripartite statistical relations in multivariate neural data",
    "abstract": "Abstract An important goal in systems neuroscience is to understand the structure of neuronal interactions, frequently approached by studying functional relations between recorded neuronal signals. Commonly used pairwise measures (e.g., correlation coefficient) offer limited insight, neither addressing the specificity of estimated neuronal interactions nor potential synergistic coupling between neuronal signals. Tripartite measures, such as partial correlation, variance partitioning, and partial information decomposition, address these questions by disentangling functional relations into interpretable information atoms (unique, redundant, and synergistic). Here, we apply these tripartite measures to simulated neuronal recordings to investigate their sensitivity to noise. We find that the considered measures are mostly accurate and specific for signals with noiseless sources but experience significant bias for noisy sources.We show that permutation testing of such measures results in high false positive rates even for small noise fractions and large data sizes. We present a conservative null hypothesis for significance testing of tripartite measures, which significantly decreases false positive rate at a tolerable expense of increasing false negative rate. We hope our study raises awareness about the potential pitfalls of significance testing and of interpretation of functional relations, offering both conceptual and practical advice.",
    "year": 2022,
    "venue": "Network Neuroscience",
    "url": "https://www.semanticscholar.org/paper/46b144d6f80d54ea717c660215789590c769b087",
    "doi": "10.1162/netn_a_00259",
    "arxivId": "",
    "authors": "Aleksejs Fomins, Yaroslav Sych, F. Helmchen",
    "citationCount": 1
  },
  {
    "s2PaperId": "969dd6e2105b36eb2c0edd095705361bee487c1a",
    "title": "Quantifying Feature Contributions to Overall Disparity Using Information Theory",
    "abstract": "When a machine-learning algorithm makes biased decisions, it can be helpful to understand the “sources” of disparity to explain why the bias exists. Towards this, we examine the problem of quantifying the contribution of each individual feature to the observed disparity. If we have access to the decision-making model, one potential approach (inspired from intervention-based approaches in explainability literature) is to vary each individual feature (while keeping the others ﬁxed), and use the resulting change in disparity to quantify its contribution. However, we may not have access to the model or be able to test/audit its outputs for individually varying features. Furthermore, the decision may not always be a deterministic function of the input features (e.g., with human-in-the-loop). For these situations, we might need to explain contributions using purely distributional (i.e., observational) techniques, rather than interventional. We ask the question: what is the “potential” contribution of each individual feature to the observed disparity in the decisions when the exact decision-making mechanism is not accessible? We ﬁrst provide canonical examples (thought experiments) that help illustrate the difference between distributional and interventional approaches to explaining contributions, and when either is better suited. When unable to intervene on the inputs, we quantify the “redundant” statistical dependency about the protected attribute that is present in both the ﬁnal decision and an individual feature, by leveraging a body of work in information theory called Partial Information Decomposition. We also perform a simple case study to show how this technique could be applied to quantify contributions.",
    "year": 2022,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/969dd6e2105b36eb2c0edd095705361bee487c1a",
    "doi": "10.48550/arXiv.2206.08454",
    "arxivId": "2206.08454",
    "authors": "Sanghamitra Dutta, Praveen Venkatesh, P. Grover",
    "citationCount": 5
  },
  {
    "s2PaperId": "27537cae97e2bb95b19f57f42188ed9ad9559468",
    "title": "Multivariate information theory uncovers synergistic subsystems of the human cerebral cortex",
    "abstract": "O-information, a measure of higher-order interactions in multivariate data, can reveal synergistic ensembles of brain regions that are invisible to bivariate functional connectivity analyses. One of the most well-established tools for modeling the brain is the functional connectivity network, which is constructed from pairs of interacting brain regions. While powerful, the network model is limited by the restriction that only pairwise dependencies are considered and potentially higher-order structures are missed. Here, we explore how multivariate information theory reveals higher-order dependencies in the human brain. We begin with a mathematical analysis of the O-information, showing analytically and numerically how it is related to previously established information theoretic measures of complexity. We then apply the O-information to brain data, showing that synergistic subsystems are widespread in the human brain. Highly synergistic subsystems typically sit between canonical functional networks, and may serve an integrative role. We then use simulated annealing to find maximally synergistic subsystems, finding that such systems typically comprise ≈10 brain regions, recruited from multiple canonical brain systems. Though ubiquitous, highly synergistic subsystems are invisible when considering pairwise functional connectivity, suggesting that higher-order dependencies form a kind of shadow structure that has been unrecognized by established network-based analyses. We assert that higher-order interactions in the brain represent an under-explored space that, accessible with tools of multivariate information theory, may offer novel scientific insights.",
    "year": 2022,
    "venue": "Communications Biology",
    "url": "https://www.semanticscholar.org/paper/27537cae97e2bb95b19f57f42188ed9ad9559468",
    "doi": "10.1038/s42003-023-04843-w",
    "arxivId": "2206.06477",
    "authors": "Thomas F. Varley, Maria Pope, Joshua Faskowitz, O. Sporns",
    "citationCount": 67
  },
  {
    "s2PaperId": "71838517899f5d2511fa9156b82b5196273d9caa",
    "title": "A Comparison of Partial Information Decompositions Using Data from Real and Simulated Layer 5b Pyramidal Cells",
    "abstract": "Partial information decomposition allows the joint mutual information between an output and a set of inputs to be divided into components that are synergistic or shared or unique to each input. We consider five different decompositions and compare their results using data from layer 5b pyramidal cells in two different studies. The first study was on the amplification of somatic action potential output by apical dendritic input and its regulation by dendritic inhibition. We find that two of the decompositions produce much larger estimates of synergy and shared information than the others, as well as large levels of unique misinformation. When within-neuron differences in the components are examined, the five methods produce more similar results for all but the shared information component, for which two methods produce a different statistical conclusion from the others. There are some differences in the expression of unique information asymmetry among the methods. It is significantly larger, on average, under dendritic inhibition. Three of the methods support a previous conclusion that apical amplification is reduced by dendritic inhibition. The second study used a detailed compartmental model to produce action potentials for many combinations of the numbers of basal and apical synaptic inputs. Decompositions of the entire data set produce similar differences to those in the first study. Two analyses of decompositions are conducted on subsets of the data. In the first, the decompositions reveal a bifurcation in unique information asymmetry. For three of the methods, this suggests that apical drive switches to basal drive as the strength of the basal input increases, while the other two show changing mixtures of information and misinformation. Decompositions produced using the second set of subsets show that all five decompositions provide support for properties of cooperative context-sensitivity—to varying extents.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/71838517899f5d2511fa9156b82b5196273d9caa",
    "doi": "10.3390/e24081021",
    "arxivId": "2206.06456",
    "authors": "J. Kay, Jan M. Schulz, W. A. Phillips",
    "citationCount": 11
  },
  {
    "s2PaperId": "489cca86a11ccd86cbe81d2037bfcb44fe640628",
    "title": "An information theory-based approach to characterize drivers of upstream salmon migration",
    "abstract": "The migration timing of Pacific salmon in the Columbia River basin is subject to multiple influences related to climate, human water resource management, and lagged effects such as oceanic conditions. We apply an information theory-based approach to analyze drivers of adult Chinook salmon migration within the spring and fall spawning seasons and between years based on salmon counts at dams along the Columbia and Snake Rivers. Time-lagged mutual information and information decomposition measures, which characterize lagged and nonlinear dependencies as reductions in uncertainty, are used to detect interactions between salmon counts and lagged streamflows, air and water temperatures, precipitation, snowpack, climate indices and downstream salmon counts. At a daily timescale, these interdependencies reflect migration timing and show differences between fall and spring run salmon, while dependencies based on variables at an annual resolution reflect long-term predictability. We also highlight several types of joint dependencies where predictability of salmon counts depends on the knowledge of multiple lagged sources. This study illustrates how co-varying human and natural drivers could propagate to influence salmon migration timing or overall returns, and how nonlinear types of dependencies between variables enhance predictability of a target. This information-based framework is broadly applicable to assess driving factors in other types of complex water resources systems or species life cycles.",
    "year": 2022,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/489cca86a11ccd86cbe81d2037bfcb44fe640628",
    "doi": "10.1371/journal.pone.0269193",
    "arxivId": "",
    "authors": "A. Goodwell, N. Campbell",
    "citationCount": 2
  },
  {
    "s2PaperId": "4f7721447927912165137a7c8bf127fdf3e9c6a3",
    "title": "The strength of weak integrated information theory",
    "abstract": "",
    "year": 2022,
    "venue": "Trends in Cognitive Sciences",
    "url": "https://www.semanticscholar.org/paper/4f7721447927912165137a7c8bf127fdf3e9c6a3",
    "doi": "10.1016/j.tics.2022.04.008",
    "arxivId": "",
    "authors": "P. Mediano, F. Rosas, D. Bor, A. Seth, A. Barrett",
    "citationCount": 41
  },
  {
    "s2PaperId": "2b19f517e17c3637729aeab941f457201e4a484f",
    "title": "May the 4C's be with you: an overview of complexity-inspired frameworks for analysing resting-state neuroimaging data",
    "abstract": "Competing and complementary models of resting-state brain dynamics contribute to our phenomenological and mechanistic understanding of whole-brain coordination and communication, and provide potential evidence for differential brain functioning associated with normal and pathological behaviour. These neuroscientific theories stem from the perspectives of physics, engineering, mathematics and psychology and create a complicated landscape of domain-specific terminology and meaning, which, when used outside of that domain, may lead to incorrect assumptions and conclusions within the neuroscience community. Here, we review and clarify the key concepts of connectivity, computation, criticality and coherence—the 4C's—and outline a potential role for metastability as a common denominator across these propositions. We analyse and synthesize whole-brain neuroimaging research, examined through functional magnetic imaging, to demonstrate that complexity science offers a principled and integrated approach to describe, and potentially understand, macroscale spontaneous brain functioning.",
    "year": 2022,
    "venue": "Journal of the Royal Society Interface",
    "url": "https://www.semanticscholar.org/paper/2b19f517e17c3637729aeab941f457201e4a484f",
    "doi": "10.1098/rsif.2022.0214",
    "arxivId": "",
    "authors": "Fran Hancock, F. Rosas, P. Mediano, A. Luppi, J. Cabral, O. Dipasquale, F. Turkheimer",
    "citationCount": 21
  },
  {
    "s2PaperId": "c1ce23f18a5584c827b8dc3ee09cefc23409a332",
    "title": "A synergistic core for human brain evolution and cognition",
    "abstract": "",
    "year": 2022,
    "venue": "Nature Neuroscience",
    "url": "https://www.semanticscholar.org/paper/c1ce23f18a5584c827b8dc3ee09cefc23409a332",
    "doi": "10.1038/s41593-022-01070-0",
    "arxivId": "",
    "authors": "A. Luppi, P. Mediano, F. Rosas, N. Holland, T. Fryer, J. O'Brien, James B. Rowe, David K. Menon, Daniel Bor, E. Stamatakis",
    "citationCount": 91
  },
  {
    "s2PaperId": "a1adeade3ea8f8bb1e56df0fa71a324f0831b9ed",
    "title": "Gacs-Korner Common Information Variational Autoencoder",
    "abstract": "We propose a notion of common information that allows one to quantify and separate the information that is shared between two random variables from the information that is unique to each. Our notion of common information is a variational relaxation of the G\\'acs-K\\\"orner common information, which we recover as a special case, but is more amenable to optimization and can be approximated empirically using samples from the underlying distribution. We then provide a method to partition and quantify the common and unique information using a simple modification of a traditional variational auto-encoder. Empirically, we demonstrate that our formulation allows us to learn semantically meaningful common and unique factors of variation even on high-dimensional data such as images and videos. Moreover, on datasets where ground-truth latent factors are known, we show that we can accurately quantify the common information between the random variables. Additionally, we show that the auto-encoder that we learn recovers semantically meaningful disentangled factors of variation, even though we do not explicitly optimize for it.",
    "year": 2022,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/a1adeade3ea8f8bb1e56df0fa71a324f0831b9ed",
    "doi": "10.48550/arXiv.2205.12239",
    "arxivId": "2205.12239",
    "authors": "Michael Kleinman, A. Achille, Stefano Soatto, J. Kao",
    "citationCount": 14
  },
  {
    "s2PaperId": "47217d0b59c0cd0c595444568a32de3da39b4647",
    "title": "Higher-Order Interactions and Their Duals Reveal Synergy and Logical Dependence beyond Shannon-Information",
    "abstract": "Information-theoretic quantities reveal dependencies among variables in the structure of joint, marginal, and conditional entropies while leaving certain fundamentally different systems indistinguishable. Furthermore, there is no consensus on the correct higher-order generalisation of mutual information (MI). In this manuscript, we show that a recently proposed model-free definition of higher-order interactions among binary variables (MFIs), such as mutual information, is a Möbius inversion on a Boolean algebra, except of surprisal instead of entropy. This provides an information-theoretic interpretation to the MFIs, and by extension to Ising interactions. We study the objects dual to mutual information and the MFIs on the order-reversed lattices. We find that dual MI is related to the previously studied differential mutual information, while dual interactions are interactions with respect to a different background state. Unlike (dual) mutual information, interactions and their duals uniquely identify all six 2-input logic gates, the dy- and triadic distributions, and different causal dynamics that are identical in terms of their Shannon information content.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/47217d0b59c0cd0c595444568a32de3da39b4647",
    "doi": "10.3390/e25040648",
    "arxivId": "2205.04440",
    "authors": "A. Jansma",
    "citationCount": 6
  },
  {
    "s2PaperId": "9cbe13f6eb4ded1a24e642825ad14d2c01198038",
    "title": "Population coding strategies in human tactile afferents",
    "abstract": "Sensory information is conveyed by populations of neurons, and coding strategies cannot always be deduced when considering individual neurons. Moreover, information coding depends on the number of neurons available and on the composition of the population when multiple classes with different response properties are available. Here, we study population coding in human tactile afferents by employing a recently developed simulator of mechanoreceptor firing activity. First, we demonstrate that the optimal afferent density for conveying maximal information depends on the tactile feature under consideration and the afferent class coding this feature. Second, we find that information is spread across different classes for all tactile features, such that combining information from multiple afferent classes improves information transmission, and is often more efficient than increasing the density of afferents from the same class. Finally, we test the importance of timing precision and afferent identity in the population code to probe whether temporal and spatial information can be traded against each other. Destroying temporal information turns out to be more destructive than removing spatial information, and the contribution of either cannot be completely recovered from the other. Overall, our results suggest that both optimal afferent innervation densities and the composition of the population depend in complex ways on the tactile features in question, potentially accounting for the variety in which tactile peripheral populations are assembled in different regions across the body.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/9cbe13f6eb4ded1a24e642825ad14d2c01198038",
    "doi": "10.1101/2022.05.04.490609",
    "arxivId": "",
    "authors": "G. Corniani, Miguel A. Casal, S. Panzeri, Hannes P. Saal",
    "citationCount": 11
  },
  {
    "s2PaperId": "85e8ecd9aa6f88d0bc93da29ece887032d32ade1",
    "title": "An information-theoretic approach to build hypergraphs in psychometrics.",
    "abstract": "Psychological network approaches propose to see symptoms or questionnaire items as interconnected nodes, with links between them reflecting pairwise statistical dependencies evaluated on cross-sectional, time-series, or panel data. These networks constitute an established methodology to visualise and conceptualise the interactions and relative importance of nodes/indicators, providing an important complement to other approaches such as factor analysis. However, limiting the representation to pairwise relationships can neglect potentially critical information shared by groups of three or more variables (higher-order statistical interdependencies). To overcome this important limitation, here we propose an information-theoretic framework to assess these interdependencies and consequently to use hypergraphs as representations in psychometrics. As edges in hypergraphs are capable of encompassing several nodes together, this extension can thus provide a richer account on the interactions that may exist among sets of psychological variables. Our results show how psychometric hypergraphs can highlight meaningful redundant and synergistic interactions on either simulated or state-of-the-art, re-analysed psychometric datasets. Overall, our framework extends current network approaches while leading to new ways of assessing the data that differ at their core from other methods, enriching the psychometrics toolbox, and opening promising avenues for future investigation.",
    "year": 2022,
    "venue": "Behavior Research Methods",
    "url": "https://www.semanticscholar.org/paper/85e8ecd9aa6f88d0bc93da29ece887032d32ade1",
    "doi": "10.3758/s13428-024-02471-8",
    "arxivId": "2205.01035",
    "authors": "D. Marinazzo, Jan Van Roozendaal, F. Rosas, Massimo Stella, Renzo Comolatti, Nigel Colenbier, S. Stramaglia, Y. Rosseel",
    "citationCount": 11
  },
  {
    "s2PaperId": "f5b2b68fc23e0d2a07a020766d6e25f72f0f8fab",
    "title": "Multiscale partial information decomposition of dynamic processes with short and long-range correlations: theory and application to cardiovascular control",
    "abstract": "Objective. In this work, an analytical framework for the multiscale analysis of multivariate Gaussian processes is presented, whereby the computation of Partial Information Decomposition measures is achieved accounting for the simultaneous presence of short-term dynamics and long-range correlations. Approach. We consider physiological time series mapping the activity of the cardiac, vascular and respiratory systems in the field of Network Physiology. In this context, the multiscale representation of transfer entropy within the network of interactions among Systolic arterial pressure (S), respiration (R) and heart period (H), as well as the decomposition into unique, redundant and synergistic contributions, is obtained using a Vector AutoRegressive Fractionally Integrated (VARFI) framework for Gaussian processes. This novel approach allows to quantify the directed information flow accounting for the simultaneous presence of short-term dynamics and long-range correlations among the analyzed processes. Additionally, it provides analytical expressions for the computation of the information measures, by exploiting the theory of state space models. The approach is first illustrated in simulated VARFI processes and then applied to H, S and R time series measured in healthy subjects monitored at rest and during mental and postural stress. Main Results. We demonstrate the ability of the VARFI modeling approach to account for the coexistence of short-term and long-range correlations in the study of multivariate processes. Physiologically, we show that postural stress induces larger redundant and synergistic effects from S and R to H at short time scales, while mental stress induces larger information transfer from S to H at longer time scales, thus evidencing the different nature of the two stressors. Significance. The proposed methodology allows to extract useful information about the dependence of the information transfer on the balance between short-term and long-range correlations in coupled dynamical systems, which cannot be observed using standard methods that do not consider long-range correlations.",
    "year": 2022,
    "venue": "Physiological Measurement",
    "url": "https://www.semanticscholar.org/paper/f5b2b68fc23e0d2a07a020766d6e25f72f0f8fab",
    "doi": "10.1088/1361-6579/ac826c",
    "arxivId": "2204.14112",
    "authors": "Hélder Pinto, R. Pernice, Maria Eduarda Silva, M. Javorka, L. Faes, A. P. Rocha",
    "citationCount": 9
  },
  {
    "s2PaperId": "3cba454eae6377bbc4c831e4445c52909612b9d0",
    "title": "Developments of Research on the Nature of Life from the Information Theory of Individuality",
    "abstract": "The research on the nature of life from the perspective of information can be traced back to Schrödinger’s theory on the negative entropy of life. Many system scientists and system philosophers inherited Schrödinger’s research approach and emphasized the relationship between information science and the nature of life. Recently, David Krakauer, the current director of the Santa Fe Institute, and others proposed The Information Theory of Individuality, and further used information theory to define and classify formally individuals, deepening the relationship between information and the nature of life. Information individuals are divided into Organismal Individuality, Colonial Individuality, and Environmental Determined Individuality. The formal definition of information individuals is a new development in Schrödinger’s research on the nature of life, and it is also instructive for contemporary artificial life research.",
    "year": 2022,
    "venue": "The 2021 Summit of the International Society for the Study of Information",
    "url": "https://www.semanticscholar.org/paper/3cba454eae6377bbc4c831e4445c52909612b9d0",
    "doi": "10.3390/proceedings2022081130",
    "arxivId": "",
    "authors": "Wangjun Zhang, Dongping Fan",
    "citationCount": 0
  },
  {
    "s2PaperId": "7b1cf4c915c78136299a50599795de3e978c58d1",
    "title": "Continuity and Additivity Properties of Information Decompositions",
    "abstract": "Information decompositions quantify how the Shannon information about a given random variable is distributed among several other random variables. Various requirements have been proposed that such a decomposition should satisfy, leading to different candidate solutions. Curiously, however, only two of the original requirements that determined the Shannon information have been considered, namely monotonicity and normalization. Two other important properties, continuity and additivity, have not been considered. In this contribution, we focus on the mutual information of two finite variables $Y,Z$ about a third finite variable $S$ and check which of the decompositions satisfy these two properties. While most of them satisfy continuity, only one of them is both continuous and additive.",
    "year": 2022,
    "venue": "International Journal of Approximate Reasoning",
    "url": "https://www.semanticscholar.org/paper/7b1cf4c915c78136299a50599795de3e978c58d1",
    "doi": "10.48550/arXiv.2204.10982",
    "arxivId": "2204.10982",
    "authors": "Johannes Rauh, P. Banerjee, E. Olbrich, Guido Montúfar, J. Jost",
    "citationCount": 7
  },
  {
    "s2PaperId": "b3d8d68ebd7f4409f552e48c04ad62747d91cc9f",
    "title": "Understanding Design Features of Music and Language: The Choric/Dialogic Distinction",
    "abstract": "Music and spoken language share certain characteristics: both consist of sequences of acoustic elements that are combinatorically combined, and these elements partition the same continuous acoustic dimensions (frequency, formant space and duration). However, the resulting categories differ sharply: scale tones and note durations of small integer ratios appear in music, while speech uses phonemes, lexical tone, and non-isochronous durations. Why did music and language diverge into the two systems we have today, differing in these specific features? We propose a framework based on information theory and a reverse-engineering perspective, suggesting that design features of music and language are a response to their differential deployment along three different continuous dimensions. These include the familiar propositional-aesthetic (‘goal’) and repetitive-novel (‘novelty’) dimensions, and a dialogic-choric (‘interactivity’) dimension that is our focus here. Specifically, we hypothesize that music exhibits specializations enhancing coherent production by several individuals concurrently—the ‘choric’ context. In contrast, language is specialized for exchange in tightly coordinated turn-taking—‘dialogic’ contexts. We examine the evidence for our framework, both from humans and non-human animals, and conclude that many proposed design features of music and language follow naturally from their use in distinct dialogic and choric communicative contexts. Furthermore, the hybrid nature of intermediate systems like poetry, chant, or solo lament follows from their deployment in the less typical interactive context.",
    "year": 2022,
    "venue": "Frontiers in Psychology",
    "url": "https://www.semanticscholar.org/paper/b3d8d68ebd7f4409f552e48c04ad62747d91cc9f",
    "doi": "10.3389/fpsyg.2022.786899",
    "arxivId": "",
    "authors": "William Shiyuan Wang, Felix Haiduk, W. Fitch, Haiduk and Fitch",
    "citationCount": 14
  },
  {
    "s2PaperId": "9e6630a05065c3d1b6114dbf23e0dc2f2d7242a7",
    "title": "Multi-View Information Bottleneck Without Variational Approximation",
    "abstract": "By \"intelligently\" fuse the complementary information across different views, multi-view learning is able to improve the performance of classification task. In this work, we extend the information bottleneck principle to supervised multi-view learning scenario and use the recently proposed matrix-based Rényi’s α-order entropy functional to optimize the resulting objective directly, without the necessity of variational approximation or adversarial training. Empirical results in both synthetic and real-world datasets suggest that our method enjoys improved robustness to noise and redundant information in each view, especially given limited training samples. Code is available at https://github.com/archy666/MEIB.",
    "year": 2022,
    "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
    "url": "https://www.semanticscholar.org/paper/9e6630a05065c3d1b6114dbf23e0dc2f2d7242a7",
    "doi": "10.48550/arXiv.2204.10530",
    "arxivId": "2204.10530",
    "authors": "Qi Zhang, Shujian Yu, J. Xin, Badong Chen",
    "citationCount": 11
  },
  {
    "s2PaperId": "1b648cad7806d5dac7f51e842fbbd44018afc153",
    "title": "Ultra-marginal Feature Importance: Learning from Data with Causal Guarantees",
    "abstract": "Scientists frequently prioritize learning from data rather than training the best possible model; however, research in machine learning often prioritizes the latter. Marginal contribution feature importance (MCI) was developed to break this trend by providing a useful framework for quantifying the relationships in data. In this work, we aim to improve upon the theoretical properties, performance, and runtime of MCI by introducing ultra-marginal feature importance (UMFI), which uses dependence removal techniques from the AI fairness literature as its foundation. We first propose axioms for feature importance methods that seek to explain the causal and associative relationships in data, and we prove that UMFI satisfies these axioms under basic assumptions. We then show on real and simulated data that UMFI performs better than MCI, especially in the presence of correlated interactions and unrelated features, while partially learning the structure of the causal graph and reducing the exponential runtime of MCI to super-linear.",
    "year": 2022,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "url": "https://www.semanticscholar.org/paper/1b648cad7806d5dac7f51e842fbbd44018afc153",
    "doi": "",
    "arxivId": "2204.09938",
    "authors": "Joseph Janssen, Vincent Guan, Elina Robeva",
    "citationCount": 7
  },
  {
    "s2PaperId": "6772ea03880a10802074baf5ecf8bd44fda60925",
    "title": "Generative power of a protein language model trained on multiple sequence alignments",
    "abstract": "Computational models starting from large ensembles of evolutionarily related protein sequences capture a representation of protein families and learn constraints associated to protein structure and function. They thus open the possibility for generating novel sequences belonging to protein families. Protein language models trained on multiple sequence alignments, such as MSA Transformer, are highly attractive candidates to this end. We propose and test an iterative method that directly employs the masked language modeling objective to generate sequences using MSA Transformer. We demonstrate that the resulting sequences score as well as natural sequences, for homology, coevolution and structure-based measures. For large protein families, our synthetic sequences have similar or better properties compared to sequences generated by Potts models, including experimentally-validated ones. Moreover, for small protein families, our generation method based on MSA Transformer outperforms Potts models. Our method also more accurately reproduces the higher-order statistics and the distribution of sequences in sequence space of natural data than Potts models. MSA Transformer is thus a strong candidate for protein sequence generation and protein design.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/6772ea03880a10802074baf5ecf8bd44fda60925",
    "doi": "10.7554/eLife.79854",
    "arxivId": "2204.07110",
    "authors": "Damiano Sgarbossa, Umberto Lupo, Anne-Florence Bitbol",
    "citationCount": 34
  },
  {
    "s2PaperId": "509c7f6ec4ae7d33006f9c5e9c174f61a43df598",
    "title": "Graph Ordering Attention Networks",
    "abstract": "Graph Neural Networks (GNNs) have been successfully used in many problems involving graph-structured data, achieving state-of-the-art performance.  GNNs typically employ a message-passing scheme, in which every node aggregates information from its neighbors using a permutation-invariant aggregation function. Standard well-examined choices such as the mean or sum aggregation functions have limited capabilities, as they are not able to capture interactions among neighbors.  In this work, we formalize these interactions using an information-theoretic framework that notably includes synergistic information.  Driven by this definition, we introduce the Graph Ordering Attention (GOAT) layer, a novel GNN component that captures interactions between nodes in a neighborhood.  This is achieved by learning local node orderings via an attention mechanism and processing the ordered representations using a recurrent neural network aggregator.  This design allows us to make use of a permutation-sensitive aggregator while maintaining the permutation-equivariance of the proposed GOAT layer.  The GOAT model demonstrates its increased performance in modeling graph metrics that capture complex information, such as the betweenness centrality and the effective size of a node. In practical use-cases, its superior modeling capability is confirmed through its success in several real-world node classification benchmarks.",
    "year": 2022,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/509c7f6ec4ae7d33006f9c5e9c174f61a43df598",
    "doi": "10.48550/arXiv.2204.05351",
    "arxivId": "2204.05351",
    "authors": "Michail Chatzianastasis, J. Lutzeyer, George Dasoulas, M. Vazirgiannis",
    "citationCount": 20
  },
  {
    "s2PaperId": "00bc88bdbf8dca194cb4c4864a1a2ffa879e7e81",
    "title": "Information-theoretic analyses of neural data to minimize the effect of researchers’ assumptions in predictive coding studies",
    "abstract": "Studies investigating neural information processing often implicitly ask both, which processing strategy out of several alternatives is used and how this strategy is implemented in neural dynamics. A prime example are studies on predictive coding. These often ask whether confirmed predictions about inputs or prediction errors between internal predictions and inputs are passed on in a hierarchical neural system—while at the same time looking for the neural correlates of coding for errors and predictions. If we do not know exactly what a neural system predicts at any given moment, this results in a circular analysis—as has been criticized correctly. To circumvent such circular analysis, we propose to express information processing strategies (such as predictive coding) by local information-theoretic quantities, such that they can be estimated directly from neural data. We demonstrate our approach by investigating two opposing accounts of predictive coding-like processing strategies, where we quantify the building blocks of predictive coding, namely predictability of inputs and transfer of information, by local active information storage and local transfer entropy. We define testable hypotheses on the relationship of both quantities, allowing us to identify which of the assumed strategies was used. We demonstrate our approach on spiking data collected from the retinogeniculate synapse of the cat (N = 16). Applying our local information dynamics framework, we are able to show that the synapse codes for predictable rather than surprising input. To support our findings, we estimate quantities applied in the partial information decomposition framework, which allow to differentiate whether the transferred information is primarily bottom-up sensory input or information transferred conditionally on the current state of the synapse. Supporting our local information-theoretic results, we find that the synapse preferentially transfers bottom-up information.",
    "year": 2022,
    "venue": "PLoS Comput. Biol.",
    "url": "https://www.semanticscholar.org/paper/00bc88bdbf8dca194cb4c4864a1a2ffa879e7e81",
    "doi": "10.48550/arXiv.2203.10810",
    "arxivId": "2203.10810",
    "authors": "Patricia Wollstadt, D. Rathbun, W. Usrey, A. Bastos, Michael Lindner, V. Priesemann, M. Wibral",
    "citationCount": 4
  },
  {
    "s2PaperId": "fe7e704dc754cd573d17a66f7c760046002550aa",
    "title": "Disentangling high-order mechanisms and high-order behaviours in complex systems",
    "abstract": "Battiston et al. (arXiv:2110.06023) provide a comprehensive overview of how investigations of complex systems should take into account interactions between more than two elements, which can be modelled by hypergraphs and studied via topological data analysis. Following a separate line of enquiry, a broad literature has developed information-theoretic tools to characterize high-order interdependencies from observed data. While these could seem to be competing approaches aiming to address the same question, in this correspondence we clarify that this is not the case, and that a complete account of higher-order phenomena needs to embrace both.",
    "year": 2022,
    "venue": "Nature Physics",
    "url": "https://www.semanticscholar.org/paper/fe7e704dc754cd573d17a66f7c760046002550aa",
    "doi": "10.1038/s41567-022-01548-5",
    "arxivId": "2203.12041",
    "authors": "F. Rosas, P. Mediano, A. Luppi, Thomas F. Varley, J. Lizier, S. Stramaglia, Henrik J. Jensen, D. Marinazzo",
    "citationCount": 73
  },
  {
    "s2PaperId": "a5ffccf2143ee95873670d98af93ee9c7be33689",
    "title": "Quantifying Reinforcement-Learning Agent’s Autonomy, Reliance on Memory and Internalisation of the Environment",
    "abstract": "Intuitively, the level of autonomy of an agent is related to the degree to which the agent’s goals and behaviour are decoupled from the immediate control by the environment. Here, we capitalise on a recent information-theoretic formulation of autonomy and introduce an algorithm for calculating autonomy in a limiting process of time step approaching infinity. We tackle the question of how the autonomy level of an agent changes during training. In particular, in this work, we use the partial information decomposition (PID) framework to monitor the levels of autonomy and environment internalisation of reinforcement-learning (RL) agents. We performed experiments on two environments: a grid world, in which the agent has to collect food, and a repeating-pattern environment, in which the agent has to learn to imitate a sequence of actions by memorising the sequence. PID also allows us to answer how much the agent relies on its internal memory (versus how much it relies on the observations) when transitioning to its next internal state. The experiments show that specific terms of PID strongly correlate with the obtained reward and with the agent’s behaviour against perturbations in the observations.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/a5ffccf2143ee95873670d98af93ee9c7be33689",
    "doi": "10.3390/e24030401",
    "arxivId": "",
    "authors": "Anti Ingel, Abdullah Makkeh, Oriol Corcoll, Raul Vicente",
    "citationCount": 3
  },
  {
    "s2PaperId": "a913a41dc7357b566f312ab94beb87d9b1b23f8d",
    "title": "Warming, increase in precipitation, and irrigation enhance greening in High Mountain Asia",
    "abstract": "High-Mountain Asia exhibits one of the highest increases in vegetation greenness on Earth, subsequently influencing the exchange of water and energy between the land surface and the atmosphere. Given the strong interactions between the hydrosphere, the biosphere, and the cryosphere, understanding the drivers of greening in this highly complex region with significant land cover heterogeneity is essential to assess the changes in the regional water budget. Here, we perform a holistic multivariate remote sensing analysis to simultaneously examine the primary components of the terrestrial water cycle from 2003 to 2020 and decipher the principal drivers of greening in High-Mountain Asia. We identified three drivers of greening: (1) precipitation drives greening in mid and low elevation areas covered by evergreen and mixed forests (e.g., Irrawaddy basin), (2) decreases in snow enhance greening in most of the hydrologic basins, and (3) irrigation induces greening in irrigated lands (Ganges–Brahmaputra and Indus). Greening in high mountain Asia between 2003 and 2020 was driven by warming at high elevations, increased precipitation in forested regions and enhanced irrigation in croplands, according to a multivariate analysis of remote sensing data.",
    "year": 2022,
    "venue": "Communications Earth & Environment",
    "url": "https://www.semanticscholar.org/paper/a913a41dc7357b566f312ab94beb87d9b1b23f8d",
    "doi": "10.1038/s43247-022-00374-0",
    "arxivId": "",
    "authors": "F. Maina, Sujay V. Kumar, C. Albergel, S. Mahanama",
    "citationCount": 35
  },
  {
    "s2PaperId": "44a607e4b782b68bf7014cfd1813a5ec5245e9bb",
    "title": "Decomposing past and future: Integrated information decomposition based on shared probability mass exclusions",
    "abstract": "A core feature of complex systems is that the interactions between elements in the present causally constrain their own futures, and the futures of other elements as the system evolves through time. To fully model all of these interactions (between elements, as well as ensembles of elements), it is possible to decompose the total information flowing from past to future into a set of non-overlapping temporal interactions that describe all the different modes by which information can be stored, transferred, or modified. To achieve this, I propose a novel information-theoretic measure of temporal dependency (Iτsx) based on the logic of local probability mass exclusions. This integrated information decomposition can reveal emergent and higher-order interactions within the dynamics of a system, as well as refining existing measures. To demonstrate the utility of this framework, I apply the decomposition to spontaneous spiking activity recorded from dissociated neural cultures of rat cerebral cortex to show how different modes of information processing are distributed over the system. Furthermore, being a localizable analysis, Iτsx can provide insight into the computational structure of single moments. I explore the time-resolved computational structure of neuronal avalanches and find that different types of information atoms have distinct profiles over the course of an avalanche, with the majority of non-trivial information dynamics happening before the first half of the cascade is completed. These analyses allow us to move beyond the historical focus on single measures of dependency such as information transfer or information integration, and explore a panoply of different relationships between elements (and groups of elements) in complex systems.",
    "year": 2022,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/44a607e4b782b68bf7014cfd1813a5ec5245e9bb",
    "doi": "10.1371/journal.pone.0282950",
    "arxivId": "2202.12992",
    "authors": "Thomas F. Varley",
    "citationCount": 16
  },
  {
    "s2PaperId": "d2fc359902c3f416c79ed2a6cdebe12741674d91",
    "title": "Information Decomposition Diagrams Applied beyond Shannon Entropy: A Generalization of Hu's Theorem",
    "abstract": "In information theory, one major goal is to find useful functions that summarize the amount of information contained in the interaction of several random variables. Specifically, one can ask how the classical Shannon entropy, mutual information, and higher interaction information relate to each other. This is answered by Hu's theorem, which is widely known in the form of information diagrams: it relates shapes in a Venn diagram to information functions, thus establishing a bridge from set theory to information theory. In this work, we view random variables together with the joint operation as a monoid that acts by conditioning on information functions, and entropy as a function satisfying the chain rule of information. This abstract viewpoint allows to prove a generalization of Hu's theorem. It applies to Shannon and Tsallis entropy, (Tsallis) Kullback-Leibler Divergence, cross-entropy, Kolmogorov complexity, submodular information functions, and the generalization error in machine learning. Our result implies for Chaitin's Kolmogorov complexity that the interaction complexities of all degrees are in expectation close to Shannon interaction information. For well-behaved probability distributions on increasing sequence lengths, this shows that the per-bit expected interaction complexity and information asymptotically coincide, thus showing a strong bridge between algorithmic and classical information theory.Comment: 46 pages, 5 figures",
    "year": 2022,
    "venue": "Compositionality",
    "url": "https://www.semanticscholar.org/paper/d2fc359902c3f416c79ed2a6cdebe12741674d91",
    "doi": "10.46298/compositionality-7-1",
    "arxivId": "2202.09393",
    "authors": "Leon Lang, P. Baudot, Rick Quax, Patrick Forr'e",
    "citationCount": 6
  },
  {
    "s2PaperId": "a0bee535274fb3067f983cfea19e99b4344b4dc7",
    "title": "Conservative Significance Testing of Tripartite Interactions in Multivariate Neural Data",
    "abstract": "An important goal in systems neuroscience is to understand the structure of neuronal interactions, frequently approached by studying functional relations between recorded neuronal signals. Commonly used pairwise metrics (e.g. correlation coefficient) offer limited insight, neither addressing the specificity of estimated neuronal interactions nor potential synergistic coupling between neuronal signals. Tripartite metrics, such as partial correlation, variance partitioning, and partial information decomposition, address these questions by disentangling functional relations into interpretable information atoms (unique, redundant and synergistic). Here, we apply these tripartite metrics to simulated neuronal recordings to investigate their sensitivity to impurities (like noise or other unexplained variance) in the data. We find that all considered metrics are accurate and specific for pure signals but experience significant bias for impure signals. We show that permutation-testing of such metrics results in high false positive rates even for small impurities and large data sizes. We present a conservative null hypothesis for significance testing of tripartite metrics, which significantly decreases false positive rate at a tolerable expense of increasing false negative rate. We hope our study raises awareness about the potential pitfalls of significance testing and of interpretation of functional relations, offering both conceptual and practical advice. Author Summary Tripartite functional relation metrics enable the study of interesting effects in neural recordings, such as redundancy, functional connection specificity and synergistic coupling. However, common estimators of such relations are designed for pure (e.g. non-noisy) signals rare for such recordings. We study the performance of tripartite estimators using simulated impure neural signals. We demonstrate that permutation-testing is not a robust procedure for inferring ground truth interactions from studied estimators. We develop an adjusted conservative testing procedure, reducing false positive rate of studied estimators for impure data. Besides addressing significance testing, our results should aid in accurate interpretation of tripartite functional relations and functional connectivity.",
    "year": 2022,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/a0bee535274fb3067f983cfea19e99b4344b4dc7",
    "doi": "10.1101/2022.02.07.479415",
    "arxivId": "",
    "authors": "Aleksejs Fomins, Yaroslav Sych, F. Helmchen",
    "citationCount": 0
  },
  {
    "s2PaperId": "87ccf8601e7f753b0aa36920b65eb2b04314e36a",
    "title": "Neural Encoding of Active Multi-Sensing Enhances Perceptual Decision-Making via a Synergistic Cross-Modal Interaction",
    "abstract": "Most perceptual decisions rely on the active acquisition of evidence from the environment involving stimulation from multiple senses. However, our understanding of the neural mechanisms underlying this process is limited. Crucially, it remains elusive how different sensory representations interact in the formation of perceptual decisions. To answer these questions, we used an active sensing paradigm coupled with neuroimaging, multivariate analysis, and computational modeling to probe how the human brain processes multisensory information to make perceptual judgments. Participants of both sexes actively sensed to discriminate two texture stimuli using visual (V) or haptic (H) information or the two sensory cues together (VH). Crucially, information acquisition was under the participants' control, who could choose where to sample information from and for how long on each trial. To understand the neural underpinnings of this process, we first characterized where and when active sensory experience (movement patterns) is encoded in human brain activity (EEG) in the three sensory conditions. Then, to offer a neurocomputational account of active multisensory decision formation, we used these neural representations of active sensing to inform a drift diffusion model of decision-making behavior. This revealed a multisensory enhancement of the neural representation of active sensing, which led to faster and more accurate multisensory decisions. We then dissected the interactions between the V, H, and VH representations using a novel information-theoretic methodology. Ultimately, we identified a synergistic neural interaction between the two unisensory (V, H) representations over contralateral somatosensory and motor locations that predicted multisensory (VH) decision-making performance. SIGNIFICANCE STATEMENT In real-world settings, perceptual decisions are made during active behaviors, such as crossing the road on a rainy night, and include information from different senses (e.g., car lights, slippery ground). Critically, it remains largely unknown how sensory evidence is combined and translated into perceptual decisions in such active scenarios. Here we address this knowledge gap. First, we show that the simultaneous exploration of information across senses (multi-sensing) enhances the neural encoding of active sensing movements. Second, the neural representation of active sensing modulates the evidence available for decision; and importantly, multi-sensing yields faster evidence accumulation. Finally, we identify a cross-modal interaction in the human brain that correlates with multisensory performance, constituting a putative neural mechanism for forging active multisensory perception.",
    "year": 2022,
    "venue": "Journal of Neuroscience",
    "url": "https://www.semanticscholar.org/paper/87ccf8601e7f753b0aa36920b65eb2b04314e36a",
    "doi": "10.1523/JNEUROSCI.0861-21.2022",
    "arxivId": "",
    "authors": "Ioannis Delis, Robin A. A. Ince, P. Sajda, Qi Wang",
    "citationCount": 15
  },
  {
    "s2PaperId": "634f264c74e3ea9134a8c4d59fd9b5ec705bb89d",
    "title": "Neural Information Squeezer for Causal Emergence",
    "abstract": "Conventional studies of causal emergence have revealed that stronger causality can be obtained on the macro-level than the micro-level of the same Markovian dynamical systems if an appropriate coarse-graining strategy has been conducted on the micro-states. However, identifying this emergent causality from data is still a difficult problem that has not been solved because the appropriate coarse-graining strategy can not be found easily. This paper proposes a general machine learning framework called Neural Information Squeezer to automatically extract the effective coarse-graining strategy and the macro-level dynamics, as well as identify causal emergence directly from time series data. By using invertible neural network, we can decompose any coarse-graining strategy into two separate procedures: information conversion and information discarding. In this way, we can not only exactly control the width of the information channel, but also can derive some important properties analytically. We also show how our framework can extract the coarse-graining functions and the dynamics on different levels, as well as identify causal emergence from the data on several exampled systems.",
    "year": 2022,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/634f264c74e3ea9134a8c4d59fd9b5ec705bb89d",
    "doi": "10.3390/e25010026",
    "arxivId": "2201.10154",
    "authors": "Jiang Zhang",
    "citationCount": 17
  },
  {
    "s2PaperId": "b50ed08c0587835856ba817ac7828bb1f145f262",
    "title": "A whitening approach for Transfer Entropy permits the application to narrow-band signals",
    "abstract": "Transfer Entropy, a generalisation of Granger Causality, promises to measure\"information transfer\"from a source to a target signal by ignoring self-predictability of a target signal when quantifying the source-target relationship. A simple example for signals with such self-predictability are narrowband signals. These are both thought to be intrinsically generated by the brain as well as commonly dealt with in analyses of brain signals, where band-pass filters are used to separate responses from noise. However, the use of Transfer Entropy is usually discouraged in such cases. We simulate simplistic examples where we confirm the failure of classic implementations of Transfer Entropy when applied to narrow-band signals, as made evident by a flawed recovery of effect sizes and interaction delays. We propose an alternative approach based on a whitening of the input signals before computing a bivariate measure of directional time-lagged dependency. This approach solves the problems found in the simple simulated systems. Finally, we explore the behaviour of our measure when applied to delta and theta response components in Magnetoencephalography (MEG) responses to continuous speech. The small effects that our measure attributes to a directed interaction from the stimulus to the neuronal responses are stronger in the theta than in the delta band. This suggests that the delta band reflects a more predictive coupling, while the theta band is stronger involved in bottom-up, reactive processing. Taken together, we hope to increase the interest in directed perspectives on frequency-specific dependencies.",
    "year": 2022,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/b50ed08c0587835856ba817ac7828bb1f145f262",
    "doi": "",
    "arxivId": "2201.02461",
    "authors": "C. Daube, J. Gross, Robin A. A. Ince",
    "citationCount": 4
  },
  {
    "s2PaperId": "cc082a10cc133dcb1f6e90850fe48f19d20b912b",
    "title": "Measuring Interactions in Categorical Datasets Using Multivariate Symmetrical Uncertainty",
    "abstract": "Interaction between variables is often found in statistical models, and it is usually expressed in the model as an additional term when the variables are numeric. However, when the variables are categorical (also known as nominal or qualitative) or mixed numerical-categorical, defining, detecting, and measuring interactions is not a simple task. In this work, based on an entropy-based correlation measure for n nominal variables (named as Multivariate Symmetrical Uncertainty (MSU)), we propose a formal and broader definition for the interaction of the variables. Two series of experiments are presented. In the first series, we observe that datasets where some record types or combinations of categories are absent, forming patterns of records, which often display interactions among their attributes. In the second series, the interaction/non-interaction behavior of a regression model (entirely built on continuous variables) gets successfully replicated under a discretized version of the dataset. It is shown that there is an interaction-wise correspondence between the continuous and the discretized versions of the dataset. Hence, we demonstrate that the proposed definition of interaction enabled by the MSU is a valuable tool for detecting and measuring interactions within linear and non-linear models.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/cc082a10cc133dcb1f6e90850fe48f19d20b912b",
    "doi": "10.3390/e24010064",
    "arxivId": "",
    "authors": "Santiago Gómez-Guerrero, Inocencio Ortiz, Gustavo Sosa-Cabrera, M. García-Torres, C. Schaerer",
    "citationCount": 2
  },
  {
    "s2PaperId": "b0251638a3738f1e2c3aa0a375c6a56cd5e0f856",
    "title": "Computationally Efficient Approximations for Matrix-Based Rényi's Entropy",
    "abstract": "The recently developed matrix-based Rényi's <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math></inline-formula>-order entropy enables measurement of information in data simply using the eigenspectrum of symmetric positive semi-definite (PSD) matrices in reproducing kernel Hilbert space, without estimation of the underlying data distribution. This intriguing property makes this new information measurement widely adopted in multiple statistical inference and learning tasks. However, the computation of such quantity involves the trace operator on a PSD matrix <inline-formula><tex-math notation=\"LaTeX\">$G$</tex-math></inline-formula> to power <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math></inline-formula> (i.e., <inline-formula><tex-math notation=\"LaTeX\">${\\text{tr}}(G^\\alpha)$</tex-math></inline-formula>), with a normal complexity of nearly <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {O}(n^{3})$</tex-math></inline-formula>, which severely hampers its practical usage when the number of samples (i.e., <inline-formula><tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula>) is large. In this work, we present computationally efficient approximations to this new entropy functional that can reduce its complexity to even significantly less than <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {O}(n^{2})$</tex-math></inline-formula>. To this end, we leverage the recent progress on Randomized Numerical Linear Algebra, developing Taylor, Chebyshev and Lanczos approximations to <inline-formula><tex-math notation=\"LaTeX\">${\\text{tr}}(G^\\alpha)$</tex-math></inline-formula> for arbitrary values of <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math></inline-formula> by converting it into a matrix-vector multiplication problem. We also establish the connection between the matrix-based Rényi's entropy and PSD matrix approximation, which enables exploiting both clustering and block low-rank structure of <inline-formula><tex-math notation=\"LaTeX\">$G$</tex-math></inline-formula> to further reduce the computational cost. We theoretically provide approximation accuracy guarantees and illustrate the properties for different approximations. Large-scale experimental evaluations on both synthetic and real-world data corroborate our theoretical findings, showing promising speedup with negligible loss in accuracy.",
    "year": 2021,
    "venue": "IEEE Transactions on Signal Processing",
    "url": "https://www.semanticscholar.org/paper/b0251638a3738f1e2c3aa0a375c6a56cd5e0f856",
    "doi": "10.1109/TSP.2022.3233724",
    "arxivId": "2112.13720",
    "authors": "Tieliang Gong, Yuxin Dong, Shujian Yu, Hong Chen, B. Dong, Chen Li, Qinghua Zheng",
    "citationCount": 4
  },
  {
    "s2PaperId": "eb759296b7dc484f7c90be43d78a9e749bf92a33",
    "title": "Signed and Unsigned Partial Information Decompositions of Continuous Network Interactions",
    "abstract": "We investigate the partial information decomposition (PID) framework as a tool for edge nomination. We consider both the $I_{\\cap}^{\\text{min}}$ and $I_{\\cap}^{\\text{PM}}$ PIDs, from Williams & Beer (2010, Nonnegative decomposition of multivariate information, CoRR, arXiv:2106.12393) and Finn & Lizier (2018, Entropy, 20, 297), respectively, and we both numerically and analytically investigate the utility of these frameworks for discovering significant edge interactions. In the course of our work, we extend both the $I_{\\cap}^{\\text{min}}$ and $I_{\\cap}^{\\text{PM}}$ PIDs to a general class of continuous trivariate systems. Moreover, we examine how each PID apportions information into redundant, synergistic and unique information atoms within the source-bivariate PID framework. Both our simulation experiments and analytic inquiry indicate that the atoms of the $I_{\\cap}^{\\text{PM}}$ PID have a non-specific sensitivity to high predictor-target mutual information, regardless of whether or not the predictors are truly interacting. By contrast, the $I_{\\cap}^{\\text{min}}$ PID is quite specific, although simulations suggest that it lacks sensitivity.",
    "year": 2021,
    "venue": "J. Complex Networks",
    "url": "https://www.semanticscholar.org/paper/eb759296b7dc484f7c90be43d78a9e749bf92a33",
    "doi": "10.1093/comnet/cnac026",
    "arxivId": "2112.12316",
    "authors": "Jesse Milzman, V. Lyzinski",
    "citationCount": 2
  },
  {
    "s2PaperId": "add978aa977abcce79f64d1aa23e21657bf320d8",
    "title": "Explore synergistic and competitive miRNA regulation mechanisms in the miRNA-mRNA regulatory network from the information decomposition perspective",
    "abstract": "Since multiple microRNAs can target 3’ untranslated regions of the same mRNA transcript, it is likely that these endogenous microRNAs may form synergistic alliances, or compete for the same mRNA harbouring overlapping binding site matches. Synergistic and competitive microRNA regulation is an intriguing yet poorly elucidated mechanism. We here introduce a computational method based on the multivariate information measurement to quantify such implicit interaction effects between microRNAs. Our informatics method of integrating sequence and expression data is designed to establish the functional correlation between microRNAs. To demonstrate our method, we exploited TargetScan and The Cancer Genome Atlas data. As a result, we indeed observed that the microRNA pair with neighbouring binding site(s) on the mRNA is likely to trigger synergistic events, while the microRNA pair with overlapping binding site(s) on the mRNA is likely to cause competitive events, provided that the pair of microRNAs has a high functional similarity and the corresponding triplet presents a positive/negative ‘synergy-redundancy’ score.",
    "year": 2021,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/add978aa977abcce79f64d1aa23e21657bf320d8",
    "doi": "10.1101/2021.12.20.473520",
    "arxivId": "",
    "authors": "Chu Pan, Jingjing Jiang, Limei Jing, Wan Chen, Yi Yang, Ying Liu, Jiawei Luo, Xiang-gang Zeng",
    "citationCount": 0
  },
  {
    "s2PaperId": "6695de01755a9673fcfa97ef9c8645d72608bcbd",
    "title": "Informeasure: an R/Bioconductor package to quantify nonlinear dependence between variables in biological networks from an information theory perspective",
    "abstract": "Using information measures to infer biological regulatory networks can observe nonlinear relationship between variables, but it is computationally challenging and there is currently no convenient tool available. We here describe an information theory R package named Informeasure that devotes to quantifying nonlinear dependence between variables in biological regulatory networks from an information theory perspective. This package compiles most of the information measures currently available: mutual information, conditional mutual information, interaction information, partial information decomposition and part mutual information. The first estimator is used to infer bivariate networks while the last four estimators are dedicated to analysis of trivariate networks. The base installation of this turn-key package allows users to approach these information measures out of the box. Informeasure is implemented in R program and is available as an R/Bioconductor package at https://bioconductor.org/packages/Informeasure.",
    "year": 2021,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/6695de01755a9673fcfa97ef9c8645d72608bcbd",
    "doi": "10.1101/2021.12.20.473524",
    "arxivId": "",
    "authors": "Chu Pan, Limei Jing, Jiawei Luo, Xiangxiang Zeng",
    "citationCount": 0
  },
  {
    "s2PaperId": "4149939bf3c5d7b54950cfe0382d449c1a9be189",
    "title": "Interaction-Aware Sensitivity Analysis for Aerodynamic Optimization Results using Information Theory",
    "abstract": "An important issue during an engineering design process is to develop an understanding which design parameters have the most influence on the performance. Especially in the context of optimization approaches this knowledge is crucial in order to realize an efficient design process and achieve high-performing results. Information theory provides powerful tools to investigate these relationships because measures are model-free and thus also capture non-linear relationships, while requiring only minimal assumptions on the input data. We therefore propose to use recently introduced information-theoretic methods and estimation algorithms to find the most influential input parameters in optimization results. The proposed methods are in particular able to account for interactions between parameters, which are often neglected but may lead to redundant or synergistic contributions of multiple parameters. We demonstrate the application of these methods on optimization data from aerospace engineering, where we first identify the most relevant optimization parameters using a recently introduced information-theoretic feature-selection algorithm that accounts for interactions between parameters. Second, we use the novel partial information decomposition (PID) framework that allows to quantify redundant and synergistic contributions between selected parameters with respect to the optimization outcome to identify parameter interactions. We thus demonstrate the power of novel information-theoretic approaches in identifying relevant parameters in optimization runs and highlight how these methods avoid the selection of redundant parameters, while detecting interactions that result in synergistic contributions of multiple parameters.",
    "year": 2021,
    "venue": "IEEE Symposium Series on Computational Intelligence",
    "url": "https://www.semanticscholar.org/paper/4149939bf3c5d7b54950cfe0382d449c1a9be189",
    "doi": "10.1109/SSCI50451.2021.9660067",
    "arxivId": "2112.05609",
    "authors": "Patricia Wollstadt, S. Schmitt",
    "citationCount": 2
  },
  {
    "s2PaperId": "bedb5992c7c2941964e62cd075df63c02b7864d5",
    "title": "Information Theoretic Representation Distillation",
    "abstract": "Despite the empirical success of knowledge distillation, current state-of-the-art methods are computationally expensive to train, which makes them difficult to adopt in practice. To address this problem, we introduce two distinct complementary losses inspired by a cheap entropy-like estimator. These losses aim to maximise the correlation and mutual information between the student and teacher representations. Our method incurs significantly less training overheads than other approaches and achieves competitive performance to the state-of-the-art on the knowledge distillation and cross-model transfer tasks. We further demonstrate the effectiveness of our method on a binary distillation task, whereby it leads to a new state-of-the-art for binary quantisation and approaches the performance of a full precision model. Code: www.github.com/roymiles/ITRD",
    "year": 2021,
    "venue": "British Machine Vision Conference",
    "url": "https://www.semanticscholar.org/paper/bedb5992c7c2941964e62cd075df63c02b7864d5",
    "doi": "",
    "arxivId": "2112.00459",
    "authors": "Roy Miles, Adri'an Rodr'iguez, K. Mikolajczyk",
    "citationCount": 23
  },
  {
    "s2PaperId": "f8a2ce140ab775bd4f0ce421687c63478f2171f0",
    "title": "HRel: Filter pruning based on High Relevance between activation maps and class labels",
    "abstract": "",
    "year": 2021,
    "venue": "Neural Networks",
    "url": "https://www.semanticscholar.org/paper/f8a2ce140ab775bd4f0ce421687c63478f2171f0",
    "doi": "10.1016/j.neunet.2021.12.017",
    "arxivId": "2202.10716",
    "authors": "C. Sarvani, Mrinmoy Ghorai, S. Dubey, S. H. Shabbeer Basha",
    "citationCount": 40
  },
  {
    "s2PaperId": "cdcdc9fa9dfab2de6f3a13fee5c22039d0d0ff63",
    "title": "Covered Information Disentanglement: Model Transparency via Unbiased Permutation Importance",
    "abstract": "Model transparency is a prerequisite in many domains and an increasingly popular area in machine learning research.  In the medical domain, for instance, unveiling the mechanisms behind a disease often has higher priority than the diagnostic itself since it might dictate or guide potential treatments and research directions. One of the most popular approaches to explain model global predictions is the permutation importance where the performance on permuted data is benchmarked against the baseline. However, this method and other related approaches will undervalue the importance of a feature in the presence of covariates since these cover part of its provided information. To address this issue, we propose Covered Information Disentanglement CID, a framework that considers all feature information overlap to correct the values provided by permutation importance. We further show how to compute CID efficiently when coupled with Markov random fields. We demonstrate its efficacy in adjusting permutation importance first on a controlled toy dataset and discuss its effect on real-world medical data.",
    "year": 2021,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/cdcdc9fa9dfab2de6f3a13fee5c22039d0d0ff63",
    "doi": "10.1609/aaai.v36i7.20769",
    "arxivId": "2111.09744",
    "authors": "J. Pereira, E. Stroes, A. Zwinderman, E. Levin",
    "citationCount": 12
  },
  {
    "s2PaperId": "d6a80034f153c44ff6bf12575a45e03a9a942833",
    "title": "Greater than the parts: a review of the information decomposition approach to causal emergence",
    "abstract": "Emergence is a profound subject that straddles many scientific disciplines, including the formation of galaxies and how consciousness arises from the collective activity of neurons. Despite the broad interest that exists on this concept, the study of emergence has suffered from a lack of formalisms that could be used to guide discussions and advance theories. Here, we summarize, elaborate on, and extend a recent formal theory of causal emergence based on information decomposition, which is quantifiable and amenable to empirical testing. This theory relates emergence with information about a system’s temporal evolution that cannot be obtained from the parts of the system separately. This article provides an accessible but rigorous introduction to the framework, discussing the merits of the approach in various scenarios of interest. We also discuss several interpretation issues and potential misunderstandings, while highlighting the distinctive benefits of this formalism. This article is part of the theme issue ‘Emergent phenomena in complex physical and socio-technical systems: from cells to societies’.",
    "year": 2021,
    "venue": "Philosophical Transactions of the Royal Society A",
    "url": "https://www.semanticscholar.org/paper/d6a80034f153c44ff6bf12575a45e03a9a942833",
    "doi": "10.1098/rsta.2021.0246",
    "arxivId": "2111.06518",
    "authors": "P. Mediano, F. Rosas, A. Luppi, Henrik J. Jensen, A. Seth, A. Barrett, Robin L. Carhart-Harris, D. Bor",
    "citationCount": 49
  },
  {
    "s2PaperId": "fbcd1b82f771034a82856ae231a910c0c0d455ca",
    "title": "Quantifying the Autonomy of Structurally Diverse Automata: A Comparison of Candidate Measures",
    "abstract": "Should the internal structure of a system matter when it comes to autonomy? While there is still no consensus on a rigorous, quantifiable definition of autonomy, multiple candidate measures and related quantities have been proposed across various disciplines, including graph-theory, information-theory, and complex system science. Here, I review and compare a range of measures related to autonomy and intelligent behavior. To that end, I analyzed the structural, information-theoretical, causal, and dynamical properties of simple artificial agents evolved to solve a spatial navigation task, with or without a need for associative memory. By contrast to standard artificial neural networks with fixed architectures and node functions, here, independent evolution simulations produced successful agents with diverse neural architectures and functions. This makes it possible to distinguish quantities that characterize task demands and input-output behavior, from those that capture intrinsic differences between substrates, which may help to determine more stringent requisites for autonomous behavior and the means to measure it.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/fbcd1b82f771034a82856ae231a910c0c0d455ca",
    "doi": "10.3390/e23111415",
    "arxivId": "",
    "authors": "Larissa Albantakis",
    "citationCount": 2
  },
  {
    "s2PaperId": "9f09dd938e0504c133bb934512fa9c0179af3442",
    "title": "Narrow and Broad γ Bands Process Complementary Visual Information in Mouse Primary Visual Cortex",
    "abstract": "Visual Abstract γ Band plays a key role in the encoding of visual features in the primary visual cortex (V1). In rodents V1 two ranges within the γ band are sensitive to contrast: a broad γ band (BB) increasing with contrast, and a narrow γ band (NB), peaking at ∼60 Hz, decreasing with contrast. The functional roles of the two bands and the neural circuits originating them are not completely clear yet. Here, we show, combining experimental and simulated data, that in mice V1 (1) BB carries information about high contrast and NB about low contrast; (2) BB modulation depends on excitatory-inhibitory interplay in the cortex, while NB modulation is because of entrainment to the thalamic drive. In awake mice presented with alternating gratings, NB power progressively decreased from low to intermediate levels of contrast where it reached a plateau. Conversely, BB power was constant across low levels of contrast, but it progressively increased from intermediate to high levels of contrast. Furthermore, BB response was stronger immediately after contrast reversal, while the opposite held for NB. These complementary modulations were reproduced by a recurrent excitatory-inhibitory leaky integrate-and-fire network provided that the thalamic inputs were composed of a sustained and a periodic component having complementary sensitivity ranges. These results show that in rodents the thalamic-driven NB plays a specific key role in encoding visual contrast. Moreover, we propose a simple and effective network model of response to visual stimuli in rodents that might help in investigating network dysfunctions of pathologic visual information processing.",
    "year": 2021,
    "venue": "eNeuro",
    "url": "https://www.semanticscholar.org/paper/9f09dd938e0504c133bb934512fa9c0179af3442",
    "doi": "10.1523/ENEURO.0106-21.2021",
    "arxivId": "",
    "authors": "N. Meneghetti, Chiara Cerri, E. Tantillo, E. Vannini, M. Caleo, A. Mazzoni",
    "citationCount": 18
  },
  {
    "s2PaperId": "ade0861af1909df7e4586d8017e4dbfaf26ea24d",
    "title": "Entropy: From Thermodynamics to Information Processing",
    "abstract": "Entropy is a concept that emerged in the 19th century. It used to be associated with heat harnessed by a thermal machine to perform work during the Industrial Revolution. However, there was an unprecedented scientific revolution in the 20th century due to one of its most essential innovations, i.e., the information theory, which also encompasses the concept of entropy. Therefore, the following question is naturally raised: “what is the difference, if any, between concepts of entropy in each field of knowledge?” There are misconceptions, as there have been multiple attempts to conciliate the entropy of thermodynamics with that of information theory. Entropy is most commonly defined as “disorder”, although it is not a good analogy since “order” is a subjective human concept, and “disorder” cannot always be obtained from entropy. Therefore, this paper presents a historical background on the evolution of the term “entropy”, and provides mathematical evidence and logical arguments regarding its interconnection in various scientific areas, with the objective of providing a theoretical review and reference material for a broad audience.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ade0861af1909df7e4586d8017e4dbfaf26ea24d",
    "doi": "10.3390/e23101340",
    "arxivId": "",
    "authors": "Jordão Natal, Ivonete Ávila, V. B. Tsukahara, Marcelo Pinheiro, Carlos Dias Maciel",
    "citationCount": 32
  },
  {
    "s2PaperId": "bb98f966eb8ef8bcc51647575ed1123708a96413",
    "title": "Neural Dependency Coding inspired Multimodal Fusion",
    "abstract": "Information integration from different modalities is an active area of research. Human beings and, in general, biological neural systems are quite adept at using a multitude of signals from different sensory perceptive fields to interact with the environment and each other. Recent work in deep fusion models via neural networks has led to substantial improvements over unimodal approaches in areas like speech recognition, emotion recognition and analysis, captioning and image description. However, such research has mostly focused on architectural changes allowing for fusion of different modalities while keeping the model complexity manageable. Inspired by recent neuroscience ideas about multisensory integration and processing, we investigate the effect of synergy maximizing loss functions. Experiments on multimodal sentiment analysis tasks: CMU-MOSI and CMU-MOSEI with different models show that our approach provides a consistent performance boost.",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/bb98f966eb8ef8bcc51647575ed1123708a96413",
    "doi": "",
    "arxivId": "2110.00385",
    "authors": "Shiv Shankar",
    "citationCount": 3
  },
  {
    "s2PaperId": "e64adb441b5b8d3da1ec2aeb377faae255857bca",
    "title": "Information transmission in a two-step cascade: interplay of activation and repression",
    "abstract": "We present an information-theoretic formalism to study signal transduction in four architectural variants of a model two-step cascade with increasing input population. Our results categorize these four types into two classes depending upon the effect of activation and repression on mutual information, net synergy, and signal-to-noise ratio. Using the Gaussian framework and linear noise approximation, we derive the analytic expressions for these metrics to establish their underlying relationships in terms of the biochemical parameters. We also verify our approximations through stochastic simulations.",
    "year": 2021,
    "venue": "Theory in biosciences",
    "url": "https://www.semanticscholar.org/paper/e64adb441b5b8d3da1ec2aeb377faae255857bca",
    "doi": "10.1007/s12064-021-00357-3",
    "arxivId": "2109.12901",
    "authors": "Tuhin Roy, Mintu Nandi, Ayan Biswas, P. Chaudhury, S. Banik",
    "citationCount": 5
  },
  {
    "s2PaperId": "00386254004172acce3b0c28d3f88d887c3746d3",
    "title": "Towards an extended taxonomy of information dynamics via Integrated Information Decomposition",
    "abstract": "Complex systems, from the human brain to the global economy, are made of multiple elements that interact in such ways that the behaviour of the `whole' often seems to be more than what is readily explainable in terms of the `sum of the parts.' Our ability to understand and control these systems remains limited, one reason being that we still don't know how best to describe -- and quantify -- the higher-order dynamical interactions that characterise their complexity. To address this limitation, we combine principles from the theories of Information Decomposition and Integrated Information into what we call Integrated Information Decomposition, or $\\Phi$ID. $\\Phi$ID provides a comprehensive framework to reason about, evaluate, and understand the information dynamics of complex multivariate systems. $\\Phi$ID reveals the existence of previously unreported modes of collective information flow, providing tools to express well-known measures of information transfer and dynamical complexity as aggregates of these modes. Via computational and empirical examples, we demonstrate that $\\Phi$ID extends our explanatory power beyond traditional causal discovery methods -- with profound implications for the study of complex systems across disciplines.",
    "year": 2021,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/00386254004172acce3b0c28d3f88d887c3746d3",
    "doi": "",
    "arxivId": "2109.13186",
    "authors": "P. Mediano, F. Rosas, A. Luppi, Robin L. Carhart-Harris, D. Bor, A. Seth, A. Barrett",
    "citationCount": 61
  },
  {
    "s2PaperId": "22f92181918bcddf45a7c7c721c69e3c6459729e",
    "title": "Comment on “Information arms race explains plant-herbivore chemical communication in ecological communities”",
    "abstract": "Zu et al (Science, 19 Jun 2020, p. 1377) propose that an ‘information arms-race’ between plants and herbivores explains plant-herbivore communication at the community level. However, our analysis shows that key assumptions of the proposed model either a) conflict with standard evolutionary theory or b) are not supported by the available evidence. We also show that the presented statistical patterns can be explained more parsimoniously (e.g. through a null model) without invoking an unlikely process of community selection.",
    "year": 2021,
    "venue": "Peer Community Journal",
    "url": "https://www.semanticscholar.org/paper/22f92181918bcddf45a7c7c721c69e3c6459729e",
    "doi": "10.32942/osf.io/xsbtm",
    "arxivId": "",
    "authors": "Ethan Bass, A. Kessler",
    "citationCount": 4
  },
  {
    "s2PaperId": "28908f7b1cc00aeb0a90e1bb5a7ebb37e1d9290e",
    "title": "High-order functional redundancy in ageing explained via alterations in the connectome in a whole-brain model",
    "abstract": "The human brain generates a rich repertoire of spatio-temporal activity patterns, which support a wide variety of motor and cognitive functions. These patterns of activity change with age in a multi-factorial manner. One of these factors is the variations in the brain’s connectomics that occurs along the lifespan. However, the precise relationship between high-order functional interactions and connnectomics, as well as their variations with age are largely unknown, in part due to the absence of mechanistic models that can efficiently map brain connnectomics to functional connectivity in aging. To investigate this issue, we have built a neurobiologically-realistic whole-brain computational model using both anatomical and functional MRI data from 161 participants ranging from 10 to 80 years old. We show that the age differences in high-order functional interactions can be largely explained by variations in the connectome. Based on this finding, we propose a simple neurodegeneration model that is representative of normal physiological aging. As such, when applied to connectomes of young participant it reproduces the age-variations that occur in the high-order structure of the functional data. Overall, these results begin to disentangle the mechanisms by which structural changes in the connectome lead to functional differences in the ageing brain. Our model can also serve as a starting point for modelling more complex forms of pathological ageing or cognitive deficits. Author summary Modern neuroimaging techniques allow us to study how the human brain’s anatomical architecture (a.k.a. structural connectome) changes under different conditions or interventions. Recently, using functional neuroimaging data, we have shown that complex patterns of interactions between brain areas change along the lifespan, exhibiting increased redundant interactions in the older population. However, the mechanisms that underlie these functional differences are still unclear. Here, we extended this work and hypothesized that the variations of functional patterns can be explained by the dynamics of the brain’s anatomical networks, which are known to degenerate as we age. To test this hypothesis, we implemented a whole-brain model of neuronal activity, where different brain regions are anatomically wired using real connectomes from 161 participants with ages ranging from 10 to 80 years old. Analyzing different functional aspects of brain activity when varying the empirical connectomes, we show that the increased redundancy found in the older group can indeed be explained by precise rules affecting anatomical connectivity, thus emphasizing the critical role that the brain connectome plays for shaping complex functional interactions and the efficiency in the global communication of the human brain.",
    "year": 2021,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/28908f7b1cc00aeb0a90e1bb5a7ebb37e1d9290e",
    "doi": "10.1371/journal.pcbi.1010431",
    "arxivId": "",
    "authors": "Marilyn Gatica, F. Rosas, P. Mediano, I. Díez, S. Swinnen, P. Orio, R. Cofré, J. Cortes",
    "citationCount": 22
  },
  {
    "s2PaperId": "084be8e37c8f99f9a7570f1a6c3c079133bb2c8b",
    "title": "Gradual (In)Compatibility of Fairness Criteria",
    "abstract": "Impossibility results show that important fairness measures (independence, separation, sufficiency) cannot be satisfied at the same time under reasonable assumptions. This paper explores whether we can satisfy and/or improve these fairness measures simultaneously to a certain degree. We introduce information-theoretic formulations of the fairness measures and define degrees of fairness based on these formulations. The information-theoretic formulations suggest unexplored theoretical relations between the three fairness measures. In the experimental part, we use the information-theoretic expressions as regularizers to obtain fairness-regularized predictors for three standard datasets. Our experiments show that a) fairness regularization directly increases fairness measures, in line with existing work, and b) some fairness regularizations indirectly increase other fairness measures, as suggested by our theoretical findings. This establishes that it is possible to increase the degree to which some fairness measures are satisfied at the same time -- some fairness measures are gradually compatible.",
    "year": 2021,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/084be8e37c8f99f9a7570f1a6c3c079133bb2c8b",
    "doi": "10.1609/aaai.v36i11.21450",
    "arxivId": "2109.04399",
    "authors": "Corinna Hertweck, T. Raz",
    "citationCount": 14
  },
  {
    "s2PaperId": "a1c441ffcae9a78e5fbef09d936a3e01b1bea9b7",
    "title": "Information-processing dynamics in neural networks of macaque cerebral cortex reflect cognitive state and behavior",
    "abstract": "One of the essential functions biological neural networks is the processing of information. This comprises processing sensory information to perceive the environment, up to processing motor information to interact with the environment. Due to methodological concerns, it has been historically unclear how information processing changes during different cognitive or behavioral states, and to what extent information is processed within or between the network of neurons in different brain areas. In this study, we leverage recent advances in the calculation of information dynamics to explore neural-level processing within and between the fronto-parietal areas AIP, F5 and M1 during a delayed grasping task performed by three macaque monkeys. While information processing was high within all areas during all cognitive and behavioral states of the task, inter-areal processing varied widely: during visuo-motor transformation, AIP and F5 formed a reciprocally connected processing unit, while no processing was present between areas during the memory period. Movement execution was processed globally across all areas with a predominance of processing in the feedback direction. Additionally, the fine-scale network structure re-configured at the neuron-level in response to different grasping conditions, despite of no differences in the overall amount of information present. These results suggest that areas dynamically form higher-order processing units according to the cognitive or behavioral demand, and that the information processing network is hierarchically organized at the neuron-level, with the coarse network structure determining the behavioral state and finer changes reflecting different conditions. Significance Statement What does it mean to say that the brain “processes information?” Scientists often discuss the brain in terms of information processing – animals take in information from their environment through their senses, and use it to make decisions about how to act in the world. In this work, we use a mathematical framework called information theory to explore how signals from the environment influence brain activity, and how brain activity in turn informs on behaviors. We found that different brain regions processed information in dynamic and flexible ways, with signals flowing up and down the hierarchy of sensory-motor depending on the demands of the moment. This shows how “computation” in the brain can reflect complex behaviors and cognitive states.",
    "year": 2021,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/a1c441ffcae9a78e5fbef09d936a3e01b1bea9b7",
    "doi": "10.1073/pnas.2207677120",
    "arxivId": "",
    "authors": "Thomas F. Varley, O. Sporns, S. Schaffelhofer, H. Scherberger, Benjamin Dann",
    "citationCount": 45
  },
  {
    "s2PaperId": "1d7c93801b2e02d76c28060df6cb4b1bb5054778",
    "title": "Sequential transmission of task-relevant information in cortical neuronal networks",
    "abstract": "During auditory task performance, cortical processing of task-relevant information enables mammals to recognize sensory input and flexibly select behavioral responses. In mouse auditory cortex, small neuronal networks encode behavioral choice during a pure-tone detection task, but it is poorly understood how neuronal networks encode behavioral choice during a pure-tone discrimination task where tones have to be categorized into targets and non-targets. While the interactions between networked neurons are thought to encode behavioral choice, it remains unclear how patterns of neuronal network activity indicate the transmission of task-relevant information within the network. To this end, we trained mice to behaviorally discriminate target vs. non-target pure-tones while we used in vivo 2-photon imaging to record neuronal population activity in primary auditory cortex layer 2/3. We found that during task performance, a specialized subset of neurons transiently encoded intersection information, i.e., sensory information that was used to inform behavioral choice. Granger causality analysis showed that these neurons formed functional networks in which task-relevant information was transmitted sequentially between neurons. Differences in network structure between target and non-target sounds encoded behavioral choice. Correct behavioral choices were associated with shorter timescale communication between neurons. In summary, we find that specialized neuronal populations in auditory cortex form functional networks during auditory task performance whose structures depend on both sensory input and behavioral choice.",
    "year": 2021,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/1d7c93801b2e02d76c28060df6cb4b1bb5054778",
    "doi": "10.1101/2021.08.31.458395",
    "arxivId": "",
    "authors": "Nikolas A. Francis, Shoutik Mukherjee, L. Koçillari, S. Panzeri, B. Babadi, P. Kanold",
    "citationCount": 30
  },
  {
    "s2PaperId": "9d31879efaea84a237bd1abec678d3315818a2ef",
    "title": "Disentanglement Analysis with Partial Information Decomposition",
    "abstract": "We propose a framework to analyze how multivariate representations disentangle ground-truth generative factors. A quantitative analysis of disentanglement has been based on metrics designed to compare how one variable explains each generative factor. Current metrics, however, may fail to detect entanglement that involves more than two variables, e.g., representations that duplicate and rotate generative factors in high dimensional spaces. In this work, we establish a framework to analyze information sharing in a multivariate representation with Partial Information Decomposition and propose a new disentanglement metric. This framework enables us to understand disentanglement in terms of uniqueness, redundancy, and synergy. We develop an experimental protocol to assess how increasingly entangled representations are evaluated with each metric and confirm that the proposed metric correctly responds to entanglement. Through experiments on variational autoencoders, we find that models with similar disentanglement scores have a variety of characteristics in entanglement, for each of which a distinct strategy may be required to obtain a disentangled representation.",
    "year": 2021,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/9d31879efaea84a237bd1abec678d3315818a2ef",
    "doi": "",
    "arxivId": "2108.13753",
    "authors": "Seiya Tokui, Issei Sato",
    "citationCount": 15
  },
  {
    "s2PaperId": "cb28a0b124683a600137b7a256eb1040c52f52dc",
    "title": "Quantifying high-order interdependencies on individual patterns via the local O-information: Theory and applications to music analysis",
    "abstract": "High-order, beyond-pairwise interdependencies are at the core of biological, economic, and social complex systems, and their adequate analysis is paramount to understand, engineer, and control such systems. This paper presents a framework to measure high-order interdependence that disentangles their effect on each individual pattern exhibited by a multivariate system. The approach is centred on the 'local O-information', a new measure that assesses the balance between synergistic and redundant interdependencies at each pattern. To illustrate the potential of this framework, we present a detailed analysis of music scores from J.S. Bach, which reveals how high-order interdependence is deeply connected with highly non-trivial aspects of the musical discourse. Our results place the local O-information as a promising tool of wide applicability, which opens new perspectives for analysing high-order relationships in the patterns exhibited by complex systems.",
    "year": 2021,
    "venue": "Physical Review Research",
    "url": "https://www.semanticscholar.org/paper/cb28a0b124683a600137b7a256eb1040c52f52dc",
    "doi": "10.1103/PhysRevResearch.4.013184",
    "arxivId": "2108.11625",
    "authors": "Tomas Scagliarini, Daniele Marinazzo, Yike Guo, S. Stramaglia, F. Rosas",
    "citationCount": 18
  },
  {
    "s2PaperId": "7a51cda7ca2e8e9e824c7cc4174c5b6e707c2999",
    "title": "GABAB Receptor-Mediated Regulation of Dendro-Somatic Synergy in Layer 5 Pyramidal Neurons",
    "abstract": "Synergistic interactions between independent synaptic input streams may fundamentally change the action potential (AP) output. Using partial information decomposition, we demonstrate here a substantial contribution of synergy between somatic and apical dendritic inputs to the information in the AP output of L5b pyramidal neurons. Activation of dendritic GABAB receptors (GABABRs), known to decrease APs in vivo, potently decreased synergy and increased somatic control of AP output. Synergy was the result of the voltage-dependence of the transfer resistance between dendrite and soma, which showed a two-fold increase per 28.7 mV dendritic depolarization. GIRK channels activated by dendritic GABABRs decreased voltage-dependent transfer resistances and AP output. In contrast, inhibition of dendritic L-type Ca2+ channels prevented high-frequency bursts of APs, but did not affect dendro-somatic synergy. Finally, we show that NDNF-positive neurogliaform cells effectively control somatic AP via synaptic activation of dendritic GIRK channels. These results uncover a novel inhibitory mechanism that powerfully gates cellular information flow in the cortex.",
    "year": 2021,
    "venue": "Frontiers in Cellular Neuroscience",
    "url": "https://www.semanticscholar.org/paper/7a51cda7ca2e8e9e824c7cc4174c5b6e707c2999",
    "doi": "10.3389/fncel.2021.718413",
    "arxivId": "",
    "authors": "Jan M. Schulz, J. Kay, J. Bischofberger, M. Larkum",
    "citationCount": 22
  },
  {
    "s2PaperId": "4a50a46f64a7bad34272ad03b3ff3a50e5a49e1f",
    "title": "Biogeochemical and Hydrological Variables Synergistically Influence Nitrate Variability in Coastal Deltaic Wetlands",
    "abstract": "",
    "year": 2021,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/4a50a46f64a7bad34272ad03b3ff3a50e5a49e1f",
    "doi": "10.1029/2020JG005737",
    "arxivId": "",
    "authors": "A. Sendrowski, E. Castañeda‐Moya, R. Twilley, P. Passalacqua",
    "citationCount": 3
  },
  {
    "s2PaperId": "ec3b2dfe14b3c473831bee0fb474fb1d50602c46",
    "title": "Group-level inference of information-based measures for the analyses of cognitive brain networks from neurophysiological data",
    "abstract": "",
    "year": 2021,
    "venue": "NeuroImage",
    "url": "https://www.semanticscholar.org/paper/ec3b2dfe14b3c473831bee0fb474fb1d50602c46",
    "doi": "10.1016/j.neuroimage.2022.119347",
    "arxivId": "",
    "authors": "Etienne Combrisson, M. Allegra, Ruggero Basanisi, Robin A. A. Ince, Bruno L. Giordano, J. Bastin, A. Brovelli",
    "citationCount": 14
  },
  {
    "s2PaperId": "23ce461e95e8a4507d4ab6f7d028c7b015989fea",
    "title": "On shared and multiple information",
    "abstract": "The goal of this article is to address three outstanding problems in information theory. Problem one is the definition of a non-negative decomposition of the information conveyed by two or more sources about a target variable into the specific contribution of each possible combination of the sources [1]. Problem two is the definition of a measure of information shared by several sources about the target variable [1]. Problem three is the definition of a measure of multiple mutual information, that is, the extension of mutual information to more than two variables [2, 3].",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/23ce461e95e8a4507d4ab6f7d028c7b015989fea",
    "doi": "10.13140/RG.2.2.27408.33289",
    "arxivId": "2107.11032",
    "authors": "C. Magri",
    "citationCount": 2
  },
  {
    "s2PaperId": "9e2acc322dca815d824d4dde4a0fe5eb5d0cf998",
    "title": "Redundant Information Neural Estimation",
    "abstract": "We introduce the Redundant Information Neural Estimator (RINE), a method that allows efficient estimation for the component of information about a target variable that is common to a set of sources, known as the “redundant information”. We show that existing definitions of the redundant information can be recast in terms of an optimization over a family of functions. In contrast to previous information decompositions, which can only be evaluated for discrete variables over small alphabets, we show that optimizing over functions enables the approximation of the redundant information for high-dimensional and continuous predictors. We demonstrate this on high-dimensional image classification and motor-neuroscience tasks.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/9e2acc322dca815d824d4dde4a0fe5eb5d0cf998",
    "doi": "10.3390/e23070922",
    "arxivId": "",
    "authors": "Michael Kleinman, A. Achille, Stefano Soatto, Jonathan C. Kao",
    "citationCount": 14
  },
  {
    "s2PaperId": "b2b72d595ba007fbbb87081cda7ccaaf81ccc44d",
    "title": "Benchmarking Analysis of the Accuracy of Classification Methods Related to Entropy",
    "abstract": "In the machine learning literature we can find numerous methods to solve classification problems. We propose two new performance measures to analyze such methods. These measures are defined by using the concept of proportional reduction of classification error with respect to three benchmark classifiers, the random and two intuitive classifiers which are based on how a non-expert person could realize classification simply by applying a frequentist approach. We show that these three simple methods are closely related to different aspects of the entropy of the dataset. Therefore, these measures account somewhat for entropy in the dataset when evaluating the performance of classifiers. This allows us to measure the improvement in the classification results compared to simple methods, and at the same time how entropy affects classification capacity. To illustrate how these new performance measures can be used to analyze classifiers taking into account the entropy of the dataset, we carry out an intensive experiment in which we use the well-known J48 algorithm, and a UCI repository dataset on which we have previously selected a subset of the most relevant attributes. Then we carry out an extensive experiment in which we consider four heuristic classifiers, and 11 datasets.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/b2b72d595ba007fbbb87081cda7ccaaf81ccc44d",
    "doi": "10.3390/e23070850",
    "arxivId": "",
    "authors": "Y. Orenes, A. Rabasa, J. J. Rodríguez-Sala, J. Sánchez-Soriano",
    "citationCount": 6
  },
  {
    "s2PaperId": "1d9a92d6684765e56a068c5b3123d9c18d63c0c3",
    "title": "A partial information decomposition for discrete and continuous variables",
    "abstract": "Conceptually, partial information decomposition (PID) is concerned with separating the information contributions several sources hold about a certain target by decomposing the corresponding joint mutual information into contributions such as synergistic, redundant, or unique information. Despite PID conceptually being defined for any type of random variables, so far, PID could only be quantified for the joint mutual information of discrete systems. Recently, a quantification for PID in continuous settings for two or three source variables was introduced. Nonetheless, no ansatz has managed to both quantify PID for more than three variables and cover general measure-theoretic random variables, such as mixed discrete-continuous, or continuous random variables yet. In this work we will propose an information quantity, defining the terms of a PID, which is well-defined for any number or type of source or target random variable. This proposed quantity is tightly related to a recently developed local shared information quantity for discrete random variables based on the idea of shared exclusions. Further, we prove that this newly proposed information-measure fulfills various desirable properties, such as satisfying a set of local PID axioms, invariance under invertible transformations, differentiability with respect to the underlying probability density, and admitting a target chain rule.",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/1d9a92d6684765e56a068c5b3123d9c18d63c0c3",
    "doi": "",
    "arxivId": "2106.12393",
    "authors": "Kyle Schick-Poland, Abdullah Makkeh, A. Gutknecht, Patricia Wollstadt, A. Sturm, M. Wibral",
    "citationCount": 18
  },
  {
    "s2PaperId": "51b79fe9b4f2a7e36c5375e96eb1f17ce614c784",
    "title": "Intersectional synergies: untangling irreducible effects of intersecting identities via information decomposition",
    "abstract": "The idea of intersectionality has become a frequent topic of discussion both in academic sociology, as well as among popular movements for social justice such as Black Lives Matter, intersectional feminism, and LGBT rights. Intersectionality proposes that an individual's experience of society has aspects that are irreducible to the sum of one's various identities considered individually, but are\"greater than the sum of their parts.\"In this work, we show that the effects of intersectional identities can be statistically observed in empirical data using information theory. We show that, when considering the predictive relationship between various identities categories such as race, sex, and income (as a proxy for class) on outcomes such as health and wellness, robust statistical synergies appear. These synergies show that there are joint-effects of identities on outcomes that are irreducible to any identity considered individually and only appear when specific categories are considered together (for example, there is a large, synergistic effect of race and sex considered jointly on income irreducible to either race or sex). We then show using synthetic data that the current gold-standard method of assessing intersectionalities in data (linear regression with multiplicative interaction coefficients) fails to disambiguate between truly synergistic, greater-than-the-sum-of-their-parts interactions, and redundant interactions. We explore the significance of these two distinct types of interactions in the context of making inferences about intersectional relationships in data and the importance of being able to reliably differentiate the two. Finally, we conclude that information theory, as a model-free framework sensitive to nonlinearities and synergies in data, is a natural method by which to explore the space of higher-order social dynamics.",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/51b79fe9b4f2a7e36c5375e96eb1f17ce614c784",
    "doi": "",
    "arxivId": "2106.10338",
    "authors": "Thomas F. Varley",
    "citationCount": 4
  },
  {
    "s2PaperId": "644b6441be9a965811f4a00d3c5d5885f0a182c7",
    "title": "Dynamical independence: Discovering emergent macroscopic processes in complex dynamical systems.",
    "abstract": "We introduce a notion of emergence for macroscopic variables associated with highly multivariate microscopic dynamical processes. Dynamical independence instantiates the intuition of an emergent macroscopic process as one possessing the characteristics of a dynamical system \"in its own right,\" with its own dynamical laws distinct from those of the underlying microscopic dynamics. We quantify (departure from) dynamical independence by a transformation-invariant Shannon information-based measure of dynamical dependence. We emphasize the data-driven discovery of dynamically independent macroscopic variables, and introduce the idea of a multiscale \"emergence portrait\" for complex systems. We show how dynamical dependence may be computed explicitly for linear systems in both time and frequency domains, facilitating discovery of emergent phenomena across spatiotemporal scales, and outline application of the linear operationalization to inference of emergence portraits for neural systems from neurophysiological time-series data. We discuss dynamical independence for discrete- and continuous-time deterministic dynamics, with potential application to Hamiltonian mechanics and classical complex systems such as flocking and cellular automata.",
    "year": 2021,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/644b6441be9a965811f4a00d3c5d5885f0a182c7",
    "doi": "10.1103/PhysRevE.108.014304",
    "arxivId": "2106.06511",
    "authors": "L. Barnett, A. Seth",
    "citationCount": 20
  },
  {
    "s2PaperId": "e8114392b684e8600f26d05887c26252c166abf5",
    "title": "Information theoretic analysis of computational models as a tool to understand the neural basis of behaviors",
    "abstract": "One of the greatest research challenges of this century is to understand the neural basis for how behavior emerges in brain-body-environment systems. To this end, research has flourished along several directions but have predominantly focused on the brain. While there is in an increasing acceptance and focus on including the body and environment in studying the neural basis of behavior, animal researchers are often limited by technology or tools. Computational models provide an alternative framework within which one can study model systems where ground-truth can be measured and interfered with. These models act as a hypothesis generation framework that would in turn guide experimentation. Furthermore, the ability to intervene as we please, allows us to conduct in-depth analysis of these models in a way that cannot be performed in natural systems. For this purpose, information theory is emerging as a powerful tool that can provide insights into the operation of these brain-body-environment models. In this work, I provide an introduction, a review and discussion to make a case for how information theoretic analysis of computational models is a potent research methodology to help us better understand the neural basis of behavior.",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/e8114392b684e8600f26d05887c26252c166abf5",
    "doi": "",
    "arxivId": "2106.05186",
    "authors": "Madhavun Candadai",
    "citationCount": 2
  },
  {
    "s2PaperId": "7e21bbd7056ad4f0da51f2bb3c52aacfccd143f2",
    "title": "Information Fragmentation, Encryption and Information Flow in Complex Biological Networks",
    "abstract": "Assessing where and how information is stored in biological networks (such as neuronal and genetic networks) is a central task both in neuroscience and in molecular genetics, but most available tools focus on the network’s structure as opposed to its function. Here, we introduce a new information-theoretic tool—information fragmentation analysis—that, given full phenotypic data, allows us to localize information in complex networks, determine how fragmented (across multiple nodes of the network) the information is, and assess the level of encryption of that information. Using information fragmentation matrices we can also create information flow graphs that illustrate how information propagates through these networks. We illustrate the use of this tool by analyzing how artificial brains that evolved in silico solve particular tasks, and show how information fragmentation analysis provides deeper insights into how these brains process information and “think”. The measures of information fragmentation and encryption that result from our methods also quantify complexity of information processing in these networks and how this processing complexity differs between primary exposure to sensory data (early in the lifetime) and later routine processing.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/7e21bbd7056ad4f0da51f2bb3c52aacfccd143f2",
    "doi": "10.3390/e24050735",
    "arxivId": "2105.13585",
    "authors": "Clifford Bohm, Douglas Kirkpatrick, Victoria Cao, C. Adami",
    "citationCount": 4
  },
  {
    "s2PaperId": "26392e3f16deb1d0083d6e377b55e75b090cb786",
    "title": "A Rigorous Information-Theoretic Definition of Redundancy and Relevancy in Feature Selection Based on (Partial) Information Decomposition",
    "abstract": "Selecting a minimal feature set that is maximally informative about a target variable is a central task in machine learning and statistics. Information theory provides a powerful framework for formulating feature selection algorithms -- yet, a rigorous, information-theoretic definition of feature relevancy, which accounts for feature interactions such as redundant and synergistic contributions, is still missing. We argue that this lack is inherent to classical information theory which does not provide measures to decompose the information a set of variables provides about a target into unique, redundant, and synergistic contributions. Such a decomposition has been introduced only recently by the partial information decomposition (PID) framework. Using PID, we clarify why feature selection is a conceptually difficult problem when approached using information theory and provide a novel definition of feature relevancy and redundancy in PID terms. From this definition, we show that the conditional mutual information (CMI) maximizes relevancy while minimizing redundancy and propose an iterative, CMI-based algorithm for practical feature selection. We demonstrate the power of our CMI-based algorithm in comparison to the unconditional mutual information on benchmark examples and provide corresponding PID estimates to highlight how PID allows to quantify information contribution of features and their interactions in feature-selection problems.",
    "year": 2021,
    "venue": "Journal of machine learning research",
    "url": "https://www.semanticscholar.org/paper/26392e3f16deb1d0083d6e377b55e75b090cb786",
    "doi": "",
    "arxivId": "2105.04187",
    "authors": "Patricia Wollstadt, Sebastian Schmitt, M. Wibral",
    "citationCount": 31
  },
  {
    "s2PaperId": "baa44bd800da2bbebb2d640d8319b479c616ce66",
    "title": "Partial Information Decomposition via Deficiency for Multivariate Gaussians",
    "abstract": "Bivariate partial information decompositions (PIDs) characterize how the information in a \"message\" random variable is decomposed between two \"constituent\" random variables in terms of unique, redundant and synergistic information components. These components are a function of the joint distribution of the three variables, and are typically defined using an optimization over the space of all possible joint distributions. This makes it computationally challenging to compute PIDs in practice and restricts their use to low-dimensional random vectors. To ease this burden, we consider the case of jointly Gaussian random vectors in this paper. This case was previously examined by Barrett [1], who showed that certain operationally well-motivated PIDs reduce to a closed form expression for scalar messages. Here, we show that Barrett’s result does not extend to vector messages in general, and characterize the set of multivariate Gaussian distributions that reduce to closed-form. Then, for all other multivariate Gaussian distributions, we propose a convex optimization framework for approximately computing a specific PID definition based on the statistical concept of deficiency. Using simplifying assumptions specific to the Gaussian case, we provide an efficient algorithm to approximately compute the bivariate PID for multivariate Gaussian variables with tens or even hundreds of dimensions. We also theoretically and empirically justify the goodness of this approximation.",
    "year": 2021,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/baa44bd800da2bbebb2d640d8319b479c616ce66",
    "doi": "10.1109/ISIT50566.2022.9834649",
    "arxivId": "2105.00769",
    "authors": "Gabriel Schamberg, Praveen Venkatesh",
    "citationCount": 15
  },
  {
    "s2PaperId": "77e3efc701b14e8c4b32ca3c1756d694864a2ef7",
    "title": "Emergence as the conversion of information: a unifying theory",
    "abstract": "Is reduction always a good scientific strategy? The existence of the special sciences above physics suggests not. Previous research has shown that dimensionality reduction (macroscales) can increase the dependency between elements of a system (a phenomenon called ‘causal emergence’). Here, we provide an umbrella mathematical framework for emergence based on information conversion. We show evidence that coarse-graining can convert information from one ‘type’ to another. We demonstrate this using the well-understood mutual information measure applied to Boolean networks. Using partial information decomposition, the mutual information can be decomposed into redundant, unique and synergistic information atoms. Then by introducing a novel measure of the synergy bias of a given decomposition, we are able to show that the synergy component of a Boolean network’s mutual information can increase at macroscales. This can occur even when there is no difference in the total mutual information between a macroscale and its underlying microscale, proving information conversion. We relate this broad framework to previous work, compare it to other theories, and argue it complexifies any notion of universal reduction in the sciences, since such reduction would likely lead to a loss of synergistic information in scientific models. This article is part of the theme issue ‘Emergent phenomena in complex physical and socio-technical systems: from cells to societies’.",
    "year": 2021,
    "venue": "Philosophical Transactions of the Royal Society A",
    "url": "https://www.semanticscholar.org/paper/77e3efc701b14e8c4b32ca3c1756d694864a2ef7",
    "doi": "10.1098/rsta.2021.0150",
    "arxivId": "2104.13368",
    "authors": "Thomas F. Varley, Erik P. Hoel",
    "citationCount": 42
  },
  {
    "s2PaperId": "256a6de754cd7ec7d162de87130d41e6a7b81d67",
    "title": "Parsimony versus predictive and functional performance of three stomatal optimization principles in a big-leaf framework.",
    "abstract": "Stomatal optimization models can improve estimates of water and carbon fluxes with relatively low complexity, yet there is no consensus on which formulations are most appropriate for ecosystem-scale applications. We implemented three existing analytical equations for stomatal conductance, based on different water penalty functions, in a big-leaf comparison framework, and determined which optimization principles were most consistent with flux tower observations from different biomes. We used information theory to dissect controls of soil water supply and atmospheric demand on evapotranspiration in wet to dry conditions and to quantify missing or inadequate information in model variants. We ranked stomatal optimization principles based on parameter uncertainty, parsimony, predictive accuracy, and functional accuracy of the interactions between soil moisture, vapor pressure deficit, and evapotranspiration. Performance was high for all model variants. Water penalty functions with explicit representation of plant hydraulics did not substantially improve predictive or functional accuracy of ecosystem-scale evapotranspiration estimates and parameterizations were more uncertain, despite having physiological underpinnings at the plant level. Stomatal optimization based on water use efficiency thus provided more information about ecosystem-scale evapotranspiration compared to those based on xylem vulnerability and proved more useful in improving ecosystem-scale models with less complexity.",
    "year": 2021,
    "venue": "New Phytologist",
    "url": "https://www.semanticscholar.org/paper/256a6de754cd7ec7d162de87130d41e6a7b81d67",
    "doi": "10.1111/nph.17392",
    "arxivId": "",
    "authors": "M. Bassiouni, G. Vico",
    "citationCount": 19
  },
  {
    "s2PaperId": "9044372984985402c2a3bfec0cedf6aeff47d90d",
    "title": "On Information Links",
    "abstract": "In a joint work with D. Bennequin, we suggested that the (negative) minima of the 3-way multivariate mutual information correspond to Borromean links, paving the way for providing probabilistic analogs of linking numbers. This short note generalizes the correspondence of the minima of k-multivariate interaction information with k Brunnian links in the binary variable case. Following Jakulin and Bratko, the negativity of the associated K-L divergence of the joint probability law with its Kirkwood approximation implies an obstruction to local decomposition into lower order interactions than k, defining a local decomposition inconsistency that reverses Abramsky's contextuality local-global relation. Those negative k-links provide a straightforward definition of collective emergence in complex k-body interacting systems or dataset.",
    "year": 2021,
    "venue": "International Conference on Geometric Science of Information",
    "url": "https://www.semanticscholar.org/paper/9044372984985402c2a3bfec0cedf6aeff47d90d",
    "doi": "10.1007/978-3-030-80209-7_68",
    "arxivId": "2103.02002",
    "authors": "P. Baudot",
    "citationCount": 0
  },
  {
    "s2PaperId": "7815e2476700ff87e7f4f0dfd4c999e8940271a8",
    "title": "Nonlinearity and Multivariate Dependencies in the Terrestrial Leg of Land‐Atmosphere Coupling",
    "abstract": "Most studies of land‐atmosphere coupling have focused on bivariate linear statistics like correlation. However, more complex dependencies exist, including nonlinear relationships between components of land‐atmosphere coupling and the transmutability of relationships between soil moisture and surface heat fluxes under different environmental conditions. In this study, a technique called multivariate mutual information, based on information theory, is proposed to quantify how surface heat fluxes depend on both surface energy and wetness conditions, that is, net radiation and soil moisture, seasonally across the globe using reanalysis data. Such interdependency is then decomposed into linear and nonlinear contributions, which are further decomposed as different components explainable as the unique contribution from individual surface conditions, redundant contributions shared by both surface conditions, and the synergistic contribution from the concurrent action of net radiation and soil moisture. In reanalysis data, the dependency linearly contributed from soil moisture bears a similar global pattern to previously identified hot spots of coupling. The linear unique contributions of net radiation and soil moisture are mainly nonoverlapping, which suggests two separate regimes are governed by either energy or water limitations. These patterns persist when the nonlinearity is superimposed, thus reinforcing the validity of the land‐atmospheric coupling hot spot paradigm and the spatial division of energy‐limited as well as water‐limited regions. Nevertheless, strong nonlinear relationships are detected, particularly over subtropical regions. Synergistic components are found across the globe, implying widespread multidimensional physical relationships among net radiation, soil moisture, and surface heat fluxes that previously had only been inferred locally.",
    "year": 2021,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/7815e2476700ff87e7f4f0dfd4c999e8940271a8",
    "doi": "10.1029/2020WR028179",
    "arxivId": "",
    "authors": "H. Hsu, P. Dirmeyer",
    "citationCount": 6
  },
  {
    "s2PaperId": "12120733496d785f5b61e8b5bb7a090d4b1cd441",
    "title": "Estimating the Unique Information of Continuous Variables",
    "abstract": "The integration and transfer of information from multiple sources to multiple targets is a core motive of neural systems. The emerging field of partial information decomposition (PID) provides a novel information-theoretic lens into these mechanisms by identifying synergistic, redundant, and unique contributions to the mutual information between one and several variables. While many works have studied aspects of PID for Gaussian and discrete distributions, the case of general continuous distributions is still uncharted territory. In this work we present a method for estimating the unique information in continuous distributions, for the case of one versus two variables. Our method solves the associated optimization problem over the space of distributions with fixed bivariate marginals by combining copula decompositions and techniques developed to optimize variational autoencoders. We obtain excellent agreement with known analytic results for Gaussians, and illustrate the power of our new approach in several brain-inspired neural models. Our method is capable of recovering the effective connectivity of a chaotic network of rate neurons, and uncovers a complex trade-off between redundancy, synergy and unique information in recurrent networks trained to solve a generalized XOR task.",
    "year": 2021,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/12120733496d785f5b61e8b5bb7a090d4b1cd441",
    "doi": "",
    "arxivId": "2102.00218",
    "authors": "Ari Pakman, Dar Gilboa, E. Schneidman",
    "citationCount": 27
  },
  {
    "s2PaperId": "ddbbad086457b3873c0869c74bb97fabc8d07f89",
    "title": "What it is like to be a bit: an integrated information decomposition account of emergent mental phenomena",
    "abstract": "Abstract A central question in neuroscience concerns the relationship between consciousness and its physical substrate. Here, we argue that a richer characterization of consciousness can be obtained by viewing it as constituted of distinct information-theoretic elements. In other words, we propose a shift from quantification of consciousness—viewed as integrated information—to its decomposition. Through this approach, termed Integrated Information Decomposition (ΦID), we lay out a formal argument that whether the consciousness of a given system is an emergent phenomenon depends on its information-theoretic composition—providing a principled answer to the long-standing dispute on the relationship between consciousness and emergence. Furthermore, we show that two organisms may attain the same amount of integrated information, yet differ in their information-theoretic composition. Building on ΦID’s revised understanding of integrated information, termed ΦR, we also introduce the notion of ΦR-ing ratio to quantify how efficiently an entity uses information for conscious processing. A combination of ΦR and ΦR-ing ratio may provide an important way to compare the neural basis of different aspects of consciousness. Decomposition of consciousness enables us to identify qualitatively different ‘modes of consciousness’, establishing a common space for mapping the phenomenology of different conscious states. We outline both theoretical and empirical avenues to carry out such mapping between phenomenology and information-theoretic modes, starting from a central feature of everyday consciousness: selfhood. Overall, ΦID yields rich new ways to explore the relationship between information, consciousness, and its emergence from neural dynamics.",
    "year": 2021,
    "venue": "Neuroscience of Consciousness",
    "url": "https://www.semanticscholar.org/paper/ddbbad086457b3873c0869c74bb97fabc8d07f89",
    "doi": "10.1093/nc/niab027",
    "arxivId": "",
    "authors": "A. Luppi, P. Mediano, F. Rosas, David J. Harrison, Robin L. Carhart-Harris, D. Bor, E. Stamatakis",
    "citationCount": 31
  },
  {
    "s2PaperId": "1b53e8652676a1806d0d2abc5d7abcd212709046",
    "title": "Estimating informativeness of samples with Smooth Unique Information",
    "abstract": "We define a notion of information that an individual sample provides to the training of a neural network, and we specialize it to measure both how much a sample informs the final weights and how much it informs the function computed by the weights. Though related, we show that these quantities have a qualitatively different behavior. We give efficient approximations of these quantities using a linearized network and demonstrate empirically that the approximation is accurate for real-world architectures, such as pre-trained ResNets. We apply these measures to several problems, such as dataset summarization, analysis of under-sampled classes, comparison of informativeness of different data sources, and detection of adversarial and corrupted examples. Our work generalizes existing frameworks but enjoys better computational properties for heavily over-parametrized models, which makes it possible to apply it to real-world networks.",
    "year": 2021,
    "venue": "International Conference on Learning Representations",
    "url": "https://www.semanticscholar.org/paper/1b53e8652676a1806d0d2abc5d7abcd212709046",
    "doi": "",
    "arxivId": "2101.06640",
    "authors": "Hrayr Harutyunyan, A. Achille, Giovanni Paolini, Orchid Majumder, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto",
    "citationCount": 25
  },
  {
    "s2PaperId": "b74c5b7c97ded089caa481964207ba5e0e65b659",
    "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation",
    "abstract": "Controlling bias in training datasets is vital for ensuring equal treatment, or parity, between different groups in downstream applications. A naive solution is to transform the data so that it is statistically independent of group membership, but this may throw away too much information when a reasonable compromise between fairness and accuracy is desired. Another common approach is to limit the ability of a particular adversary who seeks to maximize parity. Unfortunately, representations produced by adversarial approaches may still retain biases as their efficacy is tied to the complexity of the adversary used during training. To this end, we theoretically establish that by limiting the mutual information between representations and protected attributes, we can assuredly control the parity of any downstream classifier. We demonstrate an effective method for controlling parity through mutual information based on contrastive information estimators and show that they outperform approaches that rely on variational bounds based on complex generative models. We test our approach on UCI Adult and Heritage Health datasets and demonstrate that our approach provides more informative representations across a range of desired parity thresholds while providing strong theoretical guarantees on the parity of any downstream algorithm.",
    "year": 2021,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/b74c5b7c97ded089caa481964207ba5e0e65b659",
    "doi": "10.1609/aaai.v35i9.16931",
    "arxivId": "2101.04108",
    "authors": "Umang Gupta, Aaron Ferber, B. Dilkina, G. V. Steeg",
    "citationCount": 60
  },
  {
    "s2PaperId": "7bb82f074f5869daa8129e8797b03ab9a4415c7c",
    "title": "Progressive Interpretation Synthesis: Interpreting Task Solving by Quantifying Previously Used and Unused Information",
    "abstract": "Abstract A deep neural network is a good task solver, but it is difficult to make sense of its operation. People have different ideas about how to interpret its operation. We look at this problem from a new perspective where the interpretation of task solving is synthesized by quantifying how much and what previously unused information is exploited in addition to the information used to solve previous tasks. First, after learning several tasks, the network acquires several information partitions related to each task. We propose that the network then learns the minimal information partition that supplements previously learned information partitions to more accurately represent the input. This extra partition is associated with unconceptualized information that has not been used in previous tasks. We manage to identify what unconceptualized information is used and quantify the amount. To interpret how the network solves a new task, we quantify as meta-information how much information from each partition is extracted. We implement this framework with the variational information bottleneck technique. We test the framework with the MNIST and the CLEVR data set. The framework is shown to be able to compose information partitions and synthesize experience-dependent interpretation in the form of meta-information. This system progressively improves the resolution of interpretation upon new experience by converting a part of the unconceptualized information partition to a task-related partition. It can also provide a visual interpretation by imaging what is the part of previously unconceptualized information that is needed to solve a new task.",
    "year": 2021,
    "venue": "Neural Computation",
    "url": "https://www.semanticscholar.org/paper/7bb82f074f5869daa8129e8797b03ab9a4415c7c",
    "doi": "10.1162/neco_a_01542",
    "arxivId": "2101.02879",
    "authors": "Zhengqi He, Taro Toyoizumi",
    "citationCount": 1
  },
  {
    "s2PaperId": "1f5829d8bb29d2dca66da035299aede221054c22",
    "title": "Discovering Higher-Order Interactions Through Neural Information Decomposition",
    "abstract": "If regularity in data takes the form of higher-order functions among groups of variables, models which are biased towards lower-order functions may easily mistake the data for noise. To distinguish whether this is the case, one must be able to quantify the contribution of different orders of dependence to the total information. Recent work in information theory attempts to do this through measures of multivariate mutual information (MMI) and information decomposition (ID). Despite substantial theoretical progress, practical issues related to tractability and learnability of higher-order functions are still largely unaddressed. In this work, we introduce a new approach to information decomposition—termed Neural Information Decomposition (NID)—which is both theoretically grounded, and can be efficiently estimated in practice using neural networks. We show on synthetic data that NID can learn to distinguish higher-order functions from noise, while many unsupervised probability models cannot. Additionally, we demonstrate the usefulness of this framework as a tool for exploring biological and artificial neural networks.",
    "year": 2021,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/1f5829d8bb29d2dca66da035299aede221054c22",
    "doi": "10.3390/e23010079",
    "arxivId": "",
    "authors": "Kyle Reing, Greg Ver Steeg, A. Galstyan",
    "citationCount": 4
  },
  {
    "s2PaperId": "61bda270aa3b3e02a63c4d80c19f56d9739beb80",
    "title": "29th Annual Computational Neuroscience Meeting: CNS*2020",
    "abstract": "s.g‐node.org/conference/BC19/abstracts#/uuid/ e28680aa‐eb4c‐448e‐b2a8‐2e0b32c2ff49 12. Pronold J, Bakker R, Morales‐Gregorio A, van Albada S, van Meegen A. Multi‐area spiking network models of macaque and human cortices. In NEST Conference 2019 (No. FZJ‐2019‐04472). Computational and Systems",
    "year": 2020,
    "venue": "BMC Neuroscience",
    "url": "https://www.semanticscholar.org/paper/61bda270aa3b3e02a63c4d80c19f56d9739beb80",
    "doi": "10.1186/s12868-020-00593-1",
    "arxivId": "",
    "authors": "S. Chopra, K. Sabaroedin, S. Francey, Brian, O’Donoghue, V. Cropley, B. Nelson, J. Graham, Lara, Baldwin, S. Tahtalian, H. Yuen, K. Allott, Mario Alvarez, S. Harrigan, C. Pantelis, S. Wood, P. McGorry",
    "citationCount": 3
  },
  {
    "s2PaperId": "bbe1be27c0e0838d42f15365a2a63737b7b13216",
    "title": "Measuring spectrally-resolved information transfer",
    "abstract": "Information transfer, measured by transfer entropy, is a key component of distributed computation. It is therefore important to understand the pattern of information transfer in order to unravel the distributed computational algorithms of a system. Since in many natural systems distributed computation is thought to rely on rhythmic processes a frequency resolved measure of information transfer is highly desirable. Here, we present a novel algorithm, and its efficient implementation, to identify separately frequencies sending and receiving information in a network. Our approach relies on the invertible maximum overlap discrete wavelet transform (MODWT) for the creation of surrogate data in the computation of transfer entropy and entirely avoids filtering of the original signals. The approach thereby avoids well-known problems due to phase shifts or the ineffectiveness of filtering in the information theoretic setting. We also show that measuring frequency-resolved information transfer is a partial information decomposition problem that cannot be fully resolved to date and discuss the implications of this issue. Last, we evaluate the performance of our algorithm on simulated data and apply it to human magnetoencephalography (MEG) recordings and to local field potential recordings in the ferret. In human MEG we demonstrate top-down information flow in temporal cortex from very high frequencies (above 100Hz) to both similarly high frequencies and to frequencies around 20Hz, i.e. a complex spectral configuration of cortical information transmission that has not been described before. In the ferret we show that the prefrontal cortex sends information at low frequencies (4-8 Hz) to early visual cortex (V1), while V1 receives the information at high frequencies (> 125 Hz).",
    "year": 2020,
    "venue": "PLoS Comput. Biol.",
    "url": "https://www.semanticscholar.org/paper/bbe1be27c0e0838d42f15365a2a63737b7b13216",
    "doi": "10.1371/journal.pcbi.1008526",
    "arxivId": "",
    "authors": "Edoardo Pinzuti, Patricia Wollstadt, A. Gutknecht, O. Tüscher, M. Wibral",
    "citationCount": 13
  },
  {
    "s2PaperId": "9fd4e0f23535cc92539f6533f52ae37889144dfb",
    "title": "A synergistic workspace for human consciousness revealed by Integrated Information Decomposition",
    "abstract": "A central goal of neuroscience is to understand how the brain orchestrates information from multiple input streams into a unified conscious experience. Here, we address two fundamental questions: how is the human information-processing architecture functionally organised, and how does its organisation support consciousness? We combine network science and a rigorous information-theoretic notion of synergy to delineate a “synergistic global workspace”, comprising gateway regions that gather synergistic information from specialised modules across the brain. This information is then integrated within the workspace and widely distributed via broadcaster regions. Through functional MRI analysis, we show that gateway regions of the synergistic workspace correspond to the brain’s default mode network, whereas broadcasters coincide with the executive control network. Demonstrating the empirical relevance of our proposed architecture for neural information processing, we show that loss of consciousness due to general anaesthesia or disorders of consciousness corresponds to a diminished ability of the synergistic workspace to integrate information, which is restored upon recovery. Thus, loss of consciousness coincides with a breakdown of information integration within the synergistic workspace of the human brain. This work contributes to conceptual and empirical reconciliation between two prominent scientific theories of consciousness, the Global Neuronal Workspace and Integrated Information Theory. Taken together, this work provides a new perspective on the role of prominent resting-state networks within the human information-processing architecture, while also advancing our understanding of how the human brain supports consciousness through the synergistic integration of information.",
    "year": 2020,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/9fd4e0f23535cc92539f6533f52ae37889144dfb",
    "doi": "10.1101/2020.11.25.398081",
    "arxivId": "",
    "authors": "A. Luppi, P. Mediano, F. Rosas, J. Allanson, J. Pickard, R. Carhart-Harris, Guy B. Williams, Michael M. Craig, Paola Finoia, A. Owen, L. Naci, D. Menon, D. Bor, E. Stamatakis",
    "citationCount": 69
  },
  {
    "s2PaperId": "4bb564bdb52bc5645ffafc737898150cacdbb2a3",
    "title": "Biological information",
    "abstract": "In computer science, we can theoretically neatly separate transmission and processing of information, hardware and software, and programs and their inputs. This is much more intricate in biology. Nevertheless, I argue that Shannon’s concept of information is useful in biology, although its application is not as straightforward as many people think. In fact, the recently developed theory of information decomposition can shed much light on the complementarity between coding and regulatory, or internal and environmental information. The key challenge that we formulate in this contribution is to understand how genetic information and external factors combine to create an organism, and conversely how the genome has learned in the course of evolution how to harness the environment, and analogously how coding, regulation and spatial organization interact in cellular processes.",
    "year": 2020,
    "venue": "Theory in biosciences",
    "url": "https://www.semanticscholar.org/paper/4bb564bdb52bc5645ffafc737898150cacdbb2a3",
    "doi": "10.1007/s12064-020-00327-1",
    "arxivId": "2010.16193",
    "authors": "J. Jost",
    "citationCount": 9
  },
  {
    "s2PaperId": "2c4c23785ea86222aabfae071558e822ed15b06d",
    "title": "Information – based uncertainty decomposition in dual channel microwave remote sensing of soil moisture",
    "abstract": "Abstract. NASA's Soil Moisture Active-Passive (SMAP) mission characterizes global spatiotemporal patterns in surface soil moisture using dual L-band microwave retrievals of horizontal, TBh, and vertical, TBv, polarized microwave brightness temperatures through a modeled relationship between vegetation opacity and surface scattering albedo (i.e. tau-omega model). Although this model has been validated against in situ soil moisture measurements across sparse validations sites, there is lack of systematic characterization of where and why SMAP estimates deviate from the in situ observations. Here, soil moisture observations from the US Climate Reference Network are used within a mutual information framework to decompose the overall retrieval uncertainty from SMAPs Modified Dual Channel Algorithm (MDCA) into random uncertainty derived from raw data itself and model uncertainty derived from the model’s inherent structure. The results shown that, on average, 12 % of the uncertainty in SMAP soil moisture estimates is caused by the loss of information in the MDCA model itself while the remainder is induced by inadequacy of TBh and TBv observations. We find the fraction of algorithm induced uncertainty is negatively correlated (pearson r of −0.48) with correlations between in-situ observations and MDCA estimates. A decomposition of mutual information between TBh, TBv and MDCA soil moisture shows that on average 55 % of the mutual information is redundantly shared by TBh and TBv, while the information provided uniquely from both TBh and TBv is 15 %. The fraction of information redundantly provided by TBh and TBv was found to be tightly correlated (pearson r = −0.7) to how well the MDCA output correlated to in situ observations. Thus, MDCA overall quality improves as TBh and TBv provide more redundant information for the MDCA. This suggests the informational redundancy between these remotely sensed observations can be used as independent metric to assess the overall quality of algorithms using these data streams. This study provides a baseline approach that can also be applied to evaluate other remote sensing models and understand informational loss as satellite retrievals are translated to end user products.",
    "year": 2020,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2c4c23785ea86222aabfae071558e822ed15b06d",
    "doi": "10.5194/hess-2020-534",
    "arxivId": "",
    "authors": "Bonan Li, S. Good",
    "citationCount": 8
  },
  {
    "s2PaperId": "5c0ea23c8cf52784923c2da50c383c1b9c6b65a8",
    "title": "Examining the Causal Structures of Deep Neural Networks Using Information Theory",
    "abstract": "Deep Neural Networks (DNNs) are often examined at the level of their response to input, such as analyzing the mutual information between nodes and data sets. Yet DNNs can also be examined at the level of causation, exploring “what does what” within the layers of the network itself. Historically, analyzing the causal structure of DNNs has received less attention than understanding their responses to input. Yet definitionally, generalizability must be a function of a DNN’s causal structure as it reflects how the DNN responds to unseen or even not-yet-defined future inputs. Here, we introduce a suite of metrics based on information theory to quantify and track changes in the causal structure of DNNs during training. Specifically, we introduce the effective information (EI) of a feedforward DNN, which is the mutual information between layer input and output following a maximum-entropy perturbation. The EI can be used to assess the degree of causal influence nodes and edges have over their downstream targets in each layer. We show that the EI can be further decomposed in order to examine the sensitivity of a layer (measured by how well edges transmit perturbations) and the degeneracy of a layer (measured by how edge overlap interferes with transmission), along with estimates of the amount of integrated information of a layer. Together, these properties define where each layer lies in the “causal plane”, which can be used to visualize how layer connectivity becomes more sensitive or degenerate over time, and how integration changes during training, revealing how the layer-by-layer causal structure differentiates. These results may help in understanding the generalization capabilities of DNNs and provide foundational tools for making DNNs both more generalizable and more explainable.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5c0ea23c8cf52784923c2da50c383c1b9c6b65a8",
    "doi": "10.3390/e22121429",
    "arxivId": "2010.13871",
    "authors": "Simon Mattsson, Eric J. Michaud, Erik P. Hoel",
    "citationCount": 9
  },
  {
    "s2PaperId": "74a2ebe0dff6f61ac5d63c262721bf64a177bc70",
    "title": "Synergy and Redundancy Duality Between Gaussian Multiple Access and Broadcast Channels",
    "abstract": "",
    "year": 2020,
    "venue": "International Symposium on Information Theory and its Applications",
    "url": "https://www.semanticscholar.org/paper/74a2ebe0dff6f61ac5d63c262721bf64a177bc70",
    "doi": "",
    "arxivId": "",
    "authors": "Xueyan Niu, Christopher J. Quinn",
    "citationCount": 1
  },
  {
    "s2PaperId": "edf51acd85db5f5cb82f891caca0e18241992c7f",
    "title": "Information Decomposition in the Frequency Domain: a New Framework to Study Cardiovascular and Cardiorespiratory Oscillations",
    "abstract": "While cross-spectral and information-theoretic approaches are widely used for the multivariate analysis of physiological time series, their combined utilization is far less developed in the literature. This study introduces a framework for the spectral decomposition of multivariate information measures, which provides frequency-specific quantifications of the information shared between a target and two source time series and of its expansion into amounts related to how the sources contribute to the target dynamics with unique, redundant and synergistic information. The framework is illustrated in simulations of linearly interacting stochastic processes, showing how it allows to retrieve amounts of information shared by the processes within specific frequency bands which are otherwise not detectable by time-domain information measures, as well as coupling features which are not detectable by spectral measures. Then, it is applied to the time series of heart period, systolic and diastolic arterial pressure and respiration variability measured in healthy subjects monitored in the resting supine position and during head-up tilt. We show that the spectral measures of unique, redundant and synergistic information shared by these variability series, integrated within specific frequency bands of physiological interest, reflect the mechanisms of short term regulation of cardiovascular and cardiorespiratory oscillations and their alterations induced by the postural stress.",
    "year": 2020,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/edf51acd85db5f5cb82f891caca0e18241992c7f",
    "doi": "10.1098/rsta.2020.0250",
    "arxivId": "",
    "authors": "L. Faes, R. Pernice, G. Mijatović, Y. Antonacci, J. Krohova, M. Javorka, A. Porta",
    "citationCount": 16
  },
  {
    "s2PaperId": "bfec7aecc886e0429a8f454e0b877ad089d94a8d",
    "title": "Partial Information Decomposition of Boolean Functions: a Fourier Analysis perspective",
    "abstract": "Partial information decomposition (PID) partitions the information that a set of sources has about a target variable into synergistic, unique, and redundant contributions. This information-theoretic tool has recently attracted attention due to its potential to characterize the information processing in multivariate systems. However, the PID framework still lacks a solid and intuitive interpretation of its information components. In the aim to improve the understanding of PID components, we focus here on Boolean gates, a much-studied type of source-target mechanisms. Boolean gates have been extensively characterised via Fourier analysis which coefficients have been related to interesting properties of the functions defining the gates. In this paper, we establish for Boolean gates mechanisms a relation between their PID components and Fourier coefficients.",
    "year": 2020,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/bfec7aecc886e0429a8f454e0b877ad089d94a8d",
    "doi": "",
    "arxivId": "2010.06976",
    "authors": "Abdullah Makkeh, D. Theis, Raul Vicente",
    "citationCount": 0
  },
  {
    "s2PaperId": "dbaee1629a811216edd0bbba6afea879e2788f7d",
    "title": "“It’s Raining Bits”: Patterns in Directional Precipitation Persistence across the United States",
    "abstract": "The spatial and temporal ordering of precipitation occurrence impacts ecosystems, streamflow, and water availability. For example, both large-scale climate patterns and local landscapes drive weather events, and the typical speeds and directions of these events moving across a basin dictate the timing of flows at its outlet. We address the predictability of precipitation occurrence at a given location, based on the knowledge of past precipitation at surrounding locations. We identify “dominant directions of precipitation influence” across the continental United States based on a gridded daily dataset. Specifically, we apply information theory–based measures that characterize dominant directions and strengths of spatial and temporal precipitation dependencies. On a national average, this dominant direction agrees with the prevalent direction of weather movement from west to east across the country, but regional differences reflect topographic divides, precipitation gradients, and different climatic drivers of precipitation. Trends in these information relationships and their correlations with climate indices over the past 70 years also show seasonal and spatial divides. This study expands upon a framework of information-based predictability to answer questions about spatial connectivity in addition to temporal persistence. The methods presented here are generally useful to understand many aspects of weather and climate variability.",
    "year": 2020,
    "venue": "Journal of Hydrometeorology",
    "url": "https://www.semanticscholar.org/paper/dbaee1629a811216edd0bbba6afea879e2788f7d",
    "doi": "10.1175/jhm-d-20-0134.1",
    "arxivId": "",
    "authors": "A. Goodwell",
    "citationCount": 6
  },
  {
    "s2PaperId": "a17fb7284cf69cb742d01d6a43bb37e7217d3114",
    "title": "A framework for causal discovery in non-intervenable systems.",
    "abstract": "Many frameworks exist to infer cause and effect relations in complex nonlinear systems, but a complete theory is lacking. A new framework is presented that is fully nonlinear, provides a complete information theoretic disentanglement of causal processes, allows for nonlinear interactions between causes, identifies the causal strength of missing or unknown processes, and can analyze systems that cannot be represented on directed acyclic graphs. The basic building blocks are information theoretic measures such as (conditional) mutual information and a new concept called certainty that monotonically increases with the information available about the target process. The framework is presented in detail and compared with other existing frameworks, and the treatment of confounders is discussed. While there are systems with structures that the framework cannot disentangle, it is argued that any causal framework that is based on integrated quantities will miss out potentially important information of the underlying probability density functions. The framework is tested on several highly simplified stochastic processes to demonstrate how blocking and gateways are handled and on the chaotic Lorentz 1963 system. We show that the framework provides information on the local dynamics but also reveals information on the larger scale structure of the underlying attractor. Furthermore, by applying it to real observations related to the El-Nino-Southern-Oscillation system, we demonstrate its power and advantage over other methodologies.",
    "year": 2020,
    "venue": "Chaos",
    "url": "https://www.semanticscholar.org/paper/a17fb7284cf69cb742d01d6a43bb37e7217d3114",
    "doi": "10.1063/5.0054228",
    "arxivId": "2010.02247",
    "authors": "P. V. van Leeuwen, M. DeCaria, Nachiketa Chakraborty, M. Pulido",
    "citationCount": 6
  },
  {
    "s2PaperId": "3287d3ecdcc2fe42cacb140ae70e7ccc16a58786",
    "title": "A new Framework for Causal Discovery",
    "abstract": "",
    "year": 2020,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/3287d3ecdcc2fe42cacb140ae70e7ccc16a58786",
    "doi": "",
    "arxivId": "",
    "authors": "P. Leeuwen, M. DeCaria, Nachiketa Chakaborty, M. Pulido",
    "citationCount": 1
  },
  {
    "s2PaperId": "0934511918d58288407df764a0d7eb86afc9aa60",
    "title": "Hyperharmonic analysis for the study of high-order information-theoretic signals",
    "abstract": "Network representations often cannot fully account for the structural richness of complex systems spanning multiple levels of organisation. Recently proposed high-order information-theoretic signals are well-suited to capture synergistic phenomena that transcend pairwise interactions; however, the exponential-growth of their cardinality severely hinders their applicability. In this work, we combine methods from harmonic analysis and combinatorial topology to construct efficient representations of high-order information-theoretic signals. The core of our method is the diagonalisation of a discrete version of the Laplace–de Rham operator, that geometrically encodes structural properties of the system. We capitalise on these ideas by developing a complete workflow for the construction of hyperharmonic representations of high-order signals, which is applicable to a wide range of scenarios.",
    "year": 2020,
    "venue": "Journal of Physics: Complexity",
    "url": "https://www.semanticscholar.org/paper/0934511918d58288407df764a0d7eb86afc9aa60",
    "doi": "10.1088/2632-072X/abf231",
    "arxivId": "2010.01117",
    "authors": "A. Medina-Mardones, F. Rosas, Sebasti'an E. Rodr'iguez, Rodrigo Cofr'e",
    "citationCount": 7
  },
  {
    "s2PaperId": "b8e2ec982d205a08194443c282a2f0262efa5a2c",
    "title": "Information Flows: Characterizing Precipitation‐Streamflow Dependencies in the Colorado Headwaters With an Information Theory Approach",
    "abstract": "Watersheds aggregate precipitation signals of many intensities and from many locations into a single observable streamflow at an outlet point. This dependency between precipitation and streamflow varies seasonally and can shift over time due to changes in land cover, climate, human water uses, or changes in properties of precipitation events themselves. We apply information theory‐based measures to capture temporal linkages, or information transfers, from daily precipitation occurrence at different locations in a basin to streamflow at an outlet. We detect critical magnitudes of precipitation and lag times associated with the strongest precipitation‐streamflow relationships, and further partition information transfers to determine relative contributions from the knowledge of wet versus dry past states. Based on an analysis of daily U.S. Geological Survey (USGS) streamflow and Climate Prediction Center (CPC) gridded gauge‐based precipitation data sets in the Colorado Headwaters Basin, this dependency is strongest in fall, the longest dominant lag times occur in spring, and the strengths of dependencies have increased in spring and summer over the past 65 years. These features relate to both seasonal and spatial characteristics of precipitation and the landscape. A partitioning of information components shows that in this basin, the particular knowledge of a lagged, or past, wet state tends to be more informative to flow than a lagged dry state, even though dry days are more frequent. This study introduces several signatures of precipitation‐streamflow relationships that can also more broadly characterize strengths, thresholds, and timescales associated with various interconnected processes.",
    "year": 2020,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/b8e2ec982d205a08194443c282a2f0262efa5a2c",
    "doi": "10.1029/2019WR026133",
    "arxivId": "",
    "authors": "Samuel E. Franzen, M. A. Farahani, A. Goodwell",
    "citationCount": 22
  },
  {
    "s2PaperId": "cbb245a1479e2efd585ab792cfdf56e8632f8876",
    "title": "Partial Information Decomposition and the Information Delta: A Geometric Unification Disentangling Non-Pairwise Information",
    "abstract": "Information theory provides robust measures of multivariable interdependence, but classically does little to characterize the multivariable relationships it detects. The Partial Information Decomposition (PID) characterizes the mutual information between variables by decomposing it into unique, redundant, and synergistic components. This has been usefully applied, particularly in neuroscience, but there is currently no generally accepted method for its computation. Independently, the Information Delta framework characterizes non-pairwise dependencies in genetic datasets. This framework has developed an intuitive geometric interpretation for how discrete functions encode information, but lacks some important generalizations. This paper shows that the PID and Delta frameworks are largely equivalent. We equate their key expressions, allowing for results in one framework to apply towards open questions in the other. For example, we find that the approach of Bertschinger et al. is useful for the open Information Delta question of how to deal with linkage disequilibrium. We also show how PID solutions can be mapped onto the space of delta measures. Using Bertschinger et al. as an example solution, we identify a specific plane in delta-space on which this approach’s optimization is constrained, and compute it for all possible three-variable discrete functions of a three-letter alphabet. This yields a clear geometric picture of how a given solution decomposes information.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/cbb245a1479e2efd585ab792cfdf56e8632f8876",
    "doi": "10.3390/e22121333",
    "arxivId": "",
    "authors": "James M. Kunert-Graf, Nikita A. Sakhanenko, D. Galas",
    "citationCount": 9
  },
  {
    "s2PaperId": "1e379f5a8f94336f3603263b5a453ab63fa48f16",
    "title": "A synergistic core for human brain evolution and cognition",
    "abstract": "A fundamental question in neuroscience is how brain organisation gives rise to humans’ unique cognitive abilities. Although complex cognition is widely assumed to rely on frontal and parietal brain regions, the underlying mechanisms remain elusive: current approaches are unable to disentangle different forms of information processing in the brain. Here, we introduce a powerful framework to identify synergistic and redundant contributions to neural information processing and cognition. Leveraging multimodal data including functional MRI, PET, cytoarchitectonics and genetics, we reveal that synergistic interactions are the fundamental drivers of complex human cognition. Whereas redundant information dominates sensorimotor areas, synergistic activity is closely associated with the brain’s prefrontal-parietal and default networks; furthermore, meta-analytic results demonstrate a close relationship between high-level cognitive tasks and synergistic information. From an evolutionary perspective, the human brain exhibits higher prevalence of synergistic information than non-human primates. At the macroscale, we demonstrate that high-synergy regions underwent the highest degree of evolutionary cortical expansion. At the microscale, human-accelerated genes promote synergistic interactions by enhancing synaptic transmission. These convergent results provide critical insights that synergistic neural interactions underlie the evolution and functioning of humans’ sophisticated cognitive abilities, and demonstrate the power of our widely applicable information decomposition framework.",
    "year": 2020,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/1e379f5a8f94336f3603263b5a453ab63fa48f16",
    "doi": "10.1101/2020.09.22.308981",
    "arxivId": "",
    "authors": "A. Luppi, P. Mediano, F. Rosas, N. Holland, T. Fryer, J. O'Brien, J. Rowe, D. Menon, D. Bor, E. Stamatakis",
    "citationCount": 155
  },
  {
    "s2PaperId": "d332ec1adeb016b75ed7d348e339d1abf719e509",
    "title": "Gaining confidence in inferred networks",
    "abstract": "Network inference is a notoriously challenging problem. Inferred networks are associated with high uncertainty and likely riddled with false positive and false negative interactions. Especially for biological networks we do not have good ways of judging the performance of inference methods against real networks, and instead we often rely solely on the performance against simulated data. Gaining confidence in networks inferred from real data nevertheless thus requires establishing reliable validation methods. Here, we argue that the expectation of mixing patterns in biological networks such as gene regulatory networks offers a reasonable starting point: interactions are more likely to occur between nodes with similar biological functions. We can quantify this behaviour using the assortativity coefficient, and here we show that the resulting heuristic, functional assortativity, offers a reliable and informative route for comparing different inference algorithms.",
    "year": 2020,
    "venue": "Scientific Reports",
    "url": "https://www.semanticscholar.org/paper/d332ec1adeb016b75ed7d348e339d1abf719e509",
    "doi": "10.1101/2020.09.19.304980",
    "arxivId": "",
    "authors": "Léo P. M. Diaz, M. Stumpf",
    "citationCount": 4
  },
  {
    "s2PaperId": "b878f9726f89a4ddefa54a6c601df3e6ff3e4070",
    "title": "Inferring neural information flow from spiking data",
    "abstract": "",
    "year": 2020,
    "venue": "Computational and Structural Biotechnology Journal",
    "url": "https://www.semanticscholar.org/paper/b878f9726f89a4ddefa54a6c601df3e6ff3e4070",
    "doi": "10.1016/j.csbj.2020.09.007",
    "arxivId": "",
    "authors": "Adrià Tauste Campo",
    "citationCount": 8
  },
  {
    "s2PaperId": "0161fbf427dec62fdfdfa2ca8444280d64ddb431",
    "title": "A comprehensive survey of regulatory network inference methods using single cell RNA sequencing data",
    "abstract": "Gene regulatory network is a complicated set of interactions between genetic materials, which dictates how cells develop in living organisms and react to their surrounding environment. Robust comprehension of these interactions would help explain how cells function as well as predict their reactions to external factors. This knowledge can benefit both developmental biology and clinical research such as drug development or epidemiology research. Recently, the rapid advance of single-cell sequencing technologies, which pushed the limit of transcriptomic profiling to the individual cell level, opens up an entirely new area for regulatory network research. To exploit this new abundant source of data and take advantage of data in single-cell resolution, a number of computational methods have been proposed to uncover the interactions hidden by the averaging process in standard bulk sequencing. In this article, we review 15 such network inference methods developed for single-cell data. We discuss their underlying assumptions, inference techniques, usability, and pros and cons. In an extensive analysis using simulation, we also assess the methods' performance, sensitivity to dropout and time complexity. The main objective of this survey is to assist not only life scientists in selecting suitable methods for their data and analysis purposes but also computational scientists in developing new methods by highlighting outstanding challenges in the field that remain to be addressed in the future development.",
    "year": 2020,
    "venue": "Briefings Bioinform.",
    "url": "https://www.semanticscholar.org/paper/0161fbf427dec62fdfdfa2ca8444280d64ddb431",
    "doi": "10.1093/bib/bbaa190",
    "arxivId": "",
    "authors": "Hung Nguyen, Duc Tran, Bang Tran, Bahadir A. Pehlivan, Tin Nguyen",
    "citationCount": 110
  },
  {
    "s2PaperId": "8129e7b940889cebe6b2986024e168c86aa700e0",
    "title": "A comprehensive survey of regulatory network inference methods using single cell RNA sequencing data",
    "abstract": "Abstract Gene regulatory network is a complicated set of interactions between genetic materials, which dictates how cells develop in living organisms and react to their surrounding environment. Robust comprehension of these interactions would help explain how cells function as well as predict their reactions to external factors. This knowledge can benefit both developmental biology and clinical research such as drug development or epidemiology research. Recently, the rapid advance of single-cell sequencing technologies, which pushed the limit of transcriptomic profiling to the individual cell level, opens up an entirely new area for regulatory network research. To exploit this new abundant source of data and take advantage of data in single-cell resolution, a number of computational methods have been proposed to uncover the interactions hidden by the averaging process in standard bulk sequencing. In this article, we review 15 such network inference methods developed for single-cell data. We discuss their underlying assumptions, inference techniques, usability, and pros and cons. In an extensive analysis using simulation, we also assess the methods’ performance, sensitivity to dropout and time complexity. The main objective of this survey is to assist not only life scientists in selecting suitable methods for their data and analysis purposes but also computational scientists in developing new methods by highlighting outstanding challenges in the field that remain to be addressed in the future development.",
    "year": 2020,
    "venue": "Briefings in Bioinformatics",
    "url": "https://www.semanticscholar.org/paper/8129e7b940889cebe6b2986024e168c86aa700e0",
    "doi": "10.1093/bib/bbaa190",
    "arxivId": "",
    "authors": "Hung Nguyen, Duc Tran, Bang Tran, Bahadir A. Pehlivan, Tin Nguyen",
    "citationCount": 8
  },
  {
    "s2PaperId": "0de3294d28e1f32327365ce890459cd1ea90d354",
    "title": "An Approximation Scheme for Multivariate Information based on Partial Information Decomposition",
    "abstract": "We consider an approximation scheme for multivariate information assuming that synergistic information only appearing in higher order joint distributions is suppressed, which may hold in large classes of systems. Our approximation scheme gives a practical way to evaluate information among random variables and is expected to be applied to feature selection in machine learning. The truncation order of our approximation scheme is given by the order of synergy. In the classification of information, we use the partial information decomposition of the original one. The resulting multivariate information is expected to be reasonable if higher order synergy is suppressed in the system. In addition, it is calculable in relatively easy way if the truncation order is not so large. We also perform numerical experiments to check the validity of our approximation scheme.",
    "year": 2020,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/0de3294d28e1f32327365ce890459cd1ea90d354",
    "doi": "",
    "arxivId": "2009.00791",
    "authors": "M. Takimoto",
    "citationCount": 0
  },
  {
    "s2PaperId": "00677f25f311742705493290b42409b2126cc5dd",
    "title": "A Path-Based Partial Information Decomposition",
    "abstract": "Based on the conceptual basis of information theory, we propose a novel mutual information measure—‘path-based mutual information’. This information measure results from the representation of a set of random variables as a probabilistic graphical model. The edges in this graph are modeled as discrete memoryless communication channels, that is, the underlying data is ergodic, stationary, and the Markov condition is assumed to be applicable. The associated multilinear stochastic maps, tensors, transform source probability mass functions into destination probability mass functions. This allows for an exact expression of the resulting tensor of a cascade of discrete memoryless communication channels in terms of the tensors of the constituting communication channels in the paths. The resulting path-based information measure gives rise to intuitive, non-negative, and additive path-based information components—redundant, unique, and synergistic information—as proposed by Williams and Beer. The path-based redundancy satisfies the axioms postulated by Williams and Beer, the identity axiom postulated by Harder, and the left monotonicity axiom postulated Bertschinger. The ordering relations between redundancies of different joint collections of sources, as captured in the redundancy lattices of Williams and Beer, follow from the data processing inequality. Although negative information components can arise, we speculate that these either result from unobserved variables, or from adding additional sources that are statistically independent from all other sources to a system containing only non-negative information components. This path-based approach illustrates that information theory provides the concepts and measures for a partial information decomposition.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/00677f25f311742705493290b42409b2126cc5dd",
    "doi": "10.3390/e22090952",
    "arxivId": "",
    "authors": "David Sigtermans",
    "citationCount": 5
  },
  {
    "s2PaperId": "1e5217c3137de5ce9387a5ca63cb93a825c62cbc",
    "title": "Bits and pieces: understanding information decomposition from part-whole relationships and formal logic",
    "abstract": "Partial information decomposition (PID) seeks to decompose the multivariate mutual information that a set of source variables contains about a target variable into basic pieces, the so-called ‘atoms of information’. Each atom describes a distinct way in which the sources may contain information about the target. For instance, some information may be contained uniquely in a particular source, some information may be shared by multiple sources and some information may only become accessible synergistically if multiple sources are combined. In this paper, we show that the entire theory of PID can be derived, firstly, from considerations of part-whole relationships between information atoms and mutual information terms, and secondly, based on a hierarchy of logical constraints describing how a given information atom can be accessed. In this way, the idea of a PID is developed on the basis of two of the most elementary relationships in nature: the part-whole relationship and the relation of logical implication. This unifying perspective provides insights into pressing questions in the field such as the possibility of constructing a PID based on concepts other than redundant information in the general n-sources case. Additionally, it admits of a particularly accessible exposition of PID theory.",
    "year": 2020,
    "venue": "Proceedings of the Royal Society A",
    "url": "https://www.semanticscholar.org/paper/1e5217c3137de5ce9387a5ca63cb93a825c62cbc",
    "doi": "10.1098/rspa.2021.0110",
    "arxivId": "2008.09535",
    "authors": "A. Gutknecht, M. Wibral, Abdullah Makkeh",
    "citationCount": 71
  },
  {
    "s2PaperId": "166ca56d15c02551dcddef34269b0d4060f2ac8b",
    "title": "Quantifying Dynamical High-Order Interdependencies From the O-Information: An Application to Neural Spiking Dynamics",
    "abstract": "We address the problem of efficiently and informatively quantifying how multiplets of variables carry information about the future of the dynamical system they belong to. In particular we want to identify groups of variables carrying redundant or synergistic information, and track how the size and the composition of these multiplets changes as the collective behavior of the system evolves. In order to afford a parsimonious expansion of shared information, and at the same time control for lagged interactions and common effect, we develop a dynamical, conditioned version of the O-information, a framework recently proposed to quantify high-order interdependencies via multivariate extension of the mutual information. The dynamic O-information, here introduced, allows to separate multiplets of variables which influence synergistically the future of the system from redundant multiplets. We apply this framework to a dataset of spiking neurons from a monkey performing a perceptual discrimination task. The method identifies synergistic multiplets that include neurons previously categorized as containing little relevant information individually.",
    "year": 2020,
    "venue": "Frontiers in Physiology",
    "url": "https://www.semanticscholar.org/paper/166ca56d15c02551dcddef34269b0d4060f2ac8b",
    "doi": "10.3389/fphys.2020.595736",
    "arxivId": "2007.16018",
    "authors": "S. Stramaglia, Tomas Scagliarini, Bryan C. Daniels, Daniele Marinazzo",
    "citationCount": 49
  },
  {
    "s2PaperId": "c606df2b439481365569e807d5323363263beac5",
    "title": "Information Transfer in Linear Multivariate Processes Assessed through Penalized Regression Techniques: Validation and Application to Physiological Networks",
    "abstract": "The framework of information dynamics allows the dissection of the information processed in a network of multiple interacting dynamical systems into meaningful elements of computation that quantify the information generated in a target system, stored in it, transferred to it from one or more source systems, and modified in a synergistic or redundant way. The concepts of information transfer and modification have been recently formulated in the context of linear parametric modeling of vector stochastic processes, linking them to the notion of Granger causality and providing efficient tools for their computation based on the state–space (SS) representation of vector autoregressive (VAR) models. Despite their high computational reliability these tools still suffer from estimation problems which emerge, in the case of low ratio between data points available and the number of time series, when VAR identification is performed via the standard ordinary least squares (OLS). In this work we propose to replace the OLS with penalized regression performed through the Least Absolute Shrinkage and Selection Operator (LASSO), prior to computation of the measures of information transfer and information modification. First, simulating networks of several coupled Gaussian systems with complex interactions, we show that the LASSO regression allows, also in conditions of data paucity, to accurately reconstruct both the underlying network topology and the expected patterns of information transfer. Then we apply the proposed VAR-SS-LASSO approach to a challenging application context, i.e., the study of the physiological network of brain and peripheral interactions probed in humans under different conditions of rest and mental stress. Our results, which document the possibility to extract physiologically plausible patterns of interaction between the cardiovascular, respiratory and brain wave amplitudes, open the way to the use of our new analysis tools to explore the emerging field of Network Physiology in several practical applications.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/c606df2b439481365569e807d5323363263beac5",
    "doi": "10.3390/e22070732",
    "arxivId": "",
    "authors": "Y. Antonacci, L. Astolfi, G. Nollo, L. Faes",
    "citationCount": 38
  },
  {
    "s2PaperId": "aa51b0a58922661209de0f0ac9399b66ad906d22",
    "title": "Integration of single-cell multi-omics for gene regulatory network inference",
    "abstract": "",
    "year": 2020,
    "venue": "Computational and Structural Biotechnology Journal",
    "url": "https://www.semanticscholar.org/paper/aa51b0a58922661209de0f0ac9399b66ad906d22",
    "doi": "10.1016/j.csbj.2020.06.033",
    "arxivId": "",
    "authors": "Xin-Hua Hu, Yaohua Hu, F. Wu, R. Leung, J. Qin",
    "citationCount": 42
  },
  {
    "s2PaperId": "a910f06f744a78af0436dbec05fc0be959448a48",
    "title": "Fairness Under Feature Exemptions: Counterfactual and Observational Measures",
    "abstract": "With the growing use of machine learning algorithms in highly consequential domains, the quantification and removal of disparity in decision making with respect to protected attributes, such as gender, race, etc., is becoming increasingly important. While quantifying disparity is essential, sometimes the needs of a business (e.g., hiring) may require the use of certain features that are critical in a way that any disparity that can be explained by them might need to be exempted. For instance, in hiring a software engineer for a safety-critical application, a coding-test score may be a critical feature that is weighed strongly in the decision even if it introduces disparity, whereas other features, such as name, zip code, or reference letters may be used to improve decision-making, but only to the extent that they do not add disparity. In this work, we propose a novel information-theoretic decomposition of the total disparity (a quantification inspired from counterfactual fairness) into two components: a non-exempt component which quantifies the part of the disparity that cannot be accounted for by the critical features, and an exempt component which quantifies the remaining disparity. This decomposition is important: it allows one to check if the disparity arose purely due to the critical features (inspired from the business necessity defense of disparate impact law) and also enables selective removal of the non-exempt component of disparity if desired. We arrive at this decomposition through canonical examples that lead to a set of desirable properties (axioms) that any measure of non-exempt disparity should satisfy. We then demonstrate that our proposed counterfactual measure of non-exempt disparity satisfies all of them. Our quantification bridges ideas of causality, Simpson’s paradox, and a body of work from information theory called Partial Information Decomposition (PID). We also obtain an impossibility result showing that no observational measure of non-exempt disparity can satisfy all of the desired properties, which leads us to relax our goals and examine alternative observational measures that satisfy only some of these properties. We perform case studies to show how one can audit existing models as well as train new models while reducing non-exempt disparity.",
    "year": 2020,
    "venue": "IEEE Transactions on Information Theory",
    "url": "https://www.semanticscholar.org/paper/a910f06f744a78af0436dbec05fc0be959448a48",
    "doi": "10.1109/tit.2021.3103206",
    "arxivId": "2006.07986",
    "authors": "Sanghamitra Dutta, Praveen Venkatesh, Piotr (Peter) Mardziel, Anupam Datta, P. Grover",
    "citationCount": 17
  },
  {
    "s2PaperId": "e53e3300bbb36b22446ac8671a75b8e2366896a7",
    "title": "Information Theory in Computational Biology: Where We Stand Today",
    "abstract": "“A Mathematical Theory of Communication” was published in 1948 by Claude Shannon to address the problems in the field of data compression and communication over (noisy) communication channels. Since then, the concepts and ideas developed in Shannon’s work have formed the basis of information theory, a cornerstone of statistical learning and inference, and has been playing a key role in disciplines such as physics and thermodynamics, probability and statistics, computational sciences and biological sciences. In this article we review the basic information theory based concepts and describe their key applications in multiple major areas of research in computational biology—gene expression and transcriptomics, alignment-free sequence comparison, sequencing and error correction, genome-wide disease-gene association mapping, metabolic networks and metabolomics, and protein sequence, structure and interaction analysis.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/e53e3300bbb36b22446ac8671a75b8e2366896a7",
    "doi": "10.3390/e22060627",
    "arxivId": "",
    "authors": "Pritam Chanda, Eduardo Costa, Jie Hu, Shravan Sukumar, John L. Van Hemert, Rasna R. Walia",
    "citationCount": 39
  },
  {
    "s2PaperId": "930f87a08d30ec9f9e3821280b18236003c23823",
    "title": "Contextual Modulation in Mammalian Neocortex is Asymmetric",
    "abstract": "Neural systems are composed of many local processors that generate an output given their many inputs as specified by a transfer function. This paper studies a transfer function that is fundamentally asymmetric and builds on multi-site intracellular recordings indicating that some neocortical pyramidal cells can function as context-sensitive two-point processors in which some inputs modulate the strength with which they transmit information about other inputs. Learning and processing at the level of the local processor can then be guided by the context of activity in the system as a whole without corrupting the message that the local processor transmits. We use a recent advance in the foundations of information theory to compare the properties of this modulatory transfer function with that of the simple arithmetic operators. This advance enables the information transmitted by processors with two distinct inputs to be decomposed into those components unique to each input, that shared between the two inputs, and that which depends on both though it is in neither, i.e., synergy. We show that contextual modulation is fundamentally asymmetric, contrasts with all four simple arithmetic operators, can take various forms, and can occur together with the anatomical asymmetry that defines pyramidal neurons in mammalian neocortex.",
    "year": 2020,
    "venue": "Symmetry",
    "url": "https://www.semanticscholar.org/paper/930f87a08d30ec9f9e3821280b18236003c23823",
    "doi": "10.3390/sym12050815",
    "arxivId": "",
    "authors": "J. Kay, W. A. Phillips",
    "citationCount": 14
  },
  {
    "s2PaperId": "8f28ace48be2a84cfaec5fc621799ed39474b6a0",
    "title": "Unsupervised bin-wise pre-training: A fusion of information theory and hypergraph",
    "abstract": "",
    "year": 2020,
    "venue": "Knowledge-Based Systems",
    "url": "https://www.semanticscholar.org/paper/8f28ace48be2a84cfaec5fc621799ed39474b6a0",
    "doi": "10.1016/j.knosys.2020.105650",
    "arxivId": "",
    "authors": "H. AnilaGlory, C. Vigneswaran, V. Sriram",
    "citationCount": 5
  },
  {
    "s2PaperId": "ff1fe35c6fc398635590093c33fc3a0041360a1f",
    "title": "A Method to Present and Analyze Ensembles of Information Sources",
    "abstract": "Information theory is a powerful tool for analyzing complex systems. In many areas of neuroscience, it is now possible to gather data from large ensembles of neural variables (e.g., data from many neurons, genes, or voxels). The individual variables can be analyzed with information theory to provide estimates of information shared between variables (forming a network between variables), or between neural variables and other variables (e.g., behavior or sensory stimuli). However, it can be difficult to (1) evaluate if the ensemble is significantly different from what would be expected in a purely noisy system and (2) determine if two ensembles are different. Herein, we introduce relatively simple methods to address these problems by analyzing ensembles of information sources. We demonstrate how an ensemble built of mutual information connections can be compared to null surrogate data to determine if the ensemble is significantly different from noise. Next, we show how two ensembles can be compared using a randomization process to determine if the sources in one contain more information than the other. All code necessary to carry out these analyses and demonstrations are provided.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ff1fe35c6fc398635590093c33fc3a0041360a1f",
    "doi": "10.3390/e22050580",
    "arxivId": "",
    "authors": "N. Timme, D. Linsenbardt, C. Lapish",
    "citationCount": 1
  },
  {
    "s2PaperId": "de63dfe83e384f97a2e46020e5cac0ca27477854",
    "title": "Inferring spatial and signaling relationships between cells from single cell transcriptomic data",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) provides details for individual cells; however, crucial spatial information is often lost. We present SpaOTsc, a method relying on structured optimal transport to recover spatial properties of scRNA-seq data by utilizing spatial measurements of a relatively small number of genes. A spatial metric for individual cells in scRNA-seq data is first established based on a map connecting it with the spatial measurements. The cell–cell communications are then obtained by “optimally transporting” signal senders to target signal receivers in space. Using partial information decomposition, we next compute the intercellular gene–gene information flow to estimate the spatial regulations between genes across cells. Four datasets are employed for cross-validation of spatial gene expression prediction and comparison to known cell–cell communications. SpaOTsc has broader applications, both in integrating non-spatial single-cell measurements with spatial data, and directly in spatial single-cell transcriptomics data to reconstruct spatial cellular dynamics in tissues. Dissociation of tissues allows high-throughput expression profiling of single cells, but spatial information is lost. Here the authors apply an unbalanced and structured optimal transport method to infer spatial and signalling relationships between cells from scRNA-seq data by integrating it with spatial imaging data.",
    "year": 2020,
    "venue": "Nature Communications",
    "url": "https://www.semanticscholar.org/paper/de63dfe83e384f97a2e46020e5cac0ca27477854",
    "doi": "10.1038/s41467-020-15968-5",
    "arxivId": "",
    "authors": "Zixuan Cang, Q. Nie",
    "citationCount": 291
  },
  {
    "s2PaperId": "72c358cf10fb6130a793a1d709e2a3b855a45646",
    "title": "How Complexity and Uncertainty Grew with Algorithmic Trading",
    "abstract": "The machine-learning paradigm promises traders to reduce uncertainty through better predictions done by ever more complex algorithms. We ask about detectable results of both uncertainty and complexity at the aggregated market level. We analyzed almost one billion trades of eight currency pairs (2007–2017) and show that increased algorithmic trading is associated with more complex subsequences and more predictable structures in bid-ask spreads. However, algorithmic involvement is also associated with more future uncertainty, which seems contradictory, at first sight. On the micro-level, traders employ algorithms to reduce their local uncertainty by creating more complex algorithmic patterns. This entails more predictable structure and more complexity. On the macro-level, the increased overall complexity implies more combinatorial possibilities, and therefore, more uncertainty about the future. The chain rule of entropy reveals that uncertainty has been reduced when trading on the level of the fourth digit behind the dollar, while new uncertainty started to arise at the fifth digit behind the dollar (aka ‘pip-trading’). In short, our information theoretic analysis helps us to clarify that the seeming contradiction between decreased uncertainty on the micro-level and increased uncertainty on the macro-level is the result of the inherent relationship between complexity and uncertainty.",
    "year": 2020,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/72c358cf10fb6130a793a1d709e2a3b855a45646",
    "doi": "10.3390/e22050499",
    "arxivId": "",
    "authors": "Martin Hilbert, David M. Darmon",
    "citationCount": 11
  },
  {
    "s2PaperId": "0cfe84f85de736e0ff725c7d7227cea393bd40eb",
    "title": "Reconciling emergences: An information-theoretic approach to identify causal emergence in multivariate data",
    "abstract": "The broad concept of emergence is instrumental in various of the most challenging open scientific questions—yet, few quantitative theories of what constitutes emergent phenomena have been proposed. This article introduces a formal theory of causal emergence in multivariate systems, which studies the relationship between the dynamics of parts of a system and macroscopic features of interest. Our theory provides a quantitative definition of downward causation, and introduces a complementary modality of emergent behaviour—which we refer to as causal decoupling. Moreover, the theory allows practical criteria that can be efficiently calculated in large systems, making our framework applicable in a range of scenarios of practical interest. We illustrate our findings in a number of case studies, including Conway’s Game of Life, Reynolds’ flocking model, and neural activity as measured by electrocorticography.",
    "year": 2020,
    "venue": "PLoS Comput. Biol.",
    "url": "https://www.semanticscholar.org/paper/0cfe84f85de736e0ff725c7d7227cea393bd40eb",
    "doi": "10.1371/journal.pcbi.1008289",
    "arxivId": "2004.08220",
    "authors": "F. Rosas, P. Mediano, H. Jensen, A. Seth, A. Barrett, Robin L. Carhart-Harris, D. Bor",
    "citationCount": 107
  },
  {
    "s2PaperId": "6190f7181c18863ab162c3f1821688827a3d1ff5",
    "title": "An Information-Theoretic Quantification of Discrimination with Exempt Features",
    "abstract": "The needs of a business (e.g., hiring) may require the use of certain features that are critical in a way that any discrimination arising due to them should be exempted. In this work, we propose a novel information-theoretic decomposition of the total discrimination (in a counterfactual sense) into a non-exempt component, which quantifies the part of the discrimination that cannot be accounted for by the critical features, and an exempt component, which quantifies the remaining discrimination. Our decomposition enables selective removal of the non-exempt component if desired. We arrive at this decomposition through examples and counterexamples that enable us to first obtain a set of desirable properties that any measure of non-exempt discrimination should satisfy. We then demonstrate that our proposed quantification of non-exempt discrimination satisfies all of them. This decomposition leverages a body of work from information theory called Partial Information Decomposition (PID). We also obtain an impossibility result showing that no observational measure of non-exempt discrimination can satisfy all of the desired properties, which leads us to relax our goals and examine alternative observational measures that satisfy only some of these properties. We then perform a case study using one observational measure to show how one might train a model allowing for exemption of discrimination due to critical features.",
    "year": 2020,
    "venue": "AAAI Conference on Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/6190f7181c18863ab162c3f1821688827a3d1ff5",
    "doi": "10.1609/AAAI.V34I04.5794",
    "arxivId": "",
    "authors": "Sanghamitra Dutta, Praveen Venkatesh, Piotr (Peter) Mardziel, Anupam Datta, P. Grover",
    "citationCount": 31
  },
  {
    "s2PaperId": "3db924fb0b34653066b4721149c1eb09535c5bc5",
    "title": "Correlated structural evolution within multiplex networks",
    "abstract": "Many natural, engineered and social systems can be represented using the framework of a layered network, where each layer captures a different type of interaction between the same set of nodes. The study of such multiplex networks is a vibrant area of research. Yet, understanding how to quantify the correlations present between pairs of layers, and more so present in their co-evolution, is lacking. Such methods would enable us to address fundamental questions involving issues such as function, redundancy, and potential disruptions. Here, we show first how the edge set of a multiplex network can be used to construct an estimator of a joint probability distribution describing edge existence over all layers. We then adapt an information-theoretic measure of general correlation called the conditional mutual information, which uses the estimated joint probability distribution, to quantify the pairwise correlations present between layers. The pairwise comparisons can also be temporal, allowing us to identify if knowledge of a certain layer can provide additional information about the evolution of another layer. We analyse datasets from three distinct domains—economic, political, and airline networks—to demonstrate how pairwise correlation in structure and dynamical evolution between layers can be identified and show that anomalies can serve as potential indicators of major events such as shocks.",
    "year": 2020,
    "venue": "J. Complex Networks",
    "url": "https://www.semanticscholar.org/paper/3db924fb0b34653066b4721149c1eb09535c5bc5",
    "doi": "10.1093/comnet/cnaa014",
    "arxivId": "2005.04487",
    "authors": "Haochen Wu, R. James, J. Crutchfield, Raissa M. D’Souza",
    "citationCount": 5
  },
  {
    "s2PaperId": "f2259570e9adc3b56bb5a2d0b92e995dfd86d8fe",
    "title": "High-order interdependencies in the aging brain",
    "abstract": "Brain interdependencies can be studied either from a structural/anatomical perspective (“structural connectivity”, SC) or by considering statistical interdependencies (“functional connectivity”, FC). Interestingly, while SC is typically pairwise (white-matter fibers start in a certain region and arrive at another), FC is not; however, most FC analyses focus only on pairwise statistics and neglect high-order interactions. A promising tool to study high-order interdependencies is the recently proposed O-Information, which can quantify the intrinsic statistical synergy and redundancy in groups of three or more interacting variables. In this paper we used the O-Information to investigate how high-order statistical interdependencies are affected by age. For this, we analised functional magnetic resonance imaging (fMRI) data at rest obtained from 164 healthy participants, ranging from 10 to 80 years old. Our results show that older subjects (age ranging from 60 to 80 years) exhibit a higher predominance of redundant dependencies than younger subjects; moreover, this effect seems to be pervasive, taking place at all interaction orders. Additionally, we found that these effects are highly heterogeneous across brain regions, and suggest the existence of a “redundancy core” formed by the prefrontal and motor cortices – thus involving functions such as working memory, executive and motor functions. Our methodology to assess high-order interdependencies in fMRI data has unlimited applications. The code to calculate these metrics is freely available.",
    "year": 2020,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/f2259570e9adc3b56bb5a2d0b92e995dfd86d8fe",
    "doi": "10.1101/2020.03.17.995886",
    "arxivId": "",
    "authors": "Marilyn Gatica, R. Cofré, P. Mediano, F. Rosas, P. Orio, I. Díez, S. Swinnen, J. Cortes",
    "citationCount": 75
  },
  {
    "s2PaperId": "452f2d975f3862c2e8244f102493fb017e22f002",
    "title": "The effects of proliferation status and cell cycle phase on the responses of single cells to chemotherapy",
    "abstract": "DNA-damaging chemotherapeutics are widely used in cancer treatments, but for solid tumors they often leave a residual tumor-cell population. Here we investigated how cellular states might affect the response of individual cells in a clonal population to cisplatin, a DNA-damaging chemotherapeutic agent. Using a live-cell reporter of cell cycle phase and long-term imaging, we monitored single-cell proliferation before, at the time of, and after treatment. We found that in response to cisplatin, cells either arrested or died, and the ratio of these outcomes depended on the dose. While we found that the cell cycle phase at the time of cisplatin addition was not predictive of outcome, the proliferative history of the cell was: highly proliferative cells were more likely to arrest than to die, whereas slowly proliferating cells showed a higher probability of death. Information theory analysis revealed that the dose of cisplatin had the greatest influence on the cells’ decisions to arrest or die, and that the proliferation status interacted with the cisplatin dose to further guide this decision. These results show an unexpected effect of proliferation status in regulating responses to cisplatin and suggest that slowly proliferating cells within tumors may be acutely vulnerable to chemotherapy.",
    "year": 2020,
    "venue": "Molecular Biology of the Cell",
    "url": "https://www.semanticscholar.org/paper/452f2d975f3862c2e8244f102493fb017e22f002",
    "doi": "10.1091/mbc.E19-09-0515",
    "arxivId": "",
    "authors": "Adrián E. Granada, Alba Jiménez, Jacob Stewart-Ornstein, N. Blüthgen, Simone Reber, A. Jambhekar, G. Lahav",
    "citationCount": 39
  },
  {
    "s2PaperId": "4b08476b4ca6e60acb061c44b4afa8de20083e61",
    "title": "A differentiable measure of pointwise shared information",
    "abstract": "Partial information decomposition (PID) of the multivariate mutual information describes the distinct ways in which a set of source variables contains information about a target variable. The groundbreaking work of Williams and Beer has shown that this decomposition can not be determined from classic information theory without making additional assumptions, and several candidate measures have been proposed, often drawing on principles from related fields such as decision theory. None of these measures is differentiable with respect to the underlying probability mass function. We here present a novel measure that draws only on the principle linking the local mutual information to exclusion of probability mass. This principle is foundational to the original definition of the mutual information by Fano. We reuse this principle to define a measure of shared information based on the shared exclusion of probability mass by the realizations of source variables. Our measure is differentiable and well-defined for individual realizations of the random variables. Thus, it lends itself for example to local learning in artificial neural networks. We show that the measure can be interpreted as local mutual information with the help of an auxiliary variable. We also show that it has a meaningful Moebius inversion on a redundancy lattice and obeys a target chain rule. We give an operational interpretation of the measure based on the decisions that an agent should take if given only the shared information.",
    "year": 2020,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/4b08476b4ca6e60acb061c44b4afa8de20083e61",
    "doi": "",
    "arxivId": "2002.03356",
    "authors": "Abdullah Makkeh, A. Gutknecht, M. Wibral",
    "citationCount": 7
  },
  {
    "s2PaperId": "e9819c0dc4b9775c5f5f4c27ed2104e11ccccb4e",
    "title": "Debates—Does Information Theory Provide a New Paradigm for Earth Science? Causality, Interaction, and Feedback",
    "abstract": "The concept of causal interactions between components is an integral part of hydrology and Earth system sciences. Modelers, decision makers, scientists, and other water resources stakeholders all utilize some notion of cause‐and‐effect to understand processes, make decisions, and infer how systems react to change. However, there are different perspectives on the meaning of causality in complex systems and, further, different frameworks and methodologies with which to detect causal interactions. We propose here that information theory (IT) provides a compelling framework for the detection of causality and discuss approaches for several levels of analyses that capture interactions that range from pairwise to multivariate in nature. We illustrate these types of analyses with an example based on weather station time series variables, in which variables may interact pairwise or jointly and on short to long time scales. In general, many unsolved or even unanticipated questions in the hydrologic sciences could benefit from this perspective.",
    "year": 2020,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/e9819c0dc4b9775c5f5f4c27ed2104e11ccccb4e",
    "doi": "10.1029/2019WR024940",
    "arxivId": "",
    "authors": "A. Goodwell, P. Jiang, B. Ruddell, Praveen Kumar",
    "citationCount": 48
  },
  {
    "s2PaperId": "2513fab7733ad68ee90ddaf684f7d20ed5e5a39f",
    "title": "Debates—Does Information Theory Provide a New Paradigm for Earth Science?",
    "abstract": "The basis for all knowledge is “information” that we compile about the world, expressed through models that support understanding, prediction, and decision making. This overview paper provides a contextual basis for the four papers that make up the “debate series” compiled under the above title. We briefly introduce Information Theory, discuss how “information” can be considered to be both a “physical” quantity and a “probabilistic” basis for representing incompleteness in knowledge, discuss the core motivation for this debate series, and briefly summarize the major arguments advanced by each of the debate papers. Our purpose is to facilitate an understanding of how these papers are related and how they approach the debate series question from different perspectives, while pointing to future directions for research. Finally, we invite further discourse and debate to advance the understanding and prediction of natural system dynamics using Information Theory, including the assessment of its limitations and complementarity to existing physics and machine learning approaches. Ultimately, our goal is to press for the development of philosophical and methodological advances that will enable the Earth science community to address some of the compelling unsolved problems in our field.",
    "year": 2020,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/2513fab7733ad68ee90ddaf684f7d20ed5e5a39f",
    "doi": "10.1029/2019WR026398",
    "arxivId": "",
    "authors": "Praveen Kumar, H. Gupta",
    "citationCount": 24
  },
  {
    "s2PaperId": "5b02eecef9cd084ffa0ec723d1239d436f653472",
    "title": "A Partial Information Decomposition Based on Causal Tensors",
    "abstract": "We propose a partial information decomposition based on the newly introduced framework of causal tensors, i.e., multilinear stochastic maps that transform source data into destination data. The innovation that causal tensors introduce is that the framework allows for an exact expression of an indirect association in terms of the constituting, direct associations. This is not possible when expressing associations only in measures like mutual information or transfer entropy. Instead of a priori expressing associations in terms of mutual information or transfer entropy, the a posteriori expression of associations in these terms results in an intuitive definition of a nonnegative and left monotonic redundancy, which also meets the identity property. Our proposed redundancy satisfies the three axioms introduced by Williams and Beer. Symmetry and self-redundancy axioms follow directly from our definition. The data processing inequality ensures that the monotonicity axiom is satisfied. Because causal tensors can describe both mutual information as transfer entropy, the partial information decomposition applies to both measures. Results show that the decomposition closely resembles the decomposition of other another approach that expresses associations in terms of mutual information a posteriori. A negative synergistic term could indicate that there is an unobserved common cause.",
    "year": 2020,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/5b02eecef9cd084ffa0ec723d1239d436f653472",
    "doi": "10.20944/preprints202002.0066.v1",
    "arxivId": "2001.10481",
    "authors": "David Sigtermans",
    "citationCount": 1
  },
  {
    "s2PaperId": "db6295d842284ff9a37b77098feeb77604ec5f64",
    "title": "An operational information decomposition via synergistic disclosure",
    "abstract": "Multivariate information decompositions hold promise to yield insight into complex systems, and stand out for their ability to identify synergistic phenomena. However, the adoption of these approaches has been hindered by there being multiple possible decompositions, and no precise guidance for preferring one over the others. At the heart of this disagreement lies the absence of a clear operational interpretation of what synergistic information is. Here we fill this gap by proposing a new information decomposition based on a novel operationalisation of informational synergy, which leverages recent developments in the literature of data privacy. Our decomposition is defined for any number of information sources, and its atoms can be calculated using elementary optimisation techniques. The decomposition provides a natural coarse-graining that scales gracefully with the system’s size, and is applicable in a wide range of scenarios of practical interest.",
    "year": 2020,
    "venue": "Journal of Physics A: Mathematical and Theoretical",
    "url": "https://www.semanticscholar.org/paper/db6295d842284ff9a37b77098feeb77604ec5f64",
    "doi": "10.1088/1751-8121/abb723",
    "arxivId": "2001.10387",
    "authors": "F. Rosas, P. Mediano, Borzoo Rassouli, Adam Barrett",
    "citationCount": 52
  },
  {
    "s2PaperId": "a8895a0f7ba8c9764ad8334cb7c855dc149e338e",
    "title": "Correlated activity favors synergistic processing in local cortical networks in vitro at synaptically relevant timescales",
    "abstract": "Abstract Neural information processing is widely understood to depend on correlations in neuronal activity. However, whether correlation is favorable or not is contentious. Here, we sought to determine how correlated activity and information processing are related in cortical circuits. Using recordings of hundreds of spiking neurons in organotypic cultures of mouse neocortex, we asked whether mutual information between neurons that feed into a common third neuron increased synergistic information processing by the receiving neuron. We found that mutual information and synergistic processing were positively related at synaptic timescales (0.05–14 ms), where mutual information values were low. This effect was mediated by the increase in information transmission—of which synergistic processing is a component—that resulted as mutual information grew. However, at extrasynaptic windows (up to 3,000 ms), where mutual information values were high, the relationship between mutual information and synergistic processing became negative. In this regime, greater mutual information resulted in a disproportionate increase in redundancy relative to information transmission. These results indicate that the emergence of synergistic processing from correlated activity differs according to timescale and correlation regime. In a low-correlation regime, synergistic processing increases with greater correlation, and in a high-correlation regime, synergistic processing decreases with greater correlation.",
    "year": 2020,
    "venue": "Network Neuroscience",
    "url": "https://www.semanticscholar.org/paper/a8895a0f7ba8c9764ad8334cb7c855dc149e338e",
    "doi": "10.1162/netn_a_00141",
    "arxivId": "",
    "authors": "Samantha P. Sherrill, N. Timme, John M. Beggs, E. Newman",
    "citationCount": 22
  },
  {
    "s2PaperId": "a553e1d142a211d7a8551e02d9313357c84eac22",
    "title": "Synergistic information in a dynamical model implemented on the human structural connectome reveals spatially distinct associations with age",
    "abstract": "Abstract We implement the dynamical Ising model on the large-scale architecture of white matter connections of healthy subjects in the age range 4–85 years, and analyze the dynamics in terms of the synergy, a quantity measuring the extent to which the joint state of pairs of variables is projected onto the dynamics of a target one. We find that the amount of synergy in explaining the dynamics of the hubs of the structural connectivity (in terms of degree strength) peaks before the critical temperature, and can thus be considered as a precursor of a critical transition. Conversely, the greatest amount of synergy goes into explaining the dynamics of more central nodes. We also find that the aging of structural connectivity is associated with significant changes in the simulated dynamics: There are brain regions whose synergy decreases with age, in particular the frontal pole, the subcallosal area, and the supplementary motor area; these areas could then be more likely to show a decline in terms of the capability to perform higher order computation (if structural connectivity was the sole variable). On the other hand, several regions in the temporal cortex show a positive correlation with age in the first 30 years of life, that is, during brain maturation.",
    "year": 2020,
    "venue": "Network Neuroscience",
    "url": "https://www.semanticscholar.org/paper/a553e1d142a211d7a8551e02d9313357c84eac22",
    "doi": "10.1162/netn_a_00146",
    "arxivId": "2002.04527",
    "authors": "D. Nuzzi, M. Pellicoro, L. Angelini, Daniele Marinazzo, S. Stramaglia",
    "citationCount": 11
  },
  {
    "s2PaperId": "c5458a4d5c0035a917315f05b8af6654a487c5a1",
    "title": "Properties of unique information",
    "abstract": "We study the measure of unique information $UI(T:X\\setminus Y)$ defined by Bertschinger et al. (2014) within the framework of information decompositions. We study uniqueness and support of the solutions to the optimization problem underlying the definition of $UI$. We identify sufficient conditions for non-uniqueness of solutions with full support in terms of conditional independence constraints and in terms of the cardinalities of $T$, $X$ and $Y$. Our results are based on a reformulation of the first order conditions on the objective function as rank constraints on a matrix of conditional probabilities. These results help to speed up the computation of $UI(T:X\\setminus Y)$, most notably when $T$ is binary. In the case that all variables are binary, we obtain a complete picture of where the optimizing probability distributions lie.",
    "year": 2019,
    "venue": "Kybernetika (Praha)",
    "url": "https://www.semanticscholar.org/paper/c5458a4d5c0035a917315f05b8af6654a487c5a1",
    "doi": "10.14736/kyb-2021-3-0383",
    "arxivId": "1912.12505",
    "authors": "Johannes Rauh, M. Schünemann, Jürgen Jost",
    "citationCount": 3
  },
  {
    "s2PaperId": "9377f151db7613717ed20aa4e8973c6f2c15bf09",
    "title": "Properties of Unique Information",
    "abstract": "",
    "year": 2019,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/9377f151db7613717ed20aa4e8973c6f2c15bf09",
    "doi": "",
    "arxivId": "",
    "authors": "Johannes Rauh, M. Schünemann",
    "citationCount": 0
  },
  {
    "s2PaperId": "2a1f38b8e267c85197764c1a73644ea3def6993f",
    "title": "Sources of predictive information in dynamical neural networks",
    "abstract": "Behavior involves the ongoing interaction between an organism and its environment. One of the prevailing theories of adaptive behavior is that organisms are constantly making predictions about their future environmental stimuli. However, how they acquire that predictive information is still poorly understood. Two complementary mechanisms have been proposed: predictions are generated from an agent’s internal model of the world or predictions are extracted directly from the environmental stimulus. In this work, we demonstrate that predictive information, measured using bivariate mutual information, cannot distinguish between these two kinds of systems. Furthermore, we show that predictive information cannot distinguish between organisms that are adapted to their environments and random dynamical systems exposed to the same environment. To understand the role of predictive information in adaptive behavior, we need to be able to identify where it is generated. To do this, we decompose information transfer across the different components of the organism-environment system and track the flow of information in the system over time. To validate the proposed framework, we examined it on a set of computational models of idealized agent-environment systems. Analysis of the systems revealed three key insights. First, predictive information, when sourced from the environment, can be reflected in any agent irrespective of its ability to perform a task. Second, predictive information, when sourced from the nervous system, requires special dynamics acquired during the process of adapting to the environment. Third, the magnitude of predictive information in a system can be different for the same task if the environmental structure changes.",
    "year": 2019,
    "venue": "Scientific Reports",
    "url": "https://www.semanticscholar.org/paper/2a1f38b8e267c85197764c1a73644ea3def6993f",
    "doi": "10.1101/2019.12.23.887554",
    "arxivId": "",
    "authors": "Madhavun Candadai, E. Izquierdo",
    "citationCount": 8
  },
  {
    "s2PaperId": "c3b6134d08d333fce9f30fa68f5675383292dc1d",
    "title": "Direct and Indirect Effects—An Information Theoretic Perspective",
    "abstract": "Information theoretic (IT) approaches to quantifying causal influences have experienced some popularity in the literature, in both theoretical and applied (e.g., neuroscience and climate science) domains. While these causal measures are desirable in that they are model agnostic and can capture non-linear interactions, they are fundamentally different from common statistical notions of causal influence in that they (1) compare distributions over the effect rather than values of the effect and (2) are defined with respect to random variables representing a cause rather than specific values of a cause. We here present IT measures of direct, indirect, and total causal effects. The proposed measures are unlike existing IT techniques in that they enable measuring causal effects that are defined with respect to specific values of a cause while still offering the flexibility and general applicability of IT techniques. We provide an identifiability result and demonstrate application of the proposed measures in estimating the causal effect of the El Niño–Southern Oscillation on temperature anomalies in the North American Pacific Northwest.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/c3b6134d08d333fce9f30fa68f5675383292dc1d",
    "doi": "10.3390/e22080854",
    "arxivId": "1912.10508",
    "authors": "Gabriel Schamberg, W. Chapman, S. Xie, T. Coleman",
    "citationCount": 8
  },
  {
    "s2PaperId": "6c2cefef7c3c726a3541ad68da4cfaea3468fd28",
    "title": "Cross-participant prediction of vigilance stages through the combined use of wPLI and wSMI EEG functional connectivity metrics.",
    "abstract": "",
    "year": 2019,
    "venue": "Sleep",
    "url": "https://www.semanticscholar.org/paper/6c2cefef7c3c726a3541ad68da4cfaea3468fd28",
    "doi": "10.1016/j.sleep.2019.11.461",
    "arxivId": "",
    "authors": "L. Imperatori, J. Cataldi, M. Betta, E. Ricciardi, Robin A. A. Ince, F. Siclari, G. Bernardi",
    "citationCount": 21
  },
  {
    "s2PaperId": "8eba5abc288cf6c36754e049e71af3d6601e8970",
    "title": "Elements of qualitative cognition: An information topology perspective.",
    "abstract": "",
    "year": 2019,
    "venue": "Physics of Life Reviews",
    "url": "https://www.semanticscholar.org/paper/8eba5abc288cf6c36754e049e71af3d6601e8970",
    "doi": "10.1016/j.plrev.2019.10.003",
    "arxivId": "",
    "authors": "P. Baudot",
    "citationCount": 4
  },
  {
    "s2PaperId": "981e39266b9fb5d936bc2508d12d21803e5296dd",
    "title": "Interpretation of multi-scale permeability data through an information theory perspective",
    "abstract": "Abstract. We employ elements of information theory to quantify (i) the information content related to data collected at given measurement scales within the same porous medium domain and (ii) the relationships among information contents of datasets associated with differing scales. We focus on gas permeability data collected over Berea Sandstone and Topopah Spring Tuff blocks, considering four measurement scales. We quantify the way information is shared across these scales through (i) the Shannon entropy of the data associated with each support scale, (ii) mutual information shared between data taken at increasing support scales, and (iii) multivariate mutual information shared within triplets of datasets, each associated with a given scale. We also assess the level of uniqueness, redundancy and synergy (rendering, i.e., information partitioning) of information content that the data associated with the intermediate and largest scales provide with respect to the information embedded in the data collected at the smallest support scale in a triplet. Highlights.  Information theory allows characterization of the information content of permeability data related to differing measurement scales. An increase in the measurement scale is associated with quantifiable loss of information about permeability. Redundant, unique and synergetic contributions of information are evaluated for triplets of permeability datasets, each taken at a given scale.",
    "year": 2019,
    "venue": "Hydrology and Earth System Sciences",
    "url": "https://www.semanticscholar.org/paper/981e39266b9fb5d936bc2508d12d21803e5296dd",
    "doi": "10.5194/hess-2019-628",
    "arxivId": "",
    "authors": "A. Dell’Oca, A. Guadagnini, M. Riva",
    "citationCount": 4
  },
  {
    "s2PaperId": "90c8e6ea0a76c8d8a3f7039c9b54effdf09efa23",
    "title": "Cyclic and multilevel causation in evolutionary processes",
    "abstract": "Many models of evolution are implicitly causal processes. Features such as causal feedback between evolutionary variables and evolutionary processes acting at multiple levels, though, mean that conventional causal models miss important phenomena. We develop here a general theoretical framework for analyzing evolutionary processes drawing on recent approaches to causal modeling developed in the machine-learning literature, which have extended Pearls do-calculus to incorporate cyclic causal interactions and multilevel causation. We also develop information-theoretic notions necessary to analyze causal information dynamics in our framework, introducing a causal generalization of the Partial Information Decomposition framework. We show how our causal framework helps to clarify conceptual issues in the contexts of complex trait analysis and cancer genetics, including assigning variation in an observed trait to genetic, epigenetic and environmental sources in the presence of epigenetic and environmental feedback processes, and variation in fitness to mutation processes in cancer using a multilevel causal model respectively, as well as relating causally-induced to observed variation in these variables via information theoretic bounds. In the process, we introduce a general class of multilevel causal evolutionary processes which connect evolutionary processes at multiple levels via coarse-graining relationships. Further, we show how a range of fitness models can be formulated in our framework, as well as a causal analog of Prices equation (generalizing the probabilistic Rice equation), clarifying the relationships between realized/probabilistic fitness and direct/indirect selection. Finally, we consider the potential relevance of our framework to foundational issues in biology and evolution, including supervenience, multilevel selection and individuality. Particularly, we argue that our class of multilevel causal evolutionary processes, in conjunction with a minimum description length principle, provides a conceptual framework in which identification of multiple levels of selection may be reduced to a model selection problem.",
    "year": 2019,
    "venue": "Biology & Philosophy",
    "url": "https://www.semanticscholar.org/paper/90c8e6ea0a76c8d8a3f7039c9b54effdf09efa23",
    "doi": "10.1007/s10539-020-09753-3",
    "arxivId": "",
    "authors": "J. Warrell, M. Gerstein",
    "citationCount": 4
  },
  {
    "s2PaperId": "81cd729890dc8930cbe93ae00cfc09afd466594b",
    "title": "28th Annual Computational Neuroscience Meeting: CNS*2019",
    "abstract": "ion can be defined as a cognitive process that finds a common feature—an abstract variable, or concept—shared by a number of examples. Knowledge of an abstract variable enables generalization to new examples based upon old ones. Neuronal ensembles could represent abstract variables by discarding all information about specific examples, but this allows for representation of only one variable. Here we show how to construct neural representations that encode multiple abstract variables simultaneously, and we characterize their geometry. Representations conforming to this geometry were observed in dorsolateral pre-frontal cortex, anterior cingulate cortex, and the hippocampus in monkeys performing a serial reversal-learning task. These neural representations allow for generalization, a signature of abstraction, and similar representations are observed in a simulated multi-layer neural network trained with back-propagation. These findings provide a novel framework for characterizing how different brain areas represent abstract variables, which is critical for flexible conceptual generalization and deductive reasoning. F2 Signatures of network structure in timescales of spontaneous activity Roxana Zeraati, Nicholas Steinmetz, Tirin Moore, Tatiana Engel, Anna Levina University of Tübingen, International Max Planck Research School for Cognitive and System Neuroscience, Tübingen, Germany; University of Washington, Department of Biological Structure, Seattle, United States of America; Stanford University, Department of Neurobiology, Stanford, California, United States of America; Cold Spring Harbor Laboratory, Cold Spring Harbor, NY, United States of America; University of Tübingen, Tübingen, Germany Correspondence: Roxana Zeraati (roxana.zeraati@tuebingen.mpg.de) BMC Neuroscience 2019, 20(Suppl 1):F2 Cortical networks are spontaneously active. Timescales of these intrinsic fluctuations were suggested to reflect the network’s specialization for task-relevant computations. However, how these timescales arise from the spatial network structure is unknown. Spontaneous cortical activity unfolds across different spatial scales. On a local scale of individual columns, ongoing activity spontaneously transitions between episodes of vigorous (On) and faint (Off) spiking, synchronously across cortical layers. On a wider spatial scale, activity propagates as cascades of elevated firing across many columns, characterized by the branching ratio defined as the average number of units activated by each active unit. We asked, to what extent the timescales of spontaneous activity reflect the dynamics on these two spatial scales and the underlying network structure. To this end, we developed a branching network model capable of capturing both the local On-Off dynamics and the global activity propagation. Each unit in the model represents a cortical column, which has spatially structured connections to other columns (Fig. 1A). The columns stochastically transition between On and Off states. Transitions to On-state are driven by stochastic external inputs and by excitatory inputs from the neighboring columns (horizontal recurrent input). An On state can persist due to a self-excitation representing strong recurrent connections within one column (vertical recurrent input). On and Off episode durations in our model follow exponential distributions, similar to the On-Off dynamics observed in single cortical columns (Fig. 1B). We fixed the statistics of On-Off transitions and the global propagation, and studied the dependence of intrinsic timescales on the network spatial structure. We found that the timescales of local dynamics reflect the spatial network structure. In the model, activity of single columns exhibits two distinct timescales: one induced by the recurrent excitation within the column and another induced by interactions between the columns (Fig. 1C). The first timescale dominates dynamics in networks with more dispersed connectivity (Fig. 1A, non-local; Fig. 1D), whereas the second timescale is prominent in networks with more local connectivity (Fig. 1A, local; Fig. 1D). Since neighboring columns share many of their recurrent inputs, the second timescale is also evident in cross-correlations (CC) between columns, and it becomes longer with increasing distance between columns. To test the model predictions, we analyzed 16-channel microelectrode array recordings of spiking activity from single columns in the primate area V4. During spontaneous activity, we observed two distinct timescales in columnar On-Off fluctuations (Fig. 1E). Two timescales were also present in CCs of neural activity on different channels within the same column. To examine how timescales depend on horizontal cortical distance, we leveraged the fact that columnar recordings generally exhibit slight horizontal shifts due to variability in the penetration angle. As a surrogate for horizontal displacements between pairs of channels, we used distances between centers of their receptive fields (RF). As predicted by the model, the second timescale in CCs became longer with increasing RF-center distance. Our results suggest that timescales of local On-Off fluctuations in single cortical columns provide information about the underlying spatial network structure of the cortex. F3 Internal bias controls phasic but not delay‐period dopamine activity in a parametric working memory task Néstor Parga, Stefania Sarno, Manuel Beiran, José Vergara, Román Rossi‐Pool, Ranulfo Romo Universidad Autónoma Madrid, Madrid, Spain; Ecole Normale Supérieure, Department of Cognitive Studies, Paris, France; Universidad Nacional Autónoma México, Instituto de Fisiología Celular, México DF, Mexico Correspondence: Néstor Parga (nestor.parga@uam.es) BMC Neuroscience 2019, 20(Suppl 1):F3 Dopamine (DA) has been implied in coding reward prediction errors (RPEs) and in several other phenomena such as working memory and motivation to work for reward. Under uncertain stimulation conditions DA phasic responses to relevant task cues reflect cortical perceptual decision-making processes, such as the certainty about stimulus detection and evidence accumulation, in a way compatible with the RPE hypothesis [1, 2]. This suggests that the midbrain DA system receives information from cortical circuits about decision formation and transforms it into an RPE signal. However, it is not clear how DA neurons behave when making a decision involves more demanding cognitive features, such as working memory and internal biases, or how they reflect motivation under uncertain conditions. To advance knowledge on these issues we have recorded and analyzed the firing activity of putatively midbrain DA neurons, while monkeys discriminated the frequencies of two vibrotactile stimuli delivered to one fingertip. This two-interval forced choice task, in which both stimuli were selected randomly in each trial, has been widely used to investigate perception, working memory and decision-making in sensory and frontal areas [3]; the current study adds to this scenario possible roles of midbrain DA neurons. Fig. 1 a Schematic representation of the model local and non‐local connectivity. b Distributions of On‐Off episode duration in V4 data and model. c Representation of different timescales in single columns AC. d Average AC of individual columns and the population activity (inset, with the same axes) for different network structures. e V4 data AC averaged over all recordings, and an example recording Page 3 of 190 BMC Neurosci 2019, 20(Suppl 1):56 We found that the DA responses to the stimuli were not monotonically tuned to their frequency values. Instead they were controlled by an internally generated bias (contraction bias). This bias induced a subjective difficulty that modulated those responses as well as the accuracy and the response times (RTs). A Bayesian model for the choice explained the bias and gave a measure of the animal’s decision confidence, which also appeared modulated by the bias. We also found that the DA activity was above baseline throughout the delay (working memory) period. Interestingly, this activity was neither tuned to the first frequency nor controlled by the internal bias. While the phasic responses to the task events could be described by a reinforcement learning model based on belief states, the ramping behavior exhibited during the delay period could not be explained by standard models. Finally, the DA responses to the stimuli in short-RT trials and long-RTs trials were significantly different; interpreting the RTs as a measure of motivation, our analysis indicated that motivation affected strongly the responses to the task events but had only a weak influence on the DA activity during the delay interval. To summarize, our results show for the first time that an internal phenomenon (the bias) can control the DA phasic activity similar to the way physical differences in external stimuli do. We also encountered a ramping DA activity during the working memory period, independent of the memorized frequency value. Overall, our study supports the notion that delay and phasic DA activities accomplish quite different functions.",
    "year": 2019,
    "venue": "BMC Neuroscience",
    "url": "https://www.semanticscholar.org/paper/81cd729890dc8930cbe93ae00cfc09afd466594b",
    "doi": "10.1186/S12868-019-0538-0",
    "arxivId": "",
    "authors": "R. Zeraati, Nicholas A. Steinmetz, Tirin Moore, Tatiana A. Engel, Anna, Levina, Néstor Parga, Stefania Sarno, Manuel Beirán, José Vergara, Román, Rossi ‐ Pool, Ranulfo Romo",
    "citationCount": 3
  },
  {
    "s2PaperId": "b503f7755bafa40a0285e558de96f19034191f59",
    "title": "Using Information Flow for Whole System Understanding From Component Dynamics",
    "abstract": "Complex systems that exhibit emergent behaviors arise as a result of nonlinear interdependencies among multiple components. Characterizing how such whole system dynamics are sustained through multivariate interaction remains an open question. In this study, we propose an information flow‐based framework to investigate how the present state of any component arises as a result of the past interactions among interdependent variables, which is termed as causal history. Using a partitioning time lag, we divide this into immediate and distant causal history components and then characterize the information flow‐based interactions within these as self‐ and cross‐feedbacks. Such a partition allows us to characterize the information flow from the two feedbacks in both histories by using partial information decomposition as unique, synergistic, or redundant interactions. We employ this casual history analysis approach to investigate the information flows in a short‐memory coupled logistic model and a long‐memory observed stream chemistry dynamics. While the dynamics of the short‐memory system are mainly maintained by its recent historical states, the current state of each stream solute is sustained by self‐feedback‐dominated recent dynamics and cross‐dependency‐dominated earlier dynamics. The analysis suggests that the observed 1/f signature of each solute is a result of the interactions with other variables in the stream. Based on high‐density data streams, the approach developed here for investigating multivariate evolutionary dynamics provides an effective way to understand how components of dynamical system interact to create emergent whole system behavioral patterns such as long‐memory dependency.",
    "year": 2019,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/b503f7755bafa40a0285e558de96f19034191f59",
    "doi": "10.1029/2019WR025820",
    "arxivId": "",
    "authors": "P. Jiang, Praveen Kumar",
    "citationCount": 20
  },
  {
    "s2PaperId": "5ce318817b51672bdfca2123a69dee97c22cd1a1",
    "title": "Real patterns and indispensability",
    "abstract": "",
    "year": 2019,
    "venue": "Synthese",
    "url": "https://www.semanticscholar.org/paper/5ce318817b51672bdfca2123a69dee97c22cd1a1",
    "doi": "10.1007/s11229-019-02343-1",
    "arxivId": "",
    "authors": "A. Suñé, Manolo Martínez",
    "citationCount": 6
  },
  {
    "s2PaperId": "353b993d924119cd955bf00eb1004d9e8f1f6bc7",
    "title": "Correlated activity favors synergistic processing in local cortical networks at synaptically-relevant timescales",
    "abstract": "Information processing by neural circuits is widely understood to depend on correlation in the activity of upstream neurons. However, whether correlation is favorable or not is contentious. Correlated activity can facilitate information transmission but also increases redundancy. Here, we sought to determine how correlated activity and information processing are related in cortical circuits. Using high-density 512-channel electrode arrays we recorded the spiking activity of hundreds of well-isolated neurons in organotypic cultures of mouse somatosensory cortex and asked whether mutual information between neurons that feed into a common third neuron increased synergistic information processing by the receiving neuron. We found that mutual information and synergistic processing were positively related when examined at synaptic timescales (0.05-14 ms), where mutual information values were generally low. This effect was mediated by increased information transmission that resulted as mutual information grew. However, at extrasynaptic windows (up to 3000 ms), where mutual information values were generally high, the relationship between mutual information and synergy became negative. In this regime, the further increases in mutual information resulted in a disproportionate increase in redundancy, outweighing incremental gains in information transmission. These results indicate that the relationship between input correlation and synergistic processing differs according to the correlation regime. In a low-correlation regime, synergistic processing increases with greater correlation, and in a high correlation regime, synergistic processing decreases with greater correlation.",
    "year": 2019,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/353b993d924119cd955bf00eb1004d9e8f1f6bc7",
    "doi": "10.1101/809681",
    "arxivId": "",
    "authors": "Samantha P. Sherrill, N. Timme, J. Beggs, E. Newman",
    "citationCount": 0
  },
  {
    "s2PaperId": "85b49e8c264f50a38ce71ef916065282df181dcd",
    "title": "Information Decomposition based on Cooperative Game Theory",
    "abstract": "We offer a new approach to the information decomposition problem in information theory: given a 'target' random variable co-distributed with multiple 'source' variables, how can we decompose the mutual information into a sum of non-negative terms that quantify the contributions of each random variable, not only individually but also in combination? We derive our composition from cooperative game theory. It can be seen as assigning a \"fair share\" of the mutual information to each combination of the source variables. Our decomposition is based on a different lattice from the usual 'partial information decomposition' (PID) approach, and as a consequence our decomposition has a smaller number of terms: it has analogs of the synergy and unique information terms, but lacks terms corresponding to redundancy. Because of this, it is able to obey equivalents of the axioms known as 'local positivity' and 'identity', which cannot be simultaneously satisfied by a PID measure.",
    "year": 2019,
    "venue": "Kybernetika (Praha)",
    "url": "https://www.semanticscholar.org/paper/85b49e8c264f50a38ce71ef916065282df181dcd",
    "doi": "10.14736/kyb-2020-5-0979",
    "arxivId": "1910.05979",
    "authors": "N. Ay, D. Polani, N. Virgo",
    "citationCount": 23
  },
  {
    "s2PaperId": "c2f5b1e8a9c8ce2401cdcf26ddae6933ac3faa0b",
    "title": "Causal Composition: Structural Differences among Dynamically Equivalent Systems",
    "abstract": "The dynamical evolution of a system of interacting elements can be predicted in terms of its elementary constituents and their interactions, or in terms of the system’s global state transitions. For this reason, systems with equivalent global dynamics are often taken to be equivalent for all relevant purposes. Nevertheless, such systems may still vary in their causal composition—the way mechanisms within the system specify causes and effects over different subsets of system elements. We demonstrate this point based on a set of small discrete dynamical systems with reversible dynamics that cycle through all their possible states. Our analysis elucidates the role of composition within the formal framework of integrated information theory. We show that the global dynamical and information-theoretic capacities of reversible systems can be maximal even though they may differ, quantitatively and qualitatively, in the information that their various subsets specify about each other (intrinsic information). This can be the case even for a system and its time-reversed equivalent. Due to differences in their causal composition, two systems with equivalent global dynamics may still differ in their capacity for autonomy, agency, and phenomenology.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/c2f5b1e8a9c8ce2401cdcf26ddae6933ac3faa0b",
    "doi": "10.3390/e21100989",
    "arxivId": "",
    "authors": "Larissa Albantakis, G. Tononi",
    "citationCount": 28
  },
  {
    "s2PaperId": "7aea7b17481d83ad902159fa70bb4f1428cc2814",
    "title": "Towards a Framework for Observational Causality from Time Series: When Shannon Meets Turing",
    "abstract": "We propose a tensor based approach to infer causal structures from time series. An information theoretical analysis of transfer entropy (TE) shows that TE results from transmission of information over a set of communication channels. Tensors are the mathematical equivalents of these multichannel causal channels. The total effect of subsequent transmissions, i.e., the total effect of a cascade, can now be expressed in terms of the tensors of these subsequent transmissions using tensor multiplication. With this formalism, differences in the underlying structures can be detected that are otherwise undetectable using TE or mutual information. Additionally, using a system comprising three variables, we prove that bivariate analysis suffices to infer the structure, that is, bivariate analysis suffices to differentiate between direct and indirect associations. Some results translate to TE. For example, a Data Processing Inequality (DPI) is proven to exist for transfer entropy.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/7aea7b17481d83ad902159fa70bb4f1428cc2814",
    "doi": "10.3390/e22040426",
    "arxivId": "1909.13559",
    "authors": "David Sigtermans",
    "citationCount": 6
  },
  {
    "s2PaperId": "cd346338e4aac247738f59b1723f078a1eac70ef",
    "title": "Generalised Measures of Multivariate Information Content",
    "abstract": "The entropy of a pair of random variables is commonly depicted using a Venn diagram. This representation is potentially misleading, however, since the multivariate mutual information can be negative. This paper presents new measures of multivariate information content that can be accurately depicted using Venn diagrams for any number of random variables. These measures complement the existing measures of multivariate mutual information and are constructed by considering the algebraic structure of information sharing. It is shown that the distinct ways in which a set of marginal observers can share their information with a non-observing third party corresponds to the elements of a free distributive lattice. The redundancy lattice from partial information decomposition is then subsequently and independently derived by combining the algebraic structures of joint and shared information content.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/cd346338e4aac247738f59b1723f078a1eac70ef",
    "doi": "10.3390/e22020216",
    "arxivId": "1909.12166",
    "authors": "Conor Finn, J. Lizier",
    "citationCount": 25
  },
  {
    "s2PaperId": "3047fa65d2e82498d2ee7e2badc03dd73ddc121b",
    "title": "Using intersection information to map stimulus information transfer within neural networks",
    "abstract": "",
    "year": 2019,
    "venue": "Biosyst.",
    "url": "https://www.semanticscholar.org/paper/3047fa65d2e82498d2ee7e2badc03dd73ddc121b",
    "doi": "10.1016/j.biosystems.2019.104028",
    "arxivId": "",
    "authors": "Giuseppe Pica, Mohammadreza Soltanipour, S. Panzeri",
    "citationCount": 8
  },
  {
    "s2PaperId": "6093c3e020008c7caa2f65799f90b8bd9b1ad0d8",
    "title": "A Non-negative Measure Of Feature-specific Information Transfer Between Neural Signals",
    "abstract": "Quantifying the amount and content of information transfer between neural populations is crucial to understand brain dynamics and cognitive functions. Most data-driven methods exploit the notion of Wiener-Granger causality, a statistical concept based on temporal prediction. Transfer Entropy and Directed Information formalise this notion by means of information theoretical quantities and can capture any (linear and nonlinear) time-lagged conditional dependencies, thus quantifying the amount of information flow between neural signals. Nevertheless, none of these metrics can reveal what type of information is exchanged. To address this issue, we developed a new measure called Feature-specific Information Transfer (FIT) that is able to quantify both the amount and content of information transfer between neuronal signals. We tested the novel metric on simulated data and showed that it successfully captures feature-specific information transfer in different communication scenarios including feedforward communication, external confounding inputs and synergistic interactions. Moreover, the FIT measure displayed sensitivity to modulations in temporal parameters of information transfer and signal-to-noise ratios, and correctly inferred the directionality of transfer between signals. We then tested FIT’s ability to track feature-specific information flow from neurophysiological data. First, we analysed human electroencephalographic data acquired during a face detection task and confirmed current hypotheses suggesting that information about the presence of an eye in a face image flows from the contralateral to the ipsilateral hemisphere with respect to the position of the eye. Second, we analysed multi-unit activity data recorded from thalamus and cortex of rat’s brain, and showed that the FIT measure successfully detected bottom-up information transfer about visual or somatosensory stimuli in the corresponding neural pathway. Third, we analysed cortical high-gamma activity estimated from human magnetoencephalographic data during visuomotor mapping, and confirmed the notion that visuomotor-related information flows from superior parietal to premotor areas. Altogether our work suggests that the FIT measure has the potential to uncover previously hidden feature-specific information transfer from neural data and provide a better understanding of brain communication.",
    "year": 2019,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/6093c3e020008c7caa2f65799f90b8bd9b1ad0d8",
    "doi": "10.1101/758128",
    "arxivId": "",
    "authors": "J. Bím, Vito De Feo, D. Chicharro, I. Hanganu-Opatz, A. Brovelli, S. Panzeri",
    "citationCount": 6
  },
  {
    "s2PaperId": "47123257cba1267b323ae83d649a5e9f7975152d",
    "title": "Beyond integrated information: A taxonomy of information dynamics phenomena",
    "abstract": "Most information dynamics and statistical causal analysis frameworks rely on the common intuition that causal interactions are intrinsically pairwise -- every 'cause' variable has an associated 'effect' variable, so that a 'causal arrow' can be drawn between them. However, analyses that depict interdependencies as directed graphs fail to discriminate the rich variety of modes of information flow that can coexist within a system. This, in turn, creates problems with attempts to operationalise the concepts of 'dynamical complexity' or `integrated information.' To address this shortcoming, we combine concepts of partial information decomposition and integrated information, and obtain what we call Integrated Information Decomposition, or $\\Phi$ID. We show how $\\Phi$ID paves the way for more detailed analyses of interdependencies in multivariate time series, and sheds light on collective modes of information dynamics that have not been reported before. Additionally, $\\Phi$ID reveals that what is typically referred to as 'integration' is actually an aggregate of several heterogeneous phenomena. Furthermore, $\\Phi$ID can be used to formulate new, tailored measures of integrated information, as well as to understand and alleviate the limitations of existing measures.",
    "year": 2019,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/47123257cba1267b323ae83d649a5e9f7975152d",
    "doi": "",
    "arxivId": "1909.02297",
    "authors": "P. Mediano, F. Rosas, Robin L. Carhart-Harris, A. Seth, A. Barrett",
    "citationCount": 46
  },
  {
    "s2PaperId": "f2dcdc5e9f61fb2d8e5bbc5b153c1772c94c9eaf",
    "title": "Morphological Intelligence: Measuring the Body’s Contribution to Intelligence",
    "abstract": "",
    "year": 2019,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/f2dcdc5e9f61fb2d8e5bbc5b153c1772c94c9eaf",
    "doi": "10.1007/978-3-030-20621-5",
    "arxivId": "",
    "authors": "Keyan Ghazi-Zahedi",
    "citationCount": 13
  },
  {
    "s2PaperId": "2673a8800c85dbf9dc472f21908a1ac9bcdd5d1e",
    "title": "A Novel Approach to the Partial Information Decomposition",
    "abstract": "We consider the “partial information decomposition” (PID) problem, which aims to decompose the information that a set of source random variables provide about a target random variable into separate redundant, synergistic, union, and unique components. In the first part of this paper, we propose a general framework for constructing a multivariate PID. Our framework is defined in terms of a formal analogy with intersection and union from set theory, along with an ordering relation which specifies when one information source is more informative than another. Our definitions are algebraically and axiomatically motivated, and can be generalized to domains beyond Shannon information theory (such as algorithmic information theory and quantum information theory). In the second part of this paper, we use our general framework to define a PID in terms of the well-known Blackwell order, which has a fundamental operational interpretation. We demonstrate our approach on numerous examples and show that it overcomes many drawbacks associated with previous proposals.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2673a8800c85dbf9dc472f21908a1ac9bcdd5d1e",
    "doi": "10.3390/e24030403",
    "arxivId": "1908.08642",
    "authors": "Artemy Kolchinsky",
    "citationCount": 57
  },
  {
    "s2PaperId": "d87c009f3f828d43b885a6e7cf18beec6d4abfe4",
    "title": "A novel approach to multivariate redundancy and synergy",
    "abstract": "",
    "year": 2019,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/d87c009f3f828d43b885a6e7cf18beec6d4abfe4",
    "doi": "",
    "arxivId": "",
    "authors": "Artemy Kolchinsky",
    "citationCount": 18
  },
  {
    "s2PaperId": "6bfe988319f107dee4f34e12e3410774b5f55a18",
    "title": "A Measure of Added Value in Groups",
    "abstract": "The intuitive notion of added value in groups represents a fundamental property of biological, physical, and economic systems: how the interaction or cooperation of multiple entities, substances, or other agents can produce synergistic effects. However, despite the ubiquity of group formation, a well-founded measure of added value has remained elusive. Here, we propose such a measure inspired by the Shapley value—a fundamental solution concept from Cooperative Game Theory. To this end, we start by developing a solution concept that measures the average impact of each player in a coalitional game and show how this measure uniquely satisfies a set of intuitive properties. Then, building upon our solution concept, we propose a measure of added value that not only analyzes the interactions of players inside their group, but also outside it, thereby reflecting otherwise-hidden information about how these individuals typically perform in various groups of the population.",
    "year": 2019,
    "venue": "ACM Transactions on Autonomous and Adaptive Systems",
    "url": "https://www.semanticscholar.org/paper/6bfe988319f107dee4f34e12e3410774b5f55a18",
    "doi": "10.1145/3335547",
    "arxivId": "",
    "authors": "Bedoor K. AlShebli, Tomasz P. Michalak, Oskar Skibski, M. Wooldridge, Talal Rahwan",
    "citationCount": 6
  },
  {
    "s2PaperId": "aa3b23194972d0373bf8bec63e8825e853fe9175",
    "title": "Topological Information Data Analysis",
    "abstract": "This paper presents methods that quantify the structure of statistical interactions within a given data set, and were applied in a previous article. It establishes new results on the k-multivariate mutual-information (Ik) inspired by the topological formulation of Information introduced in a serie of studies. In particular, we show that the vanishing of all Ik for 2≤k≤n of n random variables is equivalent to their statistical independence. Pursuing the work of Hu Kuo Ting and Te Sun Han, we show that information functions provide co-ordinates for binary variables, and that they are analytically independent from the probability simplex for any set of finite variables. The maximal positive Ik identifies the variables that co-vary the most in the population, whereas the minimal negative Ik identifies synergistic clusters and the variables that differentiate–segregate the most in the population. Finite data size effects and estimation biases severely constrain the effective computation of the information topology on data, and we provide simple statistical tests for the undersampling bias and the k-dependences. We give an example of application of these methods to genetic expression and unsupervised cell-type classification. The methods unravel biologically relevant subtypes, with a sample size of 41 genes and with few errors. It establishes generic basic methods to quantify the epigenetic information storage and a unified epigenetic unsupervised learning formalism. We propose that higher-order statistical interactions and non-identically distributed variables are constitutive characteristics of biological systems that should be estimated in order to unravel their significant statistical structure and diversity. The topological information data analysis presented here allows for precisely estimating this higher-order structure characteristic of biological systems.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/aa3b23194972d0373bf8bec63e8825e853fe9175",
    "doi": "10.3390/e21090869",
    "arxivId": "1907.04242",
    "authors": "P. Baudot, Mónica Tapia, D. Bennequin, Jean-Marc Goaillard",
    "citationCount": 51
  },
  {
    "s2PaperId": "4a560223c3b8633b5893eb729a3a17ac96d82978",
    "title": "infotheory: A C++/Python package for multivariate information theoretic analysis",
    "abstract": "This paper introduces \\texttt{infotheory}: a package written in C++ and usable from Python and C++, for multivariate information theoretic analyses of discrete and continuous data. This package allows the user to study the relationship between components of a complex system simply from the data recorded during its operation, using the tools of information theory. It implements widely used measures such as entropy and mutual information, as well as more recent measures that arise from multivariate extensions to information theory, specifically Partial Information Decomposition. It provides an easy-to-use and flexible tool for use in research as well as pedgogical purposes to introduce students to information theory. Website: this http URL Source: this https URL",
    "year": 2019,
    "venue": "Journal of Open Source Software",
    "url": "https://www.semanticscholar.org/paper/4a560223c3b8633b5893eb729a3a17ac96d82978",
    "doi": "10.21105/joss.01609",
    "arxivId": "1907.02339",
    "authors": "Madhavun Candadai, E. Izquierdo",
    "citationCount": 12
  },
  {
    "s2PaperId": "5d93bc1d1e8d396d3b9eeedc41deb7ec6c9e5fd0",
    "title": "Bundled Causal History Interaction",
    "abstract": "Complex systems arise as a result of the nonlinear interactions between components. In particular, the evolutionary dynamics of a multivariate system encodes the ways in which different variables interact with each other individually or in groups. One fundamental question that remains unanswered is: How do two non-overlapping multivariate subsets of variables interact to causally determine the outcome of a specific variable? Here, we provide an information-based approach to address this problem. We delineate the temporal interactions between the bundles in a probabilistic graphical model. The strength of the interactions, captured by partial information decomposition, then exposes complex behavior of dependencies and memory within the system. The proposed approach successfully illustrated complex dependence between cations and anions as determinants of pH in an observed stream chemistry system. In the studied catchment, the dynamics of pH is a result of both cations and anions through mainly synergistic effects of the two and their individual influences as well. This example demonstrates the potentially broad applicability of the approach, establishing the foundation to study the interaction between groups of variables in a range of complex systems.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5d93bc1d1e8d396d3b9eeedc41deb7ec6c9e5fd0",
    "doi": "10.3390/e22030360",
    "arxivId": "1907.01159",
    "authors": "P. Jiang, Praveen Kumar",
    "citationCount": 4
  },
  {
    "s2PaperId": "ffe174eba32698c9a80d586771655d3644d0c749",
    "title": "A Measure of Synergy, Redundancy, and Unique Information using Information Geometry",
    "abstract": "It is well known that joint interactions between agents can be described qualitatively as having synergistic, unique, and redundant components. In recent years, there have been renewed efforts to decompose mutual information, a general, non-parametric measure of joint interactions, into constituent parts. We propose a novel, non-negative decomposition of mutual information between two sources and a target variable. The decomposition is for the exponential family, and thus can be applied to a broad range of distributions. We also show that values from our decomposition arise naturally from testing hypotheses of conditional dependence. We demonstrate the method numerically using standard binary logic gates and Gaussian channels, as well as apply the method to investigate redundancy between brain regions using an fMRI-based image classification data-set.",
    "year": 2019,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/ffe174eba32698c9a80d586771655d3644d0c749",
    "doi": "10.1109/ISIT.2019.8849724",
    "arxivId": "",
    "authors": "Xueyan Niu, Christopher J. Quinn",
    "citationCount": 14
  },
  {
    "s2PaperId": "d264763af02fc1c9f4974b6fe2d9276e46438188",
    "title": "What Is Controlling Our Control Rules? Opening the Black Box of Multireservoir Operating Policies Using Time‐Varying Sensitivity Analysis",
    "abstract": "Multireservoir systems are designed to serve multiple conflicting demands over varying time scales that may be out of phase with the system's hydroclimatic inputs. Adaptive, nonlinear reservoir control policies are often best suited to serve these needs. However, nonlinear operating policies are hard to interpret, so water managers tend to favor simple, static rules that may not effectively manage conflicts between the system's multisectoral demands. In this study, we introduce an analytical framework for opening the black box of optimized nonlinear operating policies, decomposing their time‐varying information sensitivities to show how their adaptive and coordinated release prescriptions better manage hydrologic variability. Interestingly, these information sensitivities vary significantly across policies depending on how they negotiate tradeoffs between conflicting objectives. We illustrate this analysis in the Red River basin of Vietnam, where four major reservoirs serve to protect the capital of Hanoi from flooding while also providing the surrounding region with electric power and meeting multisectoral water demands for the agricultural and urban economies. Utilizing Evolutionary Multi‐Objective Direct Policy Search, we are able to design policies that, using the same information as sequential if/then/else‐based operating guidelines developed by the government, outperform these traditional rules with respect to every objective. Policy diagnostics using time‐varying sensitivity analysis illustrate how the Evolutionary Multi‐Objective Direct Policy Search operations better adapt and coordinate information use to reduce food‐energy‐water conflicts in the basin. These findings accentuate the benefits of transitioning to dynamic operating policies in order to manage evolving hydroclimatic variability and socioeconomic demands in multipurpose reservoir networks.",
    "year": 2019,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/d264763af02fc1c9f4974b6fe2d9276e46438188",
    "doi": "10.1029/2018WR024177",
    "arxivId": "",
    "authors": "J. Quinn, P. Reed, M. Giuliani, A. Castelletti",
    "citationCount": 52
  },
  {
    "s2PaperId": "e5998d6a8c09f8126fb3b6a6937ec24ea98618d7",
    "title": "Information Content of Option Prices: Comparing Analyst Forecasts to Option-Based Forecasts",
    "abstract": "Finance theory dictates that public information is incorporated in asset pricing expectations. Empirical research suggests that not all return forecasts are equal. Do different forecasts weigh information differently? This paper decomposes the information content of option and analyst forecasts. The results show that analyst forecasts are constructed using a wide-spectrum of market and firm-level data while option-based forecasts capture measures of uncertainty. Further, we revisit the question of whether analyst forecast dispersion is a proxy for uncertainty. We find a negative relationship between analyst disagreement and option-based forecasts, indicating that option traders view analyst disagreement as a source of uncertainty.",
    "year": 2019,
    "venue": "Social Science Research Network",
    "url": "https://www.semanticscholar.org/paper/e5998d6a8c09f8126fb3b6a6937ec24ea98618d7",
    "doi": "10.2139/ssrn.3300120",
    "arxivId": "",
    "authors": "Anthony Sanford",
    "citationCount": 2
  },
  {
    "s2PaperId": "adbb648528a9fdfd983c6326161a55d09b8b6cb6",
    "title": "Clusters of Features Using Complementary Information Applied to Gender Classification From Face Images",
    "abstract": "Face recognition performance by computers has been shown to be more accurate than that of humans. However, a bias with soft-biometrics features has been detected. This bias reduces recognition performance when gender is used. Feature selection for gender classification from face images is a difficult problem since faces contain symmetrical and redundant features. We argue that traditional methods, based on mutual information using pairs of features to estimate the relevance and redundancy among features, fail to select the right set of features in cases where there are strong spatial correlations among features, which is the case with facial images. In this paper, a new method is proposed fusing a filter and a wrapper to measure the relationships among image features, and to select feature clusters based on mutual information for gender classification. We applied this method on nine face datasets using an SVM classifier. We were able to achieve 98.2% correct gender classification in the testing partition using the UND, 95.56% with the Morph II, 98.33% on the LFW, and 98.66% on celebA databases. We validated the results using a cross-test with three different datasets: COFW, Adience, and Image of Groups, that were not used to define the parameters of our method. Additionally, the method was tested with a Random Forest. All the results achieved are better than those previously published on the same databases, and with a significantly smaller number of total features.",
    "year": 2019,
    "venue": "IEEE Access",
    "url": "https://www.semanticscholar.org/paper/adbb648528a9fdfd983c6326161a55d09b8b6cb6",
    "doi": "10.1109/ACCESS.2019.2923626",
    "arxivId": "",
    "authors": "Juan E. Tapia, C. Pérez",
    "citationCount": 8
  },
  {
    "s2PaperId": "d06c401104cabf4b93907c856a11d9d69fa7dc72",
    "title": "Simple Acoustic Features Can Explain Phoneme-Based Predictions of Cortical Responses to Speech",
    "abstract": "",
    "year": 2019,
    "venue": "Current Biology",
    "url": "https://www.semanticscholar.org/paper/d06c401104cabf4b93907c856a11d9d69fa7dc72",
    "doi": "10.1016/j.cub.2019.04.067",
    "arxivId": "",
    "authors": "C. Daube, Robin A. A. Ince, J. Gross",
    "citationCount": 139
  },
  {
    "s2PaperId": "378ef22b643467628a7e868e48e8970448e63fda",
    "title": "Behavioral Experiments With Social Algorithms: An Information Theoretic Approach to Input–Output Conversions",
    "abstract": "ABSTRACT While traditional computer-mediated communication happened through transparent, passive, and neutral channels, today’s communication channels are obscure, proactive, and distorted. Social algorithms, guided by a socio-technological codependency, often bias communication, usually in pursuit of some third-party goal of commercial or political nature. We propose a method to derive several summary measures to tests for transformational accuracy when transforming input into an output. Since dynamical flexibility of social algorithms prevents anticipating their behavior, we study these black boxes as if we study human behavior, through controlled experiments. We conceptualize them as noisy communication channels and evaluate their throughput with the same information theoretic measures engineers had originally used to minimize communicative distortion (i.e., mutual information). We use repeated experiments to reverse-engineer algorithmic behavior and test for its statistical significance. We apply the method to three artificial intelligence algorithms: a neural net from IBM’s Watson, and to the recommender engines of YouTube and Twitter.",
    "year": 2019,
    "venue": "Communication Methods and Measures",
    "url": "https://www.semanticscholar.org/paper/378ef22b643467628a7e868e48e8970448e63fda",
    "doi": "10.1080/19312458.2019.1620712",
    "arxivId": "",
    "authors": "Martin Hilbert, Billy Liu, Jonathan Luu, Joel Fishbein",
    "citationCount": 5
  },
  {
    "s2PaperId": "21ae3654a7ffed115be3dbdc9befd0bbf2f3efc5",
    "title": "A Parsimonious Granger Causality Formulation for Capturing Arbitrarily Long Multivariate Associations",
    "abstract": "High-frequency neuroelectric signals like electroencephalography (EEG) or magnetoencephalography (MEG) provide a unique opportunity to infer causal relationships between local activity of brain areas. While causal inference is commonly performed through classical Granger causality (GC) based on multivariate autoregressive models, this method may encounter important limitations (e.g., data paucity) in the case of high dimensional data from densely connected systems like the brain. Additionally, physiological signals often present long-range dependencies which commonly require high autoregressive model orders/number of parameters. We present a generalization of autoregressive models for GC estimation based on Wiener–Volterra decompositions with Laguerre polynomials as basis functions. In this basis, the introduction of only one additional global parameter allows to capture arbitrary long dependencies without increasing model order, hence retaining model simplicity, linearity and ease of parameters estimation. We validate our method in synthetic data generated from families of complex, densely connected networks and demonstrate superior performance as compared to classical GC. Additionally, we apply our framework to studying the directed human brain connectome through MEG data from 89 subjects drawn from the Human Connectome Project (HCP) database, showing that it is able to reproduce current knowledge as well as to uncover previously unknown directed influences between cortical and limbic brain regions.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/21ae3654a7ffed115be3dbdc9befd0bbf2f3efc5",
    "doi": "10.3390/e21070629",
    "arxivId": "",
    "authors": "A. Duggento, G. Valenza, L. Passamonti, Salvatore Nigro, M. Bianco, M. Guerrisi, R. Barbieri, N. Toschi",
    "citationCount": 1
  },
  {
    "s2PaperId": "c0035da579792d895ea24a2204cb11ddbf06f279",
    "title": "Estimating the Mutual Information between Two Discrete, Asymmetric Variables with Limited Samples",
    "abstract": "Determining the strength of nonlinear, statistical dependencies between two variables is a crucial matter in many research fields. The established measure for quantifying such relations is the mutual information. However, estimating mutual information from limited samples is a challenging task. Since the mutual information is the difference of two entropies, the existing Bayesian estimators of entropy may be used to estimate information. This procedure, however, is still biased in the severely under-sampled regime. Here, we propose an alternative estimator that is applicable to those cases in which the marginal distribution of one of the two variables—the one with minimal entropy—is well sampled. The other variable, as well as the joint and conditional distributions, can be severely undersampled. We obtain a consistent estimator that presents very low bias, outperforming previous methods even when the sampled data contain few coincidences. As with other Bayesian estimators, our proposal focuses on the strength of the interaction between the two variables, without seeking to model the specific way in which they are related. A distinctive property of our method is that the main data statistics determining the amount of mutual information is the inhomogeneity of the conditional distribution of the low-entropy variable in those states in which the large-entropy variable registers coincidences.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/c0035da579792d895ea24a2204cb11ddbf06f279",
    "doi": "10.3390/e21060623",
    "arxivId": "1905.02034",
    "authors": "D. G. Hernández, I. Samengo",
    "citationCount": 14
  },
  {
    "s2PaperId": "d5d2935283a3725fe61e7b2bad47d7ed272017a8",
    "title": "Optimal Interplay between Synaptic Strengths and Network Structure Enhances Activity Fluctuations and Information Propagation in Hierarchical Modular Networks",
    "abstract": "In network models of spiking neurons, the joint impact of network structure and synaptic parameters on activity propagation is still an open problem. Here, we use an information-theoretical approach to investigate activity propagation in spiking networks with a hierarchical modular topology. We observe that optimized pairwise information propagation emerges due to the increase of either (i) the global synaptic strength parameter or (ii) the number of modules in the network, while the network size remains constant. At the population level, information propagation of activity among adjacent modules is enhanced as the number of modules increases until a maximum value is reached and then decreases, showing that there is an optimal interplay between synaptic strength and modularity for population information flow. This is in contrast to information propagation evaluated among pairs of neurons, which attains maximum value at the maximum values of these two parameter ranges. By examining the network behavior under the increase of synaptic strength and the number of modules, we find that these increases are associated with two different effects: (i) the increase of autocorrelations among individual neurons and (ii) the increase of cross-correlations among pairs of neurons. The second effect is associated with better information propagation in the network. Our results suggest roles that link topological features and synaptic strength levels to the transmission of information in cortical networks.",
    "year": 2019,
    "venue": "Brain Science",
    "url": "https://www.semanticscholar.org/paper/d5d2935283a3725fe61e7b2bad47d7ed272017a8",
    "doi": "10.3390/brainsci10040228",
    "arxivId": "1905.01181",
    "authors": "R. F. Pena, V. Lima, Renan O Shimoura, João Paulo Novato, A. Roque",
    "citationCount": 7
  },
  {
    "s2PaperId": "0e676c4ef121c6589a365220d903d2b7607b8ead",
    "title": "Imperfect melting pot - Analysis of changes in diversity and segregation of US urban census tracts in the period of 1990-2010",
    "abstract": "",
    "year": 2019,
    "venue": "Computers, Environment and Urban Systems",
    "url": "https://www.semanticscholar.org/paper/0e676c4ef121c6589a365220d903d2b7607b8ead",
    "doi": "10.1016/J.COMPENVURBSYS.2019.04.004",
    "arxivId": "",
    "authors": "T. Stepinski, A. Dmowska",
    "citationCount": 7
  },
  {
    "s2PaperId": "0026d9294a06fffeee9199bb84a9aa98f96e69ce",
    "title": "Multiscale Information Decomposition Dissects Control Mechanisms of Heart Rate Variability at Rest and During Physiological Stress",
    "abstract": "Heart rate variability (HRV; variability of the RR interval of the electrocardiogram) results from the activity of several coexisting control mechanisms, which involve the influence of respiration (RESP) and systolic blood pressure (SBP) oscillations operating across multiple temporal scales and changing in different physiological states. In this study, multiscale information decomposition is used to dissect the physiological mechanisms related to the genesis of HRV in 78 young volunteers monitored at rest and during postural and mental stress evoked by head-up tilt (HUT) and mental arithmetics (MA). After representing RR, RESP and SBP at different time scales through a recently proposed method based on multivariate state space models, the joint information transfer TRESP,SBP→RR is decomposed into unique, redundant and synergistic components, describing the strength of baroreflex modulation independent of respiration (USBP→RR), nonbaroreflex (URESP→RR) and baroreflex-mediated (RRESP,SBP→RR) respiratory influences, and simultaneous presence of baroreflex and nonbaroreflex respiratory influences (SRESP,SBP→RR), respectively. We find that fast (short time scale) HRV oscillations—respiratory sinus arrhythmia—originate from the coexistence of baroreflex and nonbaroreflex (central) mechanisms at rest, with a stronger baroreflex involvement during HUT. Focusing on slower HRV oscillations, the baroreflex origin is dominant and MA leads to its higher involvement. Respiration influences independent on baroreflex are present at long time scales, and are enhanced during HUT.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/0026d9294a06fffeee9199bb84a9aa98f96e69ce",
    "doi": "10.3390/e21050526",
    "arxivId": "",
    "authors": "J. Krohova, L. Faes, B. Czippelová, Z. Turianikova, N. Mažgútová, R. Pernice, A. Busacca, Daniele Marinazzo, S. Stramaglia, M. Javorka",
    "citationCount": 29
  },
  {
    "s2PaperId": "f988ed96886f1aa60f0d68c9cef89115c96f945a",
    "title": "Bayesian modeling of BAC firing as a mechanism for apical amplification in neocortical pyramidal neurons",
    "abstract": "Pyramidal cells in layer 5 of the neocortex have two distinct integration sites. These cells integrate inputs to basal dendrites in the soma while integrating inputs to the tuft in a site at the top of the apical trunk. The two sites communicate by action potentials that backpropagate to the apical site and by backpropagation-activated calcium spikes (BAC firing) that travel from the apical to the somatic site. Six key messages arise from the probabilistic information-theoretic analyses of BAC firing presented here. First, we suggest that pyramidal neurons with BAC firing could convert the odds in favour of the presence of a feature given the basal data into the odds in favour of the presence of a feature given the basal data and the apical input, by a simple Bayesian calculation. Second, the strength of the cell’s response to basal input can be amplified when relevant to the current context, as specified by the apical input, without corrupting the message that it sends. Third, these analyses show rigorously how this apical amplification depends upon communication between the sites. Fourth, we use data on action potentials from a very detailed multi-compartmental biophysical model to study our general model in a more realistic setting, and demonstrate that it describes the data well. Fifth, this form of BAC firing meets criteria for distinguishing modulatory from driving interactions that have been specified using recent definitions of multivariate mutual information. Sixth, our general decomposition can be extended to cases where, instead of being purely driving or purely amplifying, apical and basal inputs can be partly driving and partly amplifying to various extents. These conclusions imply that an advance beyond the assumption of a single site of integration within pyramidal cells is needed, and suggest that the evolutionary success of neocortex may depend upon the cellular mechanisms of context-sensitive selective amplification hypothesized here. Author summary The cerebral cortex has a key role in conscious perception, thought, and action, and is predominantly composed of a particular kind of neuron: the pyramidal cells. The distinct shape of the pyramidal neuron with a long dendritic shaft separating two regions of profuse dendrites allows them to integrate inputs to the two regions separately and combine the results non-linearly to produce output. Here we show how inputs to this more distant site strengthen the cell’s output when it is relevant to the current task and environment. By showing that such neurons have capabilities that transcend those of neurons with the single site of integration assumed by many neuroscientists, this ‘splitting of the neuronal atom’ offers a radically new viewpoint from which to understand the evolution of the cortex and some of its many pathologies. This also suggests that approaches to artificial intelligence using neural networks might come closer to something analogous to real intelligence, if, instead of basing them on processing elements with a single site of integration, they were based on elements with two sites, as in cortex.",
    "year": 2019,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/f988ed96886f1aa60f0d68c9cef89115c96f945a",
    "doi": "10.1101/604066",
    "arxivId": "",
    "authors": "J. Kay, William A. Phillips, Jaan Aru, B. Graham, M. Larkum",
    "citationCount": 1
  },
  {
    "s2PaperId": "d0b8e88cdf2142a57c5dd430dc4df70681568639",
    "title": "Disambiguating the role of blood flow and global signal with partial information decomposition",
    "abstract": "",
    "year": 2019,
    "venue": "NeuroImage",
    "url": "https://www.semanticscholar.org/paper/d0b8e88cdf2142a57c5dd430dc4df70681568639",
    "doi": "10.1016/j.neuroimage.2020.116699",
    "arxivId": "",
    "authors": "Nigel Colenbier, Frederik Van de Steen, L. Uddin, R. Poldrack, V. Calhoun, Daniele Marinazzo",
    "citationCount": 36
  },
  {
    "s2PaperId": "c352babf62104a3e0934cbd0d9bce4e35f157395",
    "title": "Usefulness Drives Representations to Truth",
    "abstract": "An important objection to signaling approaches to representation is that, if signaling behavior is driven by the maximization of usefulness (as is arguably the case for cognitive systems evolved under regimes of natural selection), then signals will typically carry much more information about agent-dependent usefulness than about objective features of the world. This sort of considerations are sometimes taken to provide support for an anti-realist stance on representation itself. The author examines the game-theoretic version of this skeptical line of argument developed by Donald Hoffman and his colleagues. It is shown that their argument only works under an extremely impoverished picture of the informational connections that hold between agent and world. In particular, it only works for cue-driven agents, in Kim Sterelny’s sense. In cases in which the agents’ understanding of what is useful results from combining pieces of information that reach them in different ways, and that complement one another (i.e., that are synergistic), maximizing usefulness involves construing first a picture of agent-independent, objective matters of fact.",
    "year": 2019,
    "venue": "Grazer Philosophische Studien",
    "url": "https://www.semanticscholar.org/paper/c352babf62104a3e0934cbd0d9bce4e35f157395",
    "doi": "10.1163/18756735-09603004",
    "arxivId": "",
    "authors": "Manolo Martínez",
    "citationCount": 4
  },
  {
    "s2PaperId": "f7a43fab085cb707561013ec7d679bdfd0443893",
    "title": "Decomposing information into copying versus transformation",
    "abstract": "In many real-world systems, information can be transmitted in two qualitatively different ways: by copying or by transformation. Copying occurs when messages are transmitted without modification, e.g., when an offspring receives an unaltered copy of a gene from its parent. Transformation occurs when messages are modified systematically during transmission, e.g., when non-random mutations occur during biological reproduction. Standard information-theoretic measures do not distinguish these two modes of information transfer, although they may reflect different mechanisms and have different functional consequences. Starting from a few simple axioms, we derive a decomposition of mutual information into the information transmitted by copying and by transformation. Our decomposition applies whenever the source and destination of the channel have the same set of outcomes, so that a notion of message identity exists, although generalizations to other kinds of channels and similarity notions are explored. Furthermore, copy information can be interpreted as the minimal work needed by a physical copying process, relevant to better understand the physics of replication. We use the proposed decomposition to explore a model of amino acid substitution rates. Our results apply to any system in which the fidelity of copying, rather than simple predictability, is of critical relevance.",
    "year": 2019,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/f7a43fab085cb707561013ec7d679bdfd0443893",
    "doi": "10.1098/rsif.2019.0623",
    "arxivId": "1903.10693",
    "authors": "Artemy Kolchinsky, B. Corominas-Murtra",
    "citationCount": 4
  },
  {
    "s2PaperId": "23c52f75f1c4b318ffffe964b5f1baaf89eb2afe",
    "title": "Quantifying High-order Interdependencies via Multivariate Extensions of the Mutual Information",
    "abstract": "This paper introduces a model-agnostic approach to study statistical synergy, a form of emergence in which patterns at large scales are not traceable from lower scales. Our framework leverages various multivariate extensions of Shannon's mutual information, and introduces the O-information as a metric that is capable of characterizing synergy- and redundancy-dominated systems. The O-information is a symmetric quantity, and can assess intrinsic properties of a system without dividing its parts into \"predictors\" and \"targets.\" We develop key analytical properties of the O-information, and study how it relates to other metrics of high-order interactions from the statistical mechanics and neuroscience literature. Finally, as a proof of concept, we present an exploration on the relevance of statistical synergy in Baroque music scores.",
    "year": 2019,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/23c52f75f1c4b318ffffe964b5f1baaf89eb2afe",
    "doi": "10.1103/PhysRevE.100.032305",
    "arxivId": "1902.11239",
    "authors": "F. Rosas, P. Mediano, M. Gastpar, H. Jensen",
    "citationCount": 157
  },
  {
    "s2PaperId": "24a90dde4745817ac551437da516d048a5b84b7a",
    "title": "Information Flow in Computational Systems",
    "abstract": "We develop a theoretical framework for defining and identifying flows of information in computational systems. Here, a computational system is assumed to be a directed graph, with “clocked” nodes that send transmissions to each other along the edges of the graph at discrete points in time. We are interested in a definition that captures the dynamic flow of information about a specific message, and which guarantees an unbroken “information path” between appropriately defined inputs and outputs in the directed graph. Prior measures, including those based on Granger Causality and Directed Information, fail to provide clear assumptions and guarantees about when they correctly reflect information flow about a message. We take a systematic approach—iterating through candidate definitions and counterexamples—to arrive at a definition for information flow that is based on conditional mutual information, and which satisfies desirable properties, including the existence of information paths. Finally, we describe how information flow might be detected in a noiseless setting, and provide an algorithm to identify information paths on the time-unrolled graph of a computational system.",
    "year": 2019,
    "venue": "IEEE Transactions on Information Theory",
    "url": "https://www.semanticscholar.org/paper/24a90dde4745817ac551437da516d048a5b84b7a",
    "doi": "10.1109/TIT.2020.2987806",
    "arxivId": "1902.02292",
    "authors": "Praveen Venkatesh, Sanghamitra Dutta, P. Grover",
    "citationCount": 17
  },
  {
    "s2PaperId": "fb0b4bc8e030f24b650a260fbe7cf423e1bbe33b",
    "title": "Unique Information and Secret Key Decompositions",
    "abstract": "The unique information (UI) is an information measure that quantifies a deviation from the Blackwell order. We have recently shown that this quantity is an upper bound on the one-way secret key rate. In this paper, we prove a triangle inequality for the UI, which implies that the UI is never greater than one of the best known upper bounds on the two-way secret key rate. We conjecture that the UI lower bounds the two-way rate and discuss implications of the conjecture.",
    "year": 2019,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/fb0b4bc8e030f24b650a260fbe7cf423e1bbe33b",
    "doi": "10.1109/ISIT.2019.8849550",
    "arxivId": "1901.08007",
    "authors": "Johannes Rauh, P. Banerjee, E. Olbrich, J. Jost",
    "citationCount": 7
  },
  {
    "s2PaperId": "033b823393e1c586e1a1a1d99e9a33eb8389ea39",
    "title": "Can Transfer Entropy Infer Information Flow in Neuronal Circuits for Cognitive Processing?",
    "abstract": "How cognitive neural systems process information is largely unknown, in part because of how difficult it is to accurately follow the flow of information from sensors via neurons to actuators. Measuring the flow of information is different from measuring correlations between firing neurons, for which several measures are available, foremost among them the Shannon information, which is an undirected measure. Several information-theoretic notions of “directed information” have been used to successfully detect the flow of information in some systems, in particular in the neuroscience community. However, recent work has shown that directed information measures such as transfer entropy can sometimes inadequately estimate information flow, or even fail to identify manifest directed influences, especially if neurons contribute in a cryptographic manner to influence the effector neuron. Because it is unclear how often such cryptic influences emerge in cognitive systems, the usefulness of transfer entropy measures to reconstruct information flow is unknown. Here, we test how often cryptographic logic emerges in an evolutionary process that generates artificial neural circuits for two fundamental cognitive tasks (motion detection and sound localization). Besides counting the frequency of problematic logic gates, we also test whether transfer entropy applied to an activity time-series recorded from behaving digital brains can infer information flow, compared to a ground-truth model of direct influence constructed from connectivity and circuit logic. Our results suggest that transfer entropy will sometimes fail to infer directed information when it exists, and sometimes suggest a causal connection when there is none. However, the extent of incorrect inference strongly depends on the cognitive task considered. These results emphasize the importance of understanding the fundamental logic processes that contribute to information flow in cognitive processing, and quantifying their relevance in any given nervous system.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/033b823393e1c586e1a1a1d99e9a33eb8389ea39",
    "doi": "10.3390/e22040385",
    "arxivId": "1901.07589",
    "authors": "Ali Tehrani-Saleh, Christoph Adami",
    "citationCount": 3
  },
  {
    "s2PaperId": "310fd5280aa4e33a5b73a571ff928f3aaba76fbb",
    "title": "Can Transfer Entropy Infer Causality in Neuronal Circuits for Cognitive Processing?",
    "abstract": "",
    "year": 2019,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/310fd5280aa4e33a5b73a571ff928f3aaba76fbb",
    "doi": "",
    "arxivId": "",
    "authors": "Ali Tehrani-Saleh, C. Adami",
    "citationCount": 6
  },
  {
    "s2PaperId": "db7e1543a33850bf13565e75faa9f72c58c4e216",
    "title": "MAXENT3D_PID: An Estimator for the Maximum-Entropy Trivariate Partial Information Decomposition",
    "abstract": "Partial information decomposition (PID) separates the contributions of sources about a target into unique, redundant, and synergistic components of information. In essence, PID answers the question of “who knows what” of a system of random variables and hence has applications to a wide spectrum of fields ranging from social to biological sciences. The paper presents MaxEnt3D_Pid, an algorithm that computes the PID of three sources, based on a recently-proposed maximum entropy measure, using convex optimization (cone programming). We describe the algorithm and its associated software utilization and report the results of various experiments assessing its accuracy. Moreover, the paper shows that a hierarchy of bivariate and trivariate PID allows obtaining the finer quantities of the trivariate partial information measure.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/db7e1543a33850bf13565e75faa9f72c58c4e216",
    "doi": "10.3390/e21090862",
    "arxivId": "1901.03352",
    "authors": "Abdullah Makkeh, D. Chicharro, D. Theis, Raul Vicente",
    "citationCount": 4
  },
  {
    "s2PaperId": "4c53cd4c5a1536f1cddcd541fec3e1c59822b6b8",
    "title": "Causal deconvolution by algorithmic generative models",
    "abstract": "",
    "year": 2019,
    "venue": "Nature Machine Intelligence",
    "url": "https://www.semanticscholar.org/paper/4c53cd4c5a1536f1cddcd541fec3e1c59822b6b8",
    "doi": "10.1038/s42256-018-0005-0",
    "arxivId": "",
    "authors": "H. Zenil, N. Kiani, Allan A. Zea, J. Tegnér",
    "citationCount": 86
  },
  {
    "s2PaperId": "cca63cc557a0b6f1aa394d1644b674d67d7b7893",
    "title": "Information Theory in Neuroscience",
    "abstract": "This is the Editorial article summarizing the scope and contents of the Special Issue, Information Theory in Neuroscience.",
    "year": 2019,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/cca63cc557a0b6f1aa394d1644b674d67d7b7893",
    "doi": "10.3390/e21010062",
    "arxivId": "",
    "authors": "Eugenio Piasini, S. Panzeri",
    "citationCount": 9
  },
  {
    "s2PaperId": "a5bb1cecc0bd164b066eb68fd89bf4b97dd325de",
    "title": "An Extension of MIC for Multivariate Correlation Analysis Based on Interaction Information",
    "abstract": "",
    "year": 2018,
    "venue": "International Conference on Computer Science and Artificial Intelligence",
    "url": "https://www.semanticscholar.org/paper/a5bb1cecc0bd164b066eb68fd89bf4b97dd325de",
    "doi": "10.1145/3297156.3297162",
    "arxivId": "",
    "authors": "Zi-xuan Zhang, Wen-ning Hao, Gang Chen, Jun-Yue Chen, You-wei Xu",
    "citationCount": 3
  },
  {
    "s2PaperId": "f582bc6496b60769ce77eb8e14b7542ee7be2acb",
    "title": "Paced Breathing Increases the Redundancy of Cardiorespiratory Control in Healthy Individuals and Chronic Heart Failure Patients",
    "abstract": "Synergy and redundancy are concepts that suggest, respectively, adaptability and fault tolerance of systems with complex behavior. This study computes redundancy/synergy in bivariate systems formed by a target X and a driver Y according to the predictive information decomposition approach and partial information decomposition framework based on the minimal mutual information principle. The two approaches assess the redundancy/synergy of past of X and Y in reducing the uncertainty of the current state of X. The methods were applied to evaluate the interactions between heart and respiration in healthy young subjects (n = 19) during controlled breathing at 10, 15 and 20 breaths/minute and in two groups of chronic heart failure patients during paced respiration at 6 (n = 9) and 15 (n = 20) breaths/minutes from spontaneous beat-to-beat fluctuations of heart period and respiratory signal. Both methods suggested that slowing respiratory rate below the spontaneous frequency increases redundancy of cardiorespiratory control in both healthy and pathological groups, thus possibly improving fault tolerance of the cardiorespiratory control. The two methods provide markers complementary to respiratory sinus arrhythmia and the strength of the linear coupling between heart period variability and respiration in describing the physiology of the cardiorespiratory reflex suitable to be exploited in various pathophysiological settings.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/f582bc6496b60769ce77eb8e14b7542ee7be2acb",
    "doi": "10.3390/e20120949",
    "arxivId": "",
    "authors": "A. Porta, R. Maestri, V. Bari, B. D. Maria, B. Cairo, E. Vaini, M. T. Rovere, G. Pinna",
    "citationCount": 23
  },
  {
    "s2PaperId": "9d4e2df67985287b755cc1e648b7c262d43d494c",
    "title": "Maximizing Multivariate Information With Error-Correcting Codes",
    "abstract": "Multivariate mutual information provides a conceptual framework for characterizing higher-order interactions in complex systems. Two well-known measures of multivariate information—total correlation and dual total correlation—admit a spectrum of measures with varying sensitivity to intermediate orders of dependence. Unfortunately, these intermediate measures have not received much attention due to their opaque representation of information. Here we draw on results from matroid theory to show that these measures are closely related to error-correcting codes. This connection allows us to derive the class of global maximizers for each measure, which coincide with maximum distance separable codes of order $k$ . In addition to deepening the understanding of these measures and multivariate information more generally, we use these results to show that previously proposed bounds on information geometric quantities are met with equality for the global min and max.",
    "year": 2018,
    "venue": "IEEE Transactions on Information Theory",
    "url": "https://www.semanticscholar.org/paper/9d4e2df67985287b755cc1e648b7c262d43d494c",
    "doi": "10.1109/TIT.2019.2956144",
    "arxivId": "1811.10839",
    "authors": "Kyle Reing, Greg Ver Steeg, A. Galstyan",
    "citationCount": 2
  },
  {
    "s2PaperId": "a63d46999099bd6e7d040f94ac572ce1e214b43a",
    "title": "Unique Information and Secret Key Agreement",
    "abstract": "The partial information decomposition (PID) is a promising framework for decomposing a joint random variable into the amount of influence each source variable Xi has on a target variable Y, relative to the other sources. For two sources, influence breaks down into the information that both X0 and X1 redundantly share with Y, what X0 uniquely shares with Y, what X1 uniquely shares with Y, and finally what X0 and X1 synergistically share with Y. Unfortunately, considerable disagreement has arisen as to how these four components should be quantified. Drawing from cryptography, we consider the secret key agreement rate as an operational method of quantifying unique information. Secret key agreement rate comes in several forms, depending upon which parties are permitted to communicate. We demonstrate that three of these four forms are inconsistent with the PID. The remaining form implies certain interpretations as to the PID’s meaning—interpretations not present in PID’s definition but that, we argue, need to be explicit. Specifically, the use of a consistent PID quantified using a secret key agreement rate naturally induces a directional interpretation of the PID. We further reveal a surprising connection between third-order connected information, two-way secret key agreement rate, and synergy. We also consider difficulties which arise with a popular PID measure in light of the results here as well as from a maximum entropy viewpoint. We close by reviewing the challenges facing the PID.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/a63d46999099bd6e7d040f94ac572ce1e214b43a",
    "doi": "10.3390/e21010012",
    "arxivId": "1811.01745",
    "authors": "R. James, Jeffrey Emenheiser, J. Crutchfield",
    "citationCount": 25
  },
  {
    "s2PaperId": "83a141fc8bb3393520c5bc705d35ccc66b55704c",
    "title": "Assessing the Relevance of Specific Response Features in the Neural Code",
    "abstract": "The study of the neural code aims at deciphering how the nervous system maps external stimuli into neural activity—the encoding phase—and subsequently transforms such activity into adequate responses to the original stimuli—the decoding phase. Several information-theoretical methods have been proposed to assess the relevance of individual response features, as for example, the spike count of a given neuron, or the amount of correlation in the activity of two cells. These methods work under the premise that the relevance of a feature is reflected in the information loss that is induced by eliminating the feature from the response. The alternative methods differ in the procedure by which the tested feature is removed, and the algorithm with which the lost information is calculated. Here we compare these methods, and show that more often than not, each method assigns a different relevance to the tested feature. We demonstrate that the differences are both quantitative and qualitative, and connect them with the method employed to remove the tested feature, as well as the procedure to calculate the lost information. By studying a collection of carefully designed examples, and working on analytic derivations, we identify the conditions under which the relevance of features diagnosed by different methods can be ranked, or sometimes even equated. The condition for equality involves both the amount and the type of information contributed by the tested feature. We conclude that the quest for relevant response features is more delicate than previously thought, and may yield to multiple answers depending on methodological subtleties.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/83a141fc8bb3393520c5bc705d35ccc66b55704c",
    "doi": "10.3390/e20110879",
    "arxivId": "",
    "authors": "H. G. Eyherabide, I. Samengo",
    "citationCount": 1
  },
  {
    "s2PaperId": "0aac72486c64962ba9b30439a96c330afd97ebc5",
    "title": "Phoneme-level processing in low-frequency cortical responses to speech explained by acoustic features",
    "abstract": "When we listen to speech, we have to make sense of a waveform of sound pressure. Hierarchical models of speech perception assume that before giving rise to its final semantic meaning, the signal is transformed into unknown intermediate neuronal representations. Classically, studies of such intermediate representations are guided by linguistically defined concepts such as phonemes. Here we argue that in order to arrive at an unbiased understanding of the mechanisms of speech comprehension, the focus should instead lie on representations obtained directly from the stimulus. We illustrate our view with a strongly data-driven analysis of a dataset of 24 young, healthy humans who listened to a narrative of one hour duration while their magnetoencephalogram (MEG) was recorded. We find that two recent results, a performance gain of an encoding model based on acoustic and annotated linguistic features over a model based on acoustic features alone as well as the decoding of subgroups of phonemes from phoneme-locked responses, can be explained with an encoding model entirely based on acoustic features. These acoustic features capitalise on acoustic edges and outperform Gabor-filtered spectrograms, features with the potential to describe the spectrotemporal characteristics of individual phonemes. We conclude that models of brain responses based on linguistic features can serve as excellent benchmarks. However, we put forward that linguistic concepts are better used when interpreting models, not when building them. In doing so, we find that the results of our analyses favour syllables over phonemes as candidate intermediate speech representations visible with fast non-invasive neuroimaging.",
    "year": 2018,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/0aac72486c64962ba9b30439a96c330afd97ebc5",
    "doi": "10.1101/448134",
    "arxivId": "",
    "authors": "C. Daube, Robin A. A. Ince, J. Gross",
    "citationCount": 0
  },
  {
    "s2PaperId": "b6e577fa5d1e1131e072d4a9f5e84b049729f55c",
    "title": "Dependency and Redundancy: How Information Theory Untangles Three Variable Interactions in Environmental Data",
    "abstract": "In this paper, we comment on the recent two‐part paper by Goodwell and Kumar (2017a, https://doi.org/10.1002/2016WR020216, 2017b, https://doi.org/10.1002/2016WR020218) on quantifying three‐way interactions between variables using information theory. Their proposed method of partitioning interactions into unique, redundant, and synergistic information is valuable and has potential other applications in the field of water resources. We present an example to investigate the generality of their assumption that redundancy follows from dependency of the sources. In the broader context of information theoretical methods in the geosciences, we argue that implementation challenges stem mostly from issues that are intrinsic to learning patterns from limited data. These issues are only hidden by assumptions, but not absent, when using conventional correlation‐based methods. The flexibility of individually choosing assumptions in information theoretical methods gives them a myriad of potential applications in the study of complex systems.",
    "year": 2018,
    "venue": "Water Resources Research",
    "url": "https://www.semanticscholar.org/paper/b6e577fa5d1e1131e072d4a9f5e84b049729f55c",
    "doi": "10.1029/2018WR022649",
    "arxivId": "",
    "authors": "S. Weijs, H. Foroozand, A. Kumar",
    "citationCount": 11
  },
  {
    "s2PaperId": "dce884e5b354ebb70ab3aec5c3a3d52c95ca1623",
    "title": "Multiscale Information Transfer in Turbulence",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/dce884e5b354ebb70ab3aec5c3a3d52c95ca1623",
    "doi": "",
    "arxivId": "",
    "authors": "C. Belinchon",
    "citationCount": 3
  },
  {
    "s2PaperId": "7ecd217780b6b98328f6c954ead9a39d3efe5eee",
    "title": "Dynamic process connectivity explains ecohydrologic responses to rainfall pulses and drought",
    "abstract": "Significance In the face of changing climate, weather variability, and land cover, it is important to understand how ecosystem components vary jointly to determine how the system responds as a whole. While previous works have identified thresholds along climate gradients regarding precipitation, soils, and vegetation, we relate these thresholds to shifts in connectivity between variables, captured through joint variability, to better understand whole-system attributes of resilience, sensitivity, and vulnerability. We use data from flux tower transects along elevation gradients to address the relationship between joint connectivity and energy, water, and carbon flux responses to changes in moisture availability. This analysis reveals differences in joint variability between locations that can help explain responses to disturbances such as rain events or drought. Ecohydrologic fluxes within atmosphere, vegetation, and soil systems exhibit a joint variability that arises from forcing and feedback interactions. These interactions cause fluctuations to propagate between variables at many time scales. In an ecosystem, this connectivity dictates responses to climate change, land-cover change, and weather events and must be characterized to understand resilience and sensitivity. We use an information theory-based approach to quantify connectivity in the form of information flow associated with the propagation of fluctuations between variables. We apply this approach to study ecosystems that experience changes in dry-season moisture availability due to rainfall and drought conditions. We use data from two transects with flux towers located along elevation gradients and quantify redundant, synergistic, and unique flow of information between lagged sources and targets to characterize joint asynchronous time dependencies. At the Reynolds Creek Critical Zone Observatory in Idaho, a dry-season rainfall pulse leads to increased connectivity from soil and atmospheric variables to heat and carbon fluxes. At the Southern Sierra Critical Zone Observatory in California, separate sets of dominant drivers characterize two sites at which fluxes exhibit different drought responses. For both cases, our information flow-based connectivity characterizes dominant drivers and joint variability before, during, and after disturbances. This approach to gauge the responsiveness of ecosystem fluxes under multiple sources of variability furthers our understanding of complex ecohydrologic systems.",
    "year": 2018,
    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
    "url": "https://www.semanticscholar.org/paper/7ecd217780b6b98328f6c954ead9a39d3efe5eee",
    "doi": "10.1073/pnas.1800236115",
    "arxivId": "",
    "authors": "A. Goodwell, Praveen Kumar, A. Fellows, G. Flerchinger",
    "citationCount": 52
  },
  {
    "s2PaperId": "3f954b245d9fc9c712e71ee3e4f965907d28865d",
    "title": "A Perspective on Unique Information: Directionality, Intuitions, and Secret Key Agreement",
    "abstract": "Recently, the partial information decomposition emerged as a promising framework for identifying the meaningful components of the information contained in a joint distribution. Its adoption and practical application, however, have been stymied by the lack of a generally-accepted method of quantifying its components. Here, we briefly discuss the bivariate (two-source) partial information decomposition and two implicitly directional interpretations used to intuitively motivate alternative component definitions. Drawing parallels with secret key agreement rates from information-theoretic cryptography, we demonstrate that these intuitions are mutually incompatible and suggest that this underlies the persistence of competing definitions and interpretations. Having highlighted this hitherto unacknowledged issue, we outline several possible solutions.",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/3f954b245d9fc9c712e71ee3e4f965907d28865d",
    "doi": "",
    "arxivId": "1808.08606",
    "authors": "R. James, Jeffrey Emenheiser, J. Crutchfield",
    "citationCount": 2
  },
  {
    "s2PaperId": "1ff2fef267f0bde44ffd7144fe46f31fa2fb89c0",
    "title": "Multivariate Extension of Matrix-Based Rényi's <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math><alternatives><mml:math><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq1-2932976.gif\"/></alternatives></inline-formula>-Order Entropy Functional",
    "abstract": "The matrix-based Rényi's <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math><alternatives><mml:math><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq2-2932976.gif\"/></alternatives></inline-formula>-order entropy functional was recently introduced using the normalized eigenspectrum of a Hermitian matrix of the projected data in a reproducing kernel Hilbert space (RKHS). However, the current theory in the matrix-based Rényi's <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math><alternatives><mml:math><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq3-2932976.gif\"/></alternatives></inline-formula>-order entropy functional only defines the entropy of a single variable or mutual information between two random variables. In information theory and machine learning communities, one is also frequently interested in multivariate information quantities, such as the multivariate joint entropy and different interactive quantities among multiple variables. In this paper, we first define the matrix-based Rényi's <inline-formula><tex-math notation=\"LaTeX\">$\\alpha$</tex-math><alternatives><mml:math><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq4-2932976.gif\"/></alternatives></inline-formula>-order joint entropy among multiple variables. We then show how this definition can ease the estimation of various information quantities that measure the interactions among multiple variables, such as interactive information and total correlation. We finally present an application to feature selection to show how our definition provides a simple yet powerful way to estimate a widely-acknowledged intractable quantity from data. A real example on hyperspectral image (HSI) band selection is also provided.",
    "year": 2018,
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "url": "https://www.semanticscholar.org/paper/1ff2fef267f0bde44ffd7144fe46f31fa2fb89c0",
    "doi": "10.1109/TPAMI.2019.2932976",
    "arxivId": "1808.07912",
    "authors": "Shujian Yu, L. S. Giraldo, R. Jenssen, J. Príncipe",
    "citationCount": 30
  },
  {
    "s2PaperId": "52098be80b9b6676fcf094bae12efe357563d486",
    "title": "Modes of Information Flow",
    "abstract": "Author(s): James, Ryan G; Ayala, Blanca Daniella Mansante; Zakirov, Bahti; Crutchfield, James P | Abstract: Information flow between components of a system takes many forms and is key to understanding the organization and functioning of large-scale, complex systems. We demonstrate three modalities of information flow from time series X to time series Y. Intrinsic information flow exists when the past of X is individually predictive of the present of Y, independent of Y's past; this is most commonly considered information flow. Shared information flow exists when X's past is predictive of Y's present in the same manner as Y's past; this occurs due to synchronization or common driving, for example. Finally, synergistic information flow occurs when neither X's nor Y's pasts are predictive of Y's present on their own, but taken together they are. The two most broadly-employed information-theoretic methods of quantifying information flow---time-delayed mutual information and transfer entropy---are both sensitive to a pair of these modalities: time-delayed mutual information to both intrinsic and shared flow, and transfer entropy to both intrinsic and synergistic flow. To quantify each mode individually we introduce our cryptographic flow ansatz, positing that intrinsic flow is synonymous with secret key agreement between X and Y. Based on this, we employ an easily-computed secret-key-agreement bound---intrinsic mutual informationamdashto quantify the three flow modalities in a variety of systems including asymmetric flows and financial markets.",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/52098be80b9b6676fcf094bae12efe357563d486",
    "doi": "",
    "arxivId": "1808.06723",
    "authors": "R. James, Blanca Daniella Mansante Ayala, Bahti Zakirov, J. Crutchfield",
    "citationCount": 8
  },
  {
    "s2PaperId": "ba10cdfc6bd3af79819c1b4f3fbb18a5a35ac0e2",
    "title": "An Information-Theoretic Approach to Self-Organisation: Emergence of Complex Interdependencies in Coupled Dynamical Systems",
    "abstract": "Self-organisation lies at the core of fundamental but still unresolved scientific questions, and holds the promise of de-centralised paradigms crucial for future technological developments. While self-organising processes have been traditionally explained by the tendency of dynamical systems to evolve towards specific configurations, or attractors, we see self-organisation as a consequence of the interdependencies that those attractors induce. Building on this intuition, in this work we develop a theoretical framework for understanding and quantifying self-organisation based on coupled dynamical systems and multivariate information theory. We propose a metric of global structural strength that identifies when self-organisation appears, and a multi-layered decomposition that explains the emergent structure in terms of redundant and synergistic interdependencies. We illustrate our framework on elementary cellular automata, showing how it can detect and characterise the emergence of complex structures.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ba10cdfc6bd3af79819c1b4f3fbb18a5a35ac0e2",
    "doi": "10.3390/e20100793",
    "arxivId": "1808.05602",
    "authors": "F. Rosas, P. Mediano, M. Ugarte, H. Jensen",
    "citationCount": 46
  },
  {
    "s2PaperId": "a0f7e91f590a5435a82784c39bd2715176175558",
    "title": "Representational interactions during audiovisual speech entrainment: Redundancy in left posterior superior temporal gyrus and synergy in left motor cortex",
    "abstract": "Integration of multimodal sensory information is fundamental to many aspects of human behavior, but the neural mechanisms underlying these processes remain mysterious. For example, during face-to-face communication, we know that the brain integrates dynamic auditory and visual inputs, but we do not yet understand where and how such integration mechanisms support speech comprehension. Here, we quantify representational interactions between dynamic audio and visual speech signals and show that different brain regions exhibit different types of representational interaction. With a novel information theoretic measure, we found that theta (3–7 Hz) oscillations in the posterior superior temporal gyrus/sulcus (pSTG/S) represent auditory and visual inputs redundantly (i.e., represent common features of the two), whereas the same oscillations in left motor and inferior temporal cortex represent the inputs synergistically (i.e., the instantaneous relationship between audio and visual inputs is also represented). Importantly, redundant coding in the left pSTG/S and synergistic coding in the left motor cortex predict behavior—i.e., speech comprehension performance. Our findings therefore demonstrate that processes classically described as integration can have different statistical properties and may reflect distinct mechanisms that occur in different brain regions to support audiovisual speech comprehension.",
    "year": 2018,
    "venue": "PLoS Biology",
    "url": "https://www.semanticscholar.org/paper/a0f7e91f590a5435a82784c39bd2715176175558",
    "doi": "10.1371/journal.pbio.2006558",
    "arxivId": "",
    "authors": "Hyojin Park, Robin A. A. Ince, P. Schyns, G. Thut, J. Gross",
    "citationCount": 59
  },
  {
    "s2PaperId": "fcd7a533e722942ca89d0fcba4c69fd0ae226bf4",
    "title": "IDTxl: The Information Dynamics Toolkit xl: a Python package for the efficient analysis of multivariate information dynamics in networks",
    "abstract": "The Information Dynamics Toolkit xl (IDTxl) is a comprehensive software package for efficient inference of networks and their node dynamics from multivariate time series data using information theory. IDTxl provides functionality to estimate the following measures:  1) For network inference: multivariate transfer entropy (TE)/Granger causality (GC), multivariate mutual information (MI), bivariate TE/GC, bivariate MI  2) For analysis of node dynamics: active information storage (AIS), partial information decomposition (PID)  IDTxl implements estimators for discrete and continuous data with parallel computing engines for both GPU and CPU platforms. Written for Python3.4.3+.",
    "year": 2018,
    "venue": "Journal of Open Source Software",
    "url": "https://www.semanticscholar.org/paper/fcd7a533e722942ca89d0fcba4c69fd0ae226bf4",
    "doi": "10.21105/joss.01081",
    "arxivId": "1807.10459",
    "authors": "Patricia Wollstadt, J. Lizier, Raul Vicente, Conor Finn, M. Martínez-Zarzuela, Pedro Mediano, Leonardo Novelli, M. Wibral",
    "citationCount": 106
  },
  {
    "s2PaperId": "cdeff5e5bfddd536f8cf769d05f0f9a0d96523d0",
    "title": "Quantifying Information Modification in Cellular Automata using Pointwise Partial Information Decomposition",
    "abstract": "",
    "year": 2018,
    "venue": "IEEE Symposium on Artificial Life",
    "url": "https://www.semanticscholar.org/paper/cdeff5e5bfddd536f8cf769d05f0f9a0d96523d0",
    "doi": "10.1162/ISAL_A_00075",
    "arxivId": "",
    "authors": "Conor Finn, J. Lizier",
    "citationCount": 5
  },
  {
    "s2PaperId": "949d32b3b7a55dd288733390f70230e812692bfd",
    "title": "Elements of Consciousness and Cognition. Biology, Mathematic, Physics and Panpsychism: an Information Topology Perspective",
    "abstract": "This review presents recent and older results on elementary quantitative and qualitative aspects of consciousness and cognition and tackles the question \"What is consciousness?\" conjointly from biological, neuroscience-cognitive, physical and mathematical points of view. It proposes to unify various results and theories by means of information topology.  The first chapter presents the postulates and results on elementary perception at various organizational scales of the nervous system and proposes the hypothesis of an electrodynamic intrinsic nature of consciousness which is sustained by an analogical code. It underlines the diversity of the learning mechanisms that sustain the dynamics of perception and consciousness, including adaptive and homeostatic processes on multiple scales.  The second chapter investigates the logical aspects of cognition and consciousness and proposes an axiomatization based on measure and probability theory. Topos and constructive logic are presented as providing an intrinsic probabilistic logic, with the long-term aim of avoiding the paradoxical decomposition induced by the Axiom of Choice. We sketch an elementary procedure allowing an expression of the information of a mathematical formula a la Godel. We then present the formalism of information topology and propose that it provides a preliminary basis for synthesizing the main models of cognition and consciousness within a formal Gestalt theory. Information topology establishes a characterization of information theory functions, allowing for a precise expression of information structures and patterns. It provides a quantification of the structure of statistical interactions and their expression in terms of statistical physics and machine learning. Notably, those topological methods allow conciliation of some of the main theories of consciousness.",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/949d32b3b7a55dd288733390f70230e812692bfd",
    "doi": "",
    "arxivId": "1807.04520",
    "authors": "P. Baudot",
    "citationCount": 4
  },
  {
    "s2PaperId": "744aa2f0f3be5d6d3a477b6a471dfcb93a08cb99",
    "title": "Apical Function in Neocortical Pyramidal Cells: A Common Pathway by Which General Anesthetics Can Affect Mental State",
    "abstract": "It has been argued that general anesthetics suppress the level of consciousness, or the contents of consciousness, or both. The distinction between level and content is important because, in addition to clarifying the mechanisms of anesthesia, it may help clarify the neural bases of consciousness. We assess these arguments in the light of evidence that both the level and the content of consciousness depend upon the contribution of apical input to the information processing capabilities of neocortical pyramidal cells which selectively amplify relevant signals. We summarize research suggesting that what neocortical pyramidal cells transmit information about can be distinguished from levels of arousal controlled by sub-cortical nuclei and from levels of prioritization specified by interactions within the thalamocortical system. Put simply, on the basis of the observations reviewed, we hypothesize that when conscious we have particular, directly experienced, percepts, thoughts, feelings and intentions, and that general anesthetics affect consciousness by interfering with the subcellular processes by which particular activities are selectively amplified when relevant to the current context.",
    "year": 2018,
    "venue": "Front. Neural Circuits",
    "url": "https://www.semanticscholar.org/paper/744aa2f0f3be5d6d3a477b6a471dfcb93a08cb99",
    "doi": "10.3389/fncir.2018.00050",
    "arxivId": "",
    "authors": "W. A. Phillips, T. Bachmann, J. Storm",
    "citationCount": 32
  },
  {
    "s2PaperId": "b0daa6443f88619f938696da2c7bda9fa731a649",
    "title": "Measuring Integrated Information: Comparison of Candidate Measures in Theory and Simulation",
    "abstract": "Integrated Information Theory (IIT) is a prominent theory of consciousness that has at its centre measures that quantify the extent to which a system generates more information than the sum of its parts. While several candidate measures of integrated information (“Φ”) now exist, little is known about how they compare, especially in terms of their behaviour on non-trivial network models. In this article, we provide clear and intuitive descriptions of six distinct candidate measures. We then explore the properties of each of these measures in simulation on networks consisting of eight interacting nodes, animated with Gaussian linear autoregressive dynamics. We find a striking diversity in the behaviour of these measures—no two measures show consistent agreement across all analyses. A subset of the measures appears to reflect some form of dynamical complexity, in the sense of simultaneous segregation and integration between system components. Our results help guide the operationalisation of IIT and advance the development of measures of integrated information and dynamical complexity that may have more general applicability.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/b0daa6443f88619f938696da2c7bda9fa731a649",
    "doi": "10.3390/e21010017",
    "arxivId": "1806.09373",
    "authors": "P. Mediano, A. Seth, A. Barrett",
    "citationCount": 105
  },
  {
    "s2PaperId": "d925d1c0749444e382eab1fc4c04ef3ae8540757",
    "title": "Evaluating methods of inferring gene regulatory networks highlights their lack of performance for single cell gene expression data",
    "abstract": "A fundamental fact in biology states that genes do not operate in isolation, and yet, methods that infer regulatory networks for single cell gene expression data have been slow to emerge. With single cell sequencing methods now becoming accessible, general network inference algorithms that were initially developed for data collected from bulk samples may not be suitable for single cells. Meanwhile, although methods that are specific for single cell data are now emerging, whether they have improved performance over general methods is unknown. In this study, we evaluate the applicability of five general methods and three single cell methods for inferring gene regulatory networks from both experimental single cell gene expression data and in silico simulated data. Standard evaluation metrics using ROC curves and Precision-Recall curves against reference sets sourced from the literature demonstrated that most of the methods performed poorly when they were applied to either experimental single cell data, or simulated single cell data, which demonstrates their lack of performance for this task. Using default settings, network methods were applied to the same datasets. Comparisons of the learned networks highlighted the uniqueness of some predicted edges for each method. The fact that different methods infer networks that vary substantially reflects the underlying mathematical rationale and assumptions that distinguish network methods from each other. This study provides a comprehensive evaluation of network modeling algorithms applied to experimental single cell gene expression data and in silico simulated datasets where the network structure is known. Comparisons demonstrate that most of these assessed network methods are not able to predict network structures from single cell expression data accurately, even if they are specifically developed for single cell methods. Also, single cell methods, which usually depend on more elaborative algorithms, in general have less similarity to each other in the sets of edges detected. The results from this study emphasize the importance for developing more accurate optimized network modeling methods that are compatible for single cell data. Newly-developed single cell methods may uniquely capture particular features of potential gene-gene relationships, and caution should be taken when we interpret these results.",
    "year": 2018,
    "venue": "BMC Bioinformatics",
    "url": "https://www.semanticscholar.org/paper/d925d1c0749444e382eab1fc4c04ef3ae8540757",
    "doi": "10.1186/s12859-018-2217-z",
    "arxivId": "",
    "authors": "Shuonan Chen, J. Mar",
    "citationCount": 196
  },
  {
    "s2PaperId": "c27672d0d3f51ca8cf0a57b52656ac4c6a353317",
    "title": "Synergistic Information Processing Encrypts Strategic Reasoning in Poker",
    "abstract": "There is a tendency in decision-making research to treat uncertainty only as a problem to be overcome. But it is also a feature that can be leveraged, particularly in social interaction. Comparing the behavior of profitable and unprofitable poker players, we reveal a strategic use of information processing that keeps decision makers unpredictable. To win at poker, a player must exploit public signals from others. But using public inputs makes it easier for an observer to reconstruct that player's strategy and predict his or her behavior. How should players trade off between exploiting profitable opportunities and remaining unexploitable themselves? Using a recent multivariate approach to information theoretic data analysis and 1.75 million hands of online two-player No-Limit Texas Hold'em, we find that the important difference between winning and losing players is not in the amount of information they process, but how they process it. In particular, winning players are better at integrative information processing-creating new information from the interaction between their cards and their opponents' signals. We argue that integrative information processing does not just produce better decisions, it makes decision-making harder for others to reverse engineer, as an expert poker player's cards act like the private key in public-key cryptography. Poker players encrypt their reasoning with the way they process information. The encryption function of integrative information processing makes it possible for players to exploit others while remaining unexploitable. By recognizing the act of information processing as a strategic behavior in its own right, we offer a detailed account of how experts use endemic uncertainty to conceal their intentions in high-stakes competitive environments, and we highlight new opportunities between cognitive science, information theory, and game theory.",
    "year": 2018,
    "venue": "Cognitive Sciences",
    "url": "https://www.semanticscholar.org/paper/c27672d0d3f51ca8cf0a57b52656ac4c6a353317",
    "doi": "10.1111/cogs.12632",
    "arxivId": "",
    "authors": "Seth Frey, Dominic K. Albino, Paul L. Williams",
    "citationCount": 9
  },
  {
    "s2PaperId": "a38884e3f337aea243bc2a6990fd3632a4c6584a",
    "title": "Inform: Efficient Information-Theoretic Analysis of Collective Behaviors",
    "abstract": "The study of collective behavior has traditionally relied on a variety of different methodological tools ranging from more theoretical methods such as population or game-theoretic models to empirical ones like Monte Carlo or multi-agent simulations. An approach that is increasingly being explored is the use of information theory as a methodological framework to study the flow of information and the statistical properties of collectives of interacting agents. While a few general purpose toolkits exist, most of the existing software for information theoretic analysis of collective systems is limited in scope. We introduce Inform, an open-source framework for efficient information theoretic analysis that exploits the computational power of a C library while simplifying its use through a variety of wrappers for common higher-level scripting languages. We focus on two such wrappers here: PyInform (Python) and rinform (R). Inform and its wrappers are cross-platform and general-purpose. They include classical information-theoretic measures, measures of information dynamics and information-based methods to study the statistical behavior of collective systems, and expose a lower-level API that allow users to construct measures of their own. We describe the architecture of the Inform framework, study its computational efficiency and use it to analyze three different case studies of collective behavior: biochemical information storage in regenerating planaria, nest-site selection in the ant Temnothorax rugatulus, and collective decision making in multi-agent simulations.",
    "year": 2018,
    "venue": "Frontiers in Robotics and AI",
    "url": "https://www.semanticscholar.org/paper/a38884e3f337aea243bc2a6990fd3632a4c6584a",
    "doi": "10.3389/frobt.2018.00060",
    "arxivId": "",
    "authors": "Douglas G. Moore, Gabriele Valentini, S. Walker, M. Levin",
    "citationCount": 35
  },
  {
    "s2PaperId": "32bc77e83ce5e6d2d3ad65575d0e005e554a5697",
    "title": "dit: a Python package for discrete information theory",
    "abstract": "dit(“Dit: A Python Package for Discrete Information Theory. Available at: Https://Github.com/Dit/Dit” n.d.) is a Python package for the study of discrete information theory. Information theory is a mathematical framework for the study of quantifying, compressing, and communicating random variables (Cover and Thomas 2006)(MacKay 2003)(Yeung 2008). More recently, information theory has been utilized within the physical and social sciences to quantify how different components of a system interact. dit is primarily concerned with this aspect of the theory.",
    "year": 2018,
    "venue": "Journal of Open Source Software",
    "url": "https://www.semanticscholar.org/paper/32bc77e83ce5e6d2d3ad65575d0e005e554a5697",
    "doi": "10.21105/JOSS.00738",
    "arxivId": "",
    "authors": "R. James, C. J. Ellison, J. Crutchfield",
    "citationCount": 58
  },
  {
    "s2PaperId": "8a1739284932f53be60a5cfc08e6824c5412718f",
    "title": "A Tutorial for Information Theory in Neuroscience",
    "abstract": "Abstract Understanding how neural systems integrate, encode, and compute information is central to understanding brain function. Frequently, data from neuroscience experiments are multivariate, the interactions between the variables are nonlinear, and the landscape of hypothesized or possible interactions between variables is extremely broad. Information theory is well suited to address these types of data, as it possesses multivariate analysis tools, it can be applied to many different types of data, it can capture nonlinear interactions, and it does not require assumptions about the structure of the underlying data (i.e., it is model independent). In this article, we walk through the mathematics of information theory along with common logistical problems associated with data type, data binning, data quantity requirements, bias, and significance testing. Next, we analyze models inspired by canonical neuroscience experiments to improve understanding and demonstrate the strengths of information theory analyses. To facilitate the use of information theory analyses, and an understanding of how these analyses are implemented, we also provide a free MATLAB software package that can be applied to a wide range of data from neuroscience experiments, as well as from other fields of study.",
    "year": 2018,
    "venue": "eNeuro",
    "url": "https://www.semanticscholar.org/paper/8a1739284932f53be60a5cfc08e6824c5412718f",
    "doi": "10.1523/ENEURO.0052-18.2018",
    "arxivId": "",
    "authors": "N. Timme, C. Lapish",
    "citationCount": 189
  },
  {
    "s2PaperId": "23f8354eeaf03391fbdeab0e9df551259d49ad66",
    "title": "Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation",
    "abstract": "In this work, we investigate the use of three information-theoretic quantities—entropy, mutual information with the class variable, and a class selectivity measure based on Kullback–Leibler (KL) divergence—to understand and study the behavior of already trained fully connected feedforward neural networks (NNs). We analyze the connection between these information-theoretic quantities and classification performance on the test set by cumulatively ablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our results parallel those recently published by Morcos et al., indicating that class selectivity is not a good indicator for classification performance. However, looking at individual layers separately, both mutual information and class selectivity are positively correlated with classification performance, at least for networks with ReLU activation functions. We provide explanations for this phenomenon and conclude that it is ill-advised to compare the proposed information-theoretic quantities across layers. Furthermore, we show that cumulative ablation of neurons with ascending or descending information-theoretic quantities can be used to formulate hypotheses regarding the joint behavior of multiple neurons, such as redundancy and synergy, with comparably low computational cost. We also draw connections to the information bottleneck theory for NNs.",
    "year": 2018,
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "url": "https://www.semanticscholar.org/paper/23f8354eeaf03391fbdeab0e9df551259d49ad66",
    "doi": "10.1109/TNNLS.2021.3088685",
    "arxivId": "1804.06679",
    "authors": "Rana Ali Amjad, Kairen Liu, B. Geiger",
    "citationCount": 22
  },
  {
    "s2PaperId": "d7e786739735f3107f4817b4382248e80a89ef1d",
    "title": "Understanding Convolutional Neural Networks With Information Theory: An Initial Exploration",
    "abstract": "A novel functional estimator for Rényi’s $\\alpha $ -entropy and its multivariate extension was recently proposed in terms of the normalized eigenspectrum of a Hermitian matrix of the projected data in a reproducing kernel Hilbert space (RKHS). However, the utility and possible applications of these new estimators are rather new and mostly unknown to practitioners. In this brief, we first show that this estimator enables straightforward measurement of information flow in realistic convolutional neural networks (CNNs) without any approximation. Then, we introduce the partial information decomposition (PID) framework and develop three quantities to analyze the synergy and redundancy in convolutional layer representations. Our results validate two fundamental data processing inequalities and reveal more inner properties concerning CNN training.",
    "year": 2018,
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "url": "https://www.semanticscholar.org/paper/d7e786739735f3107f4817b4382248e80a89ef1d",
    "doi": "10.1109/TNNLS.2020.2968509",
    "arxivId": "1804.06537",
    "authors": "Shujian Yu, Kristoffer Wickstrøm, R. Jenssen, J. Príncipe",
    "citationCount": 77
  },
  {
    "s2PaperId": "fcdf8fee148179f7bf26a8254cb82c86321811d2",
    "title": "Understanding Individual Neuron Importance Using Information Theory",
    "abstract": "",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/fcdf8fee148179f7bf26a8254cb82c86321811d2",
    "doi": "",
    "arxivId": "",
    "authors": "Kairen Liu, Rana Ali Amjad, B. Geiger",
    "citationCount": 33
  },
  {
    "s2PaperId": "3ffc862ab46bde05b0f95c376fb593c0ec4863f1",
    "title": "Understanding Convolutional Neural Network Training with Information Theory",
    "abstract": "",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/3ffc862ab46bde05b0f95c376fb593c0ec4863f1",
    "doi": "",
    "arxivId": "",
    "authors": "Shujian Yu, R. Jenssen, J. Príncipe",
    "citationCount": 27
  },
  {
    "s2PaperId": "7b397706e7dcda0f5353d4a515bdf79b1739b6db",
    "title": "Topological Information Data Analysis: Poincare-Shannon Machine and Statistical Physic of Finite Heterogeneous Systems",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/7b397706e7dcda0f5353d4a515bdf79b1739b6db",
    "doi": "10.20944/PREPRINTS201804.0157.V1",
    "arxivId": "",
    "authors": "P. Baudot, Mónica Tapia, Jean-Marc Goaillard",
    "citationCount": 6
  },
  {
    "s2PaperId": "2f71f7e5c5c561280f88550f6159962e56912942",
    "title": "Information Decomposition of Target Effects from Multi-Source Interactions: Perspectives on Previous, Current and Future Work",
    "abstract": "The formulation of the Partial Information Decomposition (PID) framework by Williams and Beer in 2010 attracted a significant amount of attention to the problem of defining redundant (or shared), unique and synergistic (or complementary) components of mutual information that a set of source variables provides about a target. This attention resulted in a number of measures proposed to capture these concepts, theoretical investigations into such measures, and applications to empirical data (in particular to datasets from neuroscience). In this Special Issue on “Information Decomposition of Target Effects from Multi-Source Interactions” at Entropy, we have gathered current work on such information decomposition approaches from many of the leading research groups in the field. We begin our editorial by providing the reader with a review of previous information decomposition research, including an overview of the variety of measures proposed, how they have been interpreted and applied to empirical investigations. We then introduce the articles included in the special issue one by one, providing a similar categorisation of these articles into: i. proposals of new measures; ii. theoretical investigations into properties and interpretations of such approaches, and iii. applications of these measures in empirical studies. We finish by providing an outlook on the future of the field.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2f71f7e5c5c561280f88550f6159962e56912942",
    "doi": "10.3390/e20040307",
    "arxivId": "",
    "authors": "J. Lizier, Nils Bertschinger, J. Jost, M. Wibral",
    "citationCount": 137
  },
  {
    "s2PaperId": "49467615a0da4591ea5e1f516b3203d96e66aa59",
    "title": "Computation is concentrated in rich clubs of local cortical neurons",
    "abstract": "To understand how neural circuits process information, it is essential to identify the relationship between computation and circuit topology. Rich-clubs, highly interconnected sets of neurons, are known to propagate a disproportionate amount of information within cortical circuits. Here, we test the hypothesis that rich-clubs also perform a disproportionate amount of computation. To do so, we recorded the spiking activity of on average ∼300 well-isolated individual neurons from organotypic cortical cultures. We then constructed weighted, directed networks reflecting the effective connectivity between the neurons. For each neuron, we quantified the amount of computation it performed based on its inputs. We found that rich-club neurons compute ∼200% more information than neurons outside of the rich club. Indeed, the amount of computation performed in the rich-club was proportional to the amount information propagation by the same neurons. This suggests that, in these circuits, information propagation drives computation. Comparing the computation-to-propagation ratio inside versus outside of the rich club showed that rich clubs compute at a slightly, though significantly, reduced level (∼4% lower). In total, our findings indicate that rich club topology in effective cortical circuits supports not only information propagation but also neural computation. AUTHOR SUMMARY Here we answer the question of whether rich club topology in functional cortical circuits supports neural computation as it has been previously shown to do for information propagation. To do so, we combined network analysis with information theoretic tools to analyze the spiking activity of hundreds of neurons recorded from organotypic cultures of mouse somatosensory cortex. We found that neurons in rich clubs computed significantly more than neurons outside of rich clubs, suggesting that rich-clubs do support computation in cortical circuits. Indeed, the amount of computation that we found in the rich club was proportional to the amount of information they propagate suggesting that, in these circuits, information propagation drives computation.",
    "year": 2018,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/49467615a0da4591ea5e1f516b3203d96e66aa59",
    "doi": "10.1101/290981",
    "arxivId": "",
    "authors": "Samantha P Faber, N. Timme, John M. Beggs, E. Newman",
    "citationCount": 1
  },
  {
    "s2PaperId": "a4c50211775d78a3ae3526d72697165c090008bf",
    "title": "Maternal deprivation induces alterations in cognitive and cortical function in adulthood",
    "abstract": "Early life trauma is a risk factor for a number of neuropsychiatric disorders, including schizophrenia (SZ). The current study assessed how an early life traumatic event, maternal deprivation (MD), alters cognition and brain function in rodents. Rats were maternally deprived in the early postnatal period and then recognition memory (RM) was tested in adulthood using the novel object recognition task. The expression of catechol-o-methyl transferase (COMT) and glutamic acid decarboxylase (GAD67) were quantified in the medial prefrontal cortex (mPFC), ventral striatum, and temporal cortex (TC). In addition, depth EEG recordings were obtained from the mPFC, vertex, and TC during a paired-click paradigm to assess the effects of MD on sensory gating. MD animals exhibited impaired RM, lower expression of COMT in the mPFC and TC, and lower expression of GAD67 in the TC. Increased bioelectric noise was observed at each recording site of MD animals. MD animals also exhibited altered information theoretic measures of stimulus encoding. These data indicate that a neurodevelopmental perturbation yields persistent alterations in cognition and brain function, and are consistent with human studies that identified relationships between allelic differences in COMT and GAD67 and bioelectric noise. These changes evoked by MD also lead to alterations in shared information between cognitive and primary sensory processing areas, which provides insight into how early life trauma confers a risk for neurodevelopmental disorders, such as SZ, later in life.",
    "year": 2018,
    "venue": "Translational Psychiatry",
    "url": "https://www.semanticscholar.org/paper/a4c50211775d78a3ae3526d72697165c090008bf",
    "doi": "10.1038/s41398-018-0119-5",
    "arxivId": "",
    "authors": "Sarine S. Janetsian-Fritz, N. Timme, Maureen M. Timm, Aqilah M. McCane, Anthony J. Baucum II, B. O’Donnell, C. Lapish",
    "citationCount": 30
  },
  {
    "s2PaperId": "1506255c8354dbcfd1059671cb0cf44ba1e49252",
    "title": "Contrasting information theoretic decompositions of modulatory and arithmetic interactions in neural information processing systems",
    "abstract": "Biological and artificial neural systems are composed of many local processors, and their capabilities depend upon the transfer function that relates each local processor's outputs to its inputs. This paper uses a recent advance in the foundations of information theory to study the properties of local processors that use contextual input to amplify or attenuate transmission of information about their driving inputs. This advance enables the information transmitted by processors with two distinct inputs to be decomposed into those components unique to each input, that shared between the two inputs, and that which depends on both though it is in neither, i.e. synergy. The decompositions that we report here show that contextual modulation has information processing properties that contrast with those of all four simple arithmetic operators, that it can take various forms, and that the form used in our previous studies of artificial neural nets composed of local processors with both driving and contextual inputs is particularly well-suited to provide the distinctive capabilities of contextual modulation under a wide range of conditions. We argue that the decompositions reported here could be compared with those obtained from empirical neurobiological and psychophysical data under conditions thought to reflect contextual modulation. That would then shed new light on the underlying processes involved. Finally, we suggest that such decompositions could aid the design of context-sensitive machine learning algorithms.",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/1506255c8354dbcfd1059671cb0cf44ba1e49252",
    "doi": "",
    "arxivId": "1803.05897",
    "authors": "J. Kay, W. A. Phillips",
    "citationCount": 7
  },
  {
    "s2PaperId": "5e658624ec57f2167bcea3e7830b6c49eae179b7",
    "title": "Exact Partial Information Decompositions for Gaussian Systems Based on Dependency Constraints",
    "abstract": "The Partial Information Decomposition, introduced by Williams P. L. et al. (2010), provides a theoretical framework to characterize and quantify the structure of multivariate information sharing. A new method (Idep) has recently been proposed by James R. G. et al. (2017) for computing a two-predictor partial information decomposition over discrete spaces. A lattice of maximum entropy probability models is constructed based on marginal dependency constraints, and the unique information that a particular predictor has about the target is defined as the minimum increase in joint predictor-target mutual information when that particular predictor-target marginal dependency is constrained. Here, we apply the Idep approach to Gaussian systems, for which the marginally constrained maximum entropy models are Gaussian graphical models. Closed form solutions for the Idep PID are derived for both univariate and multivariate Gaussian systems. Numerical and graphical illustrations are provided, together with practical and theoretical comparisons of the Idep PID with the minimum mutual information partial information decomposition (Immi), which was discussed by Barrett A. B. (2015). The results obtained using Idep appear to be more intuitive than those given with other methods, such as Immi, in which the redundant and unique information components are constrained to depend only on the predictor-target marginal distributions. In particular, it is proved that the Immi method generally produces larger estimates of redundancy and synergy than does the Idep method. In discussion of the practical examples, the PIDs are complemented by the use of tests of deviance for the comparison of Gaussian graphical models.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5e658624ec57f2167bcea3e7830b6c49eae179b7",
    "doi": "10.3390/e20040240",
    "arxivId": "1803.02030",
    "authors": "James W. Kay, Robin A. A. Ince",
    "citationCount": 11
  },
  {
    "s2PaperId": "fcdee23215deb6f6b3ecd5f18165d739a8dc59e4",
    "title": "Nonlinear higher order abiotic interactions explain riverine biodiversity",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/fcdee23215deb6f6b3ecd5f18165d739a8dc59e4",
    "doi": "10.1111/jbi.13164",
    "arxivId": "",
    "authors": "M. Ryo, Eric Harvey, C. Robinson, F. Altermatt",
    "citationCount": 31
  },
  {
    "s2PaperId": "55ce82840f2c7272a2e50ddeda4f2a479e4b999a",
    "title": "Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism",
    "abstract": "Complex data usually results from the interaction of objects produced by different generating mechanisms. Here we introduce a universal, unsupervised and parameter-free model-oriented approach, based upon the seminal concept of algorithmic probability, that decomposes an observation into its most likely algorithmic generative sources. Our approach uses a causal calculus to infer model representations. We demonstrate its ability to deconvolve interacting mechanisms regardless of whether the resultant objects are strings, space-time evolution diagrams, images or networks. While this is mostly a conceptual contribution and a novel framework, we provide numerical evidence evaluating the ability of our methods to separate data from observations produced by discrete dynamical systems such as cellular automata and complex networks. We think that these separating techniques can contribute to tackling the challenge of causation, thus complementing other statistically oriented approaches.",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/55ce82840f2c7272a2e50ddeda4f2a479e4b999a",
    "doi": "",
    "arxivId": "1802.09904",
    "authors": "H. Zenil, N. Kiani, Allan A. Zea, J. Tegnér",
    "citationCount": 1
  },
  {
    "s2PaperId": "164b1558f9b2a3ea62c64da00f9e8151d40d3015",
    "title": "Ab initio Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism",
    "abstract": "",
    "year": 2018,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/164b1558f9b2a3ea62c64da00f9e8151d40d3015",
    "doi": "",
    "arxivId": "",
    "authors": "H. Zenil, N. Kiani, Jesper Tegnér",
    "citationCount": 0
  },
  {
    "s2PaperId": "96c7b712d34c2c7ef75ac97fd4a4c0fc987b2c82",
    "title": "Empirical Bayes Meets Information Theoretical Network Reconstruction from Single Cell Data",
    "abstract": "Gene expression is controlled by networks of transcription factors and regulators, but the structure of these networks is as yet poorly understood and is thus inferred from data. Recent work has shown the efficacy of information theoretical approaches for network reconstruction from single cell transcriptomic data. Such methods use information to estimate dependence between every pair of genes in the dataset, then edges are inferred between top-scoring pairs. Dependence, however, does not indicate significance, and the definition of “top-scoring” is often arbitrary and a priori related to expected network size. This makes comparing networks across datasets difficult, because networks of a similar size are not necessarily similarly accurate. We present a method for performing formal hypothesis tests on putative network edges derived from information theory, bringing together empirical Bayes and work on theoretical null distributions for information measures. Thresholding based on empirical Bayes allows us to control network accuracy according to how we intend to use the network. Using single cell data from mouse pluripotent stem cells, we recover known interactions and suggest several new interactions for experimental validation (using a stringent threshold) and discover high-level interactions between sub-networks (using a more relaxed threshold). Furthermore, our method allows for the inclusion of prior information. We use in-silico data to show that even relatively poor quality prior information can increase the accuracy of a network, and demonstrate that the accuracy of networks inferred from single cell data can sometimes be improved by priors from population-level ChIP-Seq and qPCR data.",
    "year": 2018,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/96c7b712d34c2c7ef75ac97fd4a4c0fc987b2c82",
    "doi": "10.1101/264853",
    "arxivId": "",
    "authors": "Thalia E. Chan, Ananth Pallaseni, A. Babtie, Kirsten R. McEwen, M. Stumpf",
    "citationCount": 10
  },
  {
    "s2PaperId": "709ab0c8f519fa2244cedb2ed901c5c78e2fb635",
    "title": "BROJA-2PID: A Robust Estimator for Bivariate Partial Information Decomposition",
    "abstract": "Makkeh, Theis, and Vicente found that Cone Programming model is the most robust to compute the Bertschinger et al. partial information decomposition (BROJA PID) measure. We developed a production-quality robust software that computes the BROJA PID measure based on the Cone Programming model. In this paper, we prove the important property of strong duality for the Cone Program and prove an equivalence between the Cone Program and the original Convex problem. Then, we describe in detail our software, explain how to use it, and perform some experiments comparing it to other estimators. Finally, we show that the software can be extended to compute some quantities of a trivaraite PID measure.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/709ab0c8f519fa2244cedb2ed901c5c78e2fb635",
    "doi": "10.3390/e20040271",
    "arxivId": "1802.02485",
    "authors": "Abdullah Makkeh, D. Theis, Raul Vicente",
    "citationCount": 33
  },
  {
    "s2PaperId": "2672a013165ba76e6645fe2154a93d75cc2f29f7",
    "title": "Probability Mass Exclusions and the Directed Components of Mutual Information",
    "abstract": "Information is often described as a reduction of uncertainty associated with a restriction of possible choices. Despite appearing in Hartley’s foundational work on information theory, there is a surprising lack of a formal treatment of this interpretation in terms of exclusions. This paper addresses the gap by providing an explicit characterisation of information in terms of probability mass exclusions. It then demonstrates that different exclusions can yield the same amount of information and discusses the insight this provides about how information is shared amongst random variables—lack of progress in this area is a key barrier preventing us from understanding how information is distributed in complex systems. The paper closes by deriving a decomposition of the mutual information which can distinguish between differing exclusions; this provides surprising insight into the nature of directed information.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2672a013165ba76e6645fe2154a93d75cc2f29f7",
    "doi": "10.3390/e20110826",
    "arxivId": "1801.09223",
    "authors": "Conor Finn, J. Lizier",
    "citationCount": 15
  },
  {
    "s2PaperId": "932f1420dd8f3b67ba5fa358cde610010ac194f7",
    "title": "Pointwise Partial Information DecompositionUsing the Specificity and Ambiguity Lattices",
    "abstract": "What are the distinct ways in which a set of predictor variables can provide information about a target variable? When does a variable provide unique information, when do variables share redundant information, and when do variables combine synergistically to provide complementary information? The redundancy lattice from the partial information decomposition of Williams and Beer provided a promising glimpse at the answer to these questions. However, this structure was constructed using a much criticised measure of redundant information, and despite sustained research, no completely satisfactory replacement measure has been proposed. In this paper, we take a different approach, applying the axiomatic derivation of the redundancy lattice to a single realisation from a set of discrete variables. To overcome the difficulty associated with signed pointwise mutual information, we apply this decomposition separately to the unsigned entropic components of pointwise mutual information which we refer to as the specificity and ambiguity. This yields a separate redundancy lattice for each component. Then based upon an operational interpretation of redundancy, we define measures of redundant specificity and ambiguity enabling us to evaluate the partial information atoms in each lattice. These atoms can be recombined to yield the sought-after multivariate information decomposition. We apply this framework to canonical examples from the literature and discuss the results and the various properties of the decomposition. In particular, the pointwise decomposition using specificity and ambiguity satisfies a chain rule over target variables, which provides new insights into the so-called two-bit-copy example.",
    "year": 2018,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/932f1420dd8f3b67ba5fa358cde610010ac194f7",
    "doi": "10.3390/e20040297",
    "arxivId": "1801.09010",
    "authors": "Conor Finn, J. Lizier",
    "citationCount": 96
  },
  {
    "s2PaperId": "0ec37d8c8744b9f8f10134b9fd74968d1dd07fac",
    "title": "Quantifying how much sensory information in a neural code is relevant for behavior",
    "abstract": "Determining how much of the sensory information carried by a neural code contributes to behavioral performance is key to understand sensory function and neural information flow. However, there are as yet no analytical tools to compute this information that lies at the intersection between sensory coding and behavioral readout. Here we develop a novel measure, termed the information-theoretic intersection information $I_{II}(S;R;C)$, that quantifies how much of the sensory information carried by a neural response R is used for behavior during perceptual discrimination tasks. Building on the Partial Information Decomposition framework, we define $I_{II}(S;R;C)$ as the part of the mutual information between the stimulus S and the response R that also informs the consequent behavioral choice C. We compute $I_{II}(S;R;C)$ in the analysis of two experimental cortical datasets, to show how this measure can be used to compare quantitatively the contributions of spike timing and spike rates to task performance, and to identify brain areas or neural populations that specifically transform sensory information into choice.",
    "year": 2017,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/0ec37d8c8744b9f8f10134b9fd74968d1dd07fac",
    "doi": "",
    "arxivId": "1712.02449",
    "authors": "Giuseppe Pica, Eugenio Piasini, Houman Safaai, C. Runyan, C. Harvey, M. Diamond, C. Kayser, Tommaso Fellin, S. Panzeri",
    "citationCount": 45
  },
  {
    "s2PaperId": "fe9907cf434674101502d38db1aa7cc38deefc69",
    "title": "Analyzing Information Distribution in Complex Systems",
    "abstract": "Information theory is often utilized to capture both linear as well as nonlinear relationships between any two parts of a dynamical complex system. Recently, an extension to classical information theory called partial information decomposition has been developed, which allows one to partition the information that two subsystems have about a third one into unique, redundant and synergistic contributions. Here, we apply a recent estimator of partial information decomposition to characterize the dynamics of two different complex systems. First, we analyze the distribution of information in triplets of spins in the 2D Ising model as a function of temperature. We find that while redundant information obtains a maximum at the critical point, synergistic information peaks in the disorder phase. Secondly, we characterize 1D elementary cellular automata rules based on the information distribution between neighboring cells. We describe several clusters of rules with similar partial information decomposition. These examples illustrate how the partial information decomposition provides a characterization of the emergent dynamics of complex systems in terms of the information distributed across their interacting units.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/fe9907cf434674101502d38db1aa7cc38deefc69",
    "doi": "10.3390/e19120636",
    "arxivId": "",
    "authors": "Sten Sootla, D. Theis, Raul Vicente",
    "citationCount": 12
  },
  {
    "s2PaperId": "487c8956201977e436879709e6ec8d5042ec6e79",
    "title": "Pointwise Information Decomposition Using the Specificity and Ambiguity Lattices",
    "abstract": "Multivariate information theory has long been problematic.  Recently, the partial information decomposition (PID) of Williams and Beer has provided a promising axiomatic framework which clarifies the general structure of multivariate information.  However, PID lacks the necessary measure of redundant information required to complete the framework; despite much recent research, no well-accepted measure of redundant information has emerged that is applicable to more than two sources and respects the locality of information.  In this paper, we introduce a new framework based upon the axiomatic approach taken in PID but which aims to decompose multivariate information on a local or pointwise scale.  It is shown that in order to identify when information from two sources is indeed the same information, one must consider decomposing the local mutual information into its two directed components, the specificity and the ambiguity.  Based upon the axiomatic approach taken in PID, we decompose these two components separately resulting in two lattices - the specificity and ambiguity lattices.  This Specificity and Ambiguity decomposition retains the appealing multivariate structure provided by PID, but applying this notion on a much more granular level enables the decomposition to identify when information is the same information. This last point is justified by providing an operational interpretation of redundancy in terms of Kelly gambling.  Applying the decomposition to canonical examples from the PID literature demonstrates the unique ability to provide a pointwise decomposition, and the fact that the Specificity and Ambiguity decomposition possesses the much sought-after target chain rule. Finally, interpreting these results sheds light on why defining a redundancy measure for PID has proven to be so difficult - one lattice is not enough.",
    "year": 2017,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/487c8956201977e436879709e6ec8d5042ec6e79",
    "doi": "10.3390/ecea-4-05024",
    "arxivId": "",
    "authors": "Conor Finn, J. Lizier",
    "citationCount": 6
  },
  {
    "s2PaperId": "1f50bc3569e72d24733bb68ffa5d0da83041b12d",
    "title": "The Identity of Information: How Deterministic Dependencies Constrain Information Synergy and Redundancy",
    "abstract": "Understanding how different information sources together transmit information is crucial in many domains. For example, understanding the neural code requires characterizing how different neurons contribute unique, redundant, or synergistic pieces of information about sensory or behavioral variables. Williams and Beer (2010) proposed a partial information decomposition (PID) that separates the mutual information that a set of sources contains about a set of targets into nonnegative terms interpretable as these pieces. Quantifying redundancy requires assigning an identity to different information pieces, to assess when information is common across sources. Harder et al. (2013) proposed an identity axiom that imposes necessary conditions to quantify qualitatively common information. However, Bertschinger et al. (2012) showed that, in a counterexample with deterministic target-source dependencies, the identity axiom is incompatible with ensuring PID nonnegativity. Here, we study systematically the consequences of information identity criteria that assign identity based on associations between target and source variables resulting from deterministic dependencies. We show how these criteria are related to the identity axiom and to previously proposed redundancy measures, and we characterize how they lead to negative PID terms. This constitutes a further step to more explicitly address the role of information identity in the quantification of redundancy. The implications for studying neural coding are discussed.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/1f50bc3569e72d24733bb68ffa5d0da83041b12d",
    "doi": "10.3390/e20030169",
    "arxivId": "1711.11408",
    "authors": "D. Chicharro, Giuseppe Pica, S. Panzeri",
    "citationCount": 6
  },
  {
    "s2PaperId": "018d956adf89afdd0e74f06c310c43b956af143a",
    "title": "Towards measuring the semantic capacity of a physical medium demonstrated with elementary cellular automata",
    "abstract": "",
    "year": 2017,
    "venue": "Biosyst.",
    "url": "https://www.semanticscholar.org/paper/018d956adf89afdd0e74f06c310c43b956af143a",
    "doi": "10.1016/j.biosystems.2017.11.007",
    "arxivId": "",
    "authors": "P. Dittrich",
    "citationCount": 4
  },
  {
    "s2PaperId": "453a14b4749e7d937029301ae289733805e088c2",
    "title": "Inform: A toolkit for information-theoretic analysis of complex systems",
    "abstract": "",
    "year": 2017,
    "venue": "IEEE Symposium Series on Computational Intelligence",
    "url": "https://www.semanticscholar.org/paper/453a14b4749e7d937029301ae289733805e088c2",
    "doi": "10.1109/SSCI.2017.8285197",
    "arxivId": "",
    "authors": "Douglas G. Moore, Gabriele Valentini, S. Walker, M. Levin",
    "citationCount": 9
  },
  {
    "s2PaperId": "5238bcfabd8cc006bdac50271479fdf3618e94d1",
    "title": "Partial and Entropic Information Decompositions of a Neuronal Modulatory Interaction",
    "abstract": "Information processing within neural systems often depends upon selective amplification of relevant signals and suppression of irrelevant signals. This has been shown many times by studies of contextual effects but there is as yet no consensus on how to interpret such studies. Some researchers interpret the effects of context as contributing to the selective receptive field (RF) input about which neurons transmit information. Others interpret context effects as affecting transmission of information about RF input without becoming part of the RF information transmitted. Here we use partial information decomposition (PID) and entropic information decomposition (EID) to study the properties of a form of modulation previously used in neurobiologically plausible neural nets. PID shows that this form of modulation can affect transmission of information in the RF input without the binary output transmitting any information unique to the modulator. EID produces similar decompositions, except that information unique to the modulator and the mechanistic shared component can be negative when modulating and modulated signals are correlated. Synergistic and source shared components were never negative in the conditions studied. Thus, both PID and EID show that modulatory inputs to a local processor can affect the transmission of information from other inputs. Contrary to what was previously assumed, this transmission can occur without the modulatory inputs becoming part of the information transmitted, as shown by the use of PID with the model we consider. Decompositions of psychophysical data from a visual contrast detection task with surrounding context suggest that a similar form of modulation may also occur in real neural systems.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5238bcfabd8cc006bdac50271479fdf3618e94d1",
    "doi": "10.3390/e19110560",
    "arxivId": "",
    "authors": "J. Kay, Robin A. A. Ince, Benjamin R. Dering, W. A. Phillips",
    "citationCount": 25
  },
  {
    "s2PaperId": "551b106b5fb4b6e6765f71001f18a3e607be99c0",
    "title": "Entrained audiovisual speech integration implemented by two independent computational mechanisms: Redundancy in left posterior superior temporal gyrus and Synergy in left motor cortex",
    "abstract": "Information integration is fundamental to many aspects of human behavior, and yet its neural mechanism remains to be understood. For example, during face-to-face communication we know that the brain integrates the auditory and visual inputs but we do not yet understand where and how such integration mechanisms support speech comprehension. Here we show that two independent mechanisms forge audiovisual representations for speech comprehension in different brain regions. With a novel information theoretic measure, we found that theta (3-7 Hz) oscillations in the posterior superior temporal gyrus/sulcus (pSTG/S) code speech information that is common (i.e. redundant) to the auditory and visual inputs whereas the same oscillations in left motor and inferior temporal cortex code synergistic information between the same inputs. Importantly, redundant coding in the left pSTG/S and synergistic coding in the left motor cortex predict behavior - i.e. speech comprehension performance. Our findings therefore demonstrate that processes classically described as integration effectively reflect independent mechanisms that occur in different brain regions to support audiovisual speech comprehension.",
    "year": 2017,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/551b106b5fb4b6e6765f71001f18a3e607be99c0",
    "doi": "10.1101/202911",
    "arxivId": "",
    "authors": "Hyojin Park, Robin A. A. Ince, P. Schyns, G. Thut, J. Gross",
    "citationCount": 0
  },
  {
    "s2PaperId": "cbe523a55b4a8219c66f0e81214be5d5e1913b79",
    "title": "Bivariate Partial Information Decomposition: The Optimization Perspective",
    "abstract": "Bertschinger, Rauh, Olbrich, Jost, and Ay (Entropy, 2014) have proposed a definition of a decomposition of the mutual information M I ( X : Y , Z ) into shared, synergistic, and unique information by way of solving a convex optimization problem. In this paper, we discuss the solution of their Convex Program from theoretical and practical points of view.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/cbe523a55b4a8219c66f0e81214be5d5e1913b79",
    "doi": "10.3390/e19100530",
    "arxivId": "",
    "authors": "Abdullah Makkeh, D. Theis, Raul Vicente",
    "citationCount": 31
  },
  {
    "s2PaperId": "f7fc22c7b3d2ff48b466508f83b1a580858e5127",
    "title": "Disentangled representations via synergy minimization",
    "abstract": "Scientists often seek simplified representations of complex systems to facilitate prediction and understanding. If the factors comprising a representation allow us to make accurate predictions about our system, but obscuring any subset of the factors destroys our ability to make predictions, we say that the representation exhibits informational synergy. We argue that synergy is an undesirable feature in learned representations and that explicitly minimizing synergy can help disentangle the true factors of variation underlying data. We explore different ways of quantifying synergy, deriving new closed-form expressions in some cases, and then show how to modify learning to produce representations that are minimally synergistic. We introduce a benchmark task to disentangle separate characters from images of words. We demonstrate that Minimally Synergistic (MinSyn) representations correctly disentangle characters while methods relying on statistical independence fail.",
    "year": 2017,
    "venue": "Allerton Conference on Communication, Control, and Computing",
    "url": "https://www.semanticscholar.org/paper/f7fc22c7b3d2ff48b466508f83b1a580858e5127",
    "doi": "10.1109/ALLERTON.2017.8262735",
    "arxivId": "1710.03839",
    "authors": "G. V. Steeg, Rob Brekelmans, Hrayr Harutyunyan, A. Galstyan",
    "citationCount": 6
  },
  {
    "s2PaperId": "7b91daf8a2d0766b7b6114fcff8f05b39f9a1496",
    "title": "Information processing features can detect behavioral regimes of dynamical systems",
    "abstract": "In dynamical systems, local interactions between dynamical units generate correlations which are stored and transmitted throughout the system, generating the macroscopic behavior. However a framework to quantify and study this at the microscopic scale is missing. Here we propose an 'information processing' framework based on Shannon mutual information quantities between the initial and future states. We apply it to the 256 elementary cellular automata (ECA), which are the simplest possible dynamical systems exhibiting behaviors ranging from simple to complex. Our main finding for ECA is that only a few features are needed for full predictability and that the 'information integration' (synergy) feature is always most predictive. Finally we apply the formalism to foreign exchange (FX) and interest-rate swap (IRS) time series data and find that the 2008 financial crisis marks a sudden and sustained regime shift (FX and EUR IRS) resembling tipping point behavior. The USD IRS market exhibits instead a slow and steady progression which appears consistent with the hypothesis that this market is (part of) the driving force behind the crisis. Our work suggests that the proposed framework is a promising way of predicting emergent complex systemic behaviors in terms of the local information processing of units.",
    "year": 2017,
    "venue": "Complex",
    "url": "https://www.semanticscholar.org/paper/7b91daf8a2d0766b7b6114fcff8f05b39f9a1496",
    "doi": "10.1155/2018/6047846",
    "arxivId": "1709.09447",
    "authors": "Rick Quax, Gregor Chliamovitch, Alexandre Dupuis, J. Falcone, B. Chopard, A. Hoekstra, P. Sloot",
    "citationCount": 8
  },
  {
    "s2PaperId": "378f7ad14dace20a2f9ab4f8d6d85b65affd9e61",
    "title": "Stem Cell Differentiation as a Non-Markov Stochastic Process",
    "abstract": "",
    "year": 2017,
    "venue": "Cell Systems",
    "url": "https://www.semanticscholar.org/paper/378f7ad14dace20a2f9ab4f8d6d85b65affd9e61",
    "doi": "10.1016/j.cels.2017.08.009",
    "arxivId": "",
    "authors": "Patrick S. Stumpf, Rosanna C. G. Smith, M. Lenz, A. Schuppert, F. Müller, A. Babtie, Thalia E. Chan, M. Stumpf, C. Please, S. Howison, F. Arai, B. MacArthur",
    "citationCount": 168
  },
  {
    "s2PaperId": "51b54ec27bc8ac90ef612937aaa5248b3d086b9d",
    "title": "Computing the Unique Information",
    "abstract": "Given a pair of predictor variables and a response variable, how much information do the predictors have about the response, and how is this information distributed between unique, redundant, and synergistic components? Recent work has proposed to quantify the unique component of the decomposition as the minimum value of the conditional mutual information over a constrained set of information channels. We present an efficient iterative divergence minimization algorithm to solve this optimization problem with convergence guarantees and evaluate its performance against other techniques. A full version of this paper is accessible at: https://arxiv.org/abs/1709.07487",
    "year": 2017,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/51b54ec27bc8ac90ef612937aaa5248b3d086b9d",
    "doi": "10.1109/ISIT.2018.8437757",
    "arxivId": "1709.07487",
    "authors": "P. Banerjee, Johannes Rauh, Guido Montúfar",
    "citationCount": 29
  },
  {
    "s2PaperId": "e683d1e94b96b44e0ff1831d20cc17c177d5ba89",
    "title": "Unique information via dependency constraints",
    "abstract": "The partial information decomposition (PID) is perhaps the leading proposal for resolving information shared between a set of sources and a target into redundant, synergistic, and unique constituents. Unfortunately, the PID framework has been hindered by a lack of a generally agreed-upon, multivariate method of quantifying the constituents. Here, we take a step toward rectifying this by developing a decomposition based on a new method that quantifies unique information. We first develop a broadly applicable method—the dependency decomposition—that delineates how statistical dependencies influence the structure of a joint distribution. The dependency decomposition then allows us to define a measure of the information about a target that can be uniquely attributed to a particular source as the least amount which the source-target statistical dependency can influence the information shared between the sources and the target. The result is the first measure that satisfies the core axioms of the PID framework while not satisfying the Blackwell relation, which depends on a particular interpretation of how the variables are related. This makes a key step forward to a practical PID.",
    "year": 2017,
    "venue": "Journal of Physics A: Mathematical and Theoretical",
    "url": "https://www.semanticscholar.org/paper/e683d1e94b96b44e0ff1831d20cc17c177d5ba89",
    "doi": "10.1088/1751-8121/aaed53",
    "arxivId": "1709.06653",
    "authors": "R. James, Jeffrey Emenheiser, J. Crutchfield",
    "citationCount": 51
  },
  {
    "s2PaperId": "75aeba0f8a1c1b749c4e386935ef9ddb361b1b63",
    "title": "Quantifying Information Modification in Developing Neural Networks via Partial Information Decomposition",
    "abstract": "Information processing performed by any system can be conceptually decomposed into the transfer, storage and modification of information—an idea dating all the way back to the work of Alan Turing. However, formal information theoretic definitions until very recently were only available for information transfer and storage, not for modification. This has changed with the extension of Shannon information theory via the decomposition of the mutual information between inputs to and the output of a process into unique, shared and synergistic contributions from the inputs, called a partial information decomposition (PID). The synergistic contribution in particular has been identified as the basis for a definition of information modification. We here review the requirements for a functional definition of information modification in neuroscience, and apply a recently proposed measure of information modification to investigate the developmental trajectory of information modification in a culture of neurons vitro, using partial information decomposition. We found that modification rose with maturation, but ultimately collapsed when redundant information among neurons took over. This indicates that this particular developing neural system initially developed intricate processing capabilities, but ultimately displayed information processing that was highly similar across neurons, possibly due to a lack of external inputs. We close by pointing out the enormous promise PID and the analysis of information modification hold for the understanding of neural systems.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/75aeba0f8a1c1b749c4e386935ef9ddb361b1b63",
    "doi": "10.3390/e19090494",
    "arxivId": "",
    "authors": "M. Wibral, Conor Finn, Patricia Wollstadt, J. Lizier, V. Priesemann",
    "citationCount": 62
  },
  {
    "s2PaperId": "3d934d6f5c81499378f5f1b2323003fbfbccf695",
    "title": "The Partial Information Decomposition of Generative Neural Network Models",
    "abstract": "In this work we study the distributed representations learnt by generative neural network models. In particular, we investigate the properties of redundant and synergistic information that groups of hidden neurons contain about the target variable. To this end, we use an emerging branch of information theory called partial information decomposition (PID) and track the informational properties of the neurons through training. We find two differentiated phases during the training process: a first short phase in which the neurons learn redundant information about the target, and a second phase in which neurons start specialising and each of them learns unique information about the target. We also find that in smaller networks individual neurons learn more specific information about certain features of the input, suggesting that learning pressure can encourage disentangled representations.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/3d934d6f5c81499378f5f1b2323003fbfbccf695",
    "doi": "10.3390/e19090474",
    "arxivId": "",
    "authors": "T. M. S. Tax, P. Mediano, M. Shanahan",
    "citationCount": 74
  },
  {
    "s2PaperId": "04478ccd54a2d833f8d37fe7c68b1708cfe7f352",
    "title": "Morphological Computation: Synergy of Body and Brain",
    "abstract": "There are numerous examples that show how the exploitation of the body’s physical properties can lift the burden of the brain. Examples include grasping, swimming, locomotion, and motion detection. The term Morphological Computation was originally coined to describe processes in the body that would otherwise have to be conducted by the brain. In this paper, we argue for a synergistic perspective, and by that we mean that Morphological Computation is a process which requires a close interaction of body and brain. Based on a model of the sensorimotor loop, we study a new measure of synergistic information and show that it is more reliable in cases in which there is no synergistic information, compared to previous results. Furthermore, we discuss an algorithm that allows the calculation of the measure in non-trivial (non-binary) systems.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/04478ccd54a2d833f8d37fe7c68b1708cfe7f352",
    "doi": "10.3390/e19090456",
    "arxivId": "",
    "authors": "K. Zahedi, Carlotta Langer, N. Ay",
    "citationCount": 26
  },
  {
    "s2PaperId": "e5ae8b1458b660058bafc6329e6ab04ca77191cc",
    "title": "Quantifying multivariate redundancy with maximum entropy decompositions of mutual information",
    "abstract": "Williams and Beer (2010) proposed a nonnegative mutual information decomposition, based on the construction of redundancy lattices, which allows separating the information that a set of variables contains about a target variable into nonnegative components interpretable as the unique information of some variables not provided by others as well as redundant and synergistic components. However, the definition of multivariate measures of redundancy that comply with nonnegativity and conform to certain axioms that capture conceptually desirable properties of redundancy has proven to be elusive. We here present a procedure to determine nonnegative multivariate redundancy measures, within the maximum entropy framework. In particular, we generalize existing bivariate maximum entropy measures of redundancy and unique information, defining measures of the redundant information that a group of variables has about a target, and of the unique redundant information that a group of variables has about a target that is not redundant with information from another group. The two key ingredients for this approach are: First, the identification of a type of constraints on entropy maximization that allows isolating components of redundancy and unique redundancy by mirroring them to synergy components. Second, the construction of rooted tree-based decompositions of the mutual information, which conform to the axioms of the redundancy lattice by the local implementation at each tree node of binary unfoldings of the information using hierarchically related maximum entropy constraints. Altogether, the proposed measures quantify the different multivariate redundancy contributions of a nonnegative mutual information decomposition consistent with the redundancy lattice.",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/e5ae8b1458b660058bafc6329e6ab04ca77191cc",
    "doi": "",
    "arxivId": "1708.03845",
    "authors": "D. Chicharro",
    "citationCount": 13
  },
  {
    "s2PaperId": "64c17b23c62f0ec8f3286f068d6967e18f59d522",
    "title": "Synergic kinds",
    "abstract": "",
    "year": 2017,
    "venue": "Synthese",
    "url": "https://www.semanticscholar.org/paper/64c17b23c62f0ec8f3286f068d6967e18f59d522",
    "doi": "10.1007/s11229-017-1480-2",
    "arxivId": "",
    "authors": "Manolo Martínez",
    "citationCount": 8
  },
  {
    "s2PaperId": "4af06fd260fc993f61d7e0f798b38fe92173699a",
    "title": "Temporal Information Partitioning Networks (TIPNets): A process network approach to infer ecohydrologic shifts",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/4af06fd260fc993f61d7e0f798b38fe92173699a",
    "doi": "10.1002/2016WR020218",
    "arxivId": "",
    "authors": "A. Goodwell, Praveen Kumar",
    "citationCount": 57
  },
  {
    "s2PaperId": "c9c8ec3685480160178e69c83b2c83d9a00e024a",
    "title": "Invariant Components of Synergy, Redundancy, and Unique Information among Three Variables",
    "abstract": "In a system of three stochastic variables, the Partial Information Decomposition (PID) of Williams and Beer dissects the information that two variables (sources) carry about a third variable (target) into nonnegative information atoms that describe redundant, unique, and synergistic modes of dependencies among the variables. However, the classification of the three variables into two sources and one target limits the dependency modes that can be quantitatively resolved, and does not naturally suit all systems. Here, we extend the PID to describe trivariate modes of dependencies in full generality, without introducing additional decomposition axioms or making assumptions about the target/source nature of the variables. By comparing different PID lattices of the same system, we unveil a finer PID structure made of seven nonnegative information subatoms that are invariant to different target/source classifications and that are sufficient to describe the relationships among all PID lattices. This finer structure naturally splits redundant information into two nonnegative components: the source redundancy, which arises from the pairwise correlations between the source variables, and the non-source redundancy, which does not, and relates to the synergistic information the sources carry about the target. The invariant structure is also sufficient to construct the system’s entropy, hence it characterizes completely all the interdependencies in the system.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/c9c8ec3685480160178e69c83b2c83d9a00e024a",
    "doi": "10.3390/e19090451",
    "arxivId": "1706.08921",
    "authors": "Giuseppe Pica, Eugenio Piasini, D. Chicharro, S. Panzeri",
    "citationCount": 34
  },
  {
    "s2PaperId": "32e7ed6e02d3ad72187af22baadd8f67cdfc6364",
    "title": "Multiscale Information Decomposition: Exact Computation for Multivariate Gaussian Processes",
    "abstract": "Exploiting the theory of state space models, we derive the exact expressions of the information transfer, as well as redundant and synergistic transfer, for coupled Gaussian processes observed at multiple temporal scales. All of the terms, constituting the frameworks known as interaction information decomposition and partial information decomposition, can thus be analytically obtained for different time scales from the parameters of the VAR model that fits the processes. We report the application of the proposed methodology firstly to benchmark Gaussian systems, showing that this class of systems may generate patterns of information decomposition characterized by prevalently redundant or synergistic information transfer persisting across multiple time scales or even by the alternating prevalence of redundant and synergistic source interaction depending on the time scale. Then, we apply our method to an important topic in neuroscience, i.e., the detection of causal interactions in human epilepsy networks, for which we show the relevance of partial information decomposition to the detection of multiscale information transfer spreading from the seizure onset zone.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/32e7ed6e02d3ad72187af22baadd8f67cdfc6364",
    "doi": "10.3390/e19080408",
    "arxivId": "1706.07136",
    "authors": "L. Faes, Daniele Marinazzo, S. Stramaglia",
    "citationCount": 80
  },
  {
    "s2PaperId": "e3d4818067b21d2f243b4ac4044817cb93d4dfe7",
    "title": "Secret Sharing and Shared Information",
    "abstract": "Secret sharing is a cryptographic discipline in which the goal is to distribute information about a secret over a set of participants in such a way that only specific authorized combinations of participants together can reconstruct the secret. Thus, secret sharing schemes are systems of variables in which it is very clearly specified which subsets have information about the secret. As such, they provide perfect model systems for information decompositions. However, following this intuition too far leads to an information decomposition with negative partial information terms, which are difficult to interpret. One possible explanation is that the partial information lattice proposed by Williams and Beer is incomplete and has to be extended to incorporate terms corresponding to higher-order redundancy. These results put bounds on information decompositions that follow the partial information framework, and they hint at where the partial information lattice needs to be improved.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/e3d4818067b21d2f243b4ac4044817cb93d4dfe7",
    "doi": "10.3390/e19110601",
    "arxivId": "1706.06998",
    "authors": "Johannes Rauh",
    "citationCount": 32
  },
  {
    "s2PaperId": "fd7ffa4d586306dab9b0e6d178891b76ce1be4e0",
    "title": "Multiscale Information Theory and the Marginal Utility of Information",
    "abstract": "Complex systems display behavior at a range of scales. Large-scale behaviors can emerge from the correlated or dependent behavior of individual small-scale components. To capture this observation in a rigorous and general way, we introduce a formalism for multiscale information theory. Dependent behavior among system components results in overlapping or shared information. A system’s structure is revealed in the sharing of information across the system’s dependencies, each of which has an associated scale. Counting information according to its scale yields the quantity of scale-weighted information, which is conserved when a system is reorganized. In the interest of flexibility we allow information to be quantified using any function that satisfies two basic axioms. Shannon information and vector space dimension are examples. We discuss two quantitative indices that summarize system structure: an existing index, the complexity profile, and a new index, the marginal utility of information. Using simple examples, we show how these indices capture the multiscale structure of complex systems in a quantitative way.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/fd7ffa4d586306dab9b0e6d178891b76ce1be4e0",
    "doi": "10.3390/e19060273",
    "arxivId": "",
    "authors": "Benjamin Allen, Blake C. Stacey, Y. Bar-Yam",
    "citationCount": 38
  },
  {
    "s2PaperId": "968d21c5bec7e01f3201501818cf6aeb82472951",
    "title": "Multiscale Structure of More-than-Binary Variables",
    "abstract": "In earlier work, my colleagues and I developed a formalism for using information theory to understand scales of organization and structure in multi-component systems. One prominent theme of that work was that the structure of a system cannot always be decomposed into pairwise relationships. In this brief communication, I refine that formalism to address recent examples which bring out that theme in a novel and subtle way. After summarizing key points of earlier papers, I introduce the crucial new concept of an ancilla component, and I apply this refinement of our formalism to illustrative examples. The goals of this brief communication are, first, to show how a simple scheme for constructing ancillae can be useful in bringing out subtleties of structure, and second, to compare this scheme with another recent proposal in the same genre.",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/968d21c5bec7e01f3201501818cf6aeb82472951",
    "doi": "",
    "arxivId": "1705.03927",
    "authors": "Blake C. Stacey",
    "citationCount": 2
  },
  {
    "s2PaperId": "096bca4c25a307ea9194107d02e6984c1075ca30",
    "title": "Multivariate mutual information of interferometric radar altimeter",
    "abstract": "",
    "year": 2017,
    "venue": "2017 International Conference on Signals and Systems (ICSigSys)",
    "url": "https://www.semanticscholar.org/paper/096bca4c25a307ea9194107d02e6984c1075ca30",
    "doi": "10.1109/ICSIGSYS.2017.7967072",
    "arxivId": "",
    "authors": "Youngjoo Kim, H. Bang",
    "citationCount": 1
  },
  {
    "s2PaperId": "e50bc248e053b1ab1aec704a8f2456458cda47d7",
    "title": "Tapping the sensorimotor trajectory",
    "abstract": "In this paper, we propose the concept of sensorimotor tappings, a new graphical technique that explicitly represents relations between the time steps of an agent's sensorimotor loop and a single training step of an adaptive internal model. In the simplest case this is a relation linking two time steps. In realistic cases these relations can extend over several time steps and over different sensory channels. The aim is to capture the footprint of information intake relative to the agent's current time step. We argue that this view allows us to make prior considerations explicit and then use them in implementations without modification once they are established. Here we explain the basic idea, provide example tappings for standard configurations used in developmental models, and show how tappings can be applied to problems in related fields.",
    "year": 2017,
    "venue": "Joint IEEE International Conference on Development and Learning and on Epigenetic Robotics",
    "url": "https://www.semanticscholar.org/paper/e50bc248e053b1ab1aec704a8f2456458cda47d7",
    "doi": "10.1109/DEVLRN.2017.8329791",
    "arxivId": "1704.07622",
    "authors": "Oswald Berthold, V. Hafner",
    "citationCount": 0
  },
  {
    "s2PaperId": "2654fe7ae041edcd61c886399b28dbcb5b5220bf",
    "title": "Trimming the Independent Fat: Sufficient Statistics, Mutual Information, and Predictability from Effective Channel States",
    "abstract": "One of the most basic characterizations of the relationship between two random variables, X and Y, is the value of their mutual information. Unfortunately, calculating it analytically and estimating it empirically are often stymied by the extremely large dimension of the variables. One might hope to replace such a high-dimensional variable by a smaller one that preserves its relationship with the other. It is well known that either X (or Y) can be replaced by its minimal sufficient statistic about Y (or X) while preserving the mutual information. While intuitively reasonable, it is not obvious or straightforward that both variables can be replaced simultaneously. We demonstrate that this is in fact possible: the information X's minimal sufficient statistic preserves about Y is exactly the information that Y's minimal sufficient statistic preserves about X. We call this procedure information trimming. As an important corollary, we consider the case where one variable is a stochastic process' past and the other its future. In this case, the mutual information is the channel transmission rate between the channel's effective states. That is, the past-future mutual information (the excess entropy) is the amount of information about the future that can be predicted using the past. Translating our result about minimal sufficient statistics, this is equivalent to the mutual information between the forward- and reverse-time causal states of computational mechanics. We close by discussing multivariate extensions to this use of minimal sufficient statistics.",
    "year": 2017,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/2654fe7ae041edcd61c886399b28dbcb5b5220bf",
    "doi": "10.1103/PhysRevE.95.060102",
    "arxivId": "1702.01831",
    "authors": "R. James, J. Mahoney, J. Crutchfield",
    "citationCount": 3
  },
  {
    "s2PaperId": "f6fb1fb340590a276dea08d2c6a50a7e31d861f5",
    "title": "The Partial Entropy Decomposition: Decomposing multivariate entropy and mutual information via pointwise common surprisal",
    "abstract": "Obtaining meaningful quantitative descriptions of the statistical dependence within multivariate systems is a difficult open problem. Recently, the Partial Information Decomposition (PID) was proposed to decompose mutual information (MI) about a target variable into components which are redundant, unique and synergistic within different subsets of predictor variables. Here, we propose to apply the elegant formalism of the PID to multivariate entropy, resulting in a Partial Entropy Decomposition (PED). We implement the PED with an entropy redundancy measure based on pointwise common surprisal; a natural definition which is closely related to the definition of MI. We show how this approach can reveal the dyadic vs triadic generative structure of multivariate systems that are indistinguishable with classical Shannon measures. The entropy perspective also shows that misinformation is synergistic entropy and hence that MI itself includes both redundant and synergistic effects. We show the relationships between the PED and MI in two predictors, and derive two alternative information decompositions which we illustrate on several example systems. This reveals that in entropy terms, univariate predictor MI is not a proper subset of the joint MI, and we suggest this previously unrecognised fact explains in part why obtaining a consistent PID has proven difficult. The PED also allows separate quantification of mechanistic redundancy (related to the function of the system) versus source redundancy (arising from dependencies between inputs); an important distinction which no existing methods can address. The new perspective provided by the PED helps to clarify some of the difficulties encountered with the PID approach and the resulting decompositions provide useful tools for practical data analysis across a wide range of application areas.",
    "year": 2017,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/f6fb1fb340590a276dea08d2c6a50a7e31d861f5",
    "doi": "",
    "arxivId": "1702.01591",
    "authors": "Robin A. A. Ince",
    "citationCount": 49
  },
  {
    "s2PaperId": "21667fc92a72c1250b3d48e74ffc7e23e71f82f5",
    "title": "On extractable shared information",
    "abstract": "We consider the problem of quantifying the information shared by a pair of random variables X 1 , X 2 about another variable S. We propose a new measure of shared information, called extractable shared information, that is left monotonic; that is, the information shared about S is bounded from below by the information shared about f ( S ) for any function f. We show that our measure leads to a new nonnegative decomposition of the mutual information I ( S ; X 1 X 2 ) into shared, complementary and unique components. We study properties of this decomposition and show that a left monotonic shared information is not compatible with a Blackwell interpretation of unique information. We also discuss whether it is possible to have a decomposition in which both shared and unique information are left monotonic.",
    "year": 2017,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/21667fc92a72c1250b3d48e74ffc7e23e71f82f5",
    "doi": "10.3390/e19070328",
    "arxivId": "1701.07805",
    "authors": "Johannes Rauh, P. Banerjee, E. Olbrich, J. Jost, Nils Bertschinger",
    "citationCount": 29
  },
  {
    "s2PaperId": "e0c333767695f7e18a85f0bd6078ff79a5db7114",
    "title": "Stem cell differentiation is a stochastic process with memory",
    "abstract": "Pluripotent stem cells are able to self-renew indefinitely in culture and differentiate into all somatic cell types in vivo. While much is known about the molecular basis of pluripotency, the molecular mechanisms of lineage commitment are complex and only partially understood. Here, using a combination of single cell profiling and mathematical modeling, we examine the differentiation dynamics of individual mouse embryonic stem cells (ESCs) as they progress from the ground state of pluripotency along the neuronal lineage. In accordance with previous reports we find that cells do not transit directly from the pluripotent state to the neuronal state, but rather first stochastically permeate an intermediate primed pluripotent state, similar to that found in the maturing epiblast in development. However, analysis of rate at which individual cells enter and exit this intermediate metastable state using a hidden Markov model reveals that the observed ESC and epiblast-like ‘macrostates’ conceal a chain of unobserved cellular ‘microstates’, which individual cells transit through stochastically in sequence. These hidden microstates ensure that individual cells spend well-defined periods of time in each functional macrostate and encode a simple form of epigenetic ‘memory’ that allows individual cells to record their position on the differentiation trajectory. To examine the generality of this model we also consider the differentiation of mouse hematopoietic stem cells along the myeloid lineage and observe remarkably similar dynamics, suggesting a general underlying process. Based upon these results we suggest a statistical mechanics view of cellular identities that distinguishes between functionally-distinct macrostates and the many functionally-similar molecular microstates associated with each macrostate. Taken together these results indicate that differentiation is a discrete stochastic process amenable to analysis using the tools of statistical mechanics.",
    "year": 2017,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/e0c333767695f7e18a85f0bd6078ff79a5db7114",
    "doi": "10.1101/101048",
    "arxivId": "",
    "authors": "Patrick S. Stumpf, Rosanna C. G. Smith, M. Lenz, A. Schuppert, F. Müller, A. Babtie, Thalia E. Chan, M. Stumpf, C. Please, S. Howison, F. Arai, B. MacArthur",
    "citationCount": 8
  },
  {
    "s2PaperId": "680894ff5c14694741076b7f39f957534abd672e",
    "title": "Synergy and Redundancy in Dual Decompositions of Mutual Information Gain and Information Loss",
    "abstract": "Williams and Beer (2010) proposed a nonnegative mutual information decomposition, based on the construction of information gain lattices, which allows separating the information that a set of variables contains about another variable into components, interpretable as the unique information of one variable, or redundant and synergy components. In this work, we extend this framework focusing on the lattices that underpin the decomposition. We generalize the type of constructible lattices and examine the relations between different lattices, for example, relating bivariate and trivariate decompositions. We point out that, in information gain lattices, redundancy components are invariant across decompositions, but unique and synergy components are decomposition-dependent. Exploiting the connection between different lattices, we propose a procedure to construct, in the general multivariate case, information gain decompositions from measures of synergy or unique information. We then introduce an alternative type of lattices, information loss lattices, with the role and invariance properties of redundancy and synergy components reversed with respect to gain lattices, and which provide an alternative procedure to build multivariate decompositions. We finally show how information gain and information loss dual lattices lead to a self-consistent unique decomposition, which allows a deeper understanding of the origin and meaning of synergy and redundancy.",
    "year": 2016,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/680894ff5c14694741076b7f39f957534abd672e",
    "doi": "10.3390/e19020071",
    "arxivId": "1612.09522",
    "authors": "D. Chicharro, S. Panzeri",
    "citationCount": 44
  },
  {
    "s2PaperId": "6476eb98e5c71616e20aa5348dc71d11927f1302",
    "title": "Information Decomposition in Multivariate Systems: Definitions, Implementation and Application to Cardiovascular Networks",
    "abstract": "The continuously growing framework of information dynamics encompasses a set of tools, rooted in information theory and statistical physics, which allow to quantify different aspects of the statistical structure of multivariate processes reflecting the temporal dynamics of complex networks. Building on the most recent developments in this field, this work designs a complete approach to dissect the information carried by the target of a network of multiple interacting systems into the new information produced by the system, the information stored in the system, and the information transferred to it from the other systems; information storage and transfer are then further decomposed into amounts eliciting the specific contribution of assigned source systems to the target dynamics, and amounts reflecting information modification through the balance between redundant and synergetic interaction between systems. These decompositions are formulated quantifying information either as the variance or as the entropy of the investigated processes, and their exact computation for the case of linear Gaussian processes is presented. The theoretical properties of the resulting measures are first investigated in simulations of vector autoregressive processes. Then, the measures are applied to assess information dynamics in cardiovascular networks from the variability series of heart period, systolic arterial pressure and respiratory activity measured in healthy subjects during supine rest, orthostatic stress, and mental stress. Our results document the importance of combining the assessment of information storage, transfer and modification to investigate common and complementary aspects of network dynamics; suggest the higher specificity to alterations in the network properties of the measures derived from the decompositions; and indicate that measures of information transfer and information modification are better assessed, respectively, through entropy-based and variance-based implementations of the framework.",
    "year": 2016,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/6476eb98e5c71616e20aa5348dc71d11927f1302",
    "doi": "10.3390/e19010005",
    "arxivId": "",
    "authors": "L. Faes, L. Faes, Alberto Porta, G. Nollo, G. Nollo, M. Javorka",
    "citationCount": 76
  },
  {
    "s2PaperId": "6a1f812dd73fb266ec1f7ad0093e300bff234d18",
    "title": "Gene Regulatory Network Inference from Single-Cell Data Using Multivariate Information Measures",
    "abstract": "While single-cell gene expression experiments present new challenges for data processing, the cell-to-cell variability observed also reveals statistical relationships that can be used by information theory. Here, we use multivariate information theory to explore the statistical dependencies between triplets of genes in single-cell gene expression datasets. We develop PIDC, a fast, efficient algorithm that uses partial information decomposition (PID) to identify regulatory relationships between genes. We thoroughly evaluate the performance of our algorithm and demonstrate that the higher order information captured by PIDC allows it to outperform pairwise mutual information-based algorithms when recovering true relationships present in simulated data. We also infer gene regulatory networks from three experimental single-cell data sets and illustrate how network context, choices made during analysis, and sources of variability affect network inference. PIDC tutorials and open-source software for estimating PID are available here: https://github.com/Tchanders/network_inference_tutorials. PIDC should facilitate the identification of putative functional relationships and mechanistic hypotheses from single-cell transcriptomic data.",
    "year": 2016,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/6a1f812dd73fb266ec1f7ad0093e300bff234d18",
    "doi": "10.1101/082099",
    "arxivId": "",
    "authors": "Thalia E. Chan, M. Stumpf, A. Babtie",
    "citationCount": 462
  },
  {
    "s2PaperId": "d6b4f46b109c8eb9d449739d36ecf3a302704757",
    "title": "Construction of synergy networks from gene expression data related to disease.",
    "abstract": "",
    "year": 2016,
    "venue": "Gene",
    "url": "https://www.semanticscholar.org/paper/d6b4f46b109c8eb9d449739d36ecf3a302704757",
    "doi": "10.1016/j.gene.2016.05.029",
    "arxivId": "",
    "authors": "Prantik Chatterjee, N. Pal",
    "citationCount": 12
  },
  {
    "s2PaperId": "580224eb70277387237e0a2464477cb02600a3e4",
    "title": "Multivariate Dependence Beyond Shannon Information",
    "abstract": "Accurately determining dependency structure is critical to discovering a system's causal organization. We recently showed that the transfer entropy fails in a key aspect of this---measuring information flow---due to its conflation of dyadic and polyadic relationships. We extend this observation to demonstrate that this is true of all such Shannon information measures when used to analyze multivariate dependencies. This has broad implications, particularly when employing information to express the organization and mechanisms embedded in complex systems, including the burgeoning efforts to combine complex network theory with information theory. Here, we do not suggest that any aspect of information theory is wrong. Rather, the vast majority of its informational measures are simply inadequate for determining the meaningful dependency structure within joint probability distributions. Therefore, such information measures are inadequate for discovering intrinsic causal relations. We close by demonstrating that such distributions exist across an arbitrary set of variables.",
    "year": 2016,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/580224eb70277387237e0a2464477cb02600a3e4",
    "doi": "10.3390/e19100531",
    "arxivId": "1609.01233",
    "authors": "R. James, J. Crutchfield",
    "citationCount": 79
  },
  {
    "s2PaperId": "b8b3b0754549f8140ff7f59e57e4817fc9751494",
    "title": "Hidden structures of information transport underlying spiral wave dynamics.",
    "abstract": "A spiral wave is a macroscopic dynamics of excitable media that plays an important role in several distinct systems, including the Belousov-Zhabotinsky reaction, seizures in the brain, and lethal arrhythmia in the heart. Because the spiral wave dynamics can exhibit a wide spectrum of behaviors, its precise quantification can be challenging. Here we present a hybrid geometric and information-theoretic approach to quantifying the spiral wave dynamics. We demonstrate the effectiveness of our approach by applying it to numerical simulations of a two-dimensional excitable medium with different numbers and spatial patterns of spiral waves. We show that, by defining the information flow over the excitable medium, hidden coherent structures emerge that effectively quantify the information transport underlying the spiral wave dynamics. Most importantly, we find that some coherent structures become more clearly defined over a longer observation period. These findings provide validity with our approach to quantitatively characterize the spiral wave dynamics by focusing on information transport. Our approach is computationally efficient and is applicable to many excitable media of interest in distinct physical, chemical, and biological systems. Our approach could ultimately contribute to an improved therapy of clinical conditions such as seizures and cardiac arrhythmia by identifying potential targets of interventional therapies.",
    "year": 2016,
    "venue": "Chaos",
    "url": "https://www.semanticscholar.org/paper/b8b3b0754549f8140ff7f59e57e4817fc9751494",
    "doi": "10.1063/1.4973542",
    "arxivId": "1608.06816",
    "authors": "H. Ashikaga, R. James",
    "citationCount": 12
  },
  {
    "s2PaperId": "2882a8eb2ce1040ee3627b506ccbd65a57786174",
    "title": "Swamping and masking in Markov boundary discovery",
    "abstract": "",
    "year": 2016,
    "venue": "Machine-mediated learning",
    "url": "https://www.semanticscholar.org/paper/2882a8eb2ce1040ee3627b506ccbd65a57786174",
    "doi": "10.1007/s10994-016-5545-0",
    "arxivId": "",
    "authors": "Xuqing Liu, Xinsheng Liu",
    "citationCount": 15
  },
  {
    "s2PaperId": "07a29b31e25e21f08658c371bbb316ed5029f82d",
    "title": "Term selection in information retrieval",
    "abstract": "",
    "year": 2016,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/07a29b31e25e21f08658c371bbb316ed5029f82d",
    "doi": "",
    "arxivId": "",
    "authors": "K. T. Maxwell",
    "citationCount": 2
  },
  {
    "s2PaperId": "ca4c97077a157684736a82ceb91c4e5177e4d4f5",
    "title": "Information encryption in the expert management of strategic uncertainty",
    "abstract": "Strategic agents in incomplete-information environments have a conflicted relationship with uncertainty: it can keep them unpredictable to their opponents, but it must also be overcome to predict the actions of those opponents. We use a multivariate generalization of information theory to characterize the information processing behavior of strategic reasoning experts. We compare expert and novice poker players --- \"sharks\" and \"fish\" --- over 1.75 million hands of online two-player No-Limit Texas Hold'em (NLHE). Comparing the effects of privately known and publicly signaled information on wagering behavior, we find that the behavior of sharks coheres with information that emerges only from the interaction of public and private sources --- \"synergistic\" information that does not exist in either source alone. This implies that the effect of public information on shark behavior is better encrypted: it cannot be reconstructed without access to the hidden state of private cards. Integrative information processing affects not only one's own strategic behavior, but the ability of others to predict it. By characterizing the informational structure of complex strategic interactions, we offer a detailed account of how experts extract, process, and conceal valuable information in high-uncertainty, high-stakes competitive environments.",
    "year": 2016,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/ca4c97077a157684736a82ceb91c4e5177e4d4f5",
    "doi": "",
    "arxivId": "1605.04233",
    "authors": "Seth Frey, Paul L. Williams, Dominic K. Albino",
    "citationCount": 3
  },
  {
    "s2PaperId": "08a788b91c58e12328181a87b3135f1f8847af82",
    "title": "Rank Order Coding: a Retinal Information Decoding Strategy Revealed by Large-Scale Multielectrode Array Retinal Recordings",
    "abstract": "Visual Abstract How a population of retinal ganglion cells (RGCs) encodes the visual scene remains an open question. Going beyond individual RGC coding strategies, results in salamander suggest that the relative latencies of a RGC pair encode spatial information. Thus, a population code based on this concerted spiking could be a powerful mechanism to transmit visual information rapidly and efficiently. How a population of retinal ganglion cells (RGCs) encodes the visual scene remains an open question. Going beyond individual RGC coding strategies, results in salamander suggest that the relative latencies of a RGC pair encode spatial information. Thus, a population code based on this concerted spiking could be a powerful mechanism to transmit visual information rapidly and efficiently. Here, we tested this hypothesis in mouse by recording simultaneous light-evoked responses from hundreds of RGCs, at pan-retinal level, using a new generation of large-scale, high-density multielectrode array consisting of 4096 electrodes. Interestingly, we did not find any RGCs exhibiting a clear latency tuning to the stimuli, suggesting that in mouse, individual RGC pairs may not provide sufficient information. We show that a significant amount of information is encoded synergistically in the concerted spiking of large RGC populations. Thus, the RGC population response described with relative activities, or ranks, provides more relevant information than classical independent spike count- or latency- based codes. In particular, we report for the first time that when considering the relative activities across the whole population, the wave of first stimulus-evoked spikes is an accurate indicator of stimulus content. We show that this coding strategy coexists with classical neural codes, and that it is more efficient and faster. Overall, these novel observations suggest that already at the level of the retina, concerted spiking provides a reliable and fast strategy to rapidly transmit new visual scenes.",
    "year": 2016,
    "venue": "eNeuro",
    "url": "https://www.semanticscholar.org/paper/08a788b91c58e12328181a87b3135f1f8847af82",
    "doi": "10.1523/ENEURO.0134-15.2016",
    "arxivId": "",
    "authors": "Geoffrey Portelli, J. Barrett, Gerrit Hilgen, T. Masquelier, A. Maccione, S. Di Marco, L. Berdondini, Pierre Kornprobst, E. Sernagor",
    "citationCount": 51
  },
  {
    "s2PaperId": "785ff08775e22dd4d3bdac64b3b2eba55fcd893d",
    "title": "High-Degree Neurons Feed Cortical Computations",
    "abstract": "Recent work has shown that functional connectivity among cortical neurons is highly varied, with a small percentage of neurons having many more connections than others. Also, recent theoretical developments now make it possible to quantify how neurons modify information from the connections they receive. Therefore, it is now possible to investigate how information modification, or computation, depends on the number of connections a neuron receives (in-degree) or sends out (out-degree). To do this, we recorded the simultaneous spiking activity of hundreds of neurons in cortico-hippocampal slice cultures using a high-density 512-electrode array. This preparation and recording method combination produced large numbers of neurons recorded at temporal and spatial resolutions that are not currently available in any in vivo recording system. We utilized transfer entropy (a well-established method for detecting linear and nonlinear interactions in time series) and the partial information decomposition (a powerful, recently developed tool for dissecting multivariate information processing into distinct parts) to quantify computation between neurons where information flows converged. We found that computations did not occur equally in all neurons throughout the networks. Surprisingly, neurons that computed large amounts of information tended to receive connections from high out-degree neurons. However, the in-degree of a neuron was not related to the amount of information it computed. To gain insight into these findings, we developed a simple feedforward network model. We found that a degree-modified Hebbian wiring rule best reproduced the pattern of computation and degree correlation results seen in the real data. Interestingly, this rule also maximized signal propagation in the presence of network-wide correlations, suggesting a mechanism by which cortex could deal with common random background input. These are the first results to show that the extent to which a neuron modifies incoming information streams depends on its topological location in the surrounding functional network.",
    "year": 2016,
    "venue": "PLoS Comput. Biol.",
    "url": "https://www.semanticscholar.org/paper/785ff08775e22dd4d3bdac64b3b2eba55fcd893d",
    "doi": "10.1371/journal.pcbi.1004858",
    "arxivId": "",
    "authors": "N. Timme, S. Ito, Maxym Myroshnychenko, Sunny Nigam, M. Shimono, Fang-Chin Yeh, P. Hottowy, A. Litke, John M. Beggs",
    "citationCount": 93
  },
  {
    "s2PaperId": "37b98c9e89337b3ed53b71fdc45b5b7ecee2333b",
    "title": "Gender Classification From the Same Iris Code Used for Recognition",
    "abstract": "Previous researchers have explored various approaches for predicting the gender of a person based on the features of the iris texture. This paper is the first to predict gender directly from the same binary iris code that could be used for recognition. We found that the information for gender prediction is distributed across the iris, rather than localized in particular concentric bands. We also found that using selected features representing a subset of the iris region achieves better accuracy than using features representing the whole iris region. We used the measures of mutual information to guide the selection of bits from the iris code to use as features in gender prediction. Using this approach, with a person-disjoint training and testing evaluation, we were able to achieve 89% correct gender prediction using the fusion of the best features of iris code from the left and right eyes.",
    "year": 2016,
    "venue": "IEEE Transactions on Information Forensics and Security",
    "url": "https://www.semanticscholar.org/paper/37b98c9e89337b3ed53b71fdc45b5b7ecee2333b",
    "doi": "10.1109/TIFS.2016.2550418",
    "arxivId": "",
    "authors": "Juan E. Tapia, C. Pérez, K. Bowyer",
    "citationCount": 82
  },
  {
    "s2PaperId": "e273778a8460bd8550f6472c30fec394827b20c7",
    "title": "Iterative Scaling Algorithm for Channels",
    "abstract": "Here we define a procedure for evaluating KL-projections (I- and rI-projections) of channels. These can be useful in the decomposition of mutual information between input and outputs, e.g. to quantify synergies and interactions of different orders, as well as information integration and other related measures of complexity.  The algorithm is a generalization of the standard iterative scaling algorithm, which we here extend from probability distributions to channels (also known as transition kernels).",
    "year": 2016,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/e273778a8460bd8550f6472c30fec394827b20c7",
    "doi": "",
    "arxivId": "1603.07181",
    "authors": "Paolo Perrone, N. Ay",
    "citationCount": 0
  },
  {
    "s2PaperId": "133c61552bdbecc6b12eef9be8fac037d2d3aee3",
    "title": "A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula",
    "abstract": "We begin by reviewing the statistical framework of information theory as applicable to neuroimaging data analysis. A major factor hindering wider adoption of this framework in neuroimaging is the difficulty of estimating information theoretic quantities in practice. We present a novel estimation technique that combines the statistical theory of copulas with the closed form solution for the entropy of Gaussian variables. This results in a general, computationally efficient, flexible, and robust multivariate statistical framework that provides effect sizes on a common meaningful scale, allows for unified treatment of discrete, continuous, uni-and multi-dimensional variables, and enables direct comparisons of representations from behavioral and brain responses across any recording modality. We validate the use of this estimate as a statistical test within a neuroimaging context, considering both discrete stimulus classes and continuous stimulus features. We also present examples of analyses facilitated by these developments, including application of multivariate analyses to MEG planar magnetic field gradients, and pairwise temporal interactions in evoked EEG responses. We show the benefit of considering the instantaneous temporal derivative together with the raw values of M/EEG signals as a multivariate response, how we can separately quantify modulations of amplitude and direction for vector quantities, and how we can measure the emergence of novel information over time in evoked responses. Open-source Matlab and Python code implementing the new methods accompanies this article. Highlights Novel estimator for mutual information and other information theoretic quantities Provides general, efficient, flexible and robust multivariate statistical framework Validated statistical performance on EEG and MEG data Applications to spectral power and phase, 2D magnetic field gradients, temporal derivatives Interaction information relates information content in different responses",
    "year": 2016,
    "venue": "bioRxiv",
    "url": "https://www.semanticscholar.org/paper/133c61552bdbecc6b12eef9be8fac037d2d3aee3",
    "doi": "10.1002/hbm.23471",
    "arxivId": "",
    "authors": "Robin A. A. Ince, Bruno L. Giordano, C. Kayser, G. Rousselet, J. Gross, P. Schyns",
    "citationCount": 289
  },
  {
    "s2PaperId": "a4ac82976bcf986c88e7f2348765c07a7c9bc389",
    "title": "Stripping syntax from complexity: An information-theoretical perspective on complex systems",
    "abstract": "Claude Shannons information theory (1949) has had a revolutionary impact on communication science. A crucial property of his framework is that it decouples the meaning of a message from the mechanistic details from the actual communication process itself, which opened the way to solve long-standing communication problems. Here we argue that a similar impact could be expected by applying information theory in the context of complexity science to answer long-standing, cross-domain questions about the nature of complex systems. This happens by decoupling the domain-specific model details (e.g., neuronal networks, ecosystems, flocks of birds) from the cross-domain phenomena that characterize complex systems (e.g., criticality, robustness, tipping points). This goes beyond using information theory as a non-linear correlation measure, namely it allows describing a complex system entirely in terms of the storage, transfer, and modification of informational bits. After all, a phenomenon that does not depend on model details should best be studied in a framework that strips away all such details. We highlight the first successes of information-theoretic descriptions in the recent complexity literature, and emphasize that this type of research is still in its infancy. Finally we sketch how such an information-theoretic description may even lead to a new type of universality among complex systems, with a potentially tremendous impact. The goal of this perspective article is to motivate a paradigm shift in the young field of complexity science using a lesson learnt in communication science.",
    "year": 2016,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/a4ac82976bcf986c88e7f2348765c07a7c9bc389",
    "doi": "",
    "arxivId": "1603.03552",
    "authors": "Rick Quax, Omri Har-Shemesh, S. Thurner, P. Sloot",
    "citationCount": 4
  },
  {
    "s2PaperId": "f25cfbb52323ee3f53167ad02b6192480514fdab",
    "title": "Measuring multivariate redundant information with pointwise common change in surprisal",
    "abstract": "The problem of how to properly quantify redundant information is an open question that has been the subject of much recent research. Redundant information refers to information about a target variable S that is common to two or more predictor variables Xi. It can be thought of as quantifying overlapping information content or similarities in the representation of S between the Xi. We present a new measure of redundancy which measures the common change in surprisal shared between variables at the local or pointwise level. We provide a game-theoretic operational definition of unique information, and use this to derive constraints which are used to obtain a maximum entropy distribution. Redundancy is then calculated from this maximum entropy distribution by counting only those local co-information terms which admit an unambiguous interpretation as redundant information. We show how this redundancy measure can be used within the framework of the Partial Information Decomposition (PID) to give an intuitive decomposition of the multivariate mutual information into redundant, unique and synergistic contributions. We compare our new measure to existing approaches over a range of example systems, including continuous Gaussian variables. Matlab code for the measure is provided, including all considered examples.",
    "year": 2016,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/f25cfbb52323ee3f53167ad02b6192480514fdab",
    "doi": "10.3390/e19070318",
    "arxivId": "1602.05063",
    "authors": "Robin A. A. Ince",
    "citationCount": 157
  },
  {
    "s2PaperId": "03c5abf3c2413fc483c50220dbd9b1029e0a335b",
    "title": "Quantifying Synergistic Information Using Intermediate Stochastic Variables",
    "abstract": "Quantifying synergy among stochastic variables is an important open problem in information theory. Information synergy occurs when multiple sources together predict an outcome variable better than the sum of single-source predictions. It is an essential phenomenon in biology such as in neuronal networks and cellular regulatory processes, where different information flows integrate to produce a single response, but also in social cooperation processes as well as in statistical inference tasks in machine learning. Here we propose a metric of synergistic entropy and synergistic information from first principles. The proposed measure relies on so-called synergistic random variables (SRVs) which are constructed to have zero mutual information about individual source variables but non-zero mutual information about the complete set of source variables. We prove several basic and desired properties of our measure, including bounds and additivity properties. In addition, we prove several important consequences of our measure, including the fact that different types of synergistic information may co-exist between the same sets of variables. A numerical implementation is provided, which we use to demonstrate that synergy is associated with resilience to noise. Our measure may be a marked step forward in the study of multivariate information theory and its numerous applications.",
    "year": 2016,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/03c5abf3c2413fc483c50220dbd9b1029e0a335b",
    "doi": "10.3390/e19020085",
    "arxivId": "1602.01265",
    "authors": "Rick Quax, Omri Har-Shemesh, P. Sloot",
    "citationCount": 53
  },
  {
    "s2PaperId": "ece230c4b9e72be28a99a97cd09e9d9908ee6ebf",
    "title": "Information decomposition on structured space",
    "abstract": "We build information geometry for a partially ordered set of variables and define the orthogonal decomposition of information theoretic quantities. The natural connection between information geometry and order theory leads to efficient decomposition algorithms. This generalization of Amari's seminal work on hierarchical decomposition of probability distributions on event combinations enables us to analyze high-order statistical interactions arising in neuroscience, biology, and machine learning.",
    "year": 2016,
    "venue": "International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/ece230c4b9e72be28a99a97cd09e9d9908ee6ebf",
    "doi": "10.1109/ISIT.2016.7541364",
    "arxivId": "1601.05533",
    "authors": "M. Sugiyama, H. Nakahara, K. Tsuda",
    "citationCount": 20
  },
  {
    "s2PaperId": "3f62b3d3e725674388067fff716e093f7807f9ef",
    "title": "Information Flows? A Critique of Transfer Entropies",
    "abstract": "A central task in analyzing complex dynamics is to determine the loci of information storage and the communication topology of information flows within a system. Over the last decade and a half, diagnostics for the latter have come to be dominated by the transfer entropy. Via straightforward examples, we show that it and a derivative quantity, the causation entropy, do not, in fact, quantify the flow of information. At one and the same time they can overestimate flow or underestimate influence. We isolate why this is the case and propose several avenues to alternate measures for information flow. We also address an auxiliary consequence: The proliferation of networks as a now-common theoretical model for large-scale systems, in concert with the use of transferlike entropies, has shoehorned dyadic relationships into our structural interpretation of the organization and behavior of complex systems. This interpretation thus fails to include the effects of polyadic dependencies. The net result is that much of the sophisticated organization of complex systems may go undetected.",
    "year": 2015,
    "venue": "Physical Review Letters",
    "url": "https://www.semanticscholar.org/paper/3f62b3d3e725674388067fff716e093f7807f9ef",
    "doi": "10.1103/PhysRevLett.116.238701",
    "arxivId": "1512.06479",
    "authors": "R. James, Nix Barnett, J. Crutchfield",
    "citationCount": 128
  },
  {
    "s2PaperId": "b98d58d6993533786085cc89afc311d8f065e09d",
    "title": "Hierarchical Quantification of Synergy in Channels",
    "abstract": "The decomposition of channel information into synergies of different order is an open, active problem in the theory of complex systems. Most approaches to the problem are based on information theory, and propose decompositions of mutual information between inputs and outputs in se\\-veral ways, none of which is generally accepted yet. We propose a new point of view on the topic. We model a multi-input channel as a Markov kernel. We can project the channel onto a series of exponential families which form a hierarchical structure. This is carried out with tools from information geometry, in a way analogous to the projections of probability distributions introduced by Amari. A Pythagorean relation leads naturally to a decomposition of the mutual information between inputs and outputs into terms which represent single node information; pairwise interactions; and in general n-node interactions. The synergy measures introduced in this paper can be easily evaluated by an iterative scaling algorithm, which is a standard procedure in information geometry.",
    "year": 2015,
    "venue": "Frontiers in Robotics and AI",
    "url": "https://www.semanticscholar.org/paper/b98d58d6993533786085cc89afc311d8f065e09d",
    "doi": "10.3389/frobt.2015.00035",
    "arxivId": "1512.03614",
    "authors": "Paolo Perrone, N. Ay",
    "citationCount": 22
  },
  {
    "s2PaperId": "faa26675db28f27c2116a926feeffde5151a35ec",
    "title": "Tracing the Flow of Perceptual Features in an Algorithmic Brain Network",
    "abstract": "The model of the brain as an information processing machine is a profound hypothesis in which neuroscience, psychology and theory of computation are now deeply rooted. Modern neuroscience aims to model the brain as a network of densely interconnected functional nodes. However, to model the dynamic information processing mechanisms of perception and cognition, it is imperative to understand brain networks at an algorithmic level–i.e. as the information flow that network nodes code and communicate. Here, using innovative methods (Directed Feature Information), we reconstructed examples of possible algorithmic brain networks that code and communicate the specific features underlying two distinct perceptions of the same ambiguous picture. In each observer, we identified a network architecture comprising one occipito-temporal hub where the features underlying both perceptual decisions dynamically converge. Our focus on detailed information flow represents an important step towards a new brain algorithmics to model the mechanisms of perception and cognition.",
    "year": 2015,
    "venue": "Scientific Reports",
    "url": "https://www.semanticscholar.org/paper/faa26675db28f27c2116a926feeffde5151a35ec",
    "doi": "10.1038/srep17681",
    "arxivId": "",
    "authors": "Robin Ince, N. van Rijsbergen, G. Thut, G. Rousselet, Joachim Gross, Stefano Panzeri, Philippe G. Schyns",
    "citationCount": 50
  },
  {
    "s2PaperId": "a5e09a5c6014cc89d2027d0c305149c01938c98b",
    "title": "Partial information decomposition as a unified approach to the characterization and design of neural goal functions",
    "abstract": "In many neural systems anatomical motifs are found repeatedly in different places. Despite this repetition these motifs often seem to serve a perplexing variety of functions. A prime example is the canonical microcircuit, which is repeated across multiple cortical areas, but supports a variety of functions from sensory processing and memory to executive functions and motor control. The multiplicity of functions served by a single anatomical motif suggests a common, but more abstract, information processing goal underlying all the different functions. Identifying this goal from neural recordings is a key challenge in understanding the general principles of neural information processing. The apparent diversity of functions makes it clear that this common goal cannot be described using function-specific language (e.g. \"edge filters\"), but calls for an abstract framework. Here, information theory is the obvious candidate. Notable past approaches using information theoretic descriptions of neural goal functions suggested to maximize the mutual information between input and output [1], maximize the coherent mutual information that all the inputs share about the output [2], or, very generally, to minimize the free energy [3]. To facilitate these efforts, and to better dissect the implications of existing neural goal functions, we suggest to build on a recent progress in information theory, termed partial information decomposition (PID). PID allows to measure which of a set of inputs contributes either uniquely, redundantly or synergistically to the output of a (neural) processing unit [4-7], and which fraction of the output's entropy remains unexplained by the input set. We show how these measures can be used to identify an information theoretic footprint of a neural goal function. Most importantly, these measures can quantify how much of the information is modified rather than merely relayed when passing through the neural processor [8]. This shifts the focus from information transmission to more complex processing and allows a much better understanding of the (theoretical?) capabilities of a neuron or neural circuit. Using this approach we show how to better understand existing neural goal functions using PID measures and provide an information theoretic framework for the design of novel goal functions for artificial neural networks.",
    "year": 2015,
    "venue": "BMC Neuroscience",
    "url": "https://www.semanticscholar.org/paper/a5e09a5c6014cc89d2027d0c305149c01938c98b",
    "doi": "10.1186/1471-2202-16-S1-P199",
    "arxivId": "",
    "authors": "M. Wibral, W. A. Phillips, J. Lizier, V. Priesemann",
    "citationCount": 1
  },
  {
    "s2PaperId": "70f20480b98e87d1c9185582e87cef2020c13e6d",
    "title": "Information Theoretic Measures to Infer Feedback Dynamics in Coupled Logistic Networks",
    "abstract": "A process network is a collection of interacting time series nodes, in which interactions can range from weak dependencies to complete synchronization. Between these extremes, nodes may respond to each other or external forcing at certain time scales and strengths. Identification of such dependencies from time series can reveal the complex behavior of the system as a whole. Since observed time series datasets are often limited in length, robust measures are needed to quantify strengths and time scales of interactions and their unique contributions to the whole system behavior. We generate coupled chaotic logistic networks with a range of connectivity structures, time scales, noise, and forcing mechanisms, and compute variance and lagged mutual information measures to evaluate how detected time dependencies reveal system behavior. When a target node is detected to receive information from multiple sources, we compute conditional mutual information and total shared information between each source node pair to identify unique or redundant sources. While variance measures capture synchronization trends, combinations of information measures provide further distinctions regarding drivers, redundancies, and time dependencies within the network. We find that imposed network connectivity often leads to induced feedback that is identified as redundant links, and cannot be distinguished from imposed causal linkages. We find that random or external driving nodes are more likely to provide unique information than mutually dependent nodes in a highly connected network. In process networks constructed from observed data, the methods presented can be used to infer connectivity, dominant interactions, and systemic behavioral shift.",
    "year": 2015,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/70f20480b98e87d1c9185582e87cef2020c13e6d",
    "doi": "10.3390/e17117468",
    "arxivId": "",
    "authors": "A. Goodwell, Praveen Kumar",
    "citationCount": 17
  },
  {
    "s2PaperId": "8c0ebb8b35dda6d869dfe84cf69e0ed74fdc8b95",
    "title": "Information Theoretical Study of Cross-Talk Mediated Signal Transduction in MAPK Pathways",
    "abstract": "Biochemical networks related to similar functional pathways are often correlated due to cross-talk among the homologous proteins in the different networks. Using a stochastic framework, we address the functional significance of the cross-talk between two pathways. Our theoretical analysis on generic MAPK pathways reveals cross-talk is responsible for developing coordinated fluctuations between the pathways. The extent of correlation evaluated in terms of the information theoretic measure provides directionality to net information propagation. Stochastic time series and scattered plot suggest that the cross-talk generates synchronization within a cell as well as in a cellular population. Depending on the number of input and output, we identify signal integration and signal bifurcation motif that arise due to inter-pathway connectivity in the composite network. Analysis using partial information decomposition quantifies the net synergy in the information propagation through these branched pathways.",
    "year": 2015,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/8c0ebb8b35dda6d869dfe84cf69e0ed74fdc8b95",
    "doi": "10.3390/e19090469",
    "arxivId": "1510.04799",
    "authors": "A. Maity, P. Chaudhury, S. Banik",
    "citationCount": 7
  },
  {
    "s2PaperId": "8f9d95bfeee3349ac2a1f3d9c117ade6c81dd297",
    "title": "Information transfer and causality in the sensorimotor loop",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/8f9d95bfeee3349ac2a1f3d9c117ade6c81dd297",
    "doi": "",
    "arxivId": "",
    "authors": "James Thorniley",
    "citationCount": 0
  },
  {
    "s2PaperId": "bea9d06c7c05f79272b265611939f7486f0d7da7",
    "title": "Partial information decomposition as a unified approach to the specification of neural goal functions",
    "abstract": "",
    "year": 2015,
    "venue": "Brain and Cognition",
    "url": "https://www.semanticscholar.org/paper/bea9d06c7c05f79272b265611939f7486f0d7da7",
    "doi": "10.1016/j.bandc.2015.09.004",
    "arxivId": "1510.00831",
    "authors": "M. Wibral, V. Priesemann, J. Kay, J. Lizier, W. A. Phillips",
    "citationCount": 126
  },
  {
    "s2PaperId": "59345fa0d52010bb02553072ae9f06f7a00dda08",
    "title": "Human breath-print identification by E-nose, using information-theoretic feature selection prior to classification",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/59345fa0d52010bb02553072ae9f06f7a00dda08",
    "doi": "10.1016/J.SNB.2014.09.115",
    "arxivId": "",
    "authors": "X. R. Wang, J. Lizier, A. Berna, Florence G Bravo, S. Trowell",
    "citationCount": 44
  },
  {
    "s2PaperId": "a332e6d0f1d9a6cfda063327fa6b4159187d8eda",
    "title": "Understanding Interdependency Through Complex Information Sharing",
    "abstract": "The interactions between three or more random variables are often nontrivial, poorly understood, and yet, are paramount for future advances in fields such as network information theory, neuroscience, genetics and many others. In this work, we propose to analyze these interactions as different modes of information sharing. Towards this end, we introduce a novel axiomatic framework for decomposing the joint entropy, which characterizes the various ways in which random variables can share information. The key contribution of our framework is to distinguish between interdependencies where the information is shared redundantly, and synergistic interdependencies where the sharing structure exists in the whole but not between the parts. We show that our axioms determine unique formulas for all the terms of the proposed decomposition for a number of cases of interest. Moreover, we show how these results can be applied to several network information theory problems, providing a more intuitive understanding of their fundamental limits.",
    "year": 2015,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/a332e6d0f1d9a6cfda063327fa6b4159187d8eda",
    "doi": "10.3390/e18020038",
    "arxivId": "1509.04555",
    "authors": "Fernando Rosas, Vasilis Ntranos, C. J. Ellison, S. Pollin, M. Verhelst",
    "citationCount": 49
  },
  {
    "s2PaperId": "d20f192eaba9258dfe024a84a873f3cd870619df",
    "title": "Synergy, Redundancy and Common Information",
    "abstract": "We consider the problem of decomposing the total mutual information conveyed by a pair of predictor random variables about a target random variable into redundant, unique and synergistic contributions. We focus on the relationship between \"redundant information\" and the more familiar information-theoretic notions of \"common information\". Our main contribution is an impossibility result. We show that for independent predictor random variables, any common information based measure of redundancy cannot induce a nonnegative decomposition of the total mutual information. Interestingly, this entails that any reasonable measure of redundant information cannot be derived by optimization over a single random variable.",
    "year": 2015,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/d20f192eaba9258dfe024a84a873f3cd870619df",
    "doi": "",
    "arxivId": "1509.03706",
    "authors": "P. Banerjee, V. Griffith",
    "citationCount": 13
  },
  {
    "s2PaperId": "c7b71d7f3c7bf1e43294e61f0d5af27ddff544f2",
    "title": "Understanding Networks of Computing Chemical Droplet Neurons Based on Information Flow",
    "abstract": "",
    "year": 2015,
    "venue": "International Journal of Neural Systems",
    "url": "https://www.semanticscholar.org/paper/c7b71d7f3c7bf1e43294e61f0d5af27ddff544f2",
    "doi": "10.1142/S0129065714500324",
    "arxivId": "",
    "authors": "Gerd Gruenert, Konrad Gizynski, Gabi Escuela, B. Ibrahim, J. Górecki, P. Dittrich",
    "citationCount": 28
  },
  {
    "s2PaperId": "de71450476ee0c1592c8b007e743aaf55afc84c7",
    "title": "A Generative Word Embedding Model and its Low Rank Positive Semidefinite Solution",
    "abstract": "Most existing word embedding methods can be categorized into Neural Embedding Models and Matrix Factorization (MF)-based methods. However some models are opaque to probabilistic interpretation, and MF-based methods, typically solved using Singular Value Decomposition (SVD), may incur loss of corpus information. In addition, it is desirable to incorporate global latent factors, such as topics, sentiments or writing styles, into the word embedding model. Since generative models provide a principled way to incorporate latent factors, we propose a generative word embedding model, which is easy to interpret, and can serve as a basis of more sophisticated latent factor models. The model inference reduces to a low rank weighted positive semidefinite approximation problem. Its optimization is approached by eigendecomposition on a submatrix, followed by online blockwise regression, which is scalable and avoids the information loss in SVD. In experiments on 7 common benchmark datasets, our vectors are competitive to word2vec, and better than other MF-based methods.",
    "year": 2015,
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "url": "https://www.semanticscholar.org/paper/de71450476ee0c1592c8b007e743aaf55afc84c7",
    "doi": "10.18653/v1/D15-1183",
    "arxivId": "1508.03826",
    "authors": "Shaohua Li, Jun Zhu, C. Miao",
    "citationCount": 29
  },
  {
    "s2PaperId": "54b22fb5b2e2518a036a4bf622736e19c29fb96a",
    "title": "The Information Sieve",
    "abstract": "We introduce a new framework for unsupervised learning of representations based on a novel hierarchical decomposition of information. Intuitively, data is passed through a series of progressively fine-grained sieves. Each layer of the sieve recovers a single latent factor that is maximally informative about multivariate dependence in the data. The data is transformed after each pass so that the remaining unexplained information trickles down to the next layer. Ultimately, we are left with a set of latent factors explaining all the dependence in the original data and remainder information consisting of independent noise. We present a practical implementation of this framework for discrete variables and apply it to a variety of fundamental tasks in unsupervised learning including independent component analysis, lossy and lossless compression, and predicting missing values in data.",
    "year": 2015,
    "venue": "International Conference on Machine Learning",
    "url": "https://www.semanticscholar.org/paper/54b22fb5b2e2518a036a4bf622736e19c29fb96a",
    "doi": "",
    "arxivId": "1507.02284",
    "authors": "G. V. Steeg, A. Galstyan",
    "citationCount": 19
  },
  {
    "s2PaperId": "9805567ef35d58ab8e9641de317d587a4f4b8ccb",
    "title": "The Elusive Present: Hidden Past and Future Dependency and Why We Build Models",
    "abstract": "Modeling a temporal process as if it is Markovian assumes that the present encodes all of a process's history. When this occurs, the present captures all of the dependency between past and future. We recently showed that if one randomly samples in the space of structured processes, this is almost never the case. So, how does the Markov failure come about? That is, how do individual measurements fail to encode the past? and How many are needed to capture dependencies between the past and future? Here, we investigate how much information can be shared between the past and the future but not reflected in the present. We quantify this elusive information, give explicit calculational methods, and outline the consequences, the most important of which is that when the present hides past-future correlation or dependency we must move beyond sequence-based statistics and build state-based models.",
    "year": 2015,
    "venue": "Physical Review E",
    "url": "https://www.semanticscholar.org/paper/9805567ef35d58ab8e9641de317d587a4f4b8ccb",
    "doi": "10.1103/PhysRevE.93.022143",
    "arxivId": "1507.00672",
    "authors": "Pooneh M. Ara, R. James, J. Crutchfield",
    "citationCount": 16
  },
  {
    "s2PaperId": "b10ab6786e5a474d8a745217e54bfd07afd6ed40",
    "title": "Information Decomposition and Synergy",
    "abstract": "Recently, a series of papers addressed the problem of decomposing the information of two random variables into shared information, unique information and synergistic information. Several measures were proposed, although still no consensus has been reached. Here, we compare these proposals with an older approach to define synergistic information based on the projections on exponential families containing only up to k-th order interactions. We show that these measures are not compatible with a decomposition into unique, shared and synergistic information if one requires that all terms are always non-negative (local positivity). We illustrate the difference between the two measures for multivariate Gaussians.",
    "year": 2015,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/b10ab6786e5a474d8a745217e54bfd07afd6ed40",
    "doi": "10.3390/e17053501",
    "arxivId": "",
    "authors": "E. Olbrich, Nils Bertschinger, Johannes Rauh",
    "citationCount": 65
  },
  {
    "s2PaperId": "61893d5ce37a10668324bcb5aae4482898c94ac7",
    "title": "Synergetic and redundant information flow detected by unnormalized Granger causality: application to resting state fMRI.",
    "abstract": "OBJECTIVES We develop a framework for the analysis of synergy and redundancy in the pattern of information flow between subsystems of a complex network.   METHODS The presence of redundancy and/or synergy in multivariate time series data renders difficult to estimate the neat flow of information from each driver variable to a given target. We show that adopting an unnormalized definition of Granger causality one may put in evidence redundant multiplets of variables influencing the target by maximizing the total Granger causality to a given target, over all the possible partitions of the set of driving variables. Consequently we introduce a pairwise index of synergy which is zero when two independent sources additively influence the future state of the system, differently from previous definitions of synergy.   RESULTS We report the application of the proposed approach to resting state fMRI data from the Human Connectome Project, showing that redundant pairs of regions arise mainly due to space contiguity and interhemispheric symmetry, whilst synergy occurs mainly between non-homologous pairs of regions in opposite hemispheres.   CONCLUSIONS Redundancy and synergy, in healthy resting brains, display characteristic patterns, revealed by the proposed approach.   SIGNIFICANCE The pairwise synergy index, here introduced, maps the informational character of the system at hand into a weighted complex network: the same approach can be applied to other complex systems whose normal state corresponds to a balance between redundant and synergetic circuits.",
    "year": 2015,
    "venue": "IEEE transactions on bio-medical engineering",
    "url": "https://www.semanticscholar.org/paper/61893d5ce37a10668324bcb5aae4482898c94ac7",
    "doi": "10.1109/TBME.2016.2559578",
    "arxivId": "1504.03584",
    "authors": "S. Stramaglia, L. Angelini, Guorong Wu, J. Cortes, L. Faes, Daniele Marinazzo",
    "citationCount": 32
  },
  {
    "s2PaperId": "292360f415ef72ca46fd8bd229fcb209d6163ae0",
    "title": "Synergy, redundancy and unnormalized Granger causality",
    "abstract": "",
    "year": 2015,
    "venue": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
    "url": "https://www.semanticscholar.org/paper/292360f415ef72ca46fd8bd229fcb209d6163ae0",
    "doi": "10.1109/EMBC.2015.7319280",
    "arxivId": "",
    "authors": "S. Stramaglia, L. Angelini, J. Cortes, Daniele Marinazzo",
    "citationCount": 5
  },
  {
    "s2PaperId": "5cc8ca16ef906867498217c183dfbc0b2ca41f17",
    "title": "A Graph Algorithmic Approach to Separate Direct from Indirect Neural Interactions",
    "abstract": "Network graphs have become a popular tool to represent complex systems composed of many interacting subunits; especially in neuroscience, network graphs are increasingly used to represent and analyze functional interactions between multiple neural sources. Interactions are often reconstructed using pairwise bivariate analyses, overlooking the multivariate nature of interactions: it is neglected that investigating the effect of one source on a target necessitates to take all other sources as potential nuisance variables into account; also combinations of sources may act jointly on a given target. Bivariate analyses produce networks that may contain spurious interactions, which reduce the interpretability of the network and its graph metrics. A truly multivariate reconstruction, however, is computationally intractable because of the combinatorial explosion in the number of potential interactions. Thus, we have to resort to approximative methods to handle the intractability of multivariate interaction reconstruction, and thereby enable the use of networks in neuroscience. Here, we suggest such an approximative approach in the form of an algorithm that extends fast bivariate interaction reconstruction by identifying potentially spurious interactions post-hoc: the algorithm uses interaction delays reconstructed for directed bivariate interactions to tag potentially spurious edges on the basis of their timing signatures in the context of the surrounding network. Such tagged interactions may then be pruned, which produces a statistically conservative network approximation that is guaranteed to contain non-spurious interactions only. We describe the algorithm and present a reference implementation in MATLAB to test the algorithm’s performance on simulated networks as well as networks derived from magnetoencephalographic data. We discuss the algorithm in relation to other approximative multivariate methods and highlight suitable application scenarios. Our approach is a tractable and data-efficient way of reconstructing approximative networks of multivariate interactions. It is preferable if available data are limited or if fully multivariate approaches are computationally infeasible.",
    "year": 2015,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/5cc8ca16ef906867498217c183dfbc0b2ca41f17",
    "doi": "10.1371/journal.pone.0140530",
    "arxivId": "1504.00156",
    "authors": "Patricia Wollstadt, U. Meyer, M. Wibral",
    "citationCount": 15
  },
  {
    "s2PaperId": "395803ee4744070fa5e03b5ec64e400364d6552a",
    "title": "Understanding high-order correlations using a synergy-based decomposition of the total entropy",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/395803ee4744070fa5e03b5ec64e400364d6552a",
    "doi": "",
    "arxivId": "",
    "authors": "Fernando Rosas, Vasilis Ntranos, C. J. Ellison, M. Verhelst, S. Pollin",
    "citationCount": 2
  },
  {
    "s2PaperId": "1c5534c6b08f8a3b97b74ddf9895b1bfd9d245fa",
    "title": "Quantifying Morphological Computation based on an Information Decomposition of the Sensorimotor Loop",
    "abstract": "The question how an agent is affected by its embodiment has attracted growing attention in recent years. A new field of artificial intelligence has emerged, which is based on the idea that intelligence cannot be understood without taking into account embodiment. We believe that a formal approach to quantifying the embodiment's effect on the agent's behaviour is beneficial to the fields of artificial life and artificial intelligence. The contribution of an agent's body and environment to its behaviour is also known as morphological computation. Therefore, in this work, we propose a quantification of morphological computation, which is based on an information decomposition of the sensorimotor loop into shared, unique and synergistic information. In numerical simulation based on a formal representation of the sensorimotor loop, we show that the unique information of the body and environment is a good measure for morphological computation. The results are compared to our previously derived quantification of morphological computation.",
    "year": 2015,
    "venue": "European Conference on Artificial Life",
    "url": "https://www.semanticscholar.org/paper/1c5534c6b08f8a3b97b74ddf9895b1bfd9d245fa",
    "doi": "10.7551/978-0-262-33027-5-ch017",
    "arxivId": "1503.05113",
    "authors": "K. Zahedi, Johannes Rauh",
    "citationCount": 8
  },
  {
    "s2PaperId": "aff38b300d714bad2dccec9b93366e129108f9d8",
    "title": "Some new insights into information decomposition in complex systems based on common information",
    "abstract": "We take a closer look at the structure of bivariate dependency induced by a pair of predictor random variables $(X_1, X_2)$ trying to synergistically, redundantly or uniquely encode a target random variable $Y$. We evaluate a recently proposed measure of redundancy based on the G\\'acs-K\\\"{o}rner common information (Griffith et al., Entropy 2014) and show that the measure, in spite of its elegance is degenerate for most non-trivial distributions. We show that Wyner's common information also fails to capture the notion of redundancy as it violates an intuitive monotonically non-increasing property. We identify a set of conditions when a conditional version of G\\'acs and K\\\"{o}rner's common information is an ideal measure of unique information. Finally, we show how the notions of approximately sufficient statistics and conditional information bottleneck can be used to quantify unique information.",
    "year": 2015,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/aff38b300d714bad2dccec9b93366e129108f9d8",
    "doi": "10.3390/ecea-1-c004",
    "arxivId": "1503.00709",
    "authors": "P. Banerjee",
    "citationCount": 2
  },
  {
    "s2PaperId": "fe8407517f8803240853783a54b1db0a998abbb9",
    "title": "Information Flow through a Model of the C. elegans Klinotaxis Circuit",
    "abstract": "Understanding how information about external stimuli is transformed into behavior is one of the central goals of neuroscience. Here we characterize the information flow through a complete sensorimotor circuit: from stimulus, to sensory neurons, to interneurons, to motor neurons, to muscles, to motion. Specifically, we apply a recently developed framework for quantifying information flow to a previously published ensemble of models of salt klinotaxis in the nematode worm Caenorhabditis elegans. Despite large variations in the neural parameters of individual circuits, we found that the overall information flow architecture circuit is remarkably consistent across the ensemble. This suggests structural connectivity is not necessarily predictive of effective connectivity. It also suggests information flow analysis captures general principles of operation for the klinotaxis circuit. In addition, information flow analysis reveals several key principles underlying how the models operate: (1) Interneuron class AIY is responsible for integrating information about positive and negative changes in concentration, and exhibits a strong left/right information asymmetry. (2) Gap junctions play a crucial role in the transfer of information responsible for the information symmetry observed in interneuron class AIZ. (3) Neck motor neuron class SMB implements an information gating mechanism that underlies the circuit’s state-dependent response. (4) The neck carries more information about small changes in concentration than about large ones, and more information about positive changes in concentration than about negative ones. Thus, not all directions of movement are equally informative for the worm. Each of these findings corresponds to hypotheses that could potentially be tested in the worm. Knowing the results of these experiments would greatly refine our understanding of the neural circuit underlying klinotaxis.",
    "year": 2015,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/fe8407517f8803240853783a54b1db0a998abbb9",
    "doi": "10.1371/journal.pone.0140397",
    "arxivId": "1502.04262",
    "authors": "E. Izquierdo, Paul L. Williams, R. Beer",
    "citationCount": 29
  },
  {
    "s2PaperId": "6425a1ea522d569260f18549bebde4e9db9058da",
    "title": "The information theory of individuality",
    "abstract": "Despite the near universal assumption of individuality in biology, there is little agreement about what individuals are and few rigorous quantitative methods for their identification. Here, we propose that individuals are aggregates that preserve a measure of temporal integrity, i.e., “propagate” information from their past into their futures. We formalize this idea using information theory and graphical models. This mathematical formulation yields three principled and distinct forms of individuality—an organismal, a colonial, and a driven form—each of which varies in the degree of environmental dependence and inherited information. This approach can be thought of as a Gestalt approach to evolution where selection makes figure-ground (agent–environment) distinctions using suitable information-theoretic lenses. A benefit of the approach is that it expands the scope of allowable individuals to include adaptive aggregations in systems that are multi-scale, highly distributed, and do not necessarily have physical boundaries such as cell walls or clonal somatic tissue. Such individuals might be visible to selection but hard to detect by observers without suitable measurement principles. The information theory of individuality allows for the identification of individuals at all levels of organization from molecular to cultural and provides a basis for testing assumptions about the natural scales of a system and argues for the importance of uncertainty reduction through coarse-graining in adaptive systems.",
    "year": 2014,
    "venue": "Theory in biosciences",
    "url": "https://www.semanticscholar.org/paper/6425a1ea522d569260f18549bebde4e9db9058da",
    "doi": "10.1007/s12064-020-00313-7",
    "arxivId": "1412.2447",
    "authors": "D. Krakauer, Nils Bertschinger, E. Olbrich, J. Flack, N. Ay",
    "citationCount": 109
  },
  {
    "s2PaperId": "c00dff07d0df2e234e06a1fea4960aabf4a4254a",
    "title": "Bits from Brains for Biologically Inspired Computing",
    "abstract": "Computational intelligence is broadly defined as biologically-inspired computing. Usually, inspiration is drawn from neural systems. This article shows how to analyze neural systems using information theory to obtain constraints that help identify the algorithms run by such systems and the information they represent. Algorithms and representations identified information-theoretically may then guide the design of biologically inspired computing systems (BICS). The material covered includes the necessary introduction to information theory and the estimation of information theoretic quantities from neural data. We then show how to analyze the information encoded in a system about its environment, and also discuss recent methodological developments on the question of how much information each agent carries about the environment either uniquely, or redundantly or synergistically together with others. Last, we introduce the framework of local information dynamics, where information processing is decomposed into component processes of information storage, transfer, and modification -- locally in space and time. We close by discussing example applications of these measures to neural data and other complex systems.",
    "year": 2014,
    "venue": "Frontiers in Robotics and AI",
    "url": "https://www.semanticscholar.org/paper/c00dff07d0df2e234e06a1fea4960aabf4a4254a",
    "doi": "10.3389/frobt.2015.00005",
    "arxivId": "1412.0291",
    "authors": "M. Wibral, J. Lizier, V. Priesemann",
    "citationCount": 106
  },
  {
    "s2PaperId": "709d730371f4a1e2db46a92533868354ce0c86d5",
    "title": "Quantifying Redundant Information in Predicting a Target Random Variable",
    "abstract": "We consider the problem of defining a measure of redundant information that quantifies how much common information two or more random variables specify about a target random variable. We discussed desired properties of such a measure, and propose new measures with some desirable properties.",
    "year": 2014,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/709d730371f4a1e2db46a92533868354ce0c86d5",
    "doi": "10.3390/e17074644",
    "arxivId": "1411.4732",
    "authors": "V. Griffith, T. Ho",
    "citationCount": 39
  },
  {
    "s2PaperId": "dd6bc12311b82318ace47472ed2b9948393900c3",
    "title": "An exploration of synergistic and redundant information sharing in static and dynamical Gaussian systems",
    "abstract": "To fully characterize the information that two source variables carry about a third target variable, one must decompose the total information into redundant, unique, and synergistic components, i.e., obtain a partial information decomposition (PID). However, Shannon's theory of information does not provide formulas to fully determine these quantities. Several recent studies have begun addressing this. Some possible definitions for PID quantities have been proposed and some analyses have been carried out on systems composed of discrete variables. Here we present an in-depth analysis of PIDs on Gaussian systems, both static and dynamical. We show that, for a broad class of Gaussian systems, previously proposed PID formulas imply that (i) redundancy reduces to the minimum information provided by either source variable and hence is independent of correlation between sources, and (ii) synergy is the extra information contributed by the weaker source when the stronger source is known and can either increase or decrease with correlation between sources. We find that Gaussian systems frequently exhibit net synergy, i.e., the information carried jointly by both sources is greater than the sum of information carried by each source individually. Drawing from several explicit examples, we discuss the implications of these findings for measures of information transfer and information-based measures of complexity, both generally and within a neuroscience setting. Importantly, by providing independent formulas for synergy and redundancy applicable to continuous time-series data, we provide an approach to characterizing and quantifying information sharing amongst complex system variables.",
    "year": 2014,
    "venue": "Physical review. E, Statistical, nonlinear, and soft matter physics",
    "url": "https://www.semanticscholar.org/paper/dd6bc12311b82318ace47472ed2b9948393900c3",
    "doi": "10.1103/PhysRevE.91.052802",
    "arxivId": "1411.2832",
    "authors": "A. Barrett",
    "citationCount": 177
  },
  {
    "s2PaperId": "a075bb56a68d15c50c57a00d1e957a4090ae052d",
    "title": "Applying Information Theory to Neuronal Networks: From Theory to Experiments",
    "abstract": "Information-theory is being increasingly used to analyze complex, self-organizing processes on networks, predominantly in analytical and numerical studies. Perhaps one of the most paradigmatic complex systems is a network of neurons, in which cognition arises from the information storage, transfer, and processing among individual neurons. In this article we review experimental techniques suitable for validating information-theoretical predictions in simple neural networks, as well as generating new hypotheses. Specifically, we focus on techniques that may be used to measure both network (microcircuit) anatomy as well as neuronal activity simultaneously. This is needed to study the role of the network structure on the emergent collective dynamics, which is one of the reasons to study the characteristics of information processing. We discuss in detail two suitable techniques, namely calcium imaging and the application of multi-electrode arrays to simple neural networks in culture, and discuss their advantages and limitations in an accessible manner for non-experts. In particular, we show that each technique induces a qualitatively different type of error on the measured mutual information. The ultimate goal of this work is to bridge the gap between theorists and experimentalists in their shared goal of understanding the behavior of networks of neurons.",
    "year": 2014,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/a075bb56a68d15c50c57a00d1e957a4090ae052d",
    "doi": "10.3390/E16115721",
    "arxivId": "",
    "authors": "Thijs I. Jung, Filippos Vogiatzian, Omri Har-Shemesh, C. Fitzsimons, Rick Quax",
    "citationCount": 9
  },
  {
    "s2PaperId": "0c38f69414c2a34dda4478294d0f26af6558e050",
    "title": "Maximally Informative Hierarchical Representations of High-Dimensional Data",
    "abstract": "We consider a set of probabilistic functions of some input variables as a representation of the inputs. We present bounds on how informative a representation is about input data. We extend these bounds to hierarchical representations so that we can quantify the contribution of each layer towards capturing the information in the original data. The special form of these bounds leads to a simple, bottom-up optimization procedure to construct hierarchical representations that are also maximally informative about the data. This optimization has linear computational complexity and constant sample complexity in the number of variables. These results establish a new approach to unsupervised learning of deep representations that is both principled and practical. We demonstrate the usefulness of the approach on both synthetic and real-world data.",
    "year": 2014,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "url": "https://www.semanticscholar.org/paper/0c38f69414c2a34dda4478294d0f26af6558e050",
    "doi": "",
    "arxivId": "1410.7404",
    "authors": "G. V. Steeg, A. Galstyan",
    "citationCount": 65
  },
  {
    "s2PaperId": "2cc13968ee64ddfc010615271e8e4a1592b5f73f",
    "title": "Entropy Methods in Guided Self-Organisation",
    "abstract": "Self-organisation occurs in natural phenomena when a spontaneous increase in order is produced by the interactions of elements of a complex system. Thermodynamically, this increase must be offset by production of entropy which, broadly speaking, can be understood as a decrease in order. Ideally, self-organisation can be used to guide the system towards a desired regime or state, while \"exporting\" the entropy to the system's exterior. Thus, Guided Self-Organisation (GSO) attempts to harness the order-inducing potential of self-organisation for specific purposes. Not surprisingly, general methods developed to study entropy can also be applied to guided self-organisation. This special issue covers abroad diversity of GSO approaches which can be classified in three categories: information theory, intelligent agents, and collective behavior. The proposals make another step towards a unifying theory of GSO which promises to impact numerous research fields.",
    "year": 2014,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/2cc13968ee64ddfc010615271e8e4a1592b5f73f",
    "doi": "10.3390/e16105232",
    "arxivId": "",
    "authors": "M. Prokopenko, C. Gershenson",
    "citationCount": 23
  },
  {
    "s2PaperId": "70b45b61d38bb3d44794b57fdd1dbf9d1212b18b",
    "title": "JIDT: An Information-Theoretic Toolkit for Studying the Dynamics of Complex Systems",
    "abstract": "Complex systems are increasingly being viewed as distributed information processing systems, particularly in the domains of computational neuroscience, bioinformatics and Artificial Life. This trend has resulted in a strong uptake in the use of (Shannon) information-theoretic measures to analyse the dynamics of complex systems in these fields. We introduce the Java Information Dynamics Toolkit (JIDT): a Google code project which provides a standalone, (GNU GPL v3 licensed) open-source code implementation for empirical estimation of information-theoretic measures from time-series data. While the toolkit provides classic information-theoretic measures (e.g. entropy, mutual information, conditional mutual information), it ultimately focusses on implementing higher-level measures for information dynamics. That is, JIDT focusses on quantifying information storage, transfer and modification, and the dynamics of these operations in space and time. For this purpose, it includes implementations of the transfer entropy and active information storage, their multivariate extensions and local or pointwise variants. JIDT provides implementations for both discrete and continuous-valued data for each measure, including various types of estimator for continuous data (e.g. Gaussian, box-kernel and Kraskov-Stoegbauer-Grassberger) which can be swapped at run-time due to Java's object-oriented polymorphism. Furthermore, while written in Java, the toolkit can be used directly in MATLAB, GNU Octave, Python and other environments. We present the principles behind the code design, and provide several examples to guide users.",
    "year": 2014,
    "venue": "Frontiers in Robotics and AI",
    "url": "https://www.semanticscholar.org/paper/70b45b61d38bb3d44794b57fdd1dbf9d1212b18b",
    "doi": "10.3389/frobt.2014.00011",
    "arxivId": "1408.3270",
    "authors": "J. Lizier",
    "citationCount": 345
  },
  {
    "s2PaperId": "be14215e9da95f1a33950d8f9e994d319b36f11c",
    "title": "Discovering Structure in High-Dimensional Data Through Correlation Explanation",
    "abstract": "We introduce a method to learn a hierarchy of successively more abstract representations of complex data based on optimizing an information-theoretic objective. Intuitively, the optimization searches for a set of latent factors that best explain the correlations in the data as measured by multivariate mutual information. The method is unsupervised, requires no model assumptions, and scales linearly with the number of variables which makes it an attractive approach for very high dimensional systems. We demonstrate that Correlation Explanation (CorEx) automatically discovers meaningful structure for data from diverse sources including personality tests, DNA, and human language.",
    "year": 2014,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/be14215e9da95f1a33950d8f9e994d319b36f11c",
    "doi": "",
    "arxivId": "1406.1222",
    "authors": "G. V. Steeg, A. Galstyan",
    "citationCount": 99
  },
  {
    "s2PaperId": "6b839ce1672480dfb687591ec38dccd05dd2351b",
    "title": "A Causal Perspective on the Analysis of Signal and Noise Correlations and Their Role in Population Coding",
    "abstract": "",
    "year": 2014,
    "venue": "Neural Computation",
    "url": "https://www.semanticscholar.org/paper/6b839ce1672480dfb687591ec38dccd05dd2351b",
    "doi": "10.1162/NECO_a_00588",
    "arxivId": "",
    "authors": "D. Chicharro",
    "citationCount": 12
  },
  {
    "s2PaperId": "b2b115cfe7ee9313adf0c48f9dd91e80c305bf3c",
    "title": "Is Consciousness Computable? Quantifying Integrated Information Using Algorithmic Information Theory",
    "abstract": "In this article we review Tononi's (2008) theory of consciousness as integrated information. We argue that previous formalizations of integrated information (e.g. Griffith, 2014) depend on information loss. Since lossy integration would necessitate continuous damage to existing memories, we propose it is more natural to frame consciousness as a lossless integrative process and provide a formalization of this idea using algorithmic information theory. We prove that complete lossless integration requires noncomputable functions. This result implies that if unitary consciousness exists, it cannot be modelled computationally.",
    "year": 2014,
    "venue": "Annual Meeting of the Cognitive Science Society",
    "url": "https://www.semanticscholar.org/paper/b2b115cfe7ee9313adf0c48f9dd91e80c305bf3c",
    "doi": "",
    "arxivId": "1405.0126",
    "authors": "P. Maguire, Philippe Moser, R. Maguire, V. Griffith",
    "citationCount": 14
  },
  {
    "s2PaperId": "16e4e202db3afc02cebcc5305b743a1fb0f00b8b",
    "title": "Identification of redundant and synergetic circuits in triplets of electrophysiological data",
    "abstract": "Objective. Neural systems are comprised of interacting units, and relevant information regarding their function or malfunction can be inferred by analyzing the statistical dependencies between the activity of each unit. While correlations and mutual information are commonly used to characterize these dependencies, our objective here is to extend interactions to triplets of variables to better detect and characterize dynamic information transfer. Approach. Our approach relies on the measure of interaction information (II). The sign of II provides information as to the extent to which the interaction of variables in triplets is redundant (R) or synergetic (S). Three variables are said to be redundant when a third variable, say Z, added to a pair of variables (X, Y), diminishes the information shared between X and Y. Similarly, the interaction in the triplet is said to be synergetic when conditioning on Z enhances the information shared between X and Y with respect to the unconditioned state. Here, based on this approach, we calculated the R and S status for triplets of electrophysiological data recorded from drug-resistant patients with mesial temporal lobe epilepsy in order to study the spatial organization and dynamics of R and S close to the epileptogenic zone (the area responsible for seizure propagation). Main results. In terms of spatial organization, our results show that R matched the epileptogenic zone while S was distributed more in the surrounding area. In relation to dynamics, R made the largest contribution to high frequency bands (14–100 Hz), while S was expressed more strongly at lower frequencies (1–7 Hz). Thus, applying II to such clinical data reveals new aspects of epileptogenic structure in terms of the nature (redundancy versus synergy) and dynamics (fast versus slow rhythms) of the interactions. Significance. We expect this methodology, robust and simple, can reveal new aspects beyond pair-interactions in networks of interacting units in other setups with multi-recording data sets (and thus, not necessarily in epilepsy, the pathology we have approached here).",
    "year": 2014,
    "venue": "Journal of Neural Engineering",
    "url": "https://www.semanticscholar.org/paper/16e4e202db3afc02cebcc5305b743a1fb0f00b8b",
    "doi": "10.1088/1741-2560/12/6/066007",
    "arxivId": "1404.6836",
    "authors": "A. Erramuzpe, G. Ortega, J. Pastor, R. G. de Sola, Daniele Marinazzo, S. Stramaglia, J. Cortes",
    "citationCount": 15
  },
  {
    "s2PaperId": "ba6409d813d881d571c3e5eee5245f2c3ba37819",
    "title": "Interaction information in human electrocorticography data of temporal lobe epilepsy",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/ba6409d813d881d571c3e5eee5245f2c3ba37819",
    "doi": "",
    "arxivId": "",
    "authors": "A. Erramuzpe, G. Ortega, J. Pastor, R. Sola, Daniele Marinazzo, S. Stramaglia, J. Cortes",
    "citationCount": 0
  },
  {
    "s2PaperId": "58d463afd9cf90e64298cf321caba065203686ad",
    "title": "Reconsidering unique information: Towards a multivariate information decomposition",
    "abstract": "The information that two random variables Y, Z contain about a third random variable X can have aspects of shared information (contained in both Y and Z), of complementary information (only available from (Y, Z) together) and of unique information (contained exclusively in either Y or Z). Here, we study measures SĨ of shared, UĨ unique and CĨ complementary information introduced by Bertschinger et al. [1] which are motivated from a decision theoretic perspective. We find that in most cases the intuitive rule that more variables contain more information applies, with the exception that SĨ and CĨ information are not monotone in the target variable X. Additionally, we show that it is not possible to extend the bivariate information decomposition into SĨ, UĨ and CĨ to a non-negative decomposition on the partial information lattice of Williams and Beer [2]. Nevertheless, the quantities UĨ, SĨ and CĨ have a well-defined interpretation, even in the multivariate setting.",
    "year": 2014,
    "venue": "2014 IEEE International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/58d463afd9cf90e64298cf321caba065203686ad",
    "doi": "10.1109/ISIT.2014.6875230",
    "arxivId": "1404.3146",
    "authors": "Johannes Rauh, Nils Bertschinger, E. Olbrich, J. Jost",
    "citationCount": 53
  },
  {
    "s2PaperId": "3dcf7508b336b25160b97202ba8918777f7aa99c",
    "title": "Feature Selection for Chemical Sensor Arrays Using Mutual Information",
    "abstract": "We address the problem of feature selection for classifying a diverse set of chemicals using an array of metal oxide sensors. Our aim is to evaluate a filter approach to feature selection with reference to previous work, which used a wrapper approach on the same data set, and established best features and upper bounds on classification performance. We selected feature sets that exhibit the maximal mutual information with the identity of the chemicals. The selected features closely match those found to perform well in the previous study using a wrapper approach to conduct an exhaustive search of all permitted feature combinations. By comparing the classification performance of support vector machines (using features selected by mutual information) with the performance observed in the previous study, we found that while our approach does not always give the maximum possible classification performance, it always selects features that achieve classification performance approaching the optimum obtained by exhaustive search. We performed further classification using the selected feature set with some common classifiers and found that, for the selected features, Bayesian Networks gave the best performance. Finally, we compared the observed classification performances with the performance of classifiers using randomly selected features. We found that the selected features consistently outperformed randomly selected features for all tested classifiers. The mutual information filter approach is therefore a computationally efficient method for selecting near optimal features for chemical sensor arrays.",
    "year": 2014,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/3dcf7508b336b25160b97202ba8918777f7aa99c",
    "doi": "10.1371/journal.pone.0089840",
    "arxivId": "",
    "authors": "X. R. Wang, J. Lizier, Thomas Nowotny, Thomas Nowotny, A. Berna, M. Prokopenko, S. Trowell",
    "citationCount": 20
  },
  {
    "s2PaperId": "5355703a841e60a0caae5fc14b908841107f4928",
    "title": "Efficient Transfer Entropy Analysis of Non-Stationary Neural Time Series",
    "abstract": "Information theory allows us to investigate information processing in neural systems in terms of information transfer, storage and modification. Especially the measure of information transfer, transfer entropy, has seen a dramatic surge of interest in neuroscience. Estimating transfer entropy from two processes requires the observation of multiple realizations of these processes to estimate associated probability density functions. To obtain these necessary observations, available estimators typically assume stationarity of processes to allow pooling of observations over time. This assumption however, is a major obstacle to the application of these estimators in neuroscience as observed processes are often non-stationary. As a solution, Gomez-Herrero and colleagues theoretically showed that the stationarity assumption may be avoided by estimating transfer entropy from an ensemble of realizations. Such an ensemble of realizations is often readily available in neuroscience experiments in the form of experimental trials. Thus, in this work we combine the ensemble method with a recently proposed transfer entropy estimator to make transfer entropy estimation applicable to non-stationary time series. We present an efficient implementation of the approach that is suitable for the increased computational demand of the ensemble method's practical application. In particular, we use a massively parallel implementation for a graphics processing unit to handle the computationally most heavy aspects of the ensemble method for transfer entropy estimation. We test the performance and robustness of our implementation on data from numerical simulations of stochastic processes. We also demonstrate the applicability of the ensemble method to magnetoencephalographic data. While we mainly evaluate the proposed method for neuroscience data, we expect it to be applicable in a variety of fields that are concerned with the analysis of information transfer in complex biological, social, and artificial systems.",
    "year": 2014,
    "venue": "PLoS ONE",
    "url": "https://www.semanticscholar.org/paper/5355703a841e60a0caae5fc14b908841107f4928",
    "doi": "10.1371/journal.pone.0102833",
    "arxivId": "1401.4068",
    "authors": "Patricia Wollstadt, M. Martínez-Zarzuela, Raul Vicente, F. Pernas, M. Wibral",
    "citationCount": 131
  },
  {
    "s2PaperId": "efa5b00b4893d656726d0914eed09cf629739873",
    "title": "The Blackwell relation defines no lattice",
    "abstract": "Blackwell's theorem shows the equivalence of two preorders on the set of information channels. Here, we restate, and slightly generalize, his result in terms of random variables. Furthermore, we prove that the corresponding partial order is not a lattice; that is, least upper bounds and greatest lower bounds do not exist.",
    "year": 2014,
    "venue": "2014 IEEE International Symposium on Information Theory",
    "url": "https://www.semanticscholar.org/paper/efa5b00b4893d656726d0914eed09cf629739873",
    "doi": "10.1109/ISIT.2014.6875280",
    "arxivId": "1401.3146",
    "authors": "Nils Bertschinger, Johannes Rauh",
    "citationCount": 16
  },
  {
    "s2PaperId": "f1b6ab4ef026867bd05ab6ffc15cf65ceb6b7ecb",
    "title": "A Principled Infotheoretic \\phi-like Measure",
    "abstract": "Integrated information theory is a mathematical, quantifiable theory of conscious experience. The linchpin of this theory, the $\\phi$ measure, quantifies a system's irreducibility to disjoint parts. Purely as a measure of irreducibility, we pinpoint three concerns about $\\phi$ and propose a revised measure, $\\psi$, which addresses them. Our measure $\\psi$ is rigorously grounded in Partial Information Decomposition and is faster to compute than $\\phi$.",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/f1b6ab4ef026867bd05ab6ffc15cf65ceb6b7ecb",
    "doi": "",
    "arxivId": "1401.0978",
    "authors": "V. Griffith",
    "citationCount": 13
  },
  {
    "s2PaperId": "0ca3e63a3151e928f32ac20a1493eb7a45e59fc7",
    "title": "Irreducibility is Minimum Synergy Among Parts",
    "abstract": "For readers already familiar with Partial Information Decomposition (PID), we show that PID's definition of synergy enables quantifying at least four different notions of irreducibility. First, we show four common notions of \"parts\" give rise to a spectrum of four distinct measures of irreducibility. Second, we introduce a nonnegative expression based on PID for each notion of irreducibility. Third, we delineate these four notions of irreducibility with exemplary binary circuits. This work will become more useful once the complexity community has converged on a palatable $\\operatorname{I}_{\\cap}$ or $\\operatorname{I}_{\\cup}$ measure.",
    "year": 2013,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/0ca3e63a3151e928f32ac20a1493eb7a45e59fc7",
    "doi": "",
    "arxivId": "1311.7442",
    "authors": "V. Griffith, Jonathan Harel",
    "citationCount": 2
  },
  {
    "s2PaperId": "8e53e6db19238f223bb1d42a616ee7b3324aa6ad",
    "title": "Quantifying unique information",
    "abstract": "We propose new measures of shared information, unique information and synergistic information that can be used to decompose the mutual information of a pair of random variables (Y, Z) with a third random variable X. Our measures are motivated by an operational idea of unique information, which suggests that shared information and unique information should depend only on the marginal distributions of the pairs (X, Y) and (X,Z). Although this invariance property has not been studied before, it is satisfied by other proposed measures of shared information. The invariance property does not uniquely determine our new measures, but it implies that the functions that we define are bounds to any other measures satisfying the same invariance property. We study properties of our measures and compare them to other candidate measures.",
    "year": 2013,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/8e53e6db19238f223bb1d42a616ee7b3324aa6ad",
    "doi": "10.3390/e16042161",
    "arxivId": "1311.2852",
    "authors": "Nils Bertschinger, Johannes Rauh, E. Olbrich, J. Jost, N. Ay",
    "citationCount": 283
  },
  {
    "s2PaperId": "ead00c7631501a4d419a503ff116020525b1dd88",
    "title": "Intersection Information Based on Common Randomness",
    "abstract": "The introduction of the partial information decomposition generated a flurry of proposals for defining an intersection information that quantifies how much of “the same information” two or more random variables specify about a target random variable. As of yet, none is wholly satisfactory. A palatable measure of intersection information would provide a principled way to quantify slippery concepts, such as synergy. Here, we introduce an intersection information measure based on the Gacs-Korner common random variable that is the first to satisfy the coveted target monotonicity property. Our measure is imperfect, too, and we suggest directions for improvement.",
    "year": 2013,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/ead00c7631501a4d419a503ff116020525b1dd88",
    "doi": "10.3390/e16041985",
    "arxivId": "1310.1538",
    "authors": "V. Griffith, E. Chong, R. James, C. J. Ellison, J. Crutchfield",
    "citationCount": 86
  },
  {
    "s2PaperId": "5aeb04429d916c4ff0f34d9ff9ff4e2a6f1c36f5",
    "title": "Information theoretic models of social interaction",
    "abstract": "",
    "year": 2013,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/5aeb04429d916c4ff0f34d9ff9ff4e2a6f1c36f5",
    "doi": "10.18745/TH.13887",
    "arxivId": "",
    "authors": "Christoph Salge",
    "citationCount": 0
  },
  {
    "s2PaperId": "540a91e518e539b34b466f022104ed1fd9f9a24a",
    "title": "Information dynamics at the edge of chaos: Measures, examples, and principles",
    "abstract": "",
    "year": 2013,
    "venue": "IEEE Symposium on Artificial Life",
    "url": "https://www.semanticscholar.org/paper/540a91e518e539b34b466f022104ed1fd9f9a24a",
    "doi": "10.1109/ALIFE.2013.6602443",
    "arxivId": "",
    "authors": "M. Prokopenko",
    "citationCount": 6
  },
  {
    "s2PaperId": "ef7f6bbceeab0976afc14139ce2854e41ba5600d",
    "title": "Multiple pathways network description of motor neurons in locusts: An information sensitivity analysis",
    "abstract": "",
    "year": 2013,
    "venue": "ISSNIP Biosignals and Biorobotics Conference: Biosignals and Robotics for Better and Safer Living",
    "url": "https://www.semanticscholar.org/paper/ef7f6bbceeab0976afc14139ce2854e41ba5600d",
    "doi": "10.1109/BRC.2013.6487544",
    "arxivId": "",
    "authors": "W. Endo, Carlos Dias Maciel, D. Simpson, P. Newland",
    "citationCount": 0
  },
  {
    "s2PaperId": "adf76582d43ad5a547677fa65f36a341378e9055",
    "title": "On active information storage in input-driven systems",
    "abstract": "Information theory and the framework of information dynamics have been used to provide tools to characterise complex systems. In particular, we are interested in quantifying information storage, information modification and information transfer as characteristic elements of computation. Although these quantities are defined for autonomous dynamical systems, information dynamics can also help to get a \"wholistic\" understanding of input-driven systems such as neural networks. In this case, we do not distinguish between the system itself, and the effects the input has to the system. This may be desired in some cases, but it will change the questions we are able to answer, and is consequently an important consideration, for example, for biological systems which perform non-trivial computations and also retain a short-term memory of past inputs. Many other real world systems like cortical networks are also heavily input-driven, and application of tools designed for autonomous dynamic systems may not necessarily lead to intuitively interpretable results.  The aim of our work is to extend the measurements used in the information dynamics framework for input-driven systems. Using the proposed input-corrected information storage we hope to better quantify system behaviour, which will be important for heavily input-driven systems like artificial neural networks to abstract from specific benchmarks, or for brain networks, where intervention is difficult, individual components cannot be tested in isolation or with arbitrary input data.",
    "year": 2013,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/adf76582d43ad5a547677fa65f36a341378e9055",
    "doi": "",
    "arxivId": "1303.5526",
    "authors": "Oliver Obst, Joschka Boedecker, Benedikt Schmidt, M. Asada",
    "citationCount": 7
  },
  {
    "s2PaperId": "402dc2fecbc733875cf558adb05b1b6e242391c7",
    "title": "Towards a synergy-based approach to measuring information modification",
    "abstract": "Distributed computation in artificial life and complex systems is often described in terms of component operations on information: information storage, transfer and modification. Information modification remains poorly described however, with the popularly-understood examples of glider and particle collisions in cellular automata being only quantitatively identified to date using a heuristic (separable information) rather than a proper information-theoretic measure. We outline how a recently-introduced axiomatic framework for measuring information redundancy and synergy, called partial information decomposition, can be applied to a perspective of distributed computation in order to quantify component operations on information. Using this framework, we propose a new measure of information modification that captures the intuitive understanding of information modification events as those involving interactions between two or more information sources. We also consider how the local dynamics of information modification in space and time could be measured, and suggest a new axiom that redundancy measures would need to meet in order to make such local measurements. Finally, we evaluate the potential for existing redundancy measures to meet this localizability axiom.",
    "year": 2013,
    "venue": "IEEE Symposium on Artificial Life",
    "url": "https://www.semanticscholar.org/paper/402dc2fecbc733875cf558adb05b1b6e242391c7",
    "doi": "10.1109/ALIFE.2013.6602430",
    "arxivId": "1303.3440",
    "authors": "J. Lizier, Benjamin Flecker, Paul L. Williams",
    "citationCount": 69
  },
  {
    "s2PaperId": "22b48202b431b7d78e40abe00aba6910195f5f39",
    "title": "Transfer Entropy for Coupled Autoregressive Processes",
    "abstract": "A method is shown for computing transfer entropy over multiple time lags for coupled autoregressive processes using formulas for the differential entropy of multivariate Gaussian processes. Two examples are provided: (1) a first-order filtered noise process whose state is measured with additive noise, and (2) two first-order coupled processes each of which is driven by white process noise. We found that, for the first example, increasing the first-order AR coefficient while keeping the correlation coefficient between filtered and measured process fixed, transfer entropy increased since the entropy of the measured process was itself increased. For the second example, the minimum correlation coefficient occurs when the process noise variances match. It was seen that matching of these variances results in minimum information flow, expressed as the sum of transfer entropies in both directions. Without a match, the transfer entropy is larger in the direction away from the process having the larger process noise. Fixing the process noise variances, transfer entropies in both directions increase with the coupling strength. Finally, we note that the method can be generally employed to compute other information theoretic quantities as well.",
    "year": 2013,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/22b48202b431b7d78e40abe00aba6910195f5f39",
    "doi": "10.3390/e15030767",
    "arxivId": "",
    "authors": "D. Hahs, S. Pethel",
    "citationCount": 22
  },
  {
    "s2PaperId": "6e054b98147dfebb18f15b1264c57ed0635a6d5a",
    "title": "Moving Frames of Reference, Relativity and Invariance in Transfer Entropy and Information Dynamics",
    "abstract": "We present a new interpretation of a local framework for informationdynamics, including the transfer entropy, by defining a moving frame of reference for theobserver of dynamics in lattice systems. This formulation is inspired by the idea ofinvestigating “relativistic” effects on observing the dynamics of information - in particular,we investigate a Galilean transformation of the lattice system data. In applying thisinterpretation to elementary cellular automata, we demonstrate that using a moving frameof reference certainly alters the observed spatiotemporal measurements of informationdynamics, yet still returns meaningful results in this context. We find that, as expected,an observer will report coherent spatiotemporal structures that are moving in their frame asinformation transfer, and structures that are stationary in their frame as information storage.Crucially, the extent to which the shifted frame of reference alters the results dependson whether the shift of frame retains, adds or removes relevant information regarding thesource-destination interaction.",
    "year": 2013,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/6e054b98147dfebb18f15b1264c57ed0635a6d5a",
    "doi": "10.3390/e15010177",
    "arxivId": "",
    "authors": "J. Lizier, J. Mahoney",
    "citationCount": 14
  },
  {
    "s2PaperId": "02d6565ebeb6d993244961184aa5e8539f3faca0",
    "title": "Pattern Mining for General Intelligence: The FISHGRAM Algorithm for Frequent and Interesting Subhypergraph Mining",
    "abstract": "",
    "year": 2012,
    "venue": "Artificial General Intelligence",
    "url": "https://www.semanticscholar.org/paper/02d6565ebeb6d993244961184aa5e8539f3faca0",
    "doi": "10.1007/978-3-642-35506-6_20",
    "arxivId": "",
    "authors": "J. O'Neill, B. Goertzel, Shujing Ke, Ruiting Lian, Keyvan Sadeghi, S. Shiu, Dingjie Wang, Gino Yu",
    "citationCount": 1
  },
  {
    "s2PaperId": "786d85f4993897cc18e928c97a2fc1bf61d54e93",
    "title": "Local measures of information storage in complex distributed computation",
    "abstract": "",
    "year": 2012,
    "venue": "Information Sciences",
    "url": "https://www.semanticscholar.org/paper/786d85f4993897cc18e928c97a2fc1bf61d54e93",
    "doi": "10.1016/j.ins.2012.04.016",
    "arxivId": "",
    "authors": "J. Lizier, M. Prokopenko, Albert Y. Zomaya",
    "citationCount": 177
  },
  {
    "s2PaperId": "10a301e3e2ba6b11fddc97c4ab79e26cea8ec05c",
    "title": "Shared Information -- New Insights and Problems in Decomposing Information in Complex Systems",
    "abstract": "How can the information that a set {X 1,…,X n } of random variables contains about another random variable S be decomposed? To what extent do different subgroups provide the same, i.e. shared or redundant, information, carry unique information or interact for the emergence of synergistic information?",
    "year": 2012,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/10a301e3e2ba6b11fddc97c4ab79e26cea8ec05c",
    "doi": "10.1007/978-3-319-00395-5_35",
    "arxivId": "1210.5902",
    "authors": "Nils Bertschinger, Johannes Rauh, E. Olbrich, J. Jost",
    "citationCount": 106
  },
  {
    "s2PaperId": "7acfbcdb62043dd6f9e27a771433ac97b3d599b0",
    "title": "Identification of Informative Subgraphs in Complex Systems",
    "abstract": "",
    "year": 2012,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/7acfbcdb62043dd6f9e27a771433ac97b3d599b0",
    "doi": "",
    "arxivId": "",
    "authors": "S. Stramaglia, M. Pellicoro, Daniele Marinazzo, Guo-Rong Wu",
    "citationCount": 0
  },
  {
    "s2PaperId": "701db06451d6b218c25619ac1233ade1397b6556",
    "title": "A Bivariate Measure of Redundant Information",
    "abstract": "We define a measure of redundant information based on projections in the space of probability distributions. Redundant information between random variables is information that is shared between those variables. But, in contrast to mutual information, redundant information denotes information that is shared about the outcome of a third variable. Formalizing this concept, and being able to measure it, is required for the non-negative decomposition of mutual information into redundant and synergistic information. Previous attempts to formalize redundant or synergistic information struggle to capture some desired properties. We introduce a new formalism for redundant information and prove that it satisfies all the properties necessary outlined in earlier work, as well as an additional criterion that we propose to be necessary to capture redundancy. We also demonstrate the behavior of this new measure for several examples, compare it to previous measures, and apply it to the decomposition of transfer entropy.",
    "year": 2012,
    "venue": "Physical review. E, Statistical, nonlinear, and soft matter physics",
    "url": "https://www.semanticscholar.org/paper/701db06451d6b218c25619ac1233ade1397b6556",
    "doi": "10.1103/PhysRevE.87.012130",
    "arxivId": "1207.2080",
    "authors": "Malte Harder, Christoph Salge, D. Polani",
    "citationCount": 185
  },
  {
    "s2PaperId": "70840d5f3a42c41970bea8c48b5803d6bf14cdb4",
    "title": "The Minimal Complexity of Adapting Agents Increases with Fitness",
    "abstract": "What is the relationship between the complexity and the fitness of evolved organisms, whether natural or artificial? It has been asserted, primarily based on empirical data, that the complexity of plants and animals increases as their fitness within a particular environment increases via evolution by natural selection. We simulate the evolution of the brains of simple organisms living in a planar maze that they have to traverse as rapidly as possible. Their connectome evolves over 10,000s of generations. We evaluate their circuit complexity, using four information-theoretical measures, including one that emphasizes the extent to which any network is an irreducible entity. We find that their minimal complexity increases with their fitness.",
    "year": 2012,
    "venue": "IEEE Symposium on Artificial Life",
    "url": "https://www.semanticscholar.org/paper/70840d5f3a42c41970bea8c48b5803d6bf14cdb4",
    "doi": "10.1371/journal.pcbi.1003111",
    "arxivId": "",
    "authors": "Nikhil J. Joshi, G. Tononi, C. Koch",
    "citationCount": 41
  },
  {
    "s2PaperId": "3dd37217f9c89a4fb4cb74caf286d0d8c2b6ab20",
    "title": "Quantifying synergistic mutual information",
    "abstract": "Synergy is a fundamental concept in complex systems that has received much attention in computational biology (Narayanan et al. 2005; Balduzzi and Tononi 2008). Several papers (Schneidman et al. 2003a; Bell 2003; Nirenberg et al. 2001;Williams and Beer 2010) have proposed measures for quantifying synergy, but there remains no consensus which measure is most valid.",
    "year": 2012,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/3dd37217f9c89a4fb4cb74caf286d0d8c2b6ab20",
    "doi": "10.1007/978-3-642-53734-9_6",
    "arxivId": "1205.4265",
    "authors": "V. Griffith, C. Koch",
    "citationCount": 230
  },
  {
    "s2PaperId": "48e0e58c58eef573640630ae4d88f0309e4af856",
    "title": "Expanding the transfer entropy to identify information subgraphs in complex systems",
    "abstract": "We propose a formal expansion of the transfer entropy to put in evidence irreducible sets of variables which provide information for the future state of each assigned target. Multiplets characterized by an high value will be associated to informational circuits present in the system, with an informational character (synergetic or redundant) which can be associated to the sign of the contribution. We also present preliminary results on fMRI and EEG data sets.",
    "year": 2012,
    "venue": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
    "url": "https://www.semanticscholar.org/paper/48e0e58c58eef573640630ae4d88f0309e4af856",
    "doi": "10.1103/PhysRevE.86.066211",
    "arxivId": "1203.3037",
    "authors": "S. Stramaglia, Guorong Wu, M. Pellicoro, Daniele Marinazzo",
    "citationCount": 40
  },
  {
    "s2PaperId": "4931b552f6449aeff57cbfbc639636cb6ea4a1e3",
    "title": "Anatomy of a Bit: Information in a Time Series Observation",
    "abstract": "Appealing to several multivariate information measures--some familiar, some new here--we analyze the information embedded in discrete-valued stochastic time series. We dissect the uncertainty of a single observation to demonstrate how the measures' asymptotic behavior sheds structural and semantic light on the generating process's internal information dynamics. The measures scale with the length of time window, which captures both intensive (rates of growth) and subextensive components. We provide interpretations for the components, developing explicit relationships between them. We also identify the informational component shared between the past and the future that is not contained in a single observation. The existence of this component directly motivates the notion of a process's effective (internal) states and indicates why one must build models.",
    "year": 2011,
    "venue": "Chaos",
    "url": "https://www.semanticscholar.org/paper/4931b552f6449aeff57cbfbc639636cb6ea4a1e3",
    "doi": "10.1063/1.3637494",
    "arxivId": "1105.2988",
    "authors": "R. James, C. J. Ellison, J. Crutchfield",
    "citationCount": 139
  },
  {
    "s2PaperId": "5b07c12915d861495b6df86955edfc49935218f5",
    "title": "Information-theoretic inference of common ancestors",
    "abstract": "A directed acyclic graph (DAG) partially represents the conditional independence structure among observations of a system if the local Markov condition holds, that is if every variable is independent of its non-descendants given its parents. In general, there is a whole class of DAGs that represents a given set of conditional independence relations. We are interested in properties of this class that can be derived from observations of a subsystem only. To this end, we prove an information-theoretic inequality that allows for the inference of common ancestors of observed parts in any DAG representing some unknown larger system. More explicitly, we show that a large amount of dependence in terms of mutual information among the observations implies the existence of a common ancestor that distributes this information. Within the causal interpretation of DAGs, our result can be seen as a quantitative extension of Reichenbach’s principle of common cause to more than two variables. Our conclusions are valid also for non-probabilistic observations, such as binary strings, since we state the proof for an axiomatized notion of “mutual information” that includes the stochastic as well as the algorithmic version.",
    "year": 2010,
    "venue": "Entropy",
    "url": "https://www.semanticscholar.org/paper/5b07c12915d861495b6df86955edfc49935218f5",
    "doi": "10.3390/e17042304",
    "arxivId": "1010.5720",
    "authors": "Bastian Steudel, N. Ay",
    "citationCount": 70
  },
  {
    "s2PaperId": "38da187d65d2a6957087f2adf08ff0378f0d9376",
    "title": "A framework for the local information dynamics of distributed computation in complex systems",
    "abstract": "The nature of distributed computation has long been a topic of interest in complex systems science, physics, artificial life and bioinformatics. In particular, emergent complex behavior has often been described from the perspective of computation within the system (Mitchell 1998b,a) and has been postulated to be associated with the capability to support universal computation (Langton 1990; Wolfram 1984c; Casti 1991).",
    "year": 2008,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/38da187d65d2a6957087f2adf08ff0378f0d9376",
    "doi": "10.1007/978-3-642-53734-9_5",
    "arxivId": "0811.2690",
    "authors": "J. Lizier, M. Prokopenko, Albert Y. Zomaya",
    "citationCount": 37
  },
  {
    "s2PaperId": "804c0d03b4434f135b0f9313e109e2cd35e837af",
    "title": "Learning diverse causally emergent representations from time series data",
    "abstract": "",
    "year": 2024,
    "venue": "Neural Information Processing Systems",
    "url": "https://www.semanticscholar.org/paper/804c0d03b4434f135b0f9313e109e2cd35e837af",
    "doi": "",
    "arxivId": "",
    "authors": "David McSharry, Christos Kaplanis, Fernando E. Rosas, P. Mediano",
    "citationCount": 3
  },
  {
    "s2PaperId": "65898a0d3f01db7fa1ac1fe85e83eb42b5d81ea0",
    "title": "Quantifying the Technological Foundations of Economic Complexity",
    "abstract": "",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/65898a0d3f01db7fa1ac1fe85e83eb42b5d81ea0",
    "doi": "",
    "arxivId": "",
    "authors": "Hardik Rajpal, Omar A. Guerrero",
    "citationCount": 4
  },
  {
    "s2PaperId": "0a425c0d87c674b142104a07e17c5084b3ad28ca",
    "title": "Quantifying & Modeling Feature Interactions: An Information Decomposition Framework",
    "abstract": "",
    "year": 2023,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/0a425c0d87c674b142104a07e17c5084b3ad28ca",
    "doi": "10.48550/arXiv.2302.12247",
    "arxivId": "",
    "authors": "Paul Pu Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Faisal Mahmood, R. Salakhutdinov, Louis-philippe Morency",
    "citationCount": 19
  },
  {
    "s2PaperId": "2008549fce5dd65cebad6da121935b96de62d1bc",
    "title": "Active Learning based Structural Inference",
    "abstract": "",
    "year": 2023,
    "venue": "International Conference on Machine Learning",
    "url": "https://www.semanticscholar.org/paper/2008549fce5dd65cebad6da121935b96de62d1bc",
    "doi": "",
    "arxivId": "",
    "authors": "Aoran Wang, Jun Pang",
    "citationCount": 2
  },
  {
    "s2PaperId": "ba6dfdbcec5d1b705d9f68c0942d48984670b0b6",
    "title": "Double-Layered Dual-Syndrome Trellis Codes Utilizing Channel Knowledge for Robust Steganography",
    "abstract": "Robust steganography aims to hide message in cover data with high security and guarantee the success of its message extraction although it is disturbed in transmission channel. In this paper we propose a framework of coding scheme extended from Dual-Syndrome Trellis Codes (Dual-STCs) for robust adaptive steganography. We use the conditional probability distribution of correct stego bits conditioned on disturbed stego data as channel knowledge, and formulate error-correcting as maximizing this probability. By extending Dual-STCs to double-layered embedding, we design an iteratively decoding scheme for error-correcting two layer stego bits from their joint conditional probabilities, and strictly prove its convergence. Besides, we design a method to estimate these probability distributions from stego data pairs uploaded/downloaded from the lossy transmission channel. The channel knowledge can also be used by steganographer, and we propose a universal method to revise steganographic distortion values for higher robustness under the guidance of the channel knowledge. Compared with existing coding methods for robust steganography, our method can make use of channel knowledge to improve error correcting ability and meanwhile maintain high security, which is demonstrated by experimental results.",
    "year": 2023,
    "venue": "IEEE Transactions on Information Forensics and Security",
    "url": "https://www.semanticscholar.org/paper/ba6dfdbcec5d1b705d9f68c0942d48984670b0b6",
    "doi": "10.1109/TIFS.2022.3226904",
    "arxivId": "",
    "authors": "Qingxiao Guan, Peng Liu, Weiming Zhang, Wei Lu, Xinpeng Zhang",
    "citationCount": 16
  },
  {
    "s2PaperId": "0489da117e6451dde571aaa8f77794976a9448a9",
    "title": "Quantifying operation tween le-sed Hanabi ents ing formation eory",
    "abstract": "",
    "year": 2023,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/0489da117e6451dde571aaa8f77794976a9448a9",
    "doi": "",
    "arxivId": "",
    "authors": "Patricia Wollstadt, Matti Krüger, Christiane B. Wiebel-Herboth",
    "citationCount": 0
  },
  {
    "s2PaperId": "f80e5adebada00276fae6f4a746d990b55086471",
    "title": "Partial Information Decomposition Reveals the Structure of Neural Representations",
    "abstract": "",
    "year": 2022,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/f80e5adebada00276fae6f4a746d990b55086471",
    "doi": "10.48550/arXiv.2209.10438",
    "arxivId": "",
    "authors": "David A. Ehrlich, A. C. Schneider, M. Wibral, V. Priesemann, Abdullah Makkeh",
    "citationCount": 11
  },
  {
    "s2PaperId": "3393331480eeb0d0acf81e06b35a7d4722e87c1a",
    "title": "May the 4C’s be with you: An overview of complexity- inspired frameworks for analyzing resting-state neuroimaging data",
    "abstract": "",
    "year": 2022,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/3393331480eeb0d0acf81e06b35a7d4722e87c1a",
    "doi": "",
    "arxivId": "",
    "authors": "Authors, Fran Hancock, Fernando E. Rosas, P. Mediano, I. Andrea, Luppi, J. Cabral, O. Dipasquale, Federico E. Turkheimer",
    "citationCount": 1
  },
  {
    "s2PaperId": "145357b084041b5f59948b30d303bbb6cd53e316",
    "title": "Measuring Morphological Fusion Using Partial Information Decomposition",
    "abstract": "",
    "year": 2022,
    "venue": "International Conference on Computational Linguistics",
    "url": "https://www.semanticscholar.org/paper/145357b084041b5f59948b30d303bbb6cd53e316",
    "doi": "",
    "arxivId": "",
    "authors": "Michaela Socolof, Jacob Louis Hoover, Richard Futrell, Alessandro Sordoni, T. O’Donnell",
    "citationCount": 4
  },
  {
    "s2PaperId": "01ede172d5318b7198c1fd2679c39489ddc1ab64",
    "title": "Ultra Marginal Feature Importance",
    "abstract": "",
    "year": 2022,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/01ede172d5318b7198c1fd2679c39489ddc1ab64",
    "doi": "10.48550/arXiv.2204.09938",
    "arxivId": "",
    "authors": "Joseph Janssen, Vincent Guan",
    "citationCount": 2
  },
  {
    "s2PaperId": "56a902964975899e5fd2420ecf05beeecd104517",
    "title": "Poster: Quantifying Cooperation Between Artificial Agents Using Information Theory",
    "abstract": "",
    "year": 2022,
    "venue": "HHAI",
    "url": "https://www.semanticscholar.org/paper/56a902964975899e5fd2420ecf05beeecd104517",
    "doi": "10.3233/FAIA220224",
    "arxivId": "",
    "authors": "Patricia Wollstadt, Matti Krüger",
    "citationCount": 1
  },
  {
    "s2PaperId": "07786c2486c1ff3234347955af65a923011e7a78",
    "title": "Challenges and Approaches to an Information-Theoretic Framework for the Analysis of Embodied Cognitive Systems",
    "abstract": "",
    "year": 2022,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/07786c2486c1ff3234347955af65a923011e7a78",
    "doi": "",
    "arxivId": "",
    "authors": "Madhavun Candadai, Eduardo J. Izquierdo",
    "citationCount": 0
  },
  {
    "s2PaperId": "4cee90907755fb97dad53e5624c3f968f98124f3",
    "title": "A New Framework for the Time- and Frequency-Domain Assessment of High-Order Interactions in Networks of Random Processes",
    "abstract": "While the standard network description of complex systems is based on quantifying the link between pairs of system units, higher-order interactions (HOIs) involving three or more units often play a major role in governing the collective network behavior. This work introduces a new approach to quantify pairwise and HOIs for multivariate rhythmic processes interacting across multiple time scales. We define the so-called O-information rate (OIR) as a new metric to assess HOIs for multivariate time series, and present a framework to decompose the OIR into measures quantifying Granger-causal and instantaneous influences, as well as to expand all measures in the frequency domain. The framework exploits the spectral representation of vector autoregressive and state space models to assess the synergistic and redundant interaction among groups of processes, both in specific bands of interest and in the time domain after whole-band integration. Validation of the framework on simulated networks illustrates how the spectral OIR can highlight redundant and synergistic HOIs emerging at specific frequencies, which cannot be detected using time-domain measures. The applications to physiological networks described by heart period, arterial pressure and respiration variability measured in healthy subjects during a protocol of paced breathing, and to brain networks described by electrocorticographic signals acquired in an animal experiment during anesthesia, document the capability of our approach to identify informational circuits relevant to well-defined cardiovascular oscillations and brain rhythms and related to specific physiological mechanisms involving autonomic control and altered consciousness. The proposed framework allows a hierarchically-organized evaluation of time- and frequency-domain interactions in dynamic networks mapped by multivariate time series, and its high flexibility and scalability make it suitable for the investigation of networks beyond pairwise interactions in neuroscience, physiology and many other fields.",
    "year": 2022,
    "venue": "IEEE Transactions on Signal Processing",
    "url": "https://www.semanticscholar.org/paper/4cee90907755fb97dad53e5624c3f968f98124f3",
    "doi": "10.1109/TSP.2022.3221892",
    "arxivId": "",
    "authors": "L. Faes, G. Mijatović, Y. Antonacci, R. Pernice, Chiara Barà, Laura Sparacino, M. Sammartino, A. Porta, D. Marinazzo, S. Stramaglia",
    "citationCount": 38
  },
  {
    "s2PaperId": "42cd8a871eb9f87adb14b0b65e9b5a9fb182ea1e",
    "title": "Universal Dependencies and Author Attribution of Short Texts with Syntax Alone",
    "abstract": "",
    "year": 2022,
    "venue": "Digital Humanities Quarterly",
    "url": "https://www.semanticscholar.org/paper/42cd8a871eb9f87adb14b0b65e9b5a9fb182ea1e",
    "doi": "",
    "arxivId": "",
    "authors": "Robert Gorman",
    "citationCount": 5
  },
  {
    "s2PaperId": "ac1ea5eb64a21f5cbb0606db5d274e20a9e07fd1",
    "title": "Higher-order in-and-outeractions reveal synergy and logical dependence beyond Shannon-information",
    "abstract": "",
    "year": 2022,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/ac1ea5eb64a21f5cbb0606db5d274e20a9e07fd1",
    "doi": "10.48550/arXiv.2205.04440",
    "arxivId": "",
    "authors": "Abel Jansma",
    "citationCount": 1
  },
  {
    "s2PaperId": "bb7f06e30734bf4f6e527f9847d6a3043e338876",
    "title": "An Information-theoretic Progressive Framework for Interpretation",
    "abstract": "",
    "year": 2021,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/bb7f06e30734bf4f6e527f9847d6a3043e338876",
    "doi": "",
    "arxivId": "",
    "authors": "Zhengqi He, Taro Toyoizumi",
    "citationCount": 0
  },
  {
    "s2PaperId": "da47fb2c7100309da871217f3d56297bf91569b9",
    "title": "Measuring High-Order Interactions in Rhythmic Processes through Multivariate Spectral Information Decomposition",
    "abstract": "Many complex systems in physics, biology and engineering are modeled as dynamical networks and described using multivariate time series analysis. Recent developments have shown that the emergent dynamics of a network system are significantly affected by interactions involving multiple network nodes which cannot be described using pairwise links. While these higher-order interactions can be probed using information-theoretic measures, a rigorous framework to describe them in the frequency domain is still lacking. This work presents an approach for the spectral decomposition of multivariate information measures, capable of identifying higher-order synergistic and redundant interactions between oscillatory processes. We show theoretically that synergy and redundancy can coexist at different frequencies among the output signals of a network system and can be detected only using the proposed spectral method. To demonstrate the broad applicability of the framework, we provide parametric and non-parametric data-efficient estimators for the spectral information measures, and employ them to describe multivariate interactions in three complex systems producing rich oscillatory dynamics, namely the human brain, a ring of electronic oscillators, and the global climate system. In these systems, we show that the use of our framework for the spectral decomposition of information measures reveals multivariate and higher-order interactions not detectable in the time domain. Our results are exemplary of how the frequency-specific analysis of multivariate dynamics can aid the implementation of assessment and control strategies in realworld network systems.",
    "year": 2021,
    "venue": "IEEE Access",
    "url": "https://www.semanticscholar.org/paper/da47fb2c7100309da871217f3d56297bf91569b9",
    "doi": "10.1109/ACCESS.2021.3124601",
    "arxivId": "",
    "authors": "Y. Antonacci, L. Minati, D. Nuzzi, G. Mijatović, R. Pernice, D. Marinazzo, S. Stramaglia, L. Faes",
    "citationCount": 19
  },
  {
    "s2PaperId": "2acb4bbb61e9eda89c8ac2d7bebc4e8e73fae2b3",
    "title": "The information signature of diverging lineages 1 2",
    "abstract": "",
    "year": 2021,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2acb4bbb61e9eda89c8ac2d7bebc4e8e73fae2b3",
    "doi": "",
    "arxivId": "",
    "authors": "Douglas G. Moore, Matheo Morales, Sara I. Walker, Greer A. Dolby",
    "citationCount": 0
  },
  {
    "s2PaperId": "669c9a86b3dfedf1bb391ca7d8039d556fb05e81",
    "title": "The synergistic impact of ENSO and IOD on the Indian Summer Monsoon Rainfall in observations and climate simulations - an information theory perspective",
    "abstract": "The El Niño–Southern Oscillation (ENSO) and Indian Ocean Dipole (IOD) are two well-known temporal oscillations in sea surface temperature (SST), which are both thought to influence the interannual variability of Indian summer monsoon rainfall (ISMR). Until now, there has been no measure to assess the simultaneous information exchange (IE) from both ENSO and IOD to ISMR. This study explores the information exchange from two source variables (ENSO and IOD) to one target (ISMR). First, in order to illustrate the concepts and quantification of two-source IE to a target, we use idealized test cases consisting of linear and nonlinear dynamical systems. Our results show that these systems exhibit net synergy (i.e., the combined influence of two sources on a target is greater than the sum of their individual contributions), even with uncorrelated sources in both the linear and nonlinear systems. We test IE quantification with various estimators (linear, kernel, and Kraskov estimators) for robustness. Next, the two-source IE from ENSO and IOD to ISMR is investigated in observations, reanalysis, three global climate model (GCM) simulations, and three nested higher-resolution simulations using a regional climate model (RCM). This (1) quantifies IE from ENSO and IOD to ISMR in the natural system and (2) applies IE in the evaluation of the GCM and RCM simulations. The results show that both ENSO and IOD contribute to ISMR interannual variability. Interestingly, significant net synergy is noted in the central parts of the Indian subcontinent, which is India’s monsoon core region. This indicates that both ENSO and IOD are synergistic predictors in the monsoon core region. But, they share significant net redundant information in the southern part of the Indian subcontinent. The IE patterns in the GCM simulations differ substantially from the patterns derived from observations and reanalyses. Only one nested RCM simulation IE pattern adds value to the corresponding GCM simulation pattern. Only in this case does the GCM simulation show realistic SST patterns and moisture transport during the various ENSO and IOD phases. This confirms, once again, the importance of the choice of GCM in driving a higher-resolution RCM. This study shows that two-source IE is a useful metric that helps in better understanding the climate system and in process-oriented climate model evaluation.",
    "year": 2020,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/669c9a86b3dfedf1bb391ca7d8039d556fb05e81",
    "doi": "10.5194/esd-2020-50",
    "arxivId": "",
    "authors": "P. K. Pothapakula, C. Primo, S. Sørland, B. Ahrens",
    "citationCount": 11
  },
  {
    "s2PaperId": "789c330dd50fb9734fcafd96cf79f730c6efb112",
    "title": "A Synergistic Workspace for Human Consciousness Revealed 1 by Integrated Information Decomposition 2 3",
    "abstract": "",
    "year": 2020,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/789c330dd50fb9734fcafd96cf79f730c6efb112",
    "doi": "",
    "arxivId": "",
    "authors": "Andrea I. Luppia, Pedro A. M. Medianoc, Fernando E. Rosasd, Judith Allansonb, D. John, Pickardb, Robin L. Carhart-Harrisd, Guy B. Williamsb, Michael M Craiga, Paola Finoiab, Adrian M. Oweni, Lorina Nacij, David K. Menona, Daniel Borc, Emmanuel A. Stamatakisa",
    "citationCount": 0
  },
  {
    "s2PaperId": "a64d500e86020a61b482bc184b0117f38ce70bba",
    "title": "Novel Technological and Methodological Tools for the Understanding of Collective Behaviors",
    "abstract": "",
    "year": 2020,
    "venue": "Frontiers Research Topics",
    "url": "https://www.semanticscholar.org/paper/a64d500e86020a61b482bc184b0117f38ce70bba",
    "doi": "10.3389/978-2-88963-424-8",
    "arxivId": "",
    "authors": "E. Tuci, V. Trianni, Simon Garnier",
    "citationCount": 0
  },
  {
    "s2PaperId": "2622118932e5887545f12ed77ce211567718ab87",
    "title": "From Efficient Coding to Information Gain: Information-Theoretic Principles in Models of Human Decision Making",
    "abstract": "",
    "year": 2020,
    "venue": "Annual Meeting of the Cognitive Science Society",
    "url": "https://www.semanticscholar.org/paper/2622118932e5887545f12ed77ce211567718ab87",
    "doi": "",
    "arxivId": "",
    "authors": "Mikaela Akrenius, L. Maloney, Jonathan D. Nelson",
    "citationCount": 0
  },
  {
    "s2PaperId": "82e6fb44608ef5c0b64173db984b5de0e9206857",
    "title": "Quantitatively comparing predictive models with the Partial Information Decomposition",
    "abstract": "There is increasing focus in cognitive and computational neuroscience on the use of encoding and decoding models to gain insight into cognitive processing. Frequently, encoding models are fit to a number of different features sets, and the out-of-sample predictive performance of the resulting models is compared. However, to gain the maximum benefit from this modelling, we need to go beyond simply ranking model performance in terms of absolute predictive power. We also need to directly compare and relate the predictions between models, to gain insight into which models are predicting common vs unique aspects of the neural response. The Partial Information Decomposition (PID) provides a principled theoretical framework to address this question, as it decomposes the total predictive performance of two models into redundant (overlapping), unique, and synergistic parts. We show that like classical information theoretic quantities, variance decomposition approaches conflate synergy and redundancy and so could provide a misleading view of the unique predictive power of a model. We also suggest how the use of encoding models and PID can help interpret decoding models.",
    "year": 2019,
    "venue": "2019 Conference on Cognitive Computational Neuroscience",
    "url": "https://www.semanticscholar.org/paper/82e6fb44608ef5c0b64173db984b5de0e9206857",
    "doi": "10.32470/ccn.2019.1142-0",
    "arxivId": "",
    "authors": "C. Daube, Bruno L. Giordano, P. Schyns, Robin A. A. Ince",
    "citationCount": 8
  },
  {
    "s2PaperId": "72a32277ce996bb230a714ac2a893c27a1ffb7d2",
    "title": "Gender Classification From NIR Images by Using Quadrature Encoding Filters of the Most Relevant Features",
    "abstract": "In the past few years, accuracy in determining gender from iris images has increased significantly, approaching levels that make novel applications of this biometric technology feasible. In this paper, we report the gender classification rate by using a 2-D Quadrature Quaternionic filter, and a selection of the most relevant features from the normalized iris images. We encoded the phase information of the normalized images using 4 bits per pixel with a 2-D-Gabor filter and selected the best bits from the four resulting images (1 real and 3 imaginary) instead of the 1-D log-Gabor traditional encoding method. We used traditional hand-crafted and automatic methods to select and extract the most relevant features from the whole iris images, blocks from images, and pixel features and compared how effective these methods were in separating features from female and male iris images. Selecting iris blocks and features reduce the computational time and, at a basic science level, is of great value in understanding what information features, as well as pixels from the iris, can be extracted to classify gender. The Quaternionic-Code with the complementary feature selection method achieved the best results on the GFI-UND database with 93.45% for the left iris and 95.45% for the right iris, both with 2400 selected features. We compared our results and found them to be advantageous to the best results previously published, and also to those obtained using convolutional neural network feature extraction.",
    "year": 2019,
    "venue": "IEEE Access",
    "url": "https://www.semanticscholar.org/paper/72a32277ce996bb230a714ac2a893c27a1ffb7d2",
    "doi": "10.1109/ACCESS.2019.2902470",
    "arxivId": "",
    "authors": "Juan E. Tapia, C. Pérez",
    "citationCount": 7
  },
  {
    "s2PaperId": "d0a237a36dc1495c6c8c2d6068f89915cee8ff78",
    "title": "Patterns of coordination in simultaneously and sequentially improvising jazz musicians",
    "abstract": "",
    "year": 2019,
    "venue": "Annual Meeting of the Cognitive Science Society",
    "url": "https://www.semanticscholar.org/paper/d0a237a36dc1495c6c8c2d6068f89915cee8ff78",
    "doi": "",
    "arxivId": "",
    "authors": "Matthew Setzler, Robert L. Goldstone",
    "citationCount": 1
  },
  {
    "s2PaperId": "ae8f1e1b8376ec700f424d486e45641600981586",
    "title": "Fading Memory, Plasticity, and Criticality in Recurrent Networks",
    "abstract": "",
    "year": 2019,
    "venue": "Springer Series on Bio- and Neurosystems",
    "url": "https://www.semanticscholar.org/paper/ae8f1e1b8376ec700f424d486e45641600981586",
    "doi": "10.1007/978-3-030-20965-0_6",
    "arxivId": "",
    "authors": "Bruno Papa, V. Priesemann, J. Triesch",
    "citationCount": 6
  },
  {
    "s2PaperId": "e50adf8b00724fb553439c11b4421c02ff57164c",
    "title": "A Theory of Morphological Intelligence",
    "abstract": "",
    "year": 2019,
    "venue": "Morphological Intelligence",
    "url": "https://www.semanticscholar.org/paper/e50adf8b00724fb553439c11b4421c02ff57164c",
    "doi": "10.1007/978-3-030-20621-5_3",
    "arxivId": "",
    "authors": "Keyan Ghazi-Zahedi",
    "citationCount": 0
  },
  {
    "s2PaperId": "884ecb21ae99c9cb20ae0b9835b3c9da63cd4f54",
    "title": "Gene Regulatory Networks from Single Cell Data for Exploring Cell Fate Decisions.",
    "abstract": "",
    "year": 2019,
    "venue": "Methods in molecular biology",
    "url": "https://www.semanticscholar.org/paper/884ecb21ae99c9cb20ae0b9835b3c9da63cd4f54",
    "doi": "10.1007/978-1-4939-9224-9_10",
    "arxivId": "",
    "authors": "Thalia E. Chan, M. Stumpf, A. Babtie",
    "citationCount": 3
  },
  {
    "s2PaperId": "d2967d8a30bd9934976373b31a65632bb0604525",
    "title": "A Bayesian decomposition of BAC ﬁring as a mechanism for apical ampliﬁcation in neocortical pyramidal neurons",
    "abstract": "",
    "year": 2019,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/d2967d8a30bd9934976373b31a65632bb0604525",
    "doi": "",
    "arxivId": "",
    "authors": "J. Kay, W. A. Phillips, Jaan Aru, B. Graham, M. Larkum",
    "citationCount": 3
  },
  {
    "s2PaperId": "4a154fdfd0893c4522cfee9f1699f468ed5bf653",
    "title": "Joint Action: An Enactive Mechanistic Account",
    "abstract": "",
    "year": 2019,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/4a154fdfd0893c4522cfee9f1699f468ed5bf653",
    "doi": "",
    "arxivId": "",
    "authors": "E. Abramova",
    "citationCount": 0
  },
  {
    "s2PaperId": "5435f806d6793dc049ae5dd76c05c7be68b91acb",
    "title": "Computational Stem Cell Biology: Methods and Protocols",
    "abstract": "",
    "year": 2019,
    "venue": "Methods in Molecular Biology",
    "url": "https://www.semanticscholar.org/paper/5435f806d6793dc049ae5dd76c05c7be68b91acb",
    "doi": "10.1007/978-1-4939-9224-9",
    "arxivId": "",
    "authors": "P. Cahan",
    "citationCount": 10
  },
  {
    "s2PaperId": "e5f6362cd3f5f98df1bb93df4fc1b5976992955a",
    "title": "IT ] 12 S ep 2 01 5 Synergy , Redundancy and Common Information",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/e5f6362cd3f5f98df1bb93df4fc1b5976992955a",
    "doi": "",
    "arxivId": "",
    "authors": "P. Banerjee",
    "citationCount": 0
  },
  {
    "s2PaperId": "4d3521d2004b15d0ef272ba3a907b184c21936c5",
    "title": "NON-SYN VARIATIONAL AUTOENCODERS",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/4d3521d2004b15d0ef272ba3a907b184c21936c5",
    "doi": "",
    "arxivId": "",
    "authors": "",
    "citationCount": 0
  },
  {
    "s2PaperId": "61e2410a51bc1a845da9e3833d3b83254bd5fb94",
    "title": "I T ] 2 7 O ct 2 01 8 Unique Informations and Deficiencies",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/61e2410a51bc1a845da9e3833d3b83254bd5fb94",
    "doi": "",
    "arxivId": "",
    "authors": "P. Banerjee, E. Olbrich, J. Jost, Johannes Rauh",
    "citationCount": 0
  },
  {
    "s2PaperId": "be40c2444bfa4a8053d26a145acf9ca4342e2805",
    "title": "Comparing causes: an information-theoretic approach to specificity, proportionality and stability",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/be40c2444bfa4a8053d26a145acf9ca4342e2805",
    "doi": "",
    "arxivId": "",
    "authors": "A. Pocheville, P. Griffiths, K. Stotz",
    "citationCount": 31
  },
  {
    "s2PaperId": "5d6adb0eaf500a3706cdc35a23edab21ffbcc6a3",
    "title": "University of Birmingham Representational interactions during audiovisual speech entrainment:",
    "abstract": "",
    "year": 2018,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/5d6adb0eaf500a3706cdc35a23edab21ffbcc6a3",
    "doi": "",
    "arxivId": "",
    "authors": "Hyojin Park, Robin A. A. Ince, P. Schyns, G. Thut, J. Gross",
    "citationCount": 0
  },
  {
    "s2PaperId": "a99ff2ff969f38d61aae28ab4d0262c7f8cede5a",
    "title": "Decomposing multivariate information",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/a99ff2ff969f38d61aae28ab4d0262c7f8cede5a",
    "doi": "",
    "arxivId": "",
    "authors": "N. Virgo, D. Polani",
    "citationCount": 7
  },
  {
    "s2PaperId": "7096ae39138d7a9d64c4a182f7098d210da21969",
    "title": "Medical Incident Report Classification using Context-based Word Embeddings",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/7096ae39138d7a9d64c4a182f7098d210da21969",
    "doi": "",
    "arxivId": "",
    "authors": "Steven Bosch",
    "citationCount": 0
  },
  {
    "s2PaperId": "d229937d7b576e1816f4e31ef10867056562444f",
    "title": "Analysing Information Distribution in Complex Systems Bachelor ’ s Thesis ( 9 ECTS ) Supervisors :",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/d229937d7b576e1816f4e31ef10867056562444f",
    "doi": "",
    "arxivId": "",
    "authors": "Raul Vicente Zafra, D. Theis",
    "citationCount": 0
  },
  {
    "s2PaperId": "7d71291d014cb5fda63d284a1e1cb21a092474f6",
    "title": "A Novel Procedure for Measuring Semantic Synergy",
    "abstract": "One interesting characteristic of some complex systems is the formation of macro level constructions perceived as having features that cannot be reduced to their micro level constituents. This characteristic is considered to be the expression of synergy where the joint action of the constituents produces unique features that are irreducible to the constituents isolated behavior or their simple composition. The synergy, characterizing complex systems, has been well acknowledged but difficult to conceptualize and quantify in the context of computing the emerging meaning of various linguistic and conceptual constructs. In this paper, we propose a novel measure/procedure for quantifying semantic synergy. This measure draws on a general idea of synergy as has been proposed in biology. We validate this measure by providing evidence for its ability to predict the semantic transparency of linguistic compounds (Experiment 1) and the abstractness rating of nouns (Experiment 2).",
    "year": 2017,
    "venue": "Complex",
    "url": "https://www.semanticscholar.org/paper/7d71291d014cb5fda63d284a1e1cb21a092474f6",
    "doi": "10.1155/2017/5785617",
    "arxivId": "",
    "authors": "Yair Neuman, Y. Neuman, Yochai Cohen",
    "citationCount": 35
  },
  {
    "s2PaperId": "d1db3217154bba960b0f531e8ec387a98b54ec97",
    "title": "UvA-DARE ( Digital Academic Repository ) Quantifying Synergistic Information Using Intermediate Stochastic Variables",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/d1db3217154bba960b0f531e8ec387a98b54ec97",
    "doi": "",
    "arxivId": "",
    "authors": "Rick Quax, Omri Har-Shemesh, P. Sloot",
    "citationCount": 0
  },
  {
    "s2PaperId": "469c2f7f881475abbbe7507647845a9d75d7daf6",
    "title": "順序構造上の情報幾何的な統計解析 Information Geometric Statistical Analysis with Partial Orders 杉山麿人",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/469c2f7f881475abbbe7507647845a9d75d7daf6",
    "doi": "",
    "arxivId": "",
    "authors": "Mahito Sugiyama, Hiroyuki Nakahara, K. Tsuda",
    "citationCount": 0
  },
  {
    "s2PaperId": "017d40b83080d120a57b42d0fd6869a81e70c9f2",
    "title": "UvA-DARE ( Digital Academic Repository ) Quantifying Synergistic Information Using Intermediate Stochastic Variables",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/017d40b83080d120a57b42d0fd6869a81e70c9f2",
    "doi": "",
    "arxivId": "",
    "authors": "Rick Quax, Omri Har-Shemesh, P. Sloot",
    "citationCount": 0
  },
  {
    "s2PaperId": "3aa769c726d3c97b50647572e6e81bda1622b25a",
    "title": "Neural Networks and Groupoids",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/3aa769c726d3c97b50647572e6e81bda1622b25a",
    "doi": "10.1007/978-3-319-68246-4_5",
    "arxivId": "",
    "authors": "Yair Neuman",
    "citationCount": 0
  },
  {
    "s2PaperId": "010a6d00b86baddb595d64f6ba9a9360828b26fd",
    "title": "Fields of Application of Information Geometry",
    "abstract": "",
    "year": 2017,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/010a6d00b86baddb595d64f6ba9a9360828b26fd",
    "doi": "10.1007/978-3-319-56478-4_6",
    "arxivId": "",
    "authors": "N. Ay, J. Jost, H. Lê, Lorenz Schwachhöfer",
    "citationCount": 0
  },
  {
    "s2PaperId": "def94fe821e343edae8b9ae3198488ed9f0dd1bc",
    "title": "Computational Personality Analysis",
    "abstract": "",
    "year": 2016,
    "venue": "Cambridge International Law Journal",
    "url": "https://www.semanticscholar.org/paper/def94fe821e343edae8b9ae3198488ed9f0dd1bc",
    "doi": "10.1007/978-3-319-42460-6",
    "arxivId": "",
    "authors": "Yair Neuman",
    "citationCount": 26
  },
  {
    "s2PaperId": "c76ec6a0a42f88d516694b0ad5e0929c7765dfe2",
    "title": "Network inference and hypotheses-generation from single-cell transcriptomic data using multivariate information measures",
    "abstract": "",
    "year": 2016,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/c76ec6a0a42f88d516694b0ad5e0929c7765dfe2",
    "doi": "",
    "arxivId": "",
    "authors": "Thalia E. Chan, M. Stumpf, A. Babtie",
    "citationCount": 10
  },
  {
    "s2PaperId": "9652634d211b8a9d646cdc3a58c840972734d48d",
    "title": "Taking Complexity a Step Forward: The Reversibility of the Pedophile’s Mind",
    "abstract": "",
    "year": 2016,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/9652634d211b8a9d646cdc3a58c840972734d48d",
    "doi": "10.1007/978-3-319-42460-6_10",
    "arxivId": "",
    "authors": "Yair Neuman",
    "citationCount": 0
  },
  {
    "s2PaperId": "a2a5e3b28b2c0f1bdca85046909fed1bac534e25",
    "title": "Information transmission in normal vision and optogenetically resensitised dystrophic retinas",
    "abstract": "",
    "year": 2016,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/a2a5e3b28b2c0f1bdca85046909fed1bac534e25",
    "doi": "",
    "arxivId": "",
    "authors": "J. Barrett",
    "citationCount": 2
  },
  {
    "s2PaperId": "95eac71f6679b44b070605c8d570ff5343629c6f",
    "title": "Synergetic and Redundant Information Flow Detected by Unnormalized Granger Causality: Application to Resting State fMRI",
    "abstract": "",
    "year": 2016,
    "venue": "IEEE Transactions on Biomedical Engineering",
    "url": "https://www.semanticscholar.org/paper/95eac71f6679b44b070605c8d570ff5343629c6f",
    "doi": "",
    "arxivId": "",
    "authors": "S. Stramaglia, L. Angelini, Guorong Wu, J. Cortes, L. Faes, Daniele Marinazzo",
    "citationCount": 0
  },
  {
    "s2PaperId": "9cdc9884350cc41a1fec6ea301591354a379291f",
    "title": "Information Processing and Dynamics in Minimally Cognitive Agents",
    "abstract": "",
    "year": 2015,
    "venue": "Cognitive Sciences",
    "url": "https://www.semanticscholar.org/paper/9cdc9884350cc41a1fec6ea301591354a379291f",
    "doi": "10.1111/cogs.12142",
    "arxivId": "",
    "authors": "R. Beer, Paul L. Williams",
    "citationCount": 127
  },
  {
    "s2PaperId": "dcc02ca62c061a47bcba4ea79293ccd998e528b8",
    "title": "Information Theoretical Approaches",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/dcc02ca62c061a47bcba4ea79293ccd998e528b8",
    "doi": "10.1016/B978-0-12-397025-1.00338-9",
    "arxivId": "",
    "authors": "M. Wibral, V. Priesemann",
    "citationCount": 2
  },
  {
    "s2PaperId": "de3a3aadcd29135f68a35815573d160d12061728",
    "title": "Discovering Structure in High-Dimensional Data Through Correlation Explanation Report",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/de3a3aadcd29135f68a35815573d160d12061728",
    "doi": "",
    "arxivId": "",
    "authors": "A. Galstyan",
    "citationCount": 0
  },
  {
    "s2PaperId": "34fdc4be2b56be1d5e05fdb690b7e2d937fcdef8",
    "title": "Mathematik in den Naturwissenschaften Leipzig Quantifying Morphological Computation based on an Information Decomposition of the Sensorimotor Loop",
    "abstract": "",
    "year": 2015,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/34fdc4be2b56be1d5e05fdb690b7e2d937fcdef8",
    "doi": "",
    "arxivId": "",
    "authors": "Keyan Ghazi-Zahedi, Johannes Rauh",
    "citationCount": 1
  },
  {
    "s2PaperId": "cac1cd915011b0f0e1826db86574890f132d50c4",
    "title": "Quantifying Synergistic Information",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/cac1cd915011b0f0e1826db86574890f132d50c4",
    "doi": "10.7907/ZS2T-XQ55.",
    "arxivId": "",
    "authors": "V. Griffith",
    "citationCount": 8
  },
  {
    "s2PaperId": "7e6db59d2472d22d1f12edc86b6753e3f8cff6f6",
    "title": "Measuring the Dynamics of Information Processing on a Local Scale in Time and Space",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/7e6db59d2472d22d1f12edc86b6753e3f8cff6f6",
    "doi": "10.1007/978-3-642-54474-3_7",
    "arxivId": "",
    "authors": "J. Lizier",
    "citationCount": 43
  },
  {
    "s2PaperId": "08a717f747a3b6d4ddaaceeb9c64247bd59c1acb",
    "title": "Transfer Entropy in Neuroscience",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/08a717f747a3b6d4ddaaceeb9c64247bd59c1acb",
    "doi": "10.1007/978-3-642-54474-3_1",
    "arxivId": "",
    "authors": "M. Wibral, Raul Vicente, Michael Lindner",
    "citationCount": 119
  },
  {
    "s2PaperId": "2907cfaffc869487bc849d6070220d9af9ced33a",
    "title": "Efficient Estimation of Information Transfer",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2907cfaffc869487bc849d6070220d9af9ced33a",
    "doi": "10.1007/978-3-642-54474-3_2",
    "arxivId": "",
    "authors": "Raul Vicente, M. Wibral",
    "citationCount": 15
  },
  {
    "s2PaperId": "8013de431be130f2ac0681141a752f67fd7c69ef",
    "title": "Conditional Entropy-Based Evaluation of Information Dynamics in Physiological Systems",
    "abstract": "",
    "year": 2014,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/8013de431be130f2ac0681141a752f67fd7c69ef",
    "doi": "10.1007/978-3-642-54474-3_3",
    "arxivId": "",
    "authors": "L. Faes, A. Porta",
    "citationCount": 46
  },
  {
    "s2PaperId": "aa0ea3ce3ff44c7185567ceabfdb3d71a7f5999d",
    "title": "Intersection Information Based on Common Randomness",
    "abstract": "",
    "year": 2013,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/aa0ea3ce3ff44c7185567ceabfdb3d71a7f5999d",
    "doi": "10.4324/9780080927534-16",
    "arxivId": "",
    "authors": "V. Griffith, E. Chong, R. James, C. J. Ellison, J. P. Crutchfield, V. Griffith, Edwin K. P. Chong, R. James, C. J. Ellison, J. Crutchfield",
    "citationCount": 1
  },
  {
    "s2PaperId": "ae13df11580d3390a6fdce0c6a52ede6be1def70",
    "title": "Measures and Metrics of Information Processing in Complex Systems: A Rope of Sand.",
    "abstract": "",
    "year": 2013,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/ae13df11580d3390a6fdce0c6a52ede6be1def70",
    "doi": "",
    "arxivId": "",
    "authors": "R. James",
    "citationCount": 0
  },
  {
    "s2PaperId": "e1da66f0d4ebfadb8f53812a3c911369e8c0fac2",
    "title": "Synergy is a Special Case of Irreducibility",
    "abstract": "",
    "year": 2013,
    "venue": "arXiv.org",
    "url": "https://www.semanticscholar.org/paper/e1da66f0d4ebfadb8f53812a3c911369e8c0fac2",
    "doi": "",
    "arxivId": "",
    "authors": "V. Griffith, Jonathan Harel",
    "citationCount": 0
  },
  {
    "s2PaperId": "52663bb55742c1a27be9f728e75eb7958c0d0bfe",
    "title": "UNIVERSIDAD DE CHILE FACULTAD DE CIENCIAS FÍSICAS Y MATEMÁTICAS DEPARTAMENTO DE INGENIERÍA ELÉCTRICA",
    "abstract": "",
    "year": 2012,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/52663bb55742c1a27be9f728e75eb7958c0d0bfe",
    "doi": "",
    "arxivId": "",
    "authors": "Profesor Guía, Claudia Zúñiga",
    "citationCount": 2
  },
  {
    "s2PaperId": "ad6dd5a059b41e5a230cfc79fe814ee45acf2704",
    "title": "Information Theory and Multivariate Interactions",
    "abstract": "",
    "year": 2011,
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/ad6dd5a059b41e5a230cfc79fe814ee45acf2704",
    "doi": "",
    "arxivId": "",
    "authors": "T. Khoo",
    "citationCount": 1
  },
  {
    "s2PaperId": "2e1347c59494750ac93dcf34caa2ad9a9c61fbb6",
    "title": "Touch Processing for Terrain Classification with Feature Selection",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2e1347c59494750ac93dcf34caa2ad9a9c61fbb6",
    "doi": "",
    "arxivId": "",
    "authors": "Stephen D. Liang, Hewlett Packard Enterprise",
    "citationCount": 0
  },
  {
    "s2PaperId": "419b58babf8798d4e61b887b83b13286ef739458",
    "title": "Anatomy of a Bit : Information in a Time Series Measurement",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/419b58babf8798d4e61b887b83b13286ef739458",
    "doi": "",
    "arxivId": "",
    "authors": "R. James, C. J. Ellison, J. Crutchfield",
    "citationCount": 1
  },
  {
    "s2PaperId": "10649e92f7809004ae7fc778b58dccb17f4d9224",
    "title": "Your Phi-nal Response to Gt",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/10649e92f7809004ae7fc778b58dccb17f4d9224",
    "doi": "",
    "arxivId": "",
    "authors": "",
    "citationCount": 0
  },
  {
    "s2PaperId": "86e8638f40cc8228831870e9817b9c08f11967c8",
    "title": "f¨ur Mathematik in den Naturwissenschaften Leipzig Unique Informations and Deﬁciencies",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/86e8638f40cc8228831870e9817b9c08f11967c8",
    "doi": "",
    "arxivId": "",
    "authors": "P. Banerjee, E. Olbrich, Jiirgen Jost, Johannes Rauh",
    "citationCount": 14
  },
  {
    "s2PaperId": "7429218a75438d2d3cb7af608ac0acdc8bd78f48",
    "title": "Marriage Market Sorting in the U.S. ECONOMIC RESEARCH",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/7429218a75438d2d3cb7af608ac0acdc8bd78f48",
    "doi": "",
    "arxivId": "",
    "authors": "Anton Cheremukhin, Paulina Restrepo-Echavarria, Antonella Tutino",
    "citationCount": 0
  },
  {
    "s2PaperId": "5744e3ad0f644372bcb12cca5e63c397592e185d",
    "title": ": Comment on ‘‘Information arms race explains plant-herbivore chemical communication in ecological communities”",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/5744e3ad0f644372bcb12cca5e63c397592e185d",
    "doi": "",
    "arxivId": "",
    "authors": "Ethan Bass1, Andre Kessler1",
    "citationCount": 0
  },
  {
    "s2PaperId": "2dc3608367bf7b8cdb4e838f1849c7fc21f007ca",
    "title": "f¨ur Mathematik in den Naturwissenschaften Leipzig",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/2dc3608367bf7b8cdb4e838f1849c7fc21f007ca",
    "doi": "",
    "arxivId": "",
    "authors": "N. Ay, Nils Bertschinger †, J¨urgen Jost ‡, Eckehard Olbrich §, ¶. JohannesRauh",
    "citationCount": 4
  },
  {
    "s2PaperId": "42cf3fe4dcd8e631a4fd7853d5cb51af0eeb142c",
    "title": "Non-synergistic VAE",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/42cf3fe4dcd8e631a4fd7853d5cb51af0eeb142c",
    "doi": "",
    "arxivId": "",
    "authors": "Gonzalo Barrientos, Cristina Calnegru",
    "citationCount": 0
  },
  {
    "s2PaperId": "06d4655180ceb6dad7841a7d7b3be2618c59318a",
    "title": "UC Merced Proceedings of the Annual Meeting of the Cognitive Science Society",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/06d4655180ceb6dad7841a7d7b3be2618c59318a",
    "doi": "",
    "arxivId": "",
    "authors": "Hanqi Zhou, David G. Nagy, Charley M. Wu, In L. K. Samuelson, S. L. Frank, M. Toneva, A. Mackey, E. Hazeltine",
    "citationCount": 0
  },
  {
    "s2PaperId": "367adefbb6e84e684e85d429ded02961a34a3b9a",
    "title": "A SSOCIATIVE M EMORY L EARNING T HROUGH R EDUNDANCY M AXIMIZATION",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/367adefbb6e84e684e85d429ded02961a34a3b9a",
    "doi": "",
    "arxivId": "",
    "authors": "Mark Bl¨umel, A. C. Schneider, David A. Ehrlich, Valentin Neuhaus, Marcel Graetz, M. Wibral, Abdullah Makkeh, V. Priesemann",
    "citationCount": 0
  },
  {
    "s2PaperId": "725a7ebbe8b400c1519a00c8eb8dda272eb36cc9",
    "title": "Proto-Cognitive Bases of Agency",
    "abstract": "",
    "year": "",
    "venue": "",
    "url": "https://www.semanticscholar.org/paper/725a7ebbe8b400c1519a00c8eb8dda272eb36cc9",
    "doi": "",
    "arxivId": "",
    "authors": "Fernando Rodriguez Vergara, Phil Husbands",
    "citationCount": 0
  }
]