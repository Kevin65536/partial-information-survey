# Direct PID Method Survey

直接使用现成的pid计算工具，计算源变量：$X_1: EEG$, $X_2: fNIRS$，目标变量：$Y: 任务状态$的PID。

## dit

`dit` (Discrete Information Theory) 是一个功能全面、专为离散变量信息论计算而设计的 Python 库。它的目标是提供一个健壮且灵活的框架，不仅能计算PID，还能进行多种其他信息论度量的计算。

#### `dit` 的核心特点：

* **功能全面**: `dit` 的范围远不止 PID。它支持计算熵、互信息、条件互信息、全相关（总相关）、双互信息等多种信息论度量。
* **处理离散分布**: `dit` 的核心是处理离散概率分布。你需要将你的数据（无论是原始数据还是提取的特征）转换成一个离散的联合概率分布，然后才能进行计算。
* **多种 PID 定义**: PID 理论尚在发展中，存在多种不同的“冗余信息”定义方式（即所谓的 PID measure 或 "lattice"）。`dit` 实现并支持了多种主流的 PID 定义，例如 `PID_MMI` (Minimum Mutual Information), `PID_BROJA` (Broja's lattice), 和 `PID_dep` (Dependency lattice) 等，这为研究者提供了比较不同理论框架的灵活性。
* **强大的数据结构**: 库的核心是 `dit.Distribution` 对象，它能高效地表示和操作离散概率分布。此外，它还能处理具有复杂结果（outcomes）的分布，例如元组或字符串。
* **良好的文档和社区支持**: `dit` 拥有非常详尽的官方文档和一系列学术论文作为支撑，社区也相对活跃。

#### 如何使用 `dit` 进行 PID 分析 (以 `PID_MMI` 为例)

假设我们有三个离-散-化-后-的变量：`Y` (任务标签：左/右), `X1` (来自EEG的特征), `X2` (来自fNIRS的特征)。

**第一步：创建联合概率分布**

首先，你需要根据你的实验数据构建一个联合概率分布。这通常是整个流程中最具挑战性的一步，因为它要求你对连续的特征数据进行离散化（或称量化、分箱）。

例如，你有一系列观测样本 `(y, x1, x2)`：
`samples = [('left', 'low_mu', 'high_hbo'), ('right', 'high_mu', 'low_hbo'), ...]`

你可以使用 `dit` 的 `dit.Distribution.from_samples()` 方法来创建分布对象：

```python
import dit

# 假设这是你的离散化后的样本数据
# 每个元组代表一次试验 (任务标签, EEG特征, fNIRS特征)
samples = [
    ('left', 'low', 'active'), ('left', 'low', 'inactive'),
    ('right', 'high', 'inactive'), ('right', 'high', 'inactive'),
    ('left', 'low', 'active'), ('right', 'high', 'active'),
    ('left', 'low', 'inactive'), ('right', 'high', 'inactive')
]

# 从样本中创建分布对象
# dit 会自动计算每个事件的概率
d = dit.Distribution.from_samples(samples)

# 为变量命名以便后续使用
d.set_rv_names(['Y', 'X1', 'X2'])

print(d)
```

**第二步：执行 PID 计算**

创建好分布后，调用 PID 函数就非常直接了。你需要指定目标变量 (`Y`) 和两个源变量 (`X1`, `X2`)。

```python
from dit.pid import PID_MMI

# 使用 MMI (Minimum Mutual Information) 定义来计算 PID
# 参数1: 联合分布
# 参数2: 源变量列表
# 参数3: 目标变量
pid_results = PID_MMI(d, ['X1', 'X2'], 'Y')

print(pid_results)
```

**第三步：解读结果**

`pid_results` 对象会以字典的形式返回分解后的信息量（以比特为单位）：

```
{
    'Syn': 0.25,                   # 协同信息
    'Unq_X1': 0.25,                # X1 (EEG) 的独特信息
    'Unq_X2': 0.0,                 # X2 (fNIRS) 的独特信息
    'Red': 0.5                     # 冗余信息
}
```

#### `dit` 的优缺点

* **优点**:
  * **理论严谨**: 严格基于信息论的概率分布进行计算。
  * **功能强大**: 支持多种信息论度量和 PID 定义。
  * **灵活性高**: 允许用户精细控制概率分布的构建和计算过程。
* **缺点**:
  * **要求离散数据**: 最大的挑战在于如何合理地将连续的神经数据（如CSP特征或HbO浓度）离散化。离散化的方式（如分箱数量和边界）会直接影响最终的计算结果。

## pidpy

与 `dit` 不同，`pidpy` 是一个更专注于 PID 计算本身的工具包。它提供了一个相对简洁的接口，并且尝试解决连续数据的问题。

#### `pidpy` 的核心特点：

* **专注于 PID**: `pidpy` 的主要目标就是实现和方便用户使用部分信息分解。
* **支持高斯数据**: `pidpy` 的一个显著优势是它可以直接处理服从高斯分布的连续变量。它提供了专门针对高斯模型的 PID 计算方法，这避免了离散化过程中可能带来的信息损失和主观性。这对于通常可以近似为高斯分布的神经科学特征数据非常有用。
* **简洁的 API**: 其应用程序接口（API）设计得非常直观，用户只需要提供数据矩阵即可开始计算。
* **实现了特定的 PID 定义**: `pidpy` 主要实现了基于特定理论框架的 PID 度量，例如 `PID_dep` (基于依赖分解的度量)。

#### 如何使用 `pidpy` 进行 PID 分析

假设我们有三个连续的变量（特征），存储在 `numpy` 数组中。

**第一步：准备数据**

你需要将你的数据整理成一个 `(n_samples, n_variables)` 形状的 `numpy` 数组。每一列代表一个变量，每一行代表一次观测。

```python
import numpy as np
from pidpy.pid import PID

# 假设你有 n 个样本
# 第0列: Y (任务标签, 也需要是数值)
# 第1列: X1 (连续的EEG特征)
# 第2列: X2 (连续的fNIRS特征)
# 注意：pidpy通常假设数据是高斯的
# 这里我们生成一些模拟数据
np.random.seed(0)
X1 = np.random.randn(100)
X2 = X1 + 0.5 * np.random.randn(100)
Y = 0.8 * X1 + 0.2 * X2 + 0.5 * np.random.randn(100)

# 将Y离散化为0和1 (模拟分类任务)
Y_binary = (Y > np.median(Y)).astype(int)

# 将数据合并成一个矩阵
data = np.vstack([Y_binary, X1, X2]).T
```

**第二步：执行 PID 计算**

使用 `pidpy` 的 `PID` 类进行计算。你需要初始化一个 `PID` 对象，并传入你的数据。

```python
# 初始化 PID 计算器
# 'pw' 表示使用 pairwise 方法, 'corr' 表示基于相关性计算
# 对于高斯数据，通常使用协方差矩阵
pid_calculator = PID(data, 'pw', 'corr')

# 定义源变量和目标变量的索引
# 目标: 变量0 (Y)
# 源1: 变量1 (X1)
# 源2: 变量2 (X2)
target = 0
sources = [1, 2]

# 计算 PID
pid_results = pid_calculator.get_pid(sources, target)

print(pid_results)
```

**第三步：解读结果**

`pid_results` 会返回一个元组，包含了四个信息成分：

```
(
    0.12,  # 冗余信息 (Red)
    0.34,  # X1的独特信息 (Unq_1)
    0.05,  # X2的独特信息 (Unq_2)
    0.08   # 协同信息 (Syn)
)
```

#### `pidpy` 的优缺点

* **优点**:
  * **易于使用**: API 简洁明了，上手快。
  * **支持连续高斯数据**: 免去了复杂的离散化步骤，更适合许多实际应用场景。
  * **专注于 PID**: 如果你的目标明确就是做 PID，`pidpy` 提供了直接的解决方案。
* **缺点**:
  * **功能相对单一**: 不像 `dit` 那样是一个通用的信息论工具箱。
  * **PID 定义选择有限**: 主要围绕特定的 PID 理论实现，不如 `dit` 灵活。
  * **高斯假设**: 其对连续数据的处理基于高斯假设，如果你的数据分布严重偏离高斯分布，结果的准确性可能会受影响。

---

### pidpy使用怎样的输入

不能直接使用原始的 `(n_channels * n_timepoints)` 信号作为输入。** 这样做在统计上是不可行且无意义的。

直接将一个 `(64 channels * 500 timepoints)` 的矩阵作为一个“变量”输入到PID工具中，会遇到致命的“**维度灾难 (Curse of Dimensionality)**”。

#### 核心原因

信息论（包括互信息和PID）的计算是基于**概率分布**的。为了计算两个变量 `X` 和 `Y` 之间的互信息 `I(X; Y)`，您需要能够可靠地估计它们的联合概率分布 `p(x, y)` 和边缘概率分布 `p(x)`、`p(y)`。

1. **维数过高**: 一个 `(64, 500)` 的矩阵代表了一个在 **32,000维空间**中的一个数据点。您的整个实验可能只有几百次试验（trials）。用几百个样本去估计一个32,000维空间的概率分布是完全不可能的。这个空间极其稀疏，几乎每个试验样本都会落在空间中一个独一无二的位置，你无法从中归纳出任何有意义的概率模式。

2. **缺乏可重复性**: 由于空间的稀疏性，你无法找到足够多的相同或相似的“信号形态”来计算其出现的概率。计算出的互信息值会极不稳定，并且很可能接近于零或者完全是噪声，没有任何统计意义。

#### 正确的做法：特征提取 (Feature Extraction)

正确的流程是将高维的原始信号**降维**，提取出能够代表原始信号关键信息的**低维特征向量**。对于每一个试验样本（trial），原始的 `(n_channels, n_timepoints)` 矩阵都应该被转换成一个固定长度的、低维度的特征向量。

**针对您的运动想象任务：**

* **EEG 特征提取**:
  * **共空间模式 (CSP)**: 这是运动想象BCI中最经典、最有效的方法。CSP通过寻找一组空间滤波器，使得滤波后信号的方差在两类任务（左手/右手）之间差异最大化。通常你会选择2-3对（即4-6个）滤波器。对每个滤波后的信号计算其对数方差，最终每个试验样本就从 `(n_channels, n_timepoints)` 的矩阵变成了 **一个长度为4或6的特征向量**。
  * **频带功率 (Band Power)**: 计算特定电极（如C3, C4, Cz）上，特定频带（如μ节律: 8-12Hz, β节律: 13-30Hz）的功率。每个试验样本的特征可以是 `[C3的μ功率, C4的μ功率, C3的β功率, C4的β功率]`，这也是一个低维向量。

* **fNIRS 特征提取**:
  * **信号统计特征**: 在任务时间窗口内，计算感兴趣通道（Channels of Interest, 位于运动皮层区域）的**平均值、峰值、斜率**等。例如，提取左侧和右侧运动皮层上HbO浓度的平均变化，每个试验样本的fNIRS特征就变成了 **一个长度为2的特征向量 `[左侧皮层HbO均值, 右侧皮层HbO均值]`**。

**最终输入到 `pidpy` 的数据结构应该是这样的：**

假设你做了 `N` 次试验，提取了4个EEG特征和2个fNIRS特征。你的输入数据 `data` 应该是一个 `(N, 7)` 的 `numpy` 数组：

`data = [ [Y_1, EEG_feat1_1, EEG_feat2_1, ..., fNIRS_feat1_1, ...],  # Trial 1`
         `[Y_2, EEG_feat1_2, EEG_feat2_2, ..., fNIRS_feat1_2, ...],  # Trial 2`
         `...`
         `[Y_N, EEG_feat1_N, EEG_feat2_N, ..., fNIRS_feat1_N, ...] ] # Trial N`

其中：

* 第0列是任务标签 `Y` (0或1)。
* 后面几列是EEG的特征。
* 最后几列是fNIRS的特征。

然后你可以告诉 `pidpy`，目标是第0列，源1是EEG特征所在的列，源2是fNIRS特征所在的列。

### pid输出结果的含义

`pidpy` 包本身无法告诉您分解后信号的“具体意义”。** 它是一个纯粹的数学工具，负责量化信息，而“意义”的解释则需要研究者结合神经科学知识来完成。

* **它能做什么**: `pidpy` 接收你输入的特征矩阵，并根据其内部的数学定义（例如基于高斯模型的协方差）计算出四个数值（单位是比特）：`Red`, `Unq_EEG`, `Unq_fNIRS`, `Syn`。这些数值告诉你，在你所提供的**特征**层面，信息是如何分布的。

* **它不能做什么**: 它不能“反向工程”回到你的原始信号，然后告诉你“哦，冗余信息是EEG信号在10Hz的这个成分和fNIRS信号的这个血氧波峰”，或者“协同信息是当C3电极的信号出现ERD并且M1区域的血氧浓度快速上升时产生的那部分信息”。

#### 那么，如何解释结果的“意义”？

**解释的责任在于研究者**，你需要将PID的定量结果与你对特征和神经科学的理解结合起来。这是一个推断和假设的过程：

1. **检查你的特征**: 你必须非常清楚你喂给PID工具的特征是什么。解释的起点永远是**特征的物理或生理意义**。

2. **解释冗余信息 (Red)**: 如果`Red`值很高，这表明你提取的EEG特征和fNIRS特征在很大程度上是相互关联的，并且它们以相似的方式与任务相关联。
    * **可能的解释**: 这反映了**紧密的神经血管耦合**。例如，你使用的EEG特征（如μ节律功率下降）和fNIRS特征（如HbO浓度上升）都源自于运动皮层同一个区域的神经活动。一个强的神经活动同时引起了显著的电信号变化和血流变化。

3. **解释独特信息 (Unq)**:
    * **高 `Unq_EEG`**: 这意味着EEG特征包含了fNIRS特征所没有的、对分类任务有用的信息。
        * **可能的解释**: 可能是**时间信息**。EEG的时间分辨率极高，能够捕捉到运动想象开始时非常快速的神经振荡变化（ERD的精确起始点），而fNIRS的血流动力学响应有几秒的延迟，无法提供这种精确的时间信息。
    * **高 `Unq_fNIRS`**: 这意味着fNIRS特征包含了EEG特征所没有的信息。
        * **可能的解释**: 可能是**空间信息或稳定性**。fNIRS可能有更高的空间分辨率来区分两个相邻但功能不同的激活区域，而EEG的空间定位则比较模糊。或者，在长时间的任务中，血流响应可能是一个比EEG节律变化更稳定的特征。

4. **解释协同信息 (Syn)**: 这是最有趣的部分。如果`Syn`值很高，意味着EEG和fNIRS的**结合**创造了新的信息，这种信息在任何单一模态中都不存在。
    * **可能的解释**: 这可能代表了**神经血管耦合的非线性关系**本身就是一种特征。例如，单独看EEG，一个中等强度的ERD可能无法区分左右手；单独看fNIRS，一个中等强度的血氧响应也无法区分。但是，当“中等强度的ERD”和“快速但幅度不大的血氧响应”**同时出现**时，这个组合就非常明确地指向了“左手”任务。这种“if-then”的逻辑关系就是协同信息。它描述了两种信号动态相互作用的模式。
